{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "### Change tag to jobnames\n",
    "tag = 'all-feat-maxscale'\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y-%m-%d-%H-%M-%S-%f\")[:-4]\n",
    "job_name = f'{tag}-{timestamp}'\n",
    "\n",
    "prefix='dengai'\n",
    "raw_prefix = f'{prefix}/raw_data'\n",
    "pprocess_prefix = f'{prefix}/{job_name}/pprocess_data'\n",
    "model_prefix = f'{prefix}/{job_name}/models'\n",
    "batch_transform_prefix = f'{prefix}/{job_name}/batch-transform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘./data/input/dengue_features_train.csv’ already there; not retrieving.\n",
      "\n",
      "File ‘./data/input/dengue_labels_train.csv’ already there; not retrieving.\n",
      "\n",
      "File ‘./data/input/dengue_features_test.csv’ already there; not retrieving.\n",
      "\n",
      "File ‘./data/input/submission_format.csv’ already there; not retrieving.\n",
      "\n",
      "Uploaded raw files to s3://sagemaker-eu-central-1-964501460451/dengai/raw_data\n"
     ]
    }
   ],
   "source": [
    "if len(sagemaker_session.list_s3_files(bucket, raw_prefix))<5:\n",
    "    ! wget -nc https://s3.amazonaws.com/drivendata-prod/data/44/public/dengue_features_train.csv -P ./data/input\n",
    "    ! wget -nc https://s3.amazonaws.com/drivendata-prod/data/44/public/dengue_labels_train.csv -P ./data/input\n",
    "    ! wget -nc https://s3.amazonaws.com/drivendata-prod/data/44/public/dengue_features_test.csv -P ./data/input\n",
    "    ! wget -nc https://s3.amazonaws.com/drivendata-prod/data/44/public/submission_format.csv -P ./data/input  \n",
    "    s3_uri = sagemaker_session.upload_data('./data/input', bucket, raw_prefix)\n",
    "    print(f'Uploaded raw files to {s3_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  all-feat-maxscale-2020-04-09-16-57-06-70-preprocessing\n",
      "Inputs:  [{'InputName': 'input_data', 'S3Input': {'S3Uri': 's3://sagemaker-eu-central-1-964501460451/dengai/raw_data', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-eu-central-1-964501460451/all-feat-maxscale-2020-04-09-16-57-06-70-preprocessing/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'output_data', 'S3Output': {'S3Uri': 's3://sagemaker-eu-central-1-964501460451/dengai/all-feat-maxscale-2020-04-09-16-57-06-70/pprocess_data', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "........................\n",
      "\u001b[34mReceived arguments Namespace()\u001b[0m\n",
      "\u001b[34mReading input data from /opt/ml/processing/input/dengue_features_train.csv\u001b[0m\n",
      "\u001b[34mReading input data from /opt/ml/processing/input/dengue_labels_train.csv\u001b[0m\n",
      "\u001b[34mReading input data from /opt/ml/processing/input/dengue_features_test.csv\u001b[0m\n",
      "\u001b[34mRunning preprocessing and feature engineering transformations\u001b[0m\n",
      "\u001b[34mJSON created for iq: (520,) / (20, 520)\u001b[0m\n",
      "\u001b[34mJSON created for iq: (520,) / (20, 1040)\u001b[0m\n",
      "\u001b[34mJSON created for sj: (936,) / (20, 936)\u001b[0m\n",
      "\u001b[34mJSON created for sj: (936,) / (20, 1872)\u001b[0m\n",
      "\u001b[34mWrote 210031 chars to /opt/ml/processing/output/train_pp.json\u001b[0m\n",
      "\u001b[34mWrote 371003 chars to /opt/ml/processing/output/train_pp.json\u001b[0m\n",
      "\u001b[34m/opt/ml/processing/output/train_pp.json saved\u001b[0m\n",
      "\u001b[34mWrote 738342 chars to /opt/ml/processing/output/test_pp_sj.json\u001b[0m\n",
      "\u001b[34m/opt/ml/processing/output/test_pp_sj.json saved\u001b[0m\n",
      "\u001b[34mWrote 418273 chars to /opt/ml/processing/output/test_pp_iq.json\u001b[0m\n",
      "\u001b[34m/opt/ml/processing/output/test_pp_iq.json saved\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor = ScriptProcessor(image_uri='964501460451.dkr.ecr.eu-central-1.amazonaws.com/sagemaker-containers:updated-sklearn_0.22.0-cpu-py3',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m4.xlarge',\n",
    "                                     instance_count=1,\n",
    "                                     command = [\"python3\"], # default required using the same as in SKLearnProcessor\n",
    "                                     volume_size_in_gb=30, # default required using the same as in SKLearnProcessor\n",
    "                                    )\n",
    "\n",
    "sklearn_processor.run(code='preprocessing.py',\n",
    "                      job_name=f'{job_name}-preprocessing',\n",
    "                      inputs=[\n",
    "                          ProcessingInput(\n",
    "                              source=f's3://{bucket}/{raw_prefix}',\n",
    "                              input_name='input_data',\n",
    "                              destination='/opt/ml/processing/input')\n",
    "                      ],\n",
    "                      outputs=[\n",
    "                          ProcessingOutput(\n",
    "                              source='/opt/ml/processing/output',\n",
    "                              output_name='output_data',\n",
    "                              destination=f's3://{bucket}/{pprocess_prefix}')                \n",
    "                      ]\n",
    "                     )\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "output_config = preprocessing_job_description['ProcessingOutputConfig']\n",
    "\n",
    "for output in output_config['Outputs']:\n",
    "    if output['OutputName'] == 'output_data':\n",
    "        preprocessed_data = output['S3Output']['S3Uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = f'{preprocessed_data}/train_pp.json'\n",
    "test_path_sj = f'{preprocessed_data}/test_pp_sj.json'\n",
    "test_path_iq = f'{preprocessed_data}/test_pp_iq.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.estimator import Estimator\n",
    "import csv\n",
    "\n",
    "def fit_model(train_path, base_job_name, prediction_length, context_length):\n",
    "    image_name = get_image_uri(boto3.Session().region_name, 'forecasting-deepar') \n",
    "    s3_output_path_model = f's3://{bucket}/{model_prefix}'\n",
    "    \n",
    "    estimator = Estimator(sagemaker_session=sagemaker_session,\n",
    "                            image_name=image_name,\n",
    "                            role=role,\n",
    "                            train_instance_count=1,\n",
    "                            train_instance_type='ml.c4.xlarge',\n",
    "                            output_path=s3_output_path_model,\n",
    "                            base_job_name=base_job_name)\n",
    "    \n",
    "    hyperparameters_base = {\n",
    "        \"epochs\": \"100\",\n",
    "        \"time_freq\": 'W',\n",
    "        \"num_cells\": \"40\",\n",
    "        \"num_layers\": \"2\",\n",
    "        \"mini_batch_size\": \"128\",\n",
    "        \"learning_rate\": \"0.003\",\n",
    "        \"early_stopping_patience\": \"10\",\n",
    "        'prediction_length': prediction_length,\n",
    "        'context_length': context_length}\n",
    "    \n",
    "    job_dict = {'jobname': job_name}\n",
    "    job_dict.update(hyperparameters_base)\n",
    "    with open('./models.hyperparameters.csv', 'a+', newline='') as f:\n",
    "        w = csv.DictWriter(f, fieldnames=job_dict.keys())\n",
    "        if not f.readline():\n",
    "            w.writeheader()\n",
    "        w.writerow(job_dict)\n",
    "    \n",
    "    data_channels = {\"train\": train_path}\n",
    "    estimator.set_hyperparameters(**hyperparameters_base)\n",
    "    estimator.fit(inputs=data_channels)\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-09 17:01:20 Starting - Starting the training job...\n",
      "2020-04-09 17:01:21 Starting - Launching requested ML instances...\n",
      "2020-04-09 17:02:17 Starting - Preparing the instances for training......\n",
      "2020-04-09 17:02:59 Downloading - Downloading input data\n",
      "2020-04-09 17:02:59 Training - Downloading the training image....\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:56 INFO 140029870053184] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:56 INFO 140029870053184] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.003', u'num_cells': u'40', u'prediction_length': u'260', u'epochs': u'100', u'time_freq': u'W', u'context_length': u'260', u'num_layers': u'2', u'mini_batch_size': u'128', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:56 INFO 140029870053184] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'0.003', u'num_layers': u'2', u'epochs': u'100', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'128', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'260', u'time_freq': u'W', u'context_length': u'260', u'_kvstore': u'auto', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:56 INFO 140029870053184] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train_pp.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train_pp.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] [cardinality=auto] Inferred value of cardinality=[2] from dataset.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=20 from dataset.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] Training set statistics:\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] Integer time series\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] number of time series: 2\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] number of observations: 1456\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] mean target length: 728\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] min/mean/max target: 0.0/24.6751373626/461.0\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] mean abs(target): 24.6751373626\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] contains missing values: no\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] Small number of time series. Doing 640 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] No test channel found not running evaluations\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] nvidia-smi took: 0.0251920223236 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:57 INFO 140029870053184] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 2188.269853591919, \"sum\": 2188.269853591919, \"min\": 2188.269853591919}}, \"EndTime\": 1586451839.258682, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451837.069437}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:03:59 INFO 140029870053184] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 4485.0499629974365, \"sum\": 4485.0499629974365, \"min\": 4485.0499629974365}}, \"EndTime\": 1586451841.554658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451839.258772}\n",
      "\u001b[0m\n",
      "\n",
      "2020-04-09 17:03:54 Training - Training image download completed. Training in progress.\u001b[34m[04/09/2020 17:04:06 INFO 140029870053184] Epoch[0] Batch[0] avg_epoch_loss=4.859477\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:06 INFO 140029870053184] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=4.85947656631\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:13 INFO 140029870053184] Epoch[0] Batch[5] avg_epoch_loss=4.235110\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:13 INFO 140029870053184] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=4.23511048158\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:13 INFO 140029870053184] Epoch[0] Batch [5]#011Speed: 94.23 samples/sec#011loss=4.235110\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:19 INFO 140029870053184] Epoch[0] Batch[10] avg_epoch_loss=3.929095\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:19 INFO 140029870053184] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.56187553406\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:19 INFO 140029870053184] Epoch[0] Batch [10]#011Speed: 99.46 samples/sec#011loss=3.561876\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:19 INFO 140029870053184] processed a total of 1309 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}, \"update.time\": {\"count\": 1, \"max\": 18390.7368183136, \"sum\": 18390.7368183136, \"min\": 18390.7368183136}}, \"EndTime\": 1586451859.945671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451841.554837}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:19 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=71.1764360447 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:19 INFO 140029870053184] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:19 INFO 140029870053184] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.92909459634\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:19 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:20 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_884c50e6-8f28-43f7-ae61-266ed602a39c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 185.70590019226074, \"sum\": 185.70590019226074, \"min\": 185.70590019226074}}, \"EndTime\": 1586451860.132393, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451859.94581}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:24 INFO 140029870053184] Epoch[1] Batch[0] avg_epoch_loss=3.443825\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:24 INFO 140029870053184] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.44382476807\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:31 INFO 140029870053184] Epoch[1] Batch[5] avg_epoch_loss=3.424528\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:31 INFO 140029870053184] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.42452804248\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:31 INFO 140029870053184] Epoch[1] Batch [5]#011Speed: 98.46 samples/sec#011loss=3.424528\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:37 INFO 140029870053184] Epoch[1] Batch[10] avg_epoch_loss=3.344526\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:37 INFO 140029870053184] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.24852457047\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:37 INFO 140029870053184] Epoch[1] Batch [10]#011Speed: 98.74 samples/sec#011loss=3.248525\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:37 INFO 140029870053184] processed a total of 1295 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17387.916803359985, \"sum\": 17387.916803359985, \"min\": 17387.916803359985}}, \"EndTime\": 1586451877.520451, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451860.132467}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:37 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=74.4764575084 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:37 INFO 140029870053184] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:37 INFO 140029870053184] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.34452646429\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:37 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:37 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_c29ea616-3fa5-4324-8c06-8cbb641ad622-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 187.77704238891602, \"sum\": 187.77704238891602, \"min\": 187.77704238891602}}, \"EndTime\": 1586451877.709036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451877.520539}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:42 INFO 140029870053184] Epoch[2] Batch[0] avg_epoch_loss=3.117449\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:42 INFO 140029870053184] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.1174492836\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:48 INFO 140029870053184] Epoch[2] Batch[5] avg_epoch_loss=3.164798\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:48 INFO 140029870053184] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.1647977829\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:48 INFO 140029870053184] Epoch[2] Batch [5]#011Speed: 99.61 samples/sec#011loss=3.164798\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:53 INFO 140029870053184] processed a total of 1237 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15904.397010803223, \"sum\": 15904.397010803223, \"min\": 15904.397010803223}}, \"EndTime\": 1586451893.613566, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451877.709107}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:53 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=77.776627218 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:53 INFO 140029870053184] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:53 INFO 140029870053184] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.17448546886\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:53 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:53 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_fdfd2fe9-7fe1-4b88-945b-8f1280f40987-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 185.61506271362305, \"sum\": 185.61506271362305, \"min\": 185.61506271362305}}, \"EndTime\": 1586451893.800137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451893.613651}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:58 INFO 140029870053184] Epoch[3] Batch[0] avg_epoch_loss=3.085199\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:04:58 INFO 140029870053184] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.08519864082\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:04 INFO 140029870053184] Epoch[3] Batch[5] avg_epoch_loss=3.063486\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:04 INFO 140029870053184] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.06348598003\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:04 INFO 140029870053184] Epoch[3] Batch [5]#011Speed: 99.23 samples/sec#011loss=3.063486\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:11 INFO 140029870053184] Epoch[3] Batch[10] avg_epoch_loss=3.075353\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:11 INFO 140029870053184] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=3.08959388733\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:11 INFO 140029870053184] Epoch[3] Batch [10]#011Speed: 97.40 samples/sec#011loss=3.089594\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:11 INFO 140029870053184] processed a total of 1347 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17412.65296936035, \"sum\": 17412.65296936035, \"min\": 17412.65296936035}}, \"EndTime\": 1586451911.212928, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451893.800211}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:11 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=77.3570295505 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:11 INFO 140029870053184] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:11 INFO 140029870053184] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.07535321062\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:11 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:11 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_3e3edcd6-2055-41b7-bdab-dd824da81aa6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 183.43186378479004, \"sum\": 183.43186378479004, \"min\": 183.43186378479004}}, \"EndTime\": 1586451911.396969, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451911.213007}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:15 INFO 140029870053184] Epoch[4] Batch[0] avg_epoch_loss=3.156479\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:15 INFO 140029870053184] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.15647888184\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:22 INFO 140029870053184] Epoch[4] Batch[5] avg_epoch_loss=3.039702\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:22 INFO 140029870053184] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.03970233599\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:22 INFO 140029870053184] Epoch[4] Batch [5]#011Speed: 99.31 samples/sec#011loss=3.039702\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:27 INFO 140029870053184] processed a total of 1264 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15927.725076675415, \"sum\": 15927.725076675415, \"min\": 15927.725076675415}}, \"EndTime\": 1586451927.324838, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451911.397048}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:27 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.3579041755 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:27 INFO 140029870053184] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:27 INFO 140029870053184] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.02439959049\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:27 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:27 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_400ce47a-ffb3-448a-a821-539f70308d2e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 175.13108253479004, \"sum\": 175.13108253479004, \"min\": 175.13108253479004}}, \"EndTime\": 1586451927.500818, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451927.324915}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:31 INFO 140029870053184] Epoch[5] Batch[0] avg_epoch_loss=2.909193\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:31 INFO 140029870053184] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=2.90919327736\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:38 INFO 140029870053184] Epoch[5] Batch[5] avg_epoch_loss=2.911256\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:38 INFO 140029870053184] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=2.91125607491\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:38 INFO 140029870053184] Epoch[5] Batch [5]#011Speed: 98.74 samples/sec#011loss=2.911256\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:44 INFO 140029870053184] Epoch[5] Batch[10] avg_epoch_loss=2.940810\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:44 INFO 140029870053184] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=2.9762752533\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:44 INFO 140029870053184] Epoch[5] Batch [10]#011Speed: 99.80 samples/sec#011loss=2.976275\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:44 INFO 140029870053184] processed a total of 1296 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17212.183952331543, \"sum\": 17212.183952331543, \"min\": 17212.183952331543}}, \"EndTime\": 1586451944.713128, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451927.500889}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:44 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.2950099927 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:44 INFO 140029870053184] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:44 INFO 140029870053184] #quality_metric: host=algo-1, epoch=5, train loss <loss>=2.9408102469\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:44 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:44 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_072045b2-cba1-4f28-8403-3c0a0abe706a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 195.03283500671387, \"sum\": 195.03283500671387, \"min\": 195.03283500671387}}, \"EndTime\": 1586451944.909039, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451944.713206}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:49 INFO 140029870053184] Epoch[6] Batch[0] avg_epoch_loss=2.832420\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:49 INFO 140029870053184] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=2.83241987228\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:55 INFO 140029870053184] Epoch[6] Batch[5] avg_epoch_loss=2.890117\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:55 INFO 140029870053184] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=2.89011708895\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:05:55 INFO 140029870053184] Epoch[6] Batch [5]#011Speed: 99.48 samples/sec#011loss=2.890117\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:00 INFO 140029870053184] processed a total of 1278 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15875.3080368042, \"sum\": 15875.3080368042, \"min\": 15875.3080368042}}, \"EndTime\": 1586451960.784493, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451944.909114}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:00 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=80.5017160483 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:00 INFO 140029870053184] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:00 INFO 140029870053184] #quality_metric: host=algo-1, epoch=6, train loss <loss>=2.89337718487\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:00 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:00 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_490bb7c8-8cbd-4cfb-9c07-ca8b68cb6c03-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 203.8130760192871, \"sum\": 203.8130760192871, \"min\": 203.8130760192871}}, \"EndTime\": 1586451960.989006, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451960.784579}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:05 INFO 140029870053184] Epoch[7] Batch[0] avg_epoch_loss=2.873099\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:05 INFO 140029870053184] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=2.87309861183\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:11 INFO 140029870053184] Epoch[7] Batch[5] avg_epoch_loss=2.907035\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:11 INFO 140029870053184] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=2.90703539054\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:11 INFO 140029870053184] Epoch[7] Batch [5]#011Speed: 98.60 samples/sec#011loss=2.907035\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:16 INFO 140029870053184] processed a total of 1257 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15957.764863967896, \"sum\": 15957.764863967896, \"min\": 15957.764863967896}}, \"EndTime\": 1586451976.9469, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451960.989077}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:16 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=78.769881568 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:16 INFO 140029870053184] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:16 INFO 140029870053184] #quality_metric: host=algo-1, epoch=7, train loss <loss>=2.88520934582\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:16 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:17 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_136c2799-7d2a-4272-8016-6239a4166d85-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 180.61590194702148, \"sum\": 180.61590194702148, \"min\": 180.61590194702148}}, \"EndTime\": 1586451977.128209, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451976.946975}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:21 INFO 140029870053184] Epoch[8] Batch[0] avg_epoch_loss=2.893913\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:21 INFO 140029870053184] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=2.89391279221\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:27 INFO 140029870053184] Epoch[8] Batch[5] avg_epoch_loss=2.866074\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:27 INFO 140029870053184] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=2.86607412497\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:27 INFO 140029870053184] Epoch[8] Batch [5]#011Speed: 99.35 samples/sec#011loss=2.866074\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:34 INFO 140029870053184] Epoch[8] Batch[10] avg_epoch_loss=2.900750\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:34 INFO 140029870053184] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=2.94236092567\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:34 INFO 140029870053184] Epoch[8] Batch [10]#011Speed: 98.13 samples/sec#011loss=2.942361\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:34 INFO 140029870053184] processed a total of 1321 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17335.49404144287, \"sum\": 17335.49404144287, \"min\": 17335.49404144287}}, \"EndTime\": 1586451994.463839, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451977.128282}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:34 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.2015468348 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:34 INFO 140029870053184] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:34 INFO 140029870053184] #quality_metric: host=algo-1, epoch=8, train loss <loss>=2.90074994347\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:34 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:38 INFO 140029870053184] Epoch[9] Batch[0] avg_epoch_loss=3.202755\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:38 INFO 140029870053184] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.2027554512\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:45 INFO 140029870053184] Epoch[9] Batch[5] avg_epoch_loss=3.054125\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:45 INFO 140029870053184] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.05412459373\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:45 INFO 140029870053184] Epoch[9] Batch [5]#011Speed: 99.07 samples/sec#011loss=3.054125\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:51 INFO 140029870053184] Epoch[9] Batch[10] avg_epoch_loss=2.889261\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:51 INFO 140029870053184] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=2.69142518044\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:51 INFO 140029870053184] Epoch[9] Batch [10]#011Speed: 98.39 samples/sec#011loss=2.691425\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:51 INFO 140029870053184] processed a total of 1281 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17399.619102478027, \"sum\": 17399.619102478027, \"min\": 17399.619102478027}}, \"EndTime\": 1586452011.864043, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586451994.463916}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:51 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=73.6217898326 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:51 INFO 140029870053184] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:51 INFO 140029870053184] #quality_metric: host=algo-1, epoch=9, train loss <loss>=2.88926122405\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:51 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:56 INFO 140029870053184] Epoch[10] Batch[0] avg_epoch_loss=2.881826\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:06:56 INFO 140029870053184] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=2.88182592392\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:02 INFO 140029870053184] Epoch[10] Batch[5] avg_epoch_loss=2.877362\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:02 INFO 140029870053184] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=2.8773620526\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:02 INFO 140029870053184] Epoch[10] Batch [5]#011Speed: 98.36 samples/sec#011loss=2.877362\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:07 INFO 140029870053184] processed a total of 1268 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15998.2328414917, \"sum\": 15998.2328414917, \"min\": 15998.2328414917}}, \"EndTime\": 1586452027.862908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452011.864125}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:07 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.2580936509 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:07 INFO 140029870053184] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:07 INFO 140029870053184] #quality_metric: host=algo-1, epoch=10, train loss <loss>=2.83928918839\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:07 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:08 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_3c9d8e84-1095-47c7-9700-43ddf0426f2a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 176.20587348937988, \"sum\": 176.20587348937988, \"min\": 176.20587348937988}}, \"EndTime\": 1586452028.039869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452027.862999}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:12 INFO 140029870053184] Epoch[11] Batch[0] avg_epoch_loss=2.844296\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:12 INFO 140029870053184] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=2.84429645538\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:18 INFO 140029870053184] Epoch[11] Batch[5] avg_epoch_loss=2.807873\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:18 INFO 140029870053184] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=2.80787348747\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:18 INFO 140029870053184] Epoch[11] Batch [5]#011Speed: 99.68 samples/sec#011loss=2.807873\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:23 INFO 140029870053184] processed a total of 1228 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15816.920042037964, \"sum\": 15816.920042037964, \"min\": 15816.920042037964}}, \"EndTime\": 1586452043.856922, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452028.03994}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:23 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=77.637788271 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:23 INFO 140029870053184] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:23 INFO 140029870053184] #quality_metric: host=algo-1, epoch=11, train loss <loss>=2.81053881645\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:23 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:24 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_53384db7-b8db-4ec0-9e41-bb4e0bc15c07-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 172.9140281677246, \"sum\": 172.9140281677246, \"min\": 172.9140281677246}}, \"EndTime\": 1586452044.030657, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452043.857}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:28 INFO 140029870053184] Epoch[12] Batch[0] avg_epoch_loss=2.742203\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:28 INFO 140029870053184] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=2.74220275879\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:34 INFO 140029870053184] Epoch[12] Batch[5] avg_epoch_loss=2.822411\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:34 INFO 140029870053184] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.82241070271\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:34 INFO 140029870053184] Epoch[12] Batch [5]#011Speed: 100.01 samples/sec#011loss=2.822411\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:41 INFO 140029870053184] Epoch[12] Batch[10] avg_epoch_loss=2.743144\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:41 INFO 140029870053184] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=2.64802322388\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:41 INFO 140029870053184] Epoch[12] Batch [10]#011Speed: 98.45 samples/sec#011loss=2.648023\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:41 INFO 140029870053184] processed a total of 1300 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17232.715129852295, \"sum\": 17232.715129852295, \"min\": 17232.715129852295}}, \"EndTime\": 1586452061.2635, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452044.03073}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:41 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.4374103587 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:41 INFO 140029870053184] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:41 INFO 140029870053184] #quality_metric: host=algo-1, epoch=12, train loss <loss>=2.74314366687\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:41 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:41 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_76902e67-d916-4fdf-8e4a-0844d9fb90c5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 181.6389560699463, \"sum\": 181.6389560699463, \"min\": 181.6389560699463}}, \"EndTime\": 1586452061.445825, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452061.26358}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:45 INFO 140029870053184] Epoch[13] Batch[0] avg_epoch_loss=2.780538\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:45 INFO 140029870053184] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=2.78053808212\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:52 INFO 140029870053184] Epoch[13] Batch[5] avg_epoch_loss=2.768623\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:52 INFO 140029870053184] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=2.76862295469\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:52 INFO 140029870053184] Epoch[13] Batch [5]#011Speed: 98.90 samples/sec#011loss=2.768623\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:58 INFO 140029870053184] Epoch[13] Batch[10] avg_epoch_loss=2.790646\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:58 INFO 140029870053184] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=2.81707448959\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:58 INFO 140029870053184] Epoch[13] Batch [10]#011Speed: 99.35 samples/sec#011loss=2.817074\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:58 INFO 140029870053184] processed a total of 1292 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17259.629011154175, \"sum\": 17259.629011154175, \"min\": 17259.629011154175}}, \"EndTime\": 1586452078.705582, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452061.445895}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:58 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=74.8562576999 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:58 INFO 140029870053184] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:58 INFO 140029870053184] #quality_metric: host=algo-1, epoch=13, train loss <loss>=2.79064637964\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:07:58 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:03 INFO 140029870053184] Epoch[14] Batch[0] avg_epoch_loss=2.595768\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:03 INFO 140029870053184] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=2.59576845169\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:09 INFO 140029870053184] Epoch[14] Batch[5] avg_epoch_loss=2.716385\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:09 INFO 140029870053184] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=2.71638508638\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:09 INFO 140029870053184] Epoch[14] Batch [5]#011Speed: 98.51 samples/sec#011loss=2.716385\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:16 INFO 140029870053184] Epoch[14] Batch[10] avg_epoch_loss=2.656118\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:16 INFO 140029870053184] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=2.5837978363\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:16 INFO 140029870053184] Epoch[14] Batch [10]#011Speed: 98.78 samples/sec#011loss=2.583798\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:16 INFO 140029870053184] processed a total of 1300 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17298.271894454956, \"sum\": 17298.271894454956, \"min\": 17298.271894454956}}, \"EndTime\": 1586452096.00443, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452078.70566}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:16 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.151451133 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:16 INFO 140029870053184] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:16 INFO 140029870053184] #quality_metric: host=algo-1, epoch=14, train loss <loss>=2.65611815453\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:16 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:16 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_6142f0f6-fdae-4509-8361-b20d1de0939f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 182.0049285888672, \"sum\": 182.0049285888672, \"min\": 182.0049285888672}}, \"EndTime\": 1586452096.187106, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452096.004519}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:20 INFO 140029870053184] Epoch[15] Batch[0] avg_epoch_loss=2.750787\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:20 INFO 140029870053184] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=2.75078678131\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:26 INFO 140029870053184] Epoch[15] Batch[5] avg_epoch_loss=2.707901\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:26 INFO 140029870053184] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=2.70790100098\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:26 INFO 140029870053184] Epoch[15] Batch [5]#011Speed: 100.45 samples/sec#011loss=2.707901\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:33 INFO 140029870053184] Epoch[15] Batch[10] avg_epoch_loss=2.734377\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:33 INFO 140029870053184] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=2.76614899635\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:33 INFO 140029870053184] Epoch[15] Batch [10]#011Speed: 99.95 samples/sec#011loss=2.766149\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:33 INFO 140029870053184] processed a total of 1286 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17073.861837387085, \"sum\": 17073.861837387085, \"min\": 17073.861837387085}}, \"EndTime\": 1586452113.261118, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452096.187185}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:33 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.3191772168 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:33 INFO 140029870053184] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:33 INFO 140029870053184] #quality_metric: host=algo-1, epoch=15, train loss <loss>=2.73437736251\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:33 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:37 INFO 140029870053184] Epoch[16] Batch[0] avg_epoch_loss=2.653160\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:37 INFO 140029870053184] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=2.65315961838\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:43 INFO 140029870053184] Epoch[16] Batch[5] avg_epoch_loss=2.688102\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:43 INFO 140029870053184] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=2.68810212612\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:43 INFO 140029870053184] Epoch[16] Batch [5]#011Speed: 100.50 samples/sec#011loss=2.688102\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:49 INFO 140029870053184] processed a total of 1274 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15798.742055892944, \"sum\": 15798.742055892944, \"min\": 15798.742055892944}}, \"EndTime\": 1586452129.060483, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452113.26122}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:49 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=80.6387341244 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:49 INFO 140029870053184] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:49 INFO 140029870053184] #quality_metric: host=algo-1, epoch=16, train loss <loss>=2.68777742386\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:49 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:53 INFO 140029870053184] Epoch[17] Batch[0] avg_epoch_loss=2.687061\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:53 INFO 140029870053184] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=2.6870610714\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:59 INFO 140029870053184] Epoch[17] Batch[5] avg_epoch_loss=2.675970\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:59 INFO 140029870053184] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=2.6759695212\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:08:59 INFO 140029870053184] Epoch[17] Batch [5]#011Speed: 99.51 samples/sec#011loss=2.675970\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:06 INFO 140029870053184] Epoch[17] Batch[10] avg_epoch_loss=2.664607\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:06 INFO 140029870053184] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=2.65097241402\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:06 INFO 140029870053184] Epoch[17] Batch [10]#011Speed: 98.83 samples/sec#011loss=2.650972\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:06 INFO 140029870053184] processed a total of 1320 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17262.91513442993, \"sum\": 17262.91513442993, \"min\": 17262.91513442993}}, \"EndTime\": 1586452146.324044, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452129.060562}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:06 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.4640210187 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:06 INFO 140029870053184] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:06 INFO 140029870053184] #quality_metric: host=algo-1, epoch=17, train loss <loss>=2.66460719976\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:06 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:10 INFO 140029870053184] Epoch[18] Batch[0] avg_epoch_loss=2.761709\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:10 INFO 140029870053184] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=2.76170873642\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:17 INFO 140029870053184] Epoch[18] Batch[5] avg_epoch_loss=2.727832\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:17 INFO 140029870053184] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=2.72783235709\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:17 INFO 140029870053184] Epoch[18] Batch [5]#011Speed: 100.38 samples/sec#011loss=2.727832\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:22 INFO 140029870053184] processed a total of 1258 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15869.312047958374, \"sum\": 15869.312047958374, \"min\": 15869.312047958374}}, \"EndTime\": 1586452162.193862, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452146.324115}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:22 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.2719282377 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:22 INFO 140029870053184] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:22 INFO 140029870053184] #quality_metric: host=algo-1, epoch=18, train loss <loss>=2.71443383694\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:22 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:26 INFO 140029870053184] Epoch[19] Batch[0] avg_epoch_loss=2.679684\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:26 INFO 140029870053184] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=2.67968440056\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:32 INFO 140029870053184] Epoch[19] Batch[5] avg_epoch_loss=2.701201\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:32 INFO 140029870053184] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=2.70120112101\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:32 INFO 140029870053184] Epoch[19] Batch [5]#011Speed: 99.72 samples/sec#011loss=2.701201\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:38 INFO 140029870053184] processed a total of 1267 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15922.632932662964, \"sum\": 15922.632932662964, \"min\": 15922.632932662964}}, \"EndTime\": 1586452178.117177, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452162.193935}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:38 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.5711828265 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:38 INFO 140029870053184] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:38 INFO 140029870053184] #quality_metric: host=algo-1, epoch=19, train loss <loss>=2.69228773117\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:38 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:42 INFO 140029870053184] Epoch[20] Batch[0] avg_epoch_loss=2.588921\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:42 INFO 140029870053184] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=2.58892130852\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:48 INFO 140029870053184] Epoch[20] Batch[5] avg_epoch_loss=2.671324\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:48 INFO 140029870053184] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=2.67132437229\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:48 INFO 140029870053184] Epoch[20] Batch [5]#011Speed: 99.79 samples/sec#011loss=2.671324\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:55 INFO 140029870053184] Epoch[20] Batch[10] avg_epoch_loss=2.595688\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:55 INFO 140029870053184] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=2.50492506027\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:55 INFO 140029870053184] Epoch[20] Batch [10]#011Speed: 99.79 samples/sec#011loss=2.504925\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:55 INFO 140029870053184] processed a total of 1295 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17188.978910446167, \"sum\": 17188.978910446167, \"min\": 17188.978910446167}}, \"EndTime\": 1586452195.306973, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452178.117351}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:55 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.3384766317 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:55 INFO 140029870053184] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:55 INFO 140029870053184] #quality_metric: host=algo-1, epoch=20, train loss <loss>=2.59568832137\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:55 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:55 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_3d37a70f-a1d2-4572-a75e-34b5a878306f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 181.74505233764648, \"sum\": 181.74505233764648, \"min\": 181.74505233764648}}, \"EndTime\": 1586452195.489483, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452195.30705}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:59 INFO 140029870053184] Epoch[21] Batch[0] avg_epoch_loss=2.776822\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:09:59 INFO 140029870053184] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=2.77682161331\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:06 INFO 140029870053184] Epoch[21] Batch[5] avg_epoch_loss=2.688055\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:06 INFO 140029870053184] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=2.68805472056\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:06 INFO 140029870053184] Epoch[21] Batch [5]#011Speed: 99.19 samples/sec#011loss=2.688055\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:12 INFO 140029870053184] Epoch[21] Batch[10] avg_epoch_loss=2.714704\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:12 INFO 140029870053184] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=2.74668397903\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:12 INFO 140029870053184] Epoch[21] Batch [10]#011Speed: 98.54 samples/sec#011loss=2.746684\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:12 INFO 140029870053184] processed a total of 1327 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17318.772077560425, \"sum\": 17318.772077560425, \"min\": 17318.772077560425}}, \"EndTime\": 1586452212.808401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452195.489564}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:12 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.6215477523 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:12 INFO 140029870053184] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:12 INFO 140029870053184] #quality_metric: host=algo-1, epoch=21, train loss <loss>=2.7147043835\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:12 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:17 INFO 140029870053184] Epoch[22] Batch[0] avg_epoch_loss=2.777568\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:17 INFO 140029870053184] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=2.77756786346\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:23 INFO 140029870053184] Epoch[22] Batch[5] avg_epoch_loss=2.705380\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:23 INFO 140029870053184] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=2.7053797245\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:23 INFO 140029870053184] Epoch[22] Batch [5]#011Speed: 99.12 samples/sec#011loss=2.705380\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:28 INFO 140029870053184] processed a total of 1265 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16012.06088066101, \"sum\": 16012.06088066101, \"min\": 16012.06088066101}}, \"EndTime\": 1586452228.820941, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452212.80848}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:28 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.0023990053 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:28 INFO 140029870053184] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:28 INFO 140029870053184] #quality_metric: host=algo-1, epoch=22, train loss <loss>=2.70085785389\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:28 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:33 INFO 140029870053184] Epoch[23] Batch[0] avg_epoch_loss=2.633763\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:33 INFO 140029870053184] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=2.63376259804\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:39 INFO 140029870053184] Epoch[23] Batch[5] avg_epoch_loss=2.667665\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:39 INFO 140029870053184] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=2.66766536236\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:39 INFO 140029870053184] Epoch[23] Batch [5]#011Speed: 97.79 samples/sec#011loss=2.667665\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:46 INFO 140029870053184] Epoch[23] Batch[10] avg_epoch_loss=2.659792\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:46 INFO 140029870053184] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=2.65034389496\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:46 INFO 140029870053184] Epoch[23] Batch [10]#011Speed: 99.03 samples/sec#011loss=2.650344\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:46 INFO 140029870053184] processed a total of 1332 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17410.192012786865, \"sum\": 17410.192012786865, \"min\": 17410.192012786865}}, \"EndTime\": 1586452246.231812, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452228.821015}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:46 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.506287002 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:46 INFO 140029870053184] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:46 INFO 140029870053184] #quality_metric: host=algo-1, epoch=23, train loss <loss>=2.65979196809\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:46 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:50 INFO 140029870053184] Epoch[24] Batch[0] avg_epoch_loss=2.658489\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:50 INFO 140029870053184] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.65848922729\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:57 INFO 140029870053184] Epoch[24] Batch[5] avg_epoch_loss=2.620205\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:57 INFO 140029870053184] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.62020464738\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:10:57 INFO 140029870053184] Epoch[24] Batch [5]#011Speed: 99.50 samples/sec#011loss=2.620205\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:03 INFO 140029870053184] Epoch[24] Batch[10] avg_epoch_loss=2.655237\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:03 INFO 140029870053184] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=2.69727597237\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:03 INFO 140029870053184] Epoch[24] Batch [10]#011Speed: 99.64 samples/sec#011loss=2.697276\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:03 INFO 140029870053184] processed a total of 1340 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17207.791805267334, \"sum\": 17207.791805267334, \"min\": 17207.791805267334}}, \"EndTime\": 1586452263.440223, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452246.231914}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:03 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=77.8711734189 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:03 INFO 140029870053184] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:03 INFO 140029870053184] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.65523706783\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:03 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:07 INFO 140029870053184] Epoch[25] Batch[0] avg_epoch_loss=2.613195\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:07 INFO 140029870053184] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=2.61319470406\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:14 INFO 140029870053184] Epoch[25] Batch[5] avg_epoch_loss=2.570123\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:14 INFO 140029870053184] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=2.57012275855\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:14 INFO 140029870053184] Epoch[25] Batch [5]#011Speed: 98.71 samples/sec#011loss=2.570123\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:19 INFO 140029870053184] processed a total of 1242 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15953.790187835693, \"sum\": 15953.790187835693, \"min\": 15953.790187835693}}, \"EndTime\": 1586452279.394497, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452263.440303}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:19 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=77.8491515817 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:19 INFO 140029870053184] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:19 INFO 140029870053184] #quality_metric: host=algo-1, epoch=25, train loss <loss>=2.56832048893\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:19 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:19 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_f8568ea6-2ae2-45cd-8931-105237a2845a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 187.4229907989502, \"sum\": 187.4229907989502, \"min\": 187.4229907989502}}, \"EndTime\": 1586452279.582511, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452279.394602}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:23 INFO 140029870053184] Epoch[26] Batch[0] avg_epoch_loss=2.557119\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:23 INFO 140029870053184] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=2.55711936951\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:30 INFO 140029870053184] Epoch[26] Batch[5] avg_epoch_loss=2.551125\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:30 INFO 140029870053184] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.55112493038\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:30 INFO 140029870053184] Epoch[26] Batch [5]#011Speed: 98.86 samples/sec#011loss=2.551125\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:35 INFO 140029870053184] processed a total of 1276 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15910.94994544983, \"sum\": 15910.94994544983, \"min\": 15910.94994544983}}, \"EndTime\": 1586452295.493599, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452279.582585}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:35 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=80.1957830537 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:35 INFO 140029870053184] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:35 INFO 140029870053184] #quality_metric: host=algo-1, epoch=26, train loss <loss>=2.56603813171\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:35 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:35 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_f29603bc-1a07-49fd-90ef-262e5b1e0512-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 186.49005889892578, \"sum\": 186.49005889892578, \"min\": 186.49005889892578}}, \"EndTime\": 1586452295.680674, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452295.493673}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:40 INFO 140029870053184] Epoch[27] Batch[0] avg_epoch_loss=2.613459\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:40 INFO 140029870053184] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=2.61345887184\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:46 INFO 140029870053184] Epoch[27] Batch[5] avg_epoch_loss=2.572145\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:46 INFO 140029870053184] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=2.57214530309\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:46 INFO 140029870053184] Epoch[27] Batch [5]#011Speed: 99.51 samples/sec#011loss=2.572145\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:52 INFO 140029870053184] Epoch[27] Batch[10] avg_epoch_loss=2.625913\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:52 INFO 140029870053184] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=2.69043388367\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:52 INFO 140029870053184] Epoch[27] Batch [10]#011Speed: 100.01 samples/sec#011loss=2.690434\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:52 INFO 140029870053184] processed a total of 1289 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17199.692010879517, \"sum\": 17199.692010879517, \"min\": 17199.692010879517}}, \"EndTime\": 1586452312.880508, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452295.680749}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:52 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=74.9427370232 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:52 INFO 140029870053184] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:52 INFO 140029870053184] #quality_metric: host=algo-1, epoch=27, train loss <loss>=2.62591283972\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:52 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:57 INFO 140029870053184] Epoch[28] Batch[0] avg_epoch_loss=2.495638\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:11:57 INFO 140029870053184] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=2.4956381321\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:03 INFO 140029870053184] Epoch[28] Batch[5] avg_epoch_loss=2.558150\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:03 INFO 140029870053184] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=2.55815025171\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:03 INFO 140029870053184] Epoch[28] Batch [5]#011Speed: 99.17 samples/sec#011loss=2.558150\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:10 INFO 140029870053184] Epoch[28] Batch[10] avg_epoch_loss=2.535781\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:10 INFO 140029870053184] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=2.50893688202\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:10 INFO 140029870053184] Epoch[28] Batch [10]#011Speed: 98.30 samples/sec#011loss=2.508937\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:10 INFO 140029870053184] processed a total of 1309 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17295.748949050903, \"sum\": 17295.748949050903, \"min\": 17295.748949050903}}, \"EndTime\": 1586452330.176915, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452312.880574}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:10 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.682776972 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:10 INFO 140029870053184] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:10 INFO 140029870053184] #quality_metric: host=algo-1, epoch=28, train loss <loss>=2.53578053821\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:10 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:10 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_78aed839-b13e-4d1f-bab0-384bf5025299-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 184.74698066711426, \"sum\": 184.74698066711426, \"min\": 184.74698066711426}}, \"EndTime\": 1586452330.362506, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452330.176999}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:14 INFO 140029870053184] Epoch[29] Batch[0] avg_epoch_loss=2.478014\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:14 INFO 140029870053184] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.47801399231\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:21 INFO 140029870053184] Epoch[29] Batch[5] avg_epoch_loss=2.571202\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:21 INFO 140029870053184] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.57120203972\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:21 INFO 140029870053184] Epoch[29] Batch [5]#011Speed: 97.00 samples/sec#011loss=2.571202\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:26 INFO 140029870053184] processed a total of 1262 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16105.437994003296, \"sum\": 16105.437994003296, \"min\": 16105.437994003296}}, \"EndTime\": 1586452346.468135, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452330.362594}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:26 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=78.3580766442 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:26 INFO 140029870053184] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:26 INFO 140029870053184] #quality_metric: host=algo-1, epoch=29, train loss <loss>=2.55702974796\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:26 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:30 INFO 140029870053184] Epoch[30] Batch[0] avg_epoch_loss=2.523344\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:30 INFO 140029870053184] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=2.52334427834\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:37 INFO 140029870053184] Epoch[30] Batch[5] avg_epoch_loss=2.523430\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:37 INFO 140029870053184] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.5234297514\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:37 INFO 140029870053184] Epoch[30] Batch [5]#011Speed: 100.13 samples/sec#011loss=2.523430\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:43 INFO 140029870053184] Epoch[30] Batch[10] avg_epoch_loss=2.587531\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:43 INFO 140029870053184] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=2.66445150375\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:43 INFO 140029870053184] Epoch[30] Batch [10]#011Speed: 99.22 samples/sec#011loss=2.664452\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:43 INFO 140029870053184] processed a total of 1289 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17178.752183914185, \"sum\": 17178.752183914185, \"min\": 17178.752183914185}}, \"EndTime\": 1586452363.647539, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452346.468208}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:43 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.0340651066 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:43 INFO 140029870053184] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:43 INFO 140029870053184] #quality_metric: host=algo-1, epoch=30, train loss <loss>=2.58753054792\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:43 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:48 INFO 140029870053184] Epoch[31] Batch[0] avg_epoch_loss=2.664028\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:48 INFO 140029870053184] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.66402792931\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:54 INFO 140029870053184] Epoch[31] Batch[5] avg_epoch_loss=2.578291\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:54 INFO 140029870053184] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.57829085986\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:12:54 INFO 140029870053184] Epoch[31] Batch [5]#011Speed: 99.59 samples/sec#011loss=2.578291\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:00 INFO 140029870053184] Epoch[31] Batch[10] avg_epoch_loss=2.579569\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:00 INFO 140029870053184] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=2.58110218048\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:00 INFO 140029870053184] Epoch[31] Batch [10]#011Speed: 99.57 samples/sec#011loss=2.581102\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:00 INFO 140029870053184] processed a total of 1321 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17218.19019317627, \"sum\": 17218.19019317627, \"min\": 17218.19019317627}}, \"EndTime\": 1586452380.866357, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452363.647622}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:00 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.7206585563 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:00 INFO 140029870053184] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:00 INFO 140029870053184] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.57956873287\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:00 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:05 INFO 140029870053184] Epoch[32] Batch[0] avg_epoch_loss=2.481739\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:05 INFO 140029870053184] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=2.48173904419\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:11 INFO 140029870053184] Epoch[32] Batch[5] avg_epoch_loss=2.472540\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:11 INFO 140029870053184] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.47254014015\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:11 INFO 140029870053184] Epoch[32] Batch [5]#011Speed: 99.58 samples/sec#011loss=2.472540\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:17 INFO 140029870053184] Epoch[32] Batch[10] avg_epoch_loss=2.505063\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:17 INFO 140029870053184] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=2.54408936501\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:17 INFO 140029870053184] Epoch[32] Batch [10]#011Speed: 100.15 samples/sec#011loss=2.544089\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:17 INFO 140029870053184] processed a total of 1325 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17129.559993743896, \"sum\": 17129.559993743896, \"min\": 17129.559993743896}}, \"EndTime\": 1586452397.996497, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452380.866436}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:17 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=77.3512093183 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:17 INFO 140029870053184] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:17 INFO 140029870053184] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.50506251509\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:17 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:18 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_697e26e2-1671-471b-bf36-50c12c2de721-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 178.541898727417, \"sum\": 178.541898727417, \"min\": 178.541898727417}}, \"EndTime\": 1586452398.17563, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452397.996565}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:22 INFO 140029870053184] Epoch[33] Batch[0] avg_epoch_loss=2.445936\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:22 INFO 140029870053184] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=2.44593644142\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:28 INFO 140029870053184] Epoch[33] Batch[5] avg_epoch_loss=2.469132\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:28 INFO 140029870053184] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.46913178762\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:28 INFO 140029870053184] Epoch[33] Batch [5]#011Speed: 99.71 samples/sec#011loss=2.469132\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:35 INFO 140029870053184] Epoch[33] Batch[10] avg_epoch_loss=2.543970\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:35 INFO 140029870053184] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=2.63377614021\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:35 INFO 140029870053184] Epoch[33] Batch [10]#011Speed: 100.29 samples/sec#011loss=2.633776\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:35 INFO 140029870053184] processed a total of 1300 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17109.39884185791, \"sum\": 17109.39884185791, \"min\": 17109.39884185791}}, \"EndTime\": 1586452415.285176, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452398.175709}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:35 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.9810998833 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:35 INFO 140029870053184] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:35 INFO 140029870053184] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.54397012971\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:35 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:39 INFO 140029870053184] Epoch[34] Batch[0] avg_epoch_loss=2.647036\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:39 INFO 140029870053184] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=2.64703583717\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:46 INFO 140029870053184] Epoch[34] Batch[5] avg_epoch_loss=2.583364\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:46 INFO 140029870053184] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.58336385091\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:46 INFO 140029870053184] Epoch[34] Batch [5]#011Speed: 99.99 samples/sec#011loss=2.583364\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:51 INFO 140029870053184] processed a total of 1275 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15960.58988571167, \"sum\": 15960.58988571167, \"min\": 15960.58988571167}}, \"EndTime\": 1586452431.246329, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452415.285258}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:51 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.8836640796 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:51 INFO 140029870053184] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:51 INFO 140029870053184] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.56482951641\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:51 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:55 INFO 140029870053184] Epoch[35] Batch[0] avg_epoch_loss=2.554139\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:13:55 INFO 140029870053184] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.55413937569\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:02 INFO 140029870053184] Epoch[35] Batch[5] avg_epoch_loss=2.476670\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:02 INFO 140029870053184] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.47666986783\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:02 INFO 140029870053184] Epoch[35] Batch [5]#011Speed: 99.63 samples/sec#011loss=2.476670\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:08 INFO 140029870053184] Epoch[35] Batch[10] avg_epoch_loss=2.522964\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:08 INFO 140029870053184] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=2.57851600647\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:08 INFO 140029870053184] Epoch[35] Batch [10]#011Speed: 99.40 samples/sec#011loss=2.578516\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:08 INFO 140029870053184] processed a total of 1293 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17256.747007369995, \"sum\": 17256.747007369995, \"min\": 17256.747007369995}}, \"EndTime\": 1586452448.503612, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452431.24641}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:08 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=74.9267423132 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:08 INFO 140029870053184] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:08 INFO 140029870053184] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.52296356721\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:08 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:12 INFO 140029870053184] Epoch[36] Batch[0] avg_epoch_loss=2.632622\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:12 INFO 140029870053184] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.63262224197\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:19 INFO 140029870053184] Epoch[36] Batch[5] avg_epoch_loss=2.528299\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:19 INFO 140029870053184] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.52829861641\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:19 INFO 140029870053184] Epoch[36] Batch [5]#011Speed: 99.08 samples/sec#011loss=2.528299\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:25 INFO 140029870053184] Epoch[36] Batch[10] avg_epoch_loss=2.526810\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:25 INFO 140029870053184] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=2.52502326965\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:25 INFO 140029870053184] Epoch[36] Batch [10]#011Speed: 99.26 samples/sec#011loss=2.525023\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:25 INFO 140029870053184] processed a total of 1336 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17361.14001274109, \"sum\": 17361.14001274109, \"min\": 17361.14001274109}}, \"EndTime\": 1586452465.86523, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452448.503689}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:25 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.9528959449 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:25 INFO 140029870053184] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:25 INFO 140029870053184] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.52680982243\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:25 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:30 INFO 140029870053184] Epoch[37] Batch[0] avg_epoch_loss=2.404639\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:30 INFO 140029870053184] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.40463852882\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:36 INFO 140029870053184] Epoch[37] Batch[5] avg_epoch_loss=2.456276\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:36 INFO 140029870053184] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.45627558231\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:36 INFO 140029870053184] Epoch[37] Batch [5]#011Speed: 98.34 samples/sec#011loss=2.456276\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:41 INFO 140029870053184] processed a total of 1237 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16073.904991149902, \"sum\": 16073.904991149902, \"min\": 16073.904991149902}}, \"EndTime\": 1586452481.93981, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452465.865308}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:41 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.9564759543 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:41 INFO 140029870053184] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:41 INFO 140029870053184] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.47568557262\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:41 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:42 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_ab0c4e99-62fb-4aaf-b070-4e4e885e2c16-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 199.31697845458984, \"sum\": 199.31697845458984, \"min\": 199.31697845458984}}, \"EndTime\": 1586452482.139691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452481.939888}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:46 INFO 140029870053184] Epoch[38] Batch[0] avg_epoch_loss=2.432793\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:46 INFO 140029870053184] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.43279314041\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:52 INFO 140029870053184] Epoch[38] Batch[5] avg_epoch_loss=2.429843\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:52 INFO 140029870053184] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.42984318733\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:52 INFO 140029870053184] Epoch[38] Batch [5]#011Speed: 99.71 samples/sec#011loss=2.429843\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:58 INFO 140029870053184] processed a total of 1232 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15880.923986434937, \"sum\": 15880.923986434937, \"min\": 15880.923986434937}}, \"EndTime\": 1586452498.020982, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452482.139998}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:58 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=77.576842311 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:58 INFO 140029870053184] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:58 INFO 140029870053184] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.39760904312\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:58 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:14:58 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_eb6a38b4-65da-4062-b43d-b52ad12b2c98-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 180.5858612060547, \"sum\": 180.5858612060547, \"min\": 180.5858612060547}}, \"EndTime\": 1586452498.202254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452498.021054}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:02 INFO 140029870053184] Epoch[39] Batch[0] avg_epoch_loss=2.531146\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:02 INFO 140029870053184] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.53114581108\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:08 INFO 140029870053184] Epoch[39] Batch[5] avg_epoch_loss=2.510450\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:08 INFO 140029870053184] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.51045012474\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:08 INFO 140029870053184] Epoch[39] Batch [5]#011Speed: 100.02 samples/sec#011loss=2.510450\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:14 INFO 140029870053184] processed a total of 1272 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15979.485034942627, \"sum\": 15979.485034942627, \"min\": 15979.485034942627}}, \"EndTime\": 1586452514.181868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452498.202323}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:14 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.6014612584 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:14 INFO 140029870053184] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:14 INFO 140029870053184] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.46295852661\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:14 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:18 INFO 140029870053184] Epoch[40] Batch[0] avg_epoch_loss=2.386287\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:18 INFO 140029870053184] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.38628673553\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:24 INFO 140029870053184] Epoch[40] Batch[5] avg_epoch_loss=2.399298\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:24 INFO 140029870053184] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.39929755529\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:24 INFO 140029870053184] Epoch[40] Batch [5]#011Speed: 100.24 samples/sec#011loss=2.399298\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:30 INFO 140029870053184] processed a total of 1254 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15840.905904769897, \"sum\": 15840.905904769897, \"min\": 15840.905904769897}}, \"EndTime\": 1586452530.023624, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452514.181948}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:30 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.1615543081 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:30 INFO 140029870053184] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:30 INFO 140029870053184] #quality_metric: host=algo-1, epoch=40, train loss <loss>=2.38335092068\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:30 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:30 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_74047179-b956-42fe-93e0-a04514627416-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 183.4108829498291, \"sum\": 183.4108829498291, \"min\": 183.4108829498291}}, \"EndTime\": 1586452530.207679, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452530.023703}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:34 INFO 140029870053184] Epoch[41] Batch[0] avg_epoch_loss=2.438430\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:34 INFO 140029870053184] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.43842959404\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:40 INFO 140029870053184] Epoch[41] Batch[5] avg_epoch_loss=2.389549\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:40 INFO 140029870053184] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.38954921563\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:40 INFO 140029870053184] Epoch[41] Batch [5]#011Speed: 99.15 samples/sec#011loss=2.389549\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:46 INFO 140029870053184] processed a total of 1206 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15857.247114181519, \"sum\": 15857.247114181519, \"min\": 15857.247114181519}}, \"EndTime\": 1586452546.065064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452530.207753}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:46 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.0530554618 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:46 INFO 140029870053184] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:46 INFO 140029870053184] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.37513148785\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:46 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:46 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_fe5c0e70-ae59-49f6-87c7-e5151ee35a72-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 178.8311004638672, \"sum\": 178.8311004638672, \"min\": 178.8311004638672}}, \"EndTime\": 1586452546.244691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452546.065133}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:50 INFO 140029870053184] Epoch[42] Batch[0] avg_epoch_loss=2.455411\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:50 INFO 140029870053184] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.45541071892\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:57 INFO 140029870053184] Epoch[42] Batch[5] avg_epoch_loss=2.533326\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:57 INFO 140029870053184] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.53332587083\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:15:57 INFO 140029870053184] Epoch[42] Batch [5]#011Speed: 98.14 samples/sec#011loss=2.533326\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:02 INFO 140029870053184] processed a total of 1267 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16042.838096618652, \"sum\": 16042.838096618652, \"min\": 16042.838096618652}}, \"EndTime\": 1586452562.287654, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452546.244752}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:02 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=78.9746285289 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:02 INFO 140029870053184] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:02 INFO 140029870053184] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.52855007648\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:02 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:06 INFO 140029870053184] Epoch[43] Batch[0] avg_epoch_loss=2.460370\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:06 INFO 140029870053184] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=2.46036982536\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:13 INFO 140029870053184] Epoch[43] Batch[5] avg_epoch_loss=2.514299\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:13 INFO 140029870053184] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.51429887613\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:13 INFO 140029870053184] Epoch[43] Batch [5]#011Speed: 99.11 samples/sec#011loss=2.514299\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:19 INFO 140029870053184] Epoch[43] Batch[10] avg_epoch_loss=2.455612\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:19 INFO 140029870053184] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.38518724442\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:19 INFO 140029870053184] Epoch[43] Batch [10]#011Speed: 100.08 samples/sec#011loss=2.385187\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:19 INFO 140029870053184] processed a total of 1304 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17219.220876693726, \"sum\": 17219.220876693726, \"min\": 17219.220876693726}}, \"EndTime\": 1586452579.507652, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452562.287902}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:19 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.7288200608 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:19 INFO 140029870053184] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:19 INFO 140029870053184] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.4556117708\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:19 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:23 INFO 140029870053184] Epoch[44] Batch[0] avg_epoch_loss=2.391242\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:23 INFO 140029870053184] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.3912422657\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:30 INFO 140029870053184] Epoch[44] Batch[5] avg_epoch_loss=2.357658\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:30 INFO 140029870053184] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.35765786966\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:30 INFO 140029870053184] Epoch[44] Batch [5]#011Speed: 99.63 samples/sec#011loss=2.357658\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:35 INFO 140029870053184] processed a total of 1270 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16024.420022964478, \"sum\": 16024.420022964478, \"min\": 16024.420022964478}}, \"EndTime\": 1586452595.532629, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452579.50773}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:35 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.2534641549 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:35 INFO 140029870053184] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:35 INFO 140029870053184] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.36397864819\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:35 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:35 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_5584312a-fbab-4174-b8ea-0185c40b1a7a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 171.97394371032715, \"sum\": 171.97394371032715, \"min\": 171.97394371032715}}, \"EndTime\": 1586452595.705332, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452595.532703}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:40 INFO 140029870053184] Epoch[45] Batch[0] avg_epoch_loss=2.438930\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:40 INFO 140029870053184] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.43892979622\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:46 INFO 140029870053184] Epoch[45] Batch[5] avg_epoch_loss=2.424110\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:46 INFO 140029870053184] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.42410985629\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:46 INFO 140029870053184] Epoch[45] Batch [5]#011Speed: 99.39 samples/sec#011loss=2.424110\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:51 INFO 140029870053184] processed a total of 1266 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15990.220069885254, \"sum\": 15990.220069885254, \"min\": 15990.220069885254}}, \"EndTime\": 1586452611.695721, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452595.705406}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:51 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.1726377001 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:51 INFO 140029870053184] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:51 INFO 140029870053184] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.40570619106\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:51 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:56 INFO 140029870053184] Epoch[46] Batch[0] avg_epoch_loss=2.384216\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:16:56 INFO 140029870053184] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.38421559334\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:02 INFO 140029870053184] Epoch[46] Batch[5] avg_epoch_loss=2.408194\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:02 INFO 140029870053184] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.40819354852\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:02 INFO 140029870053184] Epoch[46] Batch [5]#011Speed: 98.81 samples/sec#011loss=2.408194\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:09 INFO 140029870053184] Epoch[46] Batch[10] avg_epoch_loss=2.298135\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:09 INFO 140029870053184] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=2.16606450081\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:09 INFO 140029870053184] Epoch[46] Batch [10]#011Speed: 98.51 samples/sec#011loss=2.166065\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:09 INFO 140029870053184] processed a total of 1292 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17394.042015075684, \"sum\": 17394.042015075684, \"min\": 17394.042015075684}}, \"EndTime\": 1586452629.090309, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452611.695806}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:09 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=74.2778126099 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:09 INFO 140029870053184] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:09 INFO 140029870053184] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.29813489047\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:09 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:09 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_ffc7d993-800c-4e4f-b9a5-a235f7b1c436-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 174.8361587524414, \"sum\": 174.8361587524414, \"min\": 174.8361587524414}}, \"EndTime\": 1586452629.265759, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452629.090388}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:13 INFO 140029870053184] Epoch[47] Batch[0] avg_epoch_loss=2.325166\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:13 INFO 140029870053184] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.3251657486\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:20 INFO 140029870053184] Epoch[47] Batch[5] avg_epoch_loss=2.412633\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:20 INFO 140029870053184] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=2.41263286273\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:20 INFO 140029870053184] Epoch[47] Batch [5]#011Speed: 99.87 samples/sec#011loss=2.412633\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:26 INFO 140029870053184] Epoch[47] Batch[10] avg_epoch_loss=2.344053\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:26 INFO 140029870053184] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=2.26175813675\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:26 INFO 140029870053184] Epoch[47] Batch [10]#011Speed: 99.70 samples/sec#011loss=2.261758\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:26 INFO 140029870053184] processed a total of 1322 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17217.993021011353, \"sum\": 17217.993021011353, \"min\": 17217.993021011353}}, \"EndTime\": 1586452646.483889, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452629.265831}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:26 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.7796197488 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:26 INFO 140029870053184] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:26 INFO 140029870053184] #quality_metric: host=algo-1, epoch=47, train loss <loss>=2.34405344183\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:26 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:30 INFO 140029870053184] Epoch[48] Batch[0] avg_epoch_loss=2.367251\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:30 INFO 140029870053184] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.36725139618\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:37 INFO 140029870053184] Epoch[48] Batch[5] avg_epoch_loss=2.382678\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:37 INFO 140029870053184] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.38267795245\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:37 INFO 140029870053184] Epoch[48] Batch [5]#011Speed: 100.44 samples/sec#011loss=2.382678\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:42 INFO 140029870053184] processed a total of 1245 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15847.079992294312, \"sum\": 15847.079992294312, \"min\": 15847.079992294312}}, \"EndTime\": 1586452662.331652, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452646.483971}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:42 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=78.5628446447 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:42 INFO 140029870053184] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:42 INFO 140029870053184] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.36253521442\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:42 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:46 INFO 140029870053184] Epoch[49] Batch[0] avg_epoch_loss=2.370456\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:46 INFO 140029870053184] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=2.37045550346\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:53 INFO 140029870053184] Epoch[49] Batch[5] avg_epoch_loss=2.379390\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:53 INFO 140029870053184] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.37938984235\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:53 INFO 140029870053184] Epoch[49] Batch [5]#011Speed: 99.48 samples/sec#011loss=2.379390\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:58 INFO 140029870053184] processed a total of 1196 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15828.909158706665, \"sum\": 15828.909158706665, \"min\": 15828.909158706665}}, \"EndTime\": 1586452678.161189, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452662.331725}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:58 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.5573776289 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:58 INFO 140029870053184] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:58 INFO 140029870053184] #quality_metric: host=algo-1, epoch=49, train loss <loss>=2.4019775629\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:17:58 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:02 INFO 140029870053184] Epoch[50] Batch[0] avg_epoch_loss=2.371436\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:02 INFO 140029870053184] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.37143611908\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:08 INFO 140029870053184] Epoch[50] Batch[5] avg_epoch_loss=2.365739\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:08 INFO 140029870053184] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.36573882898\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:08 INFO 140029870053184] Epoch[50] Batch [5]#011Speed: 100.57 samples/sec#011loss=2.365739\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:14 INFO 140029870053184] processed a total of 1265 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15883.104085922241, \"sum\": 15883.104085922241, \"min\": 15883.104085922241}}, \"EndTime\": 1586452694.044938, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452678.161272}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:14 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.6436258563 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:14 INFO 140029870053184] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:14 INFO 140029870053184] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.34578244686\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:14 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:18 INFO 140029870053184] Epoch[51] Batch[0] avg_epoch_loss=2.366709\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:18 INFO 140029870053184] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.36670947075\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:24 INFO 140029870053184] Epoch[51] Batch[5] avg_epoch_loss=2.355915\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:24 INFO 140029870053184] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.35591459274\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:24 INFO 140029870053184] Epoch[51] Batch [5]#011Speed: 100.33 samples/sec#011loss=2.355915\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:29 INFO 140029870053184] processed a total of 1242 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15786.533117294312, \"sum\": 15786.533117294312, \"min\": 15786.533117294312}}, \"EndTime\": 1586452709.832226, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452694.045027}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:29 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=78.6740246824 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:29 INFO 140029870053184] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:29 INFO 140029870053184] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.35036292076\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:29 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:34 INFO 140029870053184] Epoch[52] Batch[0] avg_epoch_loss=2.354590\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:34 INFO 140029870053184] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.35458993912\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:40 INFO 140029870053184] Epoch[52] Batch[5] avg_epoch_loss=2.329573\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:40 INFO 140029870053184] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.32957279682\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:40 INFO 140029870053184] Epoch[52] Batch [5]#011Speed: 99.14 samples/sec#011loss=2.329573\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:45 INFO 140029870053184] processed a total of 1268 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15858.626127243042, \"sum\": 15858.626127243042, \"min\": 15858.626127243042}}, \"EndTime\": 1586452725.691418, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452709.832312}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:45 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.9558850436 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:45 INFO 140029870053184] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:45 INFO 140029870053184] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.33026783466\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:45 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:50 INFO 140029870053184] Epoch[53] Batch[0] avg_epoch_loss=2.337713\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:50 INFO 140029870053184] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.33771300316\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:56 INFO 140029870053184] Epoch[53] Batch[5] avg_epoch_loss=2.283073\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:56 INFO 140029870053184] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.28307294846\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:18:56 INFO 140029870053184] Epoch[53] Batch [5]#011Speed: 100.18 samples/sec#011loss=2.283073\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:01 INFO 140029870053184] processed a total of 1277 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15867.162942886353, \"sum\": 15867.162942886353, \"min\": 15867.162942886353}}, \"EndTime\": 1586452741.559193, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452725.691497}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:01 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=80.4800508088 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:01 INFO 140029870053184] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:01 INFO 140029870053184] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.28893537521\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:01 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:01 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_34161ad1-8d0d-41d1-923b-34653bff75e7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 177.62207984924316, \"sum\": 177.62207984924316, \"min\": 177.62207984924316}}, \"EndTime\": 1586452741.737623, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452741.559273}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:06 INFO 140029870053184] Epoch[54] Batch[0] avg_epoch_loss=2.387591\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:06 INFO 140029870053184] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.387591362\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:12 INFO 140029870053184] Epoch[54] Batch[5] avg_epoch_loss=2.400671\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:12 INFO 140029870053184] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.40067140261\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:12 INFO 140029870053184] Epoch[54] Batch [5]#011Speed: 98.54 samples/sec#011loss=2.400671\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:17 INFO 140029870053184] processed a total of 1255 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15997.789859771729, \"sum\": 15997.789859771729, \"min\": 15997.789859771729}}, \"EndTime\": 1586452757.73556, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452741.737705}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:17 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=78.447751802 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:17 INFO 140029870053184] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:17 INFO 140029870053184] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.38953464031\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:17 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:22 INFO 140029870053184] Epoch[55] Batch[0] avg_epoch_loss=2.339689\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:22 INFO 140029870053184] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.33968853951\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:28 INFO 140029870053184] Epoch[55] Batch[5] avg_epoch_loss=2.330011\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:28 INFO 140029870053184] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=2.33001073201\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:28 INFO 140029870053184] Epoch[55] Batch [5]#011Speed: 99.12 samples/sec#011loss=2.330011\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:35 INFO 140029870053184] Epoch[55] Batch[10] avg_epoch_loss=2.310561\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:35 INFO 140029870053184] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=2.28722186089\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:35 INFO 140029870053184] Epoch[55] Batch [10]#011Speed: 99.59 samples/sec#011loss=2.287222\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:35 INFO 140029870053184] processed a total of 1293 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17304.996967315674, \"sum\": 17304.996967315674, \"min\": 17304.996967315674}}, \"EndTime\": 1586452775.041154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452757.735639}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:35 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=74.7177714254 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:35 INFO 140029870053184] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:35 INFO 140029870053184] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.31056124514\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:35 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:39 INFO 140029870053184] Epoch[56] Batch[0] avg_epoch_loss=2.303492\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:39 INFO 140029870053184] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.30349230766\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:45 INFO 140029870053184] Epoch[56] Batch[5] avg_epoch_loss=2.301825\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:45 INFO 140029870053184] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.30182460944\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:45 INFO 140029870053184] Epoch[56] Batch [5]#011Speed: 99.16 samples/sec#011loss=2.301825\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:51 INFO 140029870053184] processed a total of 1249 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15989.566087722778, \"sum\": 15989.566087722778, \"min\": 15989.566087722778}}, \"EndTime\": 1586452791.031391, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452775.041241}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:51 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=78.1129023567 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:51 INFO 140029870053184] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:51 INFO 140029870053184] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.27475712299\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:51 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:51 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_3c980aa5-4fce-47d4-aa21-e9fda9aa3de4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 202.18491554260254, \"sum\": 202.18491554260254, \"min\": 202.18491554260254}}, \"EndTime\": 1586452791.234112, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452791.031464}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:55 INFO 140029870053184] Epoch[57] Batch[0] avg_epoch_loss=2.289050\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:19:55 INFO 140029870053184] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=2.28905010223\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:02 INFO 140029870053184] Epoch[57] Batch[5] avg_epoch_loss=2.295302\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:02 INFO 140029870053184] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.29530219237\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:02 INFO 140029870053184] Epoch[57] Batch [5]#011Speed: 99.81 samples/sec#011loss=2.295302\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:08 INFO 140029870053184] Epoch[57] Batch[10] avg_epoch_loss=2.272277\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:08 INFO 140029870053184] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=2.24464621544\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:08 INFO 140029870053184] Epoch[57] Batch [10]#011Speed: 98.53 samples/sec#011loss=2.244646\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:08 INFO 140029870053184] processed a total of 1306 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17275.60806274414, \"sum\": 17275.60806274414, \"min\": 17275.60806274414}}, \"EndTime\": 1586452808.509867, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452791.234191}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:08 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.5974191974 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:08 INFO 140029870053184] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:08 INFO 140029870053184] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.27227674831\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:08 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:08 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_bf5b1844-b4a9-4e25-8e5b-9b700efef9bd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 239.1669750213623, \"sum\": 239.1669750213623, \"min\": 239.1669750213623}}, \"EndTime\": 1586452808.749597, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452808.509946}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:13 INFO 140029870053184] Epoch[58] Batch[0] avg_epoch_loss=2.380292\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:13 INFO 140029870053184] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.38029241562\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:19 INFO 140029870053184] Epoch[58] Batch[5] avg_epoch_loss=2.413326\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:19 INFO 140029870053184] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.41332610448\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:19 INFO 140029870053184] Epoch[58] Batch [5]#011Speed: 99.54 samples/sec#011loss=2.413326\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:26 INFO 140029870053184] Epoch[58] Batch[10] avg_epoch_loss=2.419338\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:26 INFO 140029870053184] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=2.42655177116\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:26 INFO 140029870053184] Epoch[58] Batch [10]#011Speed: 99.62 samples/sec#011loss=2.426552\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:26 INFO 140029870053184] processed a total of 1358 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17252.445936203003, \"sum\": 17252.445936203003, \"min\": 17252.445936203003}}, \"EndTime\": 1586452826.002185, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452808.749676}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:26 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=78.7129566771 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:26 INFO 140029870053184] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:26 INFO 140029870053184] #quality_metric: host=algo-1, epoch=58, train loss <loss>=2.41933777116\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:26 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:30 INFO 140029870053184] Epoch[59] Batch[0] avg_epoch_loss=2.302391\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:30 INFO 140029870053184] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.30239105225\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:36 INFO 140029870053184] Epoch[59] Batch[5] avg_epoch_loss=2.285702\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:36 INFO 140029870053184] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.28570199013\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:36 INFO 140029870053184] Epoch[59] Batch [5]#011Speed: 99.57 samples/sec#011loss=2.285702\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:41 INFO 140029870053184] processed a total of 1241 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15996.455907821655, \"sum\": 15996.455907821655, \"min\": 15996.455907821655}}, \"EndTime\": 1586452841.999239, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452826.002264}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:41 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=77.5791408976 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:41 INFO 140029870053184] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:41 INFO 140029870053184] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.27741539478\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:41 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:46 INFO 140029870053184] Epoch[60] Batch[0] avg_epoch_loss=2.276750\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:46 INFO 140029870053184] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.27675032616\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:52 INFO 140029870053184] Epoch[60] Batch[5] avg_epoch_loss=2.296110\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:52 INFO 140029870053184] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.29611003399\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:52 INFO 140029870053184] Epoch[60] Batch [5]#011Speed: 99.36 samples/sec#011loss=2.296110\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:57 INFO 140029870053184] processed a total of 1255 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15974.971055984497, \"sum\": 15974.971055984497, \"min\": 15974.971055984497}}, \"EndTime\": 1586452857.974773, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452841.999315}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:57 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=78.5597830471 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:57 INFO 140029870053184] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:57 INFO 140029870053184] #quality_metric: host=algo-1, epoch=60, train loss <loss>=2.30056293011\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:20:57 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:02 INFO 140029870053184] Epoch[61] Batch[0] avg_epoch_loss=2.314309\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:02 INFO 140029870053184] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.3143093586\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:08 INFO 140029870053184] Epoch[61] Batch[5] avg_epoch_loss=2.259237\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:08 INFO 140029870053184] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.25923720996\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:08 INFO 140029870053184] Epoch[61] Batch [5]#011Speed: 99.88 samples/sec#011loss=2.259237\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:13 INFO 140029870053184] processed a total of 1275 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15976.286888122559, \"sum\": 15976.286888122559, \"min\": 15976.286888122559}}, \"EndTime\": 1586452873.951688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452857.974855}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:13 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.8051679396 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:13 INFO 140029870053184] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:13 INFO 140029870053184] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.26799685955\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:13 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:14 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_19ee0795-98ae-4489-8011-78826cf884fc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 185.34493446350098, \"sum\": 185.34493446350098, \"min\": 185.34493446350098}}, \"EndTime\": 1586452874.137663, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452873.951768}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:18 INFO 140029870053184] Epoch[62] Batch[0] avg_epoch_loss=2.353634\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:18 INFO 140029870053184] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.35363388062\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:24 INFO 140029870053184] Epoch[62] Batch[5] avg_epoch_loss=2.291698\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:24 INFO 140029870053184] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.29169817766\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:24 INFO 140029870053184] Epoch[62] Batch [5]#011Speed: 99.98 samples/sec#011loss=2.291698\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:30 INFO 140029870053184] processed a total of 1242 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15871.42300605774, \"sum\": 15871.42300605774, \"min\": 15871.42300605774}}, \"EndTime\": 1586452890.009235, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452874.137743}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:30 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=78.2532862261 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:30 INFO 140029870053184] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:30 INFO 140029870053184] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.26845505238\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:30 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:34 INFO 140029870053184] Epoch[63] Batch[0] avg_epoch_loss=2.269421\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:34 INFO 140029870053184] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.26942062378\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:40 INFO 140029870053184] Epoch[63] Batch[5] avg_epoch_loss=2.262180\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:40 INFO 140029870053184] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.26218044758\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:40 INFO 140029870053184] Epoch[63] Batch [5]#011Speed: 99.60 samples/sec#011loss=2.262180\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:45 INFO 140029870053184] processed a total of 1280 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15955.338954925537, \"sum\": 15955.338954925537, \"min\": 15955.338954925537}}, \"EndTime\": 1586452905.96529, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452890.00931}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:45 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=80.2231367036 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:45 INFO 140029870053184] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:45 INFO 140029870053184] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.27061803341\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:45 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:50 INFO 140029870053184] Epoch[64] Batch[0] avg_epoch_loss=2.264338\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:50 INFO 140029870053184] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.26433849335\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:56 INFO 140029870053184] Epoch[64] Batch[5] avg_epoch_loss=2.308960\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:56 INFO 140029870053184] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=2.30895984173\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:21:56 INFO 140029870053184] Epoch[64] Batch [5]#011Speed: 99.31 samples/sec#011loss=2.308960\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:03 INFO 140029870053184] Epoch[64] Batch[10] avg_epoch_loss=2.267805\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:03 INFO 140029870053184] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=2.21841888428\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:03 INFO 140029870053184] Epoch[64] Batch [10]#011Speed: 99.22 samples/sec#011loss=2.218419\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:03 INFO 140029870053184] processed a total of 1292 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17332.813024520874, \"sum\": 17332.813024520874, \"min\": 17332.813024520874}}, \"EndTime\": 1586452923.298651, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452905.965374}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:03 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=74.5402182099 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:03 INFO 140029870053184] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:03 INFO 140029870053184] #quality_metric: host=algo-1, epoch=64, train loss <loss>=2.26780486107\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:03 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:03 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_867d93d3-0fec-4b6d-8133-f89bdfb77d89-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 189.01896476745605, \"sum\": 189.01896476745605, \"min\": 189.01896476745605}}, \"EndTime\": 1586452923.488231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452923.298727}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:07 INFO 140029870053184] Epoch[65] Batch[0] avg_epoch_loss=2.417328\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:07 INFO 140029870053184] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=2.4173283577\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:14 INFO 140029870053184] Epoch[65] Batch[5] avg_epoch_loss=2.354084\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:14 INFO 140029870053184] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.35408393542\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:14 INFO 140029870053184] Epoch[65] Batch [5]#011Speed: 99.32 samples/sec#011loss=2.354084\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:20 INFO 140029870053184] Epoch[65] Batch[10] avg_epoch_loss=2.293828\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:20 INFO 140029870053184] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=2.22152173519\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:20 INFO 140029870053184] Epoch[65] Batch [10]#011Speed: 97.99 samples/sec#011loss=2.221522\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:20 INFO 140029870053184] processed a total of 1284 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17314.777851104736, \"sum\": 17314.777851104736, \"min\": 17314.777851104736}}, \"EndTime\": 1586452940.803148, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452923.488307}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:20 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=74.1555708097 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:20 INFO 140029870053184] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:20 INFO 140029870053184] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.29382838986\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:20 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:25 INFO 140029870053184] Epoch[66] Batch[0] avg_epoch_loss=2.336911\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:25 INFO 140029870053184] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.3369114399\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:31 INFO 140029870053184] Epoch[66] Batch[5] avg_epoch_loss=2.284434\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:31 INFO 140029870053184] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.28443431854\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:31 INFO 140029870053184] Epoch[66] Batch [5]#011Speed: 99.54 samples/sec#011loss=2.284434\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:38 INFO 140029870053184] Epoch[66] Batch[10] avg_epoch_loss=2.227225\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:38 INFO 140029870053184] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=2.15857272148\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:38 INFO 140029870053184] Epoch[66] Batch [10]#011Speed: 99.89 samples/sec#011loss=2.158573\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:38 INFO 140029870053184] processed a total of 1323 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17234.328031539917, \"sum\": 17234.328031539917, \"min\": 17234.328031539917}}, \"EndTime\": 1586452958.038046, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452940.803283}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:38 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.7648916945 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:38 INFO 140029870053184] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:38 INFO 140029870053184] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.2272245017\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:38 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:38 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_96ce34f7-4a3c-49dd-b382-790e68d14d52-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 180.2527904510498, \"sum\": 180.2527904510498, \"min\": 180.2527904510498}}, \"EndTime\": 1586452958.218839, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452958.038124}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:42 INFO 140029870053184] Epoch[67] Batch[0] avg_epoch_loss=2.246901\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:42 INFO 140029870053184] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.24690079689\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:49 INFO 140029870053184] Epoch[67] Batch[5] avg_epoch_loss=2.271728\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:49 INFO 140029870053184] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=2.27172756195\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:49 INFO 140029870053184] Epoch[67] Batch [5]#011Speed: 99.00 samples/sec#011loss=2.271728\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:55 INFO 140029870053184] Epoch[67] Batch[10] avg_epoch_loss=2.324523\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:55 INFO 140029870053184] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=2.38787651062\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:55 INFO 140029870053184] Epoch[67] Batch [10]#011Speed: 99.15 samples/sec#011loss=2.387877\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:55 INFO 140029870053184] processed a total of 1332 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17362.272024154663, \"sum\": 17362.272024154663, \"min\": 17362.272024154663}}, \"EndTime\": 1586452975.581249, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452958.218915}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:55 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.7175706188 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:55 INFO 140029870053184] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:55 INFO 140029870053184] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.32452253862\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:22:55 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:00 INFO 140029870053184] Epoch[68] Batch[0] avg_epoch_loss=2.489188\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:00 INFO 140029870053184] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.48918795586\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:06 INFO 140029870053184] Epoch[68] Batch[5] avg_epoch_loss=2.404266\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:06 INFO 140029870053184] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.40426560243\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:06 INFO 140029870053184] Epoch[68] Batch [5]#011Speed: 100.09 samples/sec#011loss=2.404266\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:12 INFO 140029870053184] Epoch[68] Batch[10] avg_epoch_loss=2.387812\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:12 INFO 140029870053184] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.36806702614\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:12 INFO 140029870053184] Epoch[68] Batch [10]#011Speed: 100.05 samples/sec#011loss=2.368067\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:12 INFO 140029870053184] processed a total of 1329 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17214.65802192688, \"sum\": 17214.65802192688, \"min\": 17214.65802192688}}, \"EndTime\": 1586452992.796516, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452975.581327}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:12 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=77.2010585222 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:12 INFO 140029870053184] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:12 INFO 140029870053184] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.38781170412\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:12 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:17 INFO 140029870053184] Epoch[69] Batch[0] avg_epoch_loss=2.299037\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:17 INFO 140029870053184] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.29903674126\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:23 INFO 140029870053184] Epoch[69] Batch[5] avg_epoch_loss=2.288689\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:23 INFO 140029870053184] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.28868893782\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:23 INFO 140029870053184] Epoch[69] Batch [5]#011Speed: 100.38 samples/sec#011loss=2.288689\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:28 INFO 140029870053184] processed a total of 1270 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15816.971063613892, \"sum\": 15816.971063613892, \"min\": 15816.971063613892}}, \"EndTime\": 1586453008.61402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586452992.796613}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:28 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=80.2928933614 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:28 INFO 140029870053184] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:28 INFO 140029870053184] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.25643801689\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:28 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:33 INFO 140029870053184] Epoch[70] Batch[0] avg_epoch_loss=2.251171\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:33 INFO 140029870053184] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=2.25117063522\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:39 INFO 140029870053184] Epoch[70] Batch[5] avg_epoch_loss=2.237667\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:39 INFO 140029870053184] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.23766672611\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:39 INFO 140029870053184] Epoch[70] Batch [5]#011Speed: 100.78 samples/sec#011loss=2.237667\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:45 INFO 140029870053184] Epoch[70] Batch[10] avg_epoch_loss=2.202780\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:45 INFO 140029870053184] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=2.16091485023\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:45 INFO 140029870053184] Epoch[70] Batch [10]#011Speed: 98.45 samples/sec#011loss=2.160915\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:45 INFO 140029870053184] processed a total of 1322 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17240.652084350586, \"sum\": 17240.652084350586, \"min\": 17240.652084350586}}, \"EndTime\": 1586453025.85524, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453008.614104}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:45 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.6787061929 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:45 INFO 140029870053184] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:45 INFO 140029870053184] #quality_metric: host=algo-1, epoch=70, train loss <loss>=2.2027795098\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:45 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:46 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_476a8b17-8da8-4a7a-a329-037ca6630a51-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 172.65892028808594, \"sum\": 172.65892028808594, \"min\": 172.65892028808594}}, \"EndTime\": 1586453026.02853, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453025.855321}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:50 INFO 140029870053184] Epoch[71] Batch[0] avg_epoch_loss=2.428581\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:50 INFO 140029870053184] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.42858123779\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:56 INFO 140029870053184] Epoch[71] Batch[5] avg_epoch_loss=2.443981\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:56 INFO 140029870053184] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.44398057461\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:23:56 INFO 140029870053184] Epoch[71] Batch [5]#011Speed: 98.80 samples/sec#011loss=2.443981\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:03 INFO 140029870053184] Epoch[71] Batch[10] avg_epoch_loss=2.430670\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:03 INFO 140029870053184] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=2.41469655037\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:03 INFO 140029870053184] Epoch[71] Batch [10]#011Speed: 99.61 samples/sec#011loss=2.414697\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:03 INFO 140029870053184] processed a total of 1297 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17254.74214553833, \"sum\": 17254.74214553833, \"min\": 17254.74214553833}}, \"EndTime\": 1586453043.283407, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453026.028602}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:03 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.1671714532 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:03 INFO 140029870053184] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:03 INFO 140029870053184] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.4306696545\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:03 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:07 INFO 140029870053184] Epoch[72] Batch[0] avg_epoch_loss=2.219236\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:07 INFO 140029870053184] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.21923613548\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:14 INFO 140029870053184] Epoch[72] Batch[5] avg_epoch_loss=2.324874\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:14 INFO 140029870053184] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.32487428188\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:14 INFO 140029870053184] Epoch[72] Batch [5]#011Speed: 98.82 samples/sec#011loss=2.324874\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:19 INFO 140029870053184] processed a total of 1268 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16036.214113235474, \"sum\": 16036.214113235474, \"min\": 16036.214113235474}}, \"EndTime\": 1586453059.320127, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453043.283502}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:19 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.0704313216 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:19 INFO 140029870053184] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:19 INFO 140029870053184] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.31399328709\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:19 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:23 INFO 140029870053184] Epoch[73] Batch[0] avg_epoch_loss=2.253145\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:23 INFO 140029870053184] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.25314450264\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:30 INFO 140029870053184] Epoch[73] Batch[5] avg_epoch_loss=2.223341\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:30 INFO 140029870053184] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.22334051132\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:30 INFO 140029870053184] Epoch[73] Batch [5]#011Speed: 99.91 samples/sec#011loss=2.223341\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:35 INFO 140029870053184] processed a total of 1271 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15882.95602798462, \"sum\": 15882.95602798462, \"min\": 15882.95602798462}}, \"EndTime\": 1586453075.203694, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453059.320207}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:35 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=80.0222770706 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:35 INFO 140029870053184] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:35 INFO 140029870053184] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.2329069376\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:35 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:39 INFO 140029870053184] Epoch[74] Batch[0] avg_epoch_loss=2.191616\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:39 INFO 140029870053184] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.19161558151\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:45 INFO 140029870053184] Epoch[74] Batch[5] avg_epoch_loss=2.175689\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:45 INFO 140029870053184] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.17568914096\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:45 INFO 140029870053184] Epoch[74] Batch [5]#011Speed: 98.82 samples/sec#011loss=2.175689\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:51 INFO 140029870053184] processed a total of 1235 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15920.445919036865, \"sum\": 15920.445919036865, \"min\": 15920.445919036865}}, \"EndTime\": 1586453091.124816, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453075.203775}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:51 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=77.5725651262 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:51 INFO 140029870053184] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:51 INFO 140029870053184] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.14113242626\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:51 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:51 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_fa1ad65c-d554-467e-b167-4c2194aaaea0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 192.37995147705078, \"sum\": 192.37995147705078, \"min\": 192.37995147705078}}, \"EndTime\": 1586453091.317865, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453091.12488}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:55 INFO 140029870053184] Epoch[75] Batch[0] avg_epoch_loss=2.168433\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:24:55 INFO 140029870053184] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.16843318939\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:02 INFO 140029870053184] Epoch[75] Batch[5] avg_epoch_loss=2.187084\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:02 INFO 140029870053184] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.18708364169\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:02 INFO 140029870053184] Epoch[75] Batch [5]#011Speed: 99.37 samples/sec#011loss=2.187084\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:07 INFO 140029870053184] processed a total of 1252 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15932.19804763794, \"sum\": 15932.19804763794, \"min\": 15932.19804763794}}, \"EndTime\": 1586453107.250212, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453091.317944}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:07 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=78.5823747627 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:07 INFO 140029870053184] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:07 INFO 140029870053184] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.18989822865\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:07 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:11 INFO 140029870053184] Epoch[76] Batch[0] avg_epoch_loss=2.145525\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:11 INFO 140029870053184] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.14552545547\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:18 INFO 140029870053184] Epoch[76] Batch[5] avg_epoch_loss=2.264485\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:18 INFO 140029870053184] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.26448492209\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:18 INFO 140029870053184] Epoch[76] Batch [5]#011Speed: 99.33 samples/sec#011loss=2.264485\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:24 INFO 140029870053184] Epoch[76] Batch[10] avg_epoch_loss=2.268905\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:24 INFO 140029870053184] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=2.274208498\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:24 INFO 140029870053184] Epoch[76] Batch [10]#011Speed: 100.06 samples/sec#011loss=2.274208\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:24 INFO 140029870053184] processed a total of 1351 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17271.167039871216, \"sum\": 17271.167039871216, \"min\": 17271.167039871216}}, \"EndTime\": 1586453124.522087, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453107.250299}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:24 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=78.222348854 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:24 INFO 140029870053184] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:24 INFO 140029870053184] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.26890472932\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:24 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:28 INFO 140029870053184] Epoch[77] Batch[0] avg_epoch_loss=2.273804\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:28 INFO 140029870053184] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.27380442619\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:35 INFO 140029870053184] Epoch[77] Batch[5] avg_epoch_loss=2.215131\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:35 INFO 140029870053184] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.21513132254\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:35 INFO 140029870053184] Epoch[77] Batch [5]#011Speed: 99.77 samples/sec#011loss=2.215131\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:40 INFO 140029870053184] processed a total of 1278 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15989.162921905518, \"sum\": 15989.162921905518, \"min\": 15989.162921905518}}, \"EndTime\": 1586453140.511779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453124.522162}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:40 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.9285069134 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:40 INFO 140029870053184] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:40 INFO 140029870053184] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.20013887882\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:40 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:44 INFO 140029870053184] Epoch[78] Batch[0] avg_epoch_loss=2.169076\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:44 INFO 140029870053184] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.1690762043\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:51 INFO 140029870053184] Epoch[78] Batch[5] avg_epoch_loss=2.168854\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:51 INFO 140029870053184] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.16885411739\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:51 INFO 140029870053184] Epoch[78] Batch [5]#011Speed: 99.96 samples/sec#011loss=2.168854\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:56 INFO 140029870053184] processed a total of 1274 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15967.789888381958, \"sum\": 15967.789888381958, \"min\": 15967.789888381958}}, \"EndTime\": 1586453156.480157, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453140.511864}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:56 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.7849995114 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:56 INFO 140029870053184] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:56 INFO 140029870053184] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.1680460453\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:25:56 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:00 INFO 140029870053184] Epoch[79] Batch[0] avg_epoch_loss=2.230389\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:00 INFO 140029870053184] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.23038887978\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:07 INFO 140029870053184] Epoch[79] Batch[5] avg_epoch_loss=2.209682\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:07 INFO 140029870053184] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.20968170961\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:07 INFO 140029870053184] Epoch[79] Batch [5]#011Speed: 99.29 samples/sec#011loss=2.209682\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:12 INFO 140029870053184] processed a total of 1274 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16032.140016555786, \"sum\": 16032.140016555786, \"min\": 16032.140016555786}}, \"EndTime\": 1586453172.512839, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453156.480242}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:12 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.4647546146 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:12 INFO 140029870053184] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:12 INFO 140029870053184] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.21303882599\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:12 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:16 INFO 140029870053184] Epoch[80] Batch[0] avg_epoch_loss=2.077192\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:16 INFO 140029870053184] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.0771920681\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:23 INFO 140029870053184] Epoch[80] Batch[5] avg_epoch_loss=2.164716\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:23 INFO 140029870053184] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=2.16471640269\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:23 INFO 140029870053184] Epoch[80] Batch [5]#011Speed: 100.08 samples/sec#011loss=2.164716\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:29 INFO 140029870053184] Epoch[80] Batch[10] avg_epoch_loss=2.128111\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:29 INFO 140029870053184] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.08418416977\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:29 INFO 140029870053184] Epoch[80] Batch [10]#011Speed: 100.23 samples/sec#011loss=2.084184\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:29 INFO 140029870053184] processed a total of 1319 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17216.994047164917, \"sum\": 17216.994047164917, \"min\": 17216.994047164917}}, \"EndTime\": 1586453189.730565, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453172.512923}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:29 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.6098421452 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:29 INFO 140029870053184] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:29 INFO 140029870053184] #quality_metric: host=algo-1, epoch=80, train loss <loss>=2.12811084227\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:29 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:29 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_b1f6d46d-348a-4309-a397-c04841191906-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 183.4120750427246, \"sum\": 183.4120750427246, \"min\": 183.4120750427246}}, \"EndTime\": 1586453189.914561, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453189.730643}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:34 INFO 140029870053184] Epoch[81] Batch[0] avg_epoch_loss=2.230522\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:34 INFO 140029870053184] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.23052167892\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:40 INFO 140029870053184] Epoch[81] Batch[5] avg_epoch_loss=2.248393\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:40 INFO 140029870053184] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.24839293957\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:40 INFO 140029870053184] Epoch[81] Batch [5]#011Speed: 99.72 samples/sec#011loss=2.248393\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:45 INFO 140029870053184] processed a total of 1270 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15932.148933410645, \"sum\": 15932.148933410645, \"min\": 15932.148933410645}}, \"EndTime\": 1586453205.846834, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453189.914627}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:45 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.712443177 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:45 INFO 140029870053184] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:45 INFO 140029870053184] #quality_metric: host=algo-1, epoch=81, train loss <loss>=2.23184196949\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:45 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:50 INFO 140029870053184] Epoch[82] Batch[0] avg_epoch_loss=2.185723\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:50 INFO 140029870053184] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=2.18572282791\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:56 INFO 140029870053184] Epoch[82] Batch[5] avg_epoch_loss=2.186051\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:56 INFO 140029870053184] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.18605120977\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:26:56 INFO 140029870053184] Epoch[82] Batch [5]#011Speed: 99.84 samples/sec#011loss=2.186051\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:03 INFO 140029870053184] Epoch[82] Batch[10] avg_epoch_loss=2.203788\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:03 INFO 140029870053184] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=2.22507247925\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:03 INFO 140029870053184] Epoch[82] Batch [10]#011Speed: 98.23 samples/sec#011loss=2.225072\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:03 INFO 140029870053184] processed a total of 1326 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17356.97889328003, \"sum\": 17356.97889328003, \"min\": 17356.97889328003}}, \"EndTime\": 1586453223.204362, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453205.846914}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:03 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.3952555618 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:03 INFO 140029870053184] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:03 INFO 140029870053184] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.20378815044\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:03 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:07 INFO 140029870053184] Epoch[83] Batch[0] avg_epoch_loss=2.251589\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:07 INFO 140029870053184] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.25158858299\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:13 INFO 140029870053184] Epoch[83] Batch[5] avg_epoch_loss=2.172809\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:13 INFO 140029870053184] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.1728088061\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:13 INFO 140029870053184] Epoch[83] Batch [5]#011Speed: 99.38 samples/sec#011loss=2.172809\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:19 INFO 140029870053184] processed a total of 1275 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15900.06399154663, \"sum\": 15900.06399154663, \"min\": 15900.06399154663}}, \"EndTime\": 1586453239.105044, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453223.204445}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:19 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=80.1878022101 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:19 INFO 140029870053184] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:19 INFO 140029870053184] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.19445393085\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:19 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:23 INFO 140029870053184] Epoch[84] Batch[0] avg_epoch_loss=2.119224\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:23 INFO 140029870053184] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.1192240715\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:29 INFO 140029870053184] Epoch[84] Batch[5] avg_epoch_loss=2.208295\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:29 INFO 140029870053184] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.20829494794\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:29 INFO 140029870053184] Epoch[84] Batch [5]#011Speed: 99.65 samples/sec#011loss=2.208295\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:36 INFO 140029870053184] Epoch[84] Batch[10] avg_epoch_loss=2.229687\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:36 INFO 140029870053184] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=2.255356884\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:36 INFO 140029870053184] Epoch[84] Batch [10]#011Speed: 99.80 samples/sec#011loss=2.255357\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:36 INFO 140029870053184] processed a total of 1289 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17200.63304901123, \"sum\": 17200.63304901123, \"min\": 17200.63304901123}}, \"EndTime\": 1586453256.306363, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453239.105112}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:36 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=74.9385974972 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:36 INFO 140029870053184] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:36 INFO 140029870053184] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.22968673706\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:36 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:40 INFO 140029870053184] Epoch[85] Batch[0] avg_epoch_loss=2.258666\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:40 INFO 140029870053184] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=2.25866627693\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:47 INFO 140029870053184] Epoch[85] Batch[5] avg_epoch_loss=2.220259\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:47 INFO 140029870053184] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.22025867303\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:47 INFO 140029870053184] Epoch[85] Batch [5]#011Speed: 98.71 samples/sec#011loss=2.220259\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:53 INFO 140029870053184] Epoch[85] Batch[10] avg_epoch_loss=2.190559\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:53 INFO 140029870053184] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=2.15491843224\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:53 INFO 140029870053184] Epoch[85] Batch [10]#011Speed: 99.16 samples/sec#011loss=2.154918\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:53 INFO 140029870053184] processed a total of 1291 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17313.205003738403, \"sum\": 17313.205003738403, \"min\": 17313.205003738403}}, \"EndTime\": 1586453273.62005, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453256.306443}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:53 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=74.566830706 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:53 INFO 140029870053184] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:53 INFO 140029870053184] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.19055856358\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:53 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:57 INFO 140029870053184] Epoch[86] Batch[0] avg_epoch_loss=2.282724\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:27:57 INFO 140029870053184] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.28272390366\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:04 INFO 140029870053184] Epoch[86] Batch[5] avg_epoch_loss=2.186327\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:04 INFO 140029870053184] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.18632698059\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:04 INFO 140029870053184] Epoch[86] Batch [5]#011Speed: 98.66 samples/sec#011loss=2.186327\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:09 INFO 140029870053184] processed a total of 1271 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15942.793846130371, \"sum\": 15942.793846130371, \"min\": 15942.793846130371}}, \"EndTime\": 1586453289.563448, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453273.620136}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:09 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.721956939 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:09 INFO 140029870053184] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:09 INFO 140029870053184] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.17021324635\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:09 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:13 INFO 140029870053184] Epoch[87] Batch[0] avg_epoch_loss=2.131878\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:13 INFO 140029870053184] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.13187766075\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:20 INFO 140029870053184] Epoch[87] Batch[5] avg_epoch_loss=2.126965\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:20 INFO 140029870053184] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.12696524461\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:20 INFO 140029870053184] Epoch[87] Batch [5]#011Speed: 99.82 samples/sec#011loss=2.126965\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:26 INFO 140029870053184] Epoch[87] Batch[10] avg_epoch_loss=2.052217\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:26 INFO 140029870053184] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=1.96252017021\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:26 INFO 140029870053184] Epoch[87] Batch [10]#011Speed: 99.91 samples/sec#011loss=1.962520\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:26 INFO 140029870053184] processed a total of 1302 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17220.558881759644, \"sum\": 17220.558881759644, \"min\": 17220.558881759644}}, \"EndTime\": 1586453306.78459, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453289.563526}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:26 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.6067704714 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:26 INFO 140029870053184] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:26 INFO 140029870053184] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.05221748352\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:26 INFO 140029870053184] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:26 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/state_9ed9b940-57a8-423f-8e86-63da70e13f88-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 176.26190185546875, \"sum\": 176.26190185546875, \"min\": 176.26190185546875}}, \"EndTime\": 1586453306.961509, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453306.78467}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:31 INFO 140029870053184] Epoch[88] Batch[0] avg_epoch_loss=2.311481\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:31 INFO 140029870053184] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.31148099899\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:37 INFO 140029870053184] Epoch[88] Batch[5] avg_epoch_loss=2.332334\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:37 INFO 140029870053184] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.33233376344\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:37 INFO 140029870053184] Epoch[88] Batch [5]#011Speed: 100.18 samples/sec#011loss=2.332334\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:44 INFO 140029870053184] Epoch[88] Batch[10] avg_epoch_loss=2.262807\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:44 INFO 140029870053184] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=2.17937424183\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:44 INFO 140029870053184] Epoch[88] Batch [10]#011Speed: 99.50 samples/sec#011loss=2.179374\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:44 INFO 140029870053184] processed a total of 1328 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17273.422956466675, \"sum\": 17273.422956466675, \"min\": 17273.422956466675}}, \"EndTime\": 1586453324.235068, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453306.961581}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:44 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.8805664745 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:44 INFO 140029870053184] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:44 INFO 140029870053184] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.26280670816\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:44 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:48 INFO 140029870053184] Epoch[89] Batch[0] avg_epoch_loss=2.195477\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:48 INFO 140029870053184] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.19547724724\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:54 INFO 140029870053184] Epoch[89] Batch[5] avg_epoch_loss=2.168126\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:54 INFO 140029870053184] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.16812642415\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:28:54 INFO 140029870053184] Epoch[89] Batch [5]#011Speed: 100.23 samples/sec#011loss=2.168126\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:00 INFO 140029870053184] processed a total of 1275 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15796.379804611206, \"sum\": 15796.379804611206, \"min\": 15796.379804611206}}, \"EndTime\": 1586453340.032044, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453324.235152}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:00 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=80.7140312335 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:00 INFO 140029870053184] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:00 INFO 140029870053184] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.1474271059\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:00 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:04 INFO 140029870053184] Epoch[90] Batch[0] avg_epoch_loss=2.176377\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:04 INFO 140029870053184] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.17637658119\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:10 INFO 140029870053184] Epoch[90] Batch[5] avg_epoch_loss=2.123407\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:10 INFO 140029870053184] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.12340700626\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:10 INFO 140029870053184] Epoch[90] Batch [5]#011Speed: 99.67 samples/sec#011loss=2.123407\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:16 INFO 140029870053184] processed a total of 1276 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15992.499113082886, \"sum\": 15992.499113082886, \"min\": 15992.499113082886}}, \"EndTime\": 1586453356.025176, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453340.03213}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:16 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.7866875172 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:16 INFO 140029870053184] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:16 INFO 140029870053184] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.13201332092\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:16 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:20 INFO 140029870053184] Epoch[91] Batch[0] avg_epoch_loss=2.202119\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:20 INFO 140029870053184] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.20211863518\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:26 INFO 140029870053184] Epoch[91] Batch[5] avg_epoch_loss=2.158368\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:26 INFO 140029870053184] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.15836815039\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:26 INFO 140029870053184] Epoch[91] Batch [5]#011Speed: 99.75 samples/sec#011loss=2.158368\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:33 INFO 140029870053184] Epoch[91] Batch[10] avg_epoch_loss=2.093107\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:33 INFO 140029870053184] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=2.01479375362\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:33 INFO 140029870053184] Epoch[91] Batch [10]#011Speed: 100.06 samples/sec#011loss=2.014794\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:33 INFO 140029870053184] processed a total of 1331 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17289.08681869507, \"sum\": 17289.08681869507, \"min\": 17289.08681869507}}, \"EndTime\": 1586453373.314868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453356.025279}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:33 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=76.9844893581 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:33 INFO 140029870053184] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:33 INFO 140029870053184] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.09310706095\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:33 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:37 INFO 140029870053184] Epoch[92] Batch[0] avg_epoch_loss=2.162386\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:37 INFO 140029870053184] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.16238570213\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:44 INFO 140029870053184] Epoch[92] Batch[5] avg_epoch_loss=2.159451\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:44 INFO 140029870053184] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.15945072969\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:44 INFO 140029870053184] Epoch[92] Batch [5]#011Speed: 98.75 samples/sec#011loss=2.159451\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:49 INFO 140029870053184] processed a total of 1271 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16006.611108779907, \"sum\": 16006.611108779907, \"min\": 16006.611108779907}}, \"EndTime\": 1586453389.321995, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453373.314942}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:49 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=79.4041108995 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:49 INFO 140029870053184] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:49 INFO 140029870053184] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.16407411098\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:49 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:53 INFO 140029870053184] Epoch[93] Batch[0] avg_epoch_loss=2.127537\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:29:53 INFO 140029870053184] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.12753725052\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:00 INFO 140029870053184] Epoch[93] Batch[5] avg_epoch_loss=2.072748\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:00 INFO 140029870053184] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.0727481246\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:00 INFO 140029870053184] Epoch[93] Batch [5]#011Speed: 99.42 samples/sec#011loss=2.072748\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:05 INFO 140029870053184] processed a total of 1243 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15973.39391708374, \"sum\": 15973.39391708374, \"min\": 15973.39391708374}}, \"EndTime\": 1586453405.295906, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453389.322073}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:05 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=77.8163879659 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:05 INFO 140029870053184] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:05 INFO 140029870053184] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.11059423685\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:05 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:09 INFO 140029870053184] Epoch[94] Batch[0] avg_epoch_loss=2.036999\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:09 INFO 140029870053184] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.03699874878\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:16 INFO 140029870053184] Epoch[94] Batch[5] avg_epoch_loss=2.121662\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:16 INFO 140029870053184] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.12166210016\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:16 INFO 140029870053184] Epoch[94] Batch [5]#011Speed: 98.53 samples/sec#011loss=2.121662\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:21 INFO 140029870053184] processed a total of 1243 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15982.325077056885, \"sum\": 15982.325077056885, \"min\": 15982.325077056885}}, \"EndTime\": 1586453421.278836, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453405.295979}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:21 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=77.7725111627 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:21 INFO 140029870053184] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:21 INFO 140029870053184] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.11769118309\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:21 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:25 INFO 140029870053184] Epoch[95] Batch[0] avg_epoch_loss=2.129890\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:25 INFO 140029870053184] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.12989020348\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:32 INFO 140029870053184] Epoch[95] Batch[5] avg_epoch_loss=2.108236\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:32 INFO 140029870053184] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.10823639234\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:32 INFO 140029870053184] Epoch[95] Batch [5]#011Speed: 99.23 samples/sec#011loss=2.108236\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:38 INFO 140029870053184] Epoch[95] Batch[10] avg_epoch_loss=2.138254\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:38 INFO 140029870053184] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=2.17427577972\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:38 INFO 140029870053184] Epoch[95] Batch [10]#011Speed: 98.97 samples/sec#011loss=2.174276\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:38 INFO 140029870053184] processed a total of 1289 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17370.256900787354, \"sum\": 17370.256900787354, \"min\": 17370.256900787354}}, \"EndTime\": 1586453438.649806, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453421.278981}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:38 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=74.2068372117 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:38 INFO 140029870053184] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:38 INFO 140029870053184] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.1382542957\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:38 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:43 INFO 140029870053184] Epoch[96] Batch[0] avg_epoch_loss=2.151215\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:43 INFO 140029870053184] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.15121507645\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:49 INFO 140029870053184] Epoch[96] Batch[5] avg_epoch_loss=2.122397\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:49 INFO 140029870053184] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.12239650885\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:49 INFO 140029870053184] Epoch[96] Batch [5]#011Speed: 98.08 samples/sec#011loss=2.122397\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:56 INFO 140029870053184] Epoch[96] Batch[10] avg_epoch_loss=2.083787\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:56 INFO 140029870053184] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=2.03745512962\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:56 INFO 140029870053184] Epoch[96] Batch [10]#011Speed: 98.79 samples/sec#011loss=2.037455\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:56 INFO 140029870053184] processed a total of 1325 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17460.40415763855, \"sum\": 17460.40415763855, \"min\": 17460.40415763855}}, \"EndTime\": 1586453456.110682, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453438.649879}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:56 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=75.8854614783 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:56 INFO 140029870053184] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:56 INFO 140029870053184] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.08378679102\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:30:56 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:00 INFO 140029870053184] Epoch[97] Batch[0] avg_epoch_loss=2.220418\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:00 INFO 140029870053184] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.2204182148\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:06 INFO 140029870053184] Epoch[97] Batch[5] avg_epoch_loss=2.293926\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:06 INFO 140029870053184] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.29392627875\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:06 INFO 140029870053184] Epoch[97] Batch [5]#011Speed: 100.09 samples/sec#011loss=2.293926\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] Epoch[97] Batch[10] avg_epoch_loss=2.178512\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=2.04001390934\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] Epoch[97] Batch [10]#011Speed: 99.86 samples/sec#011loss=2.040014\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] processed a total of 1288 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 17173.764944076538, \"sum\": 17173.764944076538, \"min\": 17173.764944076538}}, \"EndTime\": 1586453473.285013, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453456.110765}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] #throughput_metric: host=algo-1, train throughput=74.9975820221 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.17851156538\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] Loading parameters from best epoch (87)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 71.52509689331055, \"sum\": 71.52509689331055, \"min\": 71.52509689331055}}, \"EndTime\": 1586453473.357211, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453473.285096}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] stopping training now\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] Final loss: 2.05221748352 (occurred at epoch 87)\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] #quality_metric: host=algo-1, train final_loss <loss>=2.05221748352\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 WARNING 140029870053184] You are using large values for `context_length` and/or `prediction_length`. The following step may take some time. If the step crashes, use an instance with more memory or reduce these two parameters.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 WARNING 140029870053184] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:13 INFO 140029870053184] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 2600.736141204834, \"sum\": 2600.736141204834, \"min\": 2600.736141204834}}, \"EndTime\": 1586453475.958972, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453473.357277}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:16 INFO 140029870053184] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 3369.234085083008, \"sum\": 3369.234085083008, \"min\": 3369.234085083008}}, \"EndTime\": 1586453476.727429, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453475.959043}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:16 INFO 140029870053184] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:16 INFO 140029870053184] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 118.13592910766602, \"sum\": 118.13592910766602, \"min\": 118.13592910766602}}, \"EndTime\": 1586453476.845691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453476.727505}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:16 INFO 140029870053184] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:31:16 INFO 140029870053184] No test data passed, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 1640130.115032196, \"sum\": 1640130.115032196, \"min\": 1640130.115032196}, \"setuptime\": {\"count\": 1, \"max\": 8.996009826660156, \"sum\": 8.996009826660156, \"min\": 8.996009826660156}}, \"EndTime\": 1586453477.017817, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453476.845747}\n",
      "\u001b[0m\n",
      "\n",
      "2020-04-09 17:31:31 Uploading - Uploading generated training model\n",
      "2020-04-09 17:31:31 Completed - Training job completed\n",
      "Training seconds: 1717\n",
      "Billable seconds: 1717\n"
     ]
    }
   ],
   "source": [
    "estimator_sj = fit_model(train_path, f'{prefix}-deepar-{tag}-SJ', str(PREDICTION_LENGTH_SJ), str(PREDICTION_LENGTH_SJ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-09 17:31:52 Starting - Starting the training job...\n",
      "2020-04-09 17:31:54 Starting - Launching requested ML instances...\n",
      "2020-04-09 17:32:49 Starting - Preparing the instances for training......\n",
      "2020-04-09 17:33:50 Downloading - Downloading input data...\n",
      "2020-04-09 17:34:03 Training - Downloading the training image...\n",
      "2020-04-09 17:34:40 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.003', u'num_cells': u'40', u'prediction_length': u'156', u'epochs': u'100', u'time_freq': u'W', u'context_length': u'260', u'num_layers': u'2', u'mini_batch_size': u'128', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'0.003', u'num_layers': u'2', u'epochs': u'100', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'128', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'156', u'time_freq': u'W', u'context_length': u'260', u'_kvstore': u'auto', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train_pp.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train_pp.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] [cardinality=auto] Inferred value of cardinality=[2] from dataset.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=20 from dataset.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] Training set statistics:\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] Integer time series\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] number of time series: 2\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] number of observations: 1456\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] mean target length: 728\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] min/mean/max target: 0.0/24.6751373626/461.0\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] mean abs(target): 24.6751373626\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] contains missing values: no\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] Small number of time series. Doing 640 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] No test channel found not running evaluations\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] nvidia-smi took: 0.0252380371094 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:43 INFO 139873125553984] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 1957.59916305542, \"sum\": 1957.59916305542, \"min\": 1957.59916305542}}, \"EndTime\": 1586453685.56098, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453683.602346}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:45 INFO 139873125553984] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 3891.942024230957, \"sum\": 3891.942024230957, \"min\": 3891.942024230957}}, \"EndTime\": 1586453687.494435, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453685.561069}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:52 INFO 139873125553984] Epoch[0] Batch[0] avg_epoch_loss=4.367054\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:52 INFO 139873125553984] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=4.36705350876\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:58 INFO 139873125553984] Epoch[0] Batch[5] avg_epoch_loss=3.946916\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:58 INFO 139873125553984] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.94691638152\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:34:58 INFO 139873125553984] Epoch[0] Batch [5]#011Speed: 112.42 samples/sec#011loss=3.946916\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:03 INFO 139873125553984] Epoch[0] Batch[10] avg_epoch_loss=3.740709\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:03 INFO 139873125553984] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.49326043129\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:03 INFO 139873125553984] Epoch[0] Batch [10]#011Speed: 120.61 samples/sec#011loss=3.493260\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:03 INFO 139873125553984] processed a total of 1292 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}, \"update.time\": {\"count\": 1, \"max\": 15826.987028121948, \"sum\": 15826.987028121948, \"min\": 15826.987028121948}}, \"EndTime\": 1586453703.321602, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453687.494526}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:03 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=81.6320546948 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:03 INFO 139873125553984] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:03 INFO 139873125553984] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.74070913141\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:03 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:03 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_087a52aa-bf62-4f23-9a21-50fe55ac8a7a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 154.93083000183105, \"sum\": 154.93083000183105, \"min\": 154.93083000183105}}, \"EndTime\": 1586453703.477273, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453703.321692}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:07 INFO 139873125553984] Epoch[1] Batch[0] avg_epoch_loss=3.326195\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:07 INFO 139873125553984] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.32619547844\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:13 INFO 139873125553984] Epoch[1] Batch[5] avg_epoch_loss=3.355248\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:13 INFO 139873125553984] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.35524817308\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:13 INFO 139873125553984] Epoch[1] Batch [5]#011Speed: 124.58 samples/sec#011loss=3.355248\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:18 INFO 139873125553984] Epoch[1] Batch[10] avg_epoch_loss=3.275344\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:18 INFO 139873125553984] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.1794593811\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:18 INFO 139873125553984] Epoch[1] Batch [10]#011Speed: 123.09 samples/sec#011loss=3.179459\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:18 INFO 139873125553984] processed a total of 1354 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14762.663841247559, \"sum\": 14762.663841247559, \"min\": 14762.663841247559}}, \"EndTime\": 1586453718.240083, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453703.477356}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:18 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=91.717123754 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:18 INFO 139873125553984] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:18 INFO 139873125553984] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.27534417673\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:18 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:18 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_904c1b3a-cac2-41af-ba16-b6991c2ee346-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 164.3080711364746, \"sum\": 164.3080711364746, \"min\": 164.3080711364746}}, \"EndTime\": 1586453718.404923, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453718.240165}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:22 INFO 139873125553984] Epoch[2] Batch[0] avg_epoch_loss=2.988431\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:22 INFO 139873125553984] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=2.98843073845\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:27 INFO 139873125553984] Epoch[2] Batch[5] avg_epoch_loss=3.013933\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:27 INFO 139873125553984] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.01393258572\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:27 INFO 139873125553984] Epoch[2] Batch [5]#011Speed: 123.78 samples/sec#011loss=3.013933\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:33 INFO 139873125553984] Epoch[2] Batch[10] avg_epoch_loss=2.996564\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:33 INFO 139873125553984] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=2.97572073936\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:33 INFO 139873125553984] Epoch[2] Batch [10]#011Speed: 122.48 samples/sec#011loss=2.975721\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:33 INFO 139873125553984] processed a total of 1286 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14633.5928440094, \"sum\": 14633.5928440094, \"min\": 14633.5928440094}}, \"EndTime\": 1586453733.038661, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453718.405002}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:33 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=87.8792803305 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:33 INFO 139873125553984] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:33 INFO 139873125553984] #quality_metric: host=algo-1, epoch=2, train loss <loss>=2.99656356465\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:33 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:33 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_d685490f-7b01-48da-91d5-ae9a0f6b2f32-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 146.49200439453125, \"sum\": 146.49200439453125, \"min\": 146.49200439453125}}, \"EndTime\": 1586453733.185863, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453733.038738}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:37 INFO 139873125553984] Epoch[3] Batch[0] avg_epoch_loss=2.960940\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:37 INFO 139873125553984] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=2.96093964577\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:42 INFO 139873125553984] Epoch[3] Batch[5] avg_epoch_loss=2.866766\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:42 INFO 139873125553984] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=2.86676649253\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:42 INFO 139873125553984] Epoch[3] Batch [5]#011Speed: 124.37 samples/sec#011loss=2.866766\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:46 INFO 139873125553984] processed a total of 1268 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13517.4720287323, \"sum\": 13517.4720287323, \"min\": 13517.4720287323}}, \"EndTime\": 1586453746.70348, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453733.185939}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:46 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=93.8036416406 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:46 INFO 139873125553984] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:46 INFO 139873125553984] #quality_metric: host=algo-1, epoch=3, train loss <loss>=2.88218510151\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:46 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:46 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_e946a351-5529-4878-9763-438f6be23bd9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 148.83708953857422, \"sum\": 148.83708953857422, \"min\": 148.83708953857422}}, \"EndTime\": 1586453746.853109, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453746.703568}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:51 INFO 139873125553984] Epoch[4] Batch[0] avg_epoch_loss=2.803231\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:51 INFO 139873125553984] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=2.80323123932\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:56 INFO 139873125553984] Epoch[4] Batch[5] avg_epoch_loss=2.843783\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:56 INFO 139873125553984] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=2.84378333886\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:35:56 INFO 139873125553984] Epoch[4] Batch [5]#011Speed: 123.37 samples/sec#011loss=2.843783\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:00 INFO 139873125553984] processed a total of 1279 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13618.714094161987, \"sum\": 13618.714094161987, \"min\": 13618.714094161987}}, \"EndTime\": 1586453760.471993, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453746.853174}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:00 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=93.9125428665 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:00 INFO 139873125553984] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:00 INFO 139873125553984] #quality_metric: host=algo-1, epoch=4, train loss <loss>=2.82521288395\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:00 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:00 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_2bc58f70-cc53-402d-9a3e-cb2e0877403a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 155.04884719848633, \"sum\": 155.04884719848633, \"min\": 155.04884719848633}}, \"EndTime\": 1586453760.627819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453760.472255}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:04 INFO 139873125553984] Epoch[5] Batch[0] avg_epoch_loss=2.881898\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:04 INFO 139873125553984] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=2.88189840317\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:10 INFO 139873125553984] Epoch[5] Batch[5] avg_epoch_loss=2.809076\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:10 INFO 139873125553984] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=2.80907607079\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:10 INFO 139873125553984] Epoch[5] Batch [5]#011Speed: 124.27 samples/sec#011loss=2.809076\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:15 INFO 139873125553984] Epoch[5] Batch[10] avg_epoch_loss=2.765710\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:15 INFO 139873125553984] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=2.71367049217\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:15 INFO 139873125553984] Epoch[5] Batch [10]#011Speed: 123.62 samples/sec#011loss=2.713670\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:15 INFO 139873125553984] processed a total of 1302 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14631.534099578857, \"sum\": 14631.534099578857, \"min\": 14631.534099578857}}, \"EndTime\": 1586453775.259494, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453760.627893}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:15 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=88.9851244653 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:15 INFO 139873125553984] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:15 INFO 139873125553984] #quality_metric: host=algo-1, epoch=5, train loss <loss>=2.76570989869\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:15 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:15 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_449f7466-c522-491a-ba71-cb51318f816c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 145.4751491546631, \"sum\": 145.4751491546631, \"min\": 145.4751491546631}}, \"EndTime\": 1586453775.405638, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453775.25958}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:19 INFO 139873125553984] Epoch[6] Batch[0] avg_epoch_loss=2.677922\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:19 INFO 139873125553984] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=2.67792201042\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:24 INFO 139873125553984] Epoch[6] Batch[5] avg_epoch_loss=2.778829\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:24 INFO 139873125553984] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=2.77882949511\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:24 INFO 139873125553984] Epoch[6] Batch [5]#011Speed: 124.09 samples/sec#011loss=2.778829\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:30 INFO 139873125553984] Epoch[6] Batch[10] avg_epoch_loss=2.761709\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:30 INFO 139873125553984] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=2.74116339684\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:30 INFO 139873125553984] Epoch[6] Batch [10]#011Speed: 122.64 samples/sec#011loss=2.741163\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:30 INFO 139873125553984] processed a total of 1282 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14629.791021347046, \"sum\": 14629.791021347046, \"min\": 14629.791021347046}}, \"EndTime\": 1586453790.035566, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453775.405714}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:30 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=87.6287247052 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:30 INFO 139873125553984] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:30 INFO 139873125553984] #quality_metric: host=algo-1, epoch=6, train loss <loss>=2.76170854135\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:30 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:30 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_9172bcf7-c8b8-40eb-98d9-fecb89f64805-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 147.3681926727295, \"sum\": 147.3681926727295, \"min\": 147.3681926727295}}, \"EndTime\": 1586453790.183692, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453790.035643}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:34 INFO 139873125553984] Epoch[7] Batch[0] avg_epoch_loss=2.830589\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:34 INFO 139873125553984] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=2.83058905602\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:39 INFO 139873125553984] Epoch[7] Batch[5] avg_epoch_loss=2.788203\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:39 INFO 139873125553984] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=2.78820347786\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:39 INFO 139873125553984] Epoch[7] Batch [5]#011Speed: 123.75 samples/sec#011loss=2.788203\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:43 INFO 139873125553984] processed a total of 1247 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13517.78507232666, \"sum\": 13517.78507232666, \"min\": 13517.78507232666}}, \"EndTime\": 1586453803.701622, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453790.183771}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:43 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=92.2480433326 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:43 INFO 139873125553984] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:43 INFO 139873125553984] #quality_metric: host=algo-1, epoch=7, train loss <loss>=2.81800701618\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:43 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:47 INFO 139873125553984] Epoch[8] Batch[0] avg_epoch_loss=2.886855\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:47 INFO 139873125553984] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=2.88685536385\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:53 INFO 139873125553984] Epoch[8] Batch[5] avg_epoch_loss=2.733479\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:53 INFO 139873125553984] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=2.73347949982\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:53 INFO 139873125553984] Epoch[8] Batch [5]#011Speed: 124.39 samples/sec#011loss=2.733479\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:58 INFO 139873125553984] Epoch[8] Batch[10] avg_epoch_loss=2.768009\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:58 INFO 139873125553984] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=2.80944337845\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:58 INFO 139873125553984] Epoch[8] Batch [10]#011Speed: 122.99 samples/sec#011loss=2.809443\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:58 INFO 139873125553984] processed a total of 1301 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14588.613033294678, \"sum\": 14588.613033294678, \"min\": 14588.613033294678}}, \"EndTime\": 1586453818.290804, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453803.7017}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:58 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=89.1784341526 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:58 INFO 139873125553984] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:58 INFO 139873125553984] #quality_metric: host=algo-1, epoch=8, train loss <loss>=2.76800853556\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:36:58 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:02 INFO 139873125553984] Epoch[9] Batch[0] avg_epoch_loss=2.672303\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:02 INFO 139873125553984] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=2.67230296135\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:07 INFO 139873125553984] Epoch[9] Batch[5] avg_epoch_loss=2.720781\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:07 INFO 139873125553984] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=2.72078084946\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:07 INFO 139873125553984] Epoch[9] Batch [5]#011Speed: 123.48 samples/sec#011loss=2.720781\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:11 INFO 139873125553984] processed a total of 1250 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13530.79104423523, \"sum\": 13530.79104423523, \"min\": 13530.79104423523}}, \"EndTime\": 1586453831.822245, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453818.29088}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:11 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=92.3803773597 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:11 INFO 139873125553984] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:11 INFO 139873125553984] #quality_metric: host=algo-1, epoch=9, train loss <loss>=2.66515872478\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:11 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:11 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_31992f01-6857-42cd-8d99-05fd78c55a4e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 167.9239273071289, \"sum\": 167.9239273071289, \"min\": 167.9239273071289}}, \"EndTime\": 1586453831.990955, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453831.822392}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:16 INFO 139873125553984] Epoch[10] Batch[0] avg_epoch_loss=2.481364\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:16 INFO 139873125553984] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=2.48136425018\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:21 INFO 139873125553984] Epoch[10] Batch[5] avg_epoch_loss=2.669771\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:21 INFO 139873125553984] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=2.66977087657\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:21 INFO 139873125553984] Epoch[10] Batch [5]#011Speed: 123.67 samples/sec#011loss=2.669771\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:25 INFO 139873125553984] processed a total of 1265 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13549.942970275879, \"sum\": 13549.942970275879, \"min\": 13549.942970275879}}, \"EndTime\": 1586453845.541036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453831.991031}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:25 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=93.3575330965 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:25 INFO 139873125553984] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:25 INFO 139873125553984] #quality_metric: host=algo-1, epoch=10, train loss <loss>=2.69301834106\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:25 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:29 INFO 139873125553984] Epoch[11] Batch[0] avg_epoch_loss=2.759940\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:29 INFO 139873125553984] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=2.7599401474\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:35 INFO 139873125553984] Epoch[11] Batch[5] avg_epoch_loss=2.683553\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:35 INFO 139873125553984] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=2.68355337779\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:35 INFO 139873125553984] Epoch[11] Batch [5]#011Speed: 124.25 samples/sec#011loss=2.683553\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:39 INFO 139873125553984] processed a total of 1255 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13628.3540725708, \"sum\": 13628.3540725708, \"min\": 13628.3540725708}}, \"EndTime\": 1586453859.170016, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453845.541113}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:39 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=92.0856859085 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:39 INFO 139873125553984] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:39 INFO 139873125553984] #quality_metric: host=algo-1, epoch=11, train loss <loss>=2.67866015434\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:39 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:43 INFO 139873125553984] Epoch[12] Batch[0] avg_epoch_loss=2.667792\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:43 INFO 139873125553984] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=2.667791605\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:48 INFO 139873125553984] Epoch[12] Batch[5] avg_epoch_loss=2.662180\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:48 INFO 139873125553984] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.66218030453\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:48 INFO 139873125553984] Epoch[12] Batch [5]#011Speed: 124.41 samples/sec#011loss=2.662180\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:52 INFO 139873125553984] processed a total of 1268 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13578.021049499512, \"sum\": 13578.021049499512, \"min\": 13578.021049499512}}, \"EndTime\": 1586453872.74878, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453859.170182}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:52 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=93.3853628359 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:52 INFO 139873125553984] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:52 INFO 139873125553984] #quality_metric: host=algo-1, epoch=12, train loss <loss>=2.6549577713\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:52 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:52 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_9bf9cce1-29e4-489d-8e6e-37afadd52c0e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 157.22107887268066, \"sum\": 157.22107887268066, \"min\": 157.22107887268066}}, \"EndTime\": 1586453872.906717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453872.748866}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:57 INFO 139873125553984] Epoch[13] Batch[0] avg_epoch_loss=2.491514\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:37:57 INFO 139873125553984] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=2.49151420593\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:02 INFO 139873125553984] Epoch[13] Batch[5] avg_epoch_loss=2.609947\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:02 INFO 139873125553984] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=2.60994660854\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:02 INFO 139873125553984] Epoch[13] Batch [5]#011Speed: 121.26 samples/sec#011loss=2.609947\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:06 INFO 139873125553984] processed a total of 1252 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13649.538040161133, \"sum\": 13649.538040161133, \"min\": 13649.538040161133}}, \"EndTime\": 1586453886.556397, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453872.90679}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:06 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=91.7238828599 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:06 INFO 139873125553984] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:06 INFO 139873125553984] #quality_metric: host=algo-1, epoch=13, train loss <loss>=2.63444542885\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:06 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:06 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_5317fea0-9269-456e-bd9d-436bc1f5fd52-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 143.18108558654785, \"sum\": 143.18108558654785, \"min\": 143.18108558654785}}, \"EndTime\": 1586453886.700295, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453886.556481}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:11 INFO 139873125553984] Epoch[14] Batch[0] avg_epoch_loss=2.556809\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:11 INFO 139873125553984] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=2.55680894852\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:16 INFO 139873125553984] Epoch[14] Batch[5] avg_epoch_loss=2.642942\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:16 INFO 139873125553984] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=2.64294219017\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:16 INFO 139873125553984] Epoch[14] Batch [5]#011Speed: 123.69 samples/sec#011loss=2.642942\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:21 INFO 139873125553984] Epoch[14] Batch[10] avg_epoch_loss=2.571915\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:21 INFO 139873125553984] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=2.48668162823\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:21 INFO 139873125553984] Epoch[14] Batch [10]#011Speed: 123.59 samples/sec#011loss=2.486682\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:21 INFO 139873125553984] processed a total of 1325 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14680.463075637817, \"sum\": 14680.463075637817, \"min\": 14680.463075637817}}, \"EndTime\": 1586453901.380924, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453886.700369}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:21 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=90.2551539338 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:21 INFO 139873125553984] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:21 INFO 139873125553984] #quality_metric: host=algo-1, epoch=14, train loss <loss>=2.57191466201\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:21 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:21 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_f93e3c4e-caef-429c-83db-485278e4e859-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 149.50990676879883, \"sum\": 149.50990676879883, \"min\": 149.50990676879883}}, \"EndTime\": 1586453901.531111, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453901.380999}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:25 INFO 139873125553984] Epoch[15] Batch[0] avg_epoch_loss=2.559858\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:25 INFO 139873125553984] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=2.55985832214\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:31 INFO 139873125553984] Epoch[15] Batch[5] avg_epoch_loss=2.629277\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:31 INFO 139873125553984] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=2.6292771101\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:31 INFO 139873125553984] Epoch[15] Batch [5]#011Speed: 122.08 samples/sec#011loss=2.629277\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:36 INFO 139873125553984] Epoch[15] Batch[10] avg_epoch_loss=2.650309\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:36 INFO 139873125553984] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=2.67554631233\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:36 INFO 139873125553984] Epoch[15] Batch [10]#011Speed: 123.62 samples/sec#011loss=2.675546\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:36 INFO 139873125553984] processed a total of 1314 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14704.016923904419, \"sum\": 14704.016923904419, \"min\": 14704.016923904419}}, \"EndTime\": 1586453916.235273, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453901.53119}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:36 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=89.3624488962 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:36 INFO 139873125553984] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:36 INFO 139873125553984] #quality_metric: host=algo-1, epoch=15, train loss <loss>=2.65030856566\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:36 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:40 INFO 139873125553984] Epoch[16] Batch[0] avg_epoch_loss=2.596341\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:40 INFO 139873125553984] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=2.5963408947\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:45 INFO 139873125553984] Epoch[16] Batch[5] avg_epoch_loss=2.585087\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:45 INFO 139873125553984] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=2.58508682251\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:45 INFO 139873125553984] Epoch[16] Batch [5]#011Speed: 124.77 samples/sec#011loss=2.585087\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:50 INFO 139873125553984] Epoch[16] Batch[10] avg_epoch_loss=2.634211\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:50 INFO 139873125553984] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=2.69316020012\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:50 INFO 139873125553984] Epoch[16] Batch [10]#011Speed: 123.98 samples/sec#011loss=2.693160\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:50 INFO 139873125553984] processed a total of 1286 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14530.760049819946, \"sum\": 14530.760049819946, \"min\": 14530.760049819946}}, \"EndTime\": 1586453930.766784, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453916.235362}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:50 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=88.5009895638 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:50 INFO 139873125553984] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:50 INFO 139873125553984] #quality_metric: host=algo-1, epoch=16, train loss <loss>=2.63421108506\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:50 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:55 INFO 139873125553984] Epoch[17] Batch[0] avg_epoch_loss=2.554412\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:38:55 INFO 139873125553984] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=2.55441236496\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:00 INFO 139873125553984] Epoch[17] Batch[5] avg_epoch_loss=2.534848\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:00 INFO 139873125553984] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=2.53484817346\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:00 INFO 139873125553984] Epoch[17] Batch [5]#011Speed: 122.46 samples/sec#011loss=2.534848\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:05 INFO 139873125553984] Epoch[17] Batch[10] avg_epoch_loss=2.573740\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:05 INFO 139873125553984] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=2.62040920258\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:05 INFO 139873125553984] Epoch[17] Batch [10]#011Speed: 124.51 samples/sec#011loss=2.620409\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:05 INFO 139873125553984] processed a total of 1326 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14631.214141845703, \"sum\": 14631.214141845703, \"min\": 14631.214141845703}}, \"EndTime\": 1586453945.398664, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453930.766894}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:05 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=90.6274854723 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:05 INFO 139873125553984] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:05 INFO 139873125553984] #quality_metric: host=algo-1, epoch=17, train loss <loss>=2.57373955033\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:05 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:09 INFO 139873125553984] Epoch[18] Batch[0] avg_epoch_loss=2.443109\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:09 INFO 139873125553984] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=2.44310903549\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:14 INFO 139873125553984] Epoch[18] Batch[5] avg_epoch_loss=2.582887\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:14 INFO 139873125553984] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=2.58288721244\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:14 INFO 139873125553984] Epoch[18] Batch [5]#011Speed: 124.39 samples/sec#011loss=2.582887\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:20 INFO 139873125553984] Epoch[18] Batch[10] avg_epoch_loss=2.489270\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:20 INFO 139873125553984] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=2.37692883015\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:20 INFO 139873125553984] Epoch[18] Batch [10]#011Speed: 124.06 samples/sec#011loss=2.376929\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:20 INFO 139873125553984] processed a total of 1306 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14637.373924255371, \"sum\": 14637.373924255371, \"min\": 14637.373924255371}}, \"EndTime\": 1586453960.036493, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453945.398738}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:20 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=89.2229050239 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:20 INFO 139873125553984] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:20 INFO 139873125553984] #quality_metric: host=algo-1, epoch=18, train loss <loss>=2.48926976594\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:20 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:20 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_354c828d-4139-477c-9a02-e872a630ff68-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 160.31813621520996, \"sum\": 160.31813621520996, \"min\": 160.31813621520996}}, \"EndTime\": 1586453960.197379, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453960.036565}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:24 INFO 139873125553984] Epoch[19] Batch[0] avg_epoch_loss=2.559434\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:24 INFO 139873125553984] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=2.55943441391\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:29 INFO 139873125553984] Epoch[19] Batch[5] avg_epoch_loss=2.569280\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:29 INFO 139873125553984] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=2.56927994887\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:29 INFO 139873125553984] Epoch[19] Batch [5]#011Speed: 124.80 samples/sec#011loss=2.569280\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:34 INFO 139873125553984] Epoch[19] Batch[10] avg_epoch_loss=2.626298\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:34 INFO 139873125553984] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=2.69471964836\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:34 INFO 139873125553984] Epoch[19] Batch [10]#011Speed: 122.22 samples/sec#011loss=2.694720\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:34 INFO 139873125553984] processed a total of 1285 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14614.233016967773, \"sum\": 14614.233016967773, \"min\": 14614.233016967773}}, \"EndTime\": 1586453974.811765, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453960.197462}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:34 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=87.9265248297 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:34 INFO 139873125553984] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:34 INFO 139873125553984] #quality_metric: host=algo-1, epoch=19, train loss <loss>=2.62629799409\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:34 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:39 INFO 139873125553984] Epoch[20] Batch[0] avg_epoch_loss=2.653298\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:39 INFO 139873125553984] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=2.65329790115\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:44 INFO 139873125553984] Epoch[20] Batch[5] avg_epoch_loss=2.670833\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:44 INFO 139873125553984] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=2.67083291213\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:44 INFO 139873125553984] Epoch[20] Batch [5]#011Speed: 123.80 samples/sec#011loss=2.670833\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:49 INFO 139873125553984] Epoch[20] Batch[10] avg_epoch_loss=2.685319\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:49 INFO 139873125553984] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=2.70270328522\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:49 INFO 139873125553984] Epoch[20] Batch [10]#011Speed: 123.28 samples/sec#011loss=2.702703\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:49 INFO 139873125553984] processed a total of 1288 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14635.23006439209, \"sum\": 14635.23006439209, \"min\": 14635.23006439209}}, \"EndTime\": 1586453989.448079, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453974.811963}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:49 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=88.0054626538 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:49 INFO 139873125553984] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:49 INFO 139873125553984] #quality_metric: host=algo-1, epoch=20, train loss <loss>=2.68531944535\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:49 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:53 INFO 139873125553984] Epoch[21] Batch[0] avg_epoch_loss=2.593958\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:53 INFO 139873125553984] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=2.59395837784\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:59 INFO 139873125553984] Epoch[21] Batch[5] avg_epoch_loss=2.608380\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:59 INFO 139873125553984] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=2.60838047663\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:39:59 INFO 139873125553984] Epoch[21] Batch [5]#011Speed: 121.44 samples/sec#011loss=2.608380\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:04 INFO 139873125553984] Epoch[21] Batch[10] avg_epoch_loss=2.516111\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:04 INFO 139873125553984] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=2.40538806915\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:04 INFO 139873125553984] Epoch[21] Batch [10]#011Speed: 121.49 samples/sec#011loss=2.405388\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:04 INFO 139873125553984] processed a total of 1295 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14831.284046173096, \"sum\": 14831.284046173096, \"min\": 14831.284046173096}}, \"EndTime\": 1586454004.280306, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586453989.448161}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:04 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=87.3146744229 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:04 INFO 139873125553984] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:04 INFO 139873125553984] #quality_metric: host=algo-1, epoch=21, train loss <loss>=2.51611120051\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:04 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:08 INFO 139873125553984] Epoch[22] Batch[0] avg_epoch_loss=2.595463\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:08 INFO 139873125553984] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=2.59546256065\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:13 INFO 139873125553984] Epoch[22] Batch[5] avg_epoch_loss=2.532254\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:13 INFO 139873125553984] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=2.53225390116\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:13 INFO 139873125553984] Epoch[22] Batch [5]#011Speed: 123.96 samples/sec#011loss=2.532254\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:17 INFO 139873125553984] processed a total of 1232 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13541.178941726685, \"sum\": 13541.178941726685, \"min\": 13541.178941726685}}, \"EndTime\": 1586454017.822132, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454004.280393}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:17 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=90.9808781753 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:17 INFO 139873125553984] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:17 INFO 139873125553984] #quality_metric: host=algo-1, epoch=22, train loss <loss>=2.49727571011\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:17 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:22 INFO 139873125553984] Epoch[23] Batch[0] avg_epoch_loss=2.527766\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:22 INFO 139873125553984] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=2.52776575089\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:27 INFO 139873125553984] Epoch[23] Batch[5] avg_epoch_loss=2.532830\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:27 INFO 139873125553984] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=2.53282999992\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:27 INFO 139873125553984] Epoch[23] Batch [5]#011Speed: 124.47 samples/sec#011loss=2.532830\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:32 INFO 139873125553984] Epoch[23] Batch[10] avg_epoch_loss=2.480191\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:32 INFO 139873125553984] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=2.4170232296\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:32 INFO 139873125553984] Epoch[23] Batch [10]#011Speed: 123.13 samples/sec#011loss=2.417023\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:32 INFO 139873125553984] processed a total of 1314 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14696.704149246216, \"sum\": 14696.704149246216, \"min\": 14696.704149246216}}, \"EndTime\": 1586454032.519383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454017.82222}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:32 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=89.4070845 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:32 INFO 139873125553984] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:32 INFO 139873125553984] #quality_metric: host=algo-1, epoch=23, train loss <loss>=2.48019055887\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:32 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:32 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_fb953dcb-60f2-4611-acfc-e4e324d2f2be-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 171.88382148742676, \"sum\": 171.88382148742676, \"min\": 171.88382148742676}}, \"EndTime\": 1586454032.691905, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454032.519465}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:36 INFO 139873125553984] Epoch[24] Batch[0] avg_epoch_loss=2.431885\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:36 INFO 139873125553984] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.43188500404\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:42 INFO 139873125553984] Epoch[24] Batch[5] avg_epoch_loss=2.491835\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:42 INFO 139873125553984] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.49183511734\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:42 INFO 139873125553984] Epoch[24] Batch [5]#011Speed: 124.04 samples/sec#011loss=2.491835\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:46 INFO 139873125553984] processed a total of 1252 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13563.631057739258, \"sum\": 13563.631057739258, \"min\": 13563.631057739258}}, \"EndTime\": 1586454046.255715, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454032.691979}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:46 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=92.304639086 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:46 INFO 139873125553984] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:46 INFO 139873125553984] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.54403414726\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:46 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:50 INFO 139873125553984] Epoch[25] Batch[0] avg_epoch_loss=2.473814\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:50 INFO 139873125553984] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=2.4738137722\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:55 INFO 139873125553984] Epoch[25] Batch[5] avg_epoch_loss=2.474040\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:55 INFO 139873125553984] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=2.47404003143\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:55 INFO 139873125553984] Epoch[25] Batch [5]#011Speed: 123.58 samples/sec#011loss=2.474040\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:59 INFO 139873125553984] processed a total of 1264 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13547.756910324097, \"sum\": 13547.756910324097, \"min\": 13547.756910324097}}, \"EndTime\": 1586454059.804163, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454046.25579}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:59 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=93.298668194 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:59 INFO 139873125553984] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:59 INFO 139873125553984] #quality_metric: host=algo-1, epoch=25, train loss <loss>=2.45965275764\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:59 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:40:59 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_2ba4e7e5-c6fa-453f-8187-5b8b7c57f4d9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 168.4558391571045, \"sum\": 168.4558391571045, \"min\": 168.4558391571045}}, \"EndTime\": 1586454059.973351, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454059.804251}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:04 INFO 139873125553984] Epoch[26] Batch[0] avg_epoch_loss=2.479703\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:04 INFO 139873125553984] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=2.47970271111\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:09 INFO 139873125553984] Epoch[26] Batch[5] avg_epoch_loss=2.496056\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:09 INFO 139873125553984] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.49605584145\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:09 INFO 139873125553984] Epoch[26] Batch [5]#011Speed: 122.51 samples/sec#011loss=2.496056\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:14 INFO 139873125553984] Epoch[26] Batch[10] avg_epoch_loss=2.489204\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:14 INFO 139873125553984] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=2.48098196983\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:14 INFO 139873125553984] Epoch[26] Batch [10]#011Speed: 124.32 samples/sec#011loss=2.480982\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:14 INFO 139873125553984] processed a total of 1282 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14648.585081100464, \"sum\": 14648.585081100464, \"min\": 14648.585081100464}}, \"EndTime\": 1586454074.622069, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454059.973425}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:14 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=87.5162926839 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:14 INFO 139873125553984] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:14 INFO 139873125553984] #quality_metric: host=algo-1, epoch=26, train loss <loss>=2.48920408162\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:14 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:18 INFO 139873125553984] Epoch[27] Batch[0] avg_epoch_loss=2.484319\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:18 INFO 139873125553984] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=2.48431897163\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:24 INFO 139873125553984] Epoch[27] Batch[5] avg_epoch_loss=2.445362\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:24 INFO 139873125553984] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=2.44536161423\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:24 INFO 139873125553984] Epoch[27] Batch [5]#011Speed: 123.67 samples/sec#011loss=2.445362\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:29 INFO 139873125553984] Epoch[27] Batch[10] avg_epoch_loss=2.462738\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:29 INFO 139873125553984] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=2.48358998299\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:29 INFO 139873125553984] Epoch[27] Batch [10]#011Speed: 123.43 samples/sec#011loss=2.483590\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:29 INFO 139873125553984] processed a total of 1292 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14648.416996002197, \"sum\": 14648.416996002197, \"min\": 14648.416996002197}}, \"EndTime\": 1586454089.271053, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454074.622149}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:29 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=88.1997968995 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:29 INFO 139873125553984] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:29 INFO 139873125553984] #quality_metric: host=algo-1, epoch=27, train loss <loss>=2.46273814548\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:29 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:33 INFO 139873125553984] Epoch[28] Batch[0] avg_epoch_loss=2.466946\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:33 INFO 139873125553984] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=2.46694564819\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:38 INFO 139873125553984] Epoch[28] Batch[5] avg_epoch_loss=2.493829\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:38 INFO 139873125553984] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=2.49382873376\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:38 INFO 139873125553984] Epoch[28] Batch [5]#011Speed: 123.98 samples/sec#011loss=2.493829\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:42 INFO 139873125553984] processed a total of 1279 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13727.363109588623, \"sum\": 13727.363109588623, \"min\": 13727.363109588623}}, \"EndTime\": 1586454102.999344, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454089.271138}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:42 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=93.1707240383 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:42 INFO 139873125553984] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:42 INFO 139873125553984] #quality_metric: host=algo-1, epoch=28, train loss <loss>=2.47682733536\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:42 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:47 INFO 139873125553984] Epoch[29] Batch[0] avg_epoch_loss=2.466405\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:47 INFO 139873125553984] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.46640467644\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:52 INFO 139873125553984] Epoch[29] Batch[5] avg_epoch_loss=2.486071\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:52 INFO 139873125553984] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.48607051373\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:52 INFO 139873125553984] Epoch[29] Batch [5]#011Speed: 122.87 samples/sec#011loss=2.486071\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:57 INFO 139873125553984] Epoch[29] Batch[10] avg_epoch_loss=2.538743\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:57 INFO 139873125553984] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=2.60194969177\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:57 INFO 139873125553984] Epoch[29] Batch [10]#011Speed: 123.44 samples/sec#011loss=2.601950\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:57 INFO 139873125553984] processed a total of 1295 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14679.049015045166, \"sum\": 14679.049015045166, \"min\": 14679.049015045166}}, \"EndTime\": 1586454117.678974, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454102.999432}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:57 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=88.2202459937 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:57 INFO 139873125553984] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:57 INFO 139873125553984] #quality_metric: host=algo-1, epoch=29, train loss <loss>=2.53874286738\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:41:57 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:02 INFO 139873125553984] Epoch[30] Batch[0] avg_epoch_loss=2.642100\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:02 INFO 139873125553984] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=2.64209961891\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:07 INFO 139873125553984] Epoch[30] Batch[5] avg_epoch_loss=2.532509\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:07 INFO 139873125553984] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.53250940641\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:07 INFO 139873125553984] Epoch[30] Batch [5]#011Speed: 123.78 samples/sec#011loss=2.532509\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:11 INFO 139873125553984] processed a total of 1271 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13631.173849105835, \"sum\": 13631.173849105835, \"min\": 13631.173849105835}}, \"EndTime\": 1586454131.310794, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454117.679057}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:11 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=93.2413524256 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:11 INFO 139873125553984] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:11 INFO 139873125553984] #quality_metric: host=algo-1, epoch=30, train loss <loss>=2.54767522812\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:11 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:15 INFO 139873125553984] Epoch[31] Batch[0] avg_epoch_loss=2.557393\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:15 INFO 139873125553984] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.5573925972\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:20 INFO 139873125553984] Epoch[31] Batch[5] avg_epoch_loss=2.469449\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:20 INFO 139873125553984] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.46944936117\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:20 INFO 139873125553984] Epoch[31] Batch [5]#011Speed: 123.27 samples/sec#011loss=2.469449\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:24 INFO 139873125553984] processed a total of 1256 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13611.791133880615, \"sum\": 13611.791133880615, \"min\": 13611.791133880615}}, \"EndTime\": 1586454144.923264, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454131.310872}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:24 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=92.272100561 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:24 INFO 139873125553984] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:24 INFO 139873125553984] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.43417439461\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:24 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:25 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_7a265ae9-dc0b-4a68-8722-5c36f9619167-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 146.18921279907227, \"sum\": 146.18921279907227, \"min\": 146.18921279907227}}, \"EndTime\": 1586454145.070407, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454144.923348}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:29 INFO 139873125553984] Epoch[32] Batch[0] avg_epoch_loss=2.269923\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:29 INFO 139873125553984] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=2.26992273331\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:34 INFO 139873125553984] Epoch[32] Batch[5] avg_epoch_loss=2.443584\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:34 INFO 139873125553984] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.44358384609\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:34 INFO 139873125553984] Epoch[32] Batch [5]#011Speed: 121.82 samples/sec#011loss=2.443584\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:39 INFO 139873125553984] Epoch[32] Batch[10] avg_epoch_loss=2.440532\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:39 INFO 139873125553984] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=2.43687005043\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:39 INFO 139873125553984] Epoch[32] Batch [10]#011Speed: 123.37 samples/sec#011loss=2.436870\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:39 INFO 139873125553984] processed a total of 1310 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14757.83085823059, \"sum\": 14757.83085823059, \"min\": 14757.83085823059}}, \"EndTime\": 1586454159.82838, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454145.07048}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:39 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=88.7657171335 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:39 INFO 139873125553984] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:39 INFO 139873125553984] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.44053212079\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:39 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:44 INFO 139873125553984] Epoch[33] Batch[0] avg_epoch_loss=2.501948\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:44 INFO 139873125553984] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=2.50194835663\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:49 INFO 139873125553984] Epoch[33] Batch[5] avg_epoch_loss=2.445931\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:49 INFO 139873125553984] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.44593056043\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:49 INFO 139873125553984] Epoch[33] Batch [5]#011Speed: 119.90 samples/sec#011loss=2.445931\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:53 INFO 139873125553984] processed a total of 1238 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13790.748834609985, \"sum\": 13790.748834609985, \"min\": 13790.748834609985}}, \"EndTime\": 1586454173.61978, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454159.828459}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:53 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=89.7694633079 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:53 INFO 139873125553984] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:53 INFO 139873125553984] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.38235909939\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:53 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:53 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_55e94f6a-c5e5-45c8-af29-ff77661fdf3b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 151.72505378723145, \"sum\": 151.72505378723145, \"min\": 151.72505378723145}}, \"EndTime\": 1586454173.772511, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454173.61987}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:58 INFO 139873125553984] Epoch[34] Batch[0] avg_epoch_loss=2.476672\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:42:58 INFO 139873125553984] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=2.47667241096\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:03 INFO 139873125553984] Epoch[34] Batch[5] avg_epoch_loss=2.477823\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:03 INFO 139873125553984] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.47782270114\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:03 INFO 139873125553984] Epoch[34] Batch [5]#011Speed: 121.11 samples/sec#011loss=2.477823\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:08 INFO 139873125553984] Epoch[34] Batch[10] avg_epoch_loss=2.457162\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:08 INFO 139873125553984] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=2.43236942291\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:08 INFO 139873125553984] Epoch[34] Batch [10]#011Speed: 123.77 samples/sec#011loss=2.432369\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:08 INFO 139873125553984] processed a total of 1293 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14751.888990402222, \"sum\": 14751.888990402222, \"min\": 14751.888990402222}}, \"EndTime\": 1586454188.524565, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454173.772589}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:08 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=87.6489660278 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:08 INFO 139873125553984] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:08 INFO 139873125553984] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.45716212013\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:08 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:12 INFO 139873125553984] Epoch[35] Batch[0] avg_epoch_loss=2.453779\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:12 INFO 139873125553984] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.45377898216\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:17 INFO 139873125553984] Epoch[35] Batch[5] avg_epoch_loss=2.435469\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:17 INFO 139873125553984] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.43546915054\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:17 INFO 139873125553984] Epoch[35] Batch [5]#011Speed: 124.16 samples/sec#011loss=2.435469\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:22 INFO 139873125553984] processed a total of 1275 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13586.4839553833, \"sum\": 13586.4839553833, \"min\": 13586.4839553833}}, \"EndTime\": 1586454202.111922, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454188.524646}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:22 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=93.8424702094 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:22 INFO 139873125553984] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:22 INFO 139873125553984] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.4470954895\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:22 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:26 INFO 139873125553984] Epoch[36] Batch[0] avg_epoch_loss=2.296938\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:26 INFO 139873125553984] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.2969379425\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:31 INFO 139873125553984] Epoch[36] Batch[5] avg_epoch_loss=2.347571\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:31 INFO 139873125553984] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.34757085641\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:31 INFO 139873125553984] Epoch[36] Batch [5]#011Speed: 122.40 samples/sec#011loss=2.347571\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:36 INFO 139873125553984] Epoch[36] Batch[10] avg_epoch_loss=2.411259\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:36 INFO 139873125553984] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=2.48768577576\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:36 INFO 139873125553984] Epoch[36] Batch [10]#011Speed: 122.11 samples/sec#011loss=2.487686\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:36 INFO 139873125553984] processed a total of 1289 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14674.892902374268, \"sum\": 14674.892902374268, \"min\": 14674.892902374268}}, \"EndTime\": 1586454216.787539, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454202.111995}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:36 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=87.8362470695 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:36 INFO 139873125553984] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:36 INFO 139873125553984] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.41125945611\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:36 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:41 INFO 139873125553984] Epoch[37] Batch[0] avg_epoch_loss=2.472131\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:41 INFO 139873125553984] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.47213101387\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:46 INFO 139873125553984] Epoch[37] Batch[5] avg_epoch_loss=2.393296\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:46 INFO 139873125553984] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.39329640071\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:46 INFO 139873125553984] Epoch[37] Batch [5]#011Speed: 123.82 samples/sec#011loss=2.393296\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:51 INFO 139873125553984] Epoch[37] Batch[10] avg_epoch_loss=2.364190\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:51 INFO 139873125553984] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=2.32926168442\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:51 INFO 139873125553984] Epoch[37] Batch [10]#011Speed: 124.12 samples/sec#011loss=2.329262\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:51 INFO 139873125553984] processed a total of 1319 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14573.132038116455, \"sum\": 14573.132038116455, \"min\": 14573.132038116455}}, \"EndTime\": 1586454231.361278, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454216.787639}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:51 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=90.5079904169 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:51 INFO 139873125553984] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:51 INFO 139873125553984] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.36418971148\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:51 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:51 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_cf7e0ba1-bb8a-4c7d-9642-c4de9fc9b947-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 148.09489250183105, \"sum\": 148.09489250183105, \"min\": 148.09489250183105}}, \"EndTime\": 1586454231.510072, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454231.361404}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:55 INFO 139873125553984] Epoch[38] Batch[0] avg_epoch_loss=2.310854\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:43:55 INFO 139873125553984] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.31085371971\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:00 INFO 139873125553984] Epoch[38] Batch[5] avg_epoch_loss=2.364884\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:00 INFO 139873125553984] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.36488429705\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:00 INFO 139873125553984] Epoch[38] Batch [5]#011Speed: 124.81 samples/sec#011loss=2.364884\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:06 INFO 139873125553984] Epoch[38] Batch[10] avg_epoch_loss=2.376956\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:06 INFO 139873125553984] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=2.3914419651\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:06 INFO 139873125553984] Epoch[38] Batch [10]#011Speed: 122.83 samples/sec#011loss=2.391442\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:06 INFO 139873125553984] processed a total of 1309 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14625.180959701538, \"sum\": 14625.180959701538, \"min\": 14625.180959701538}}, \"EndTime\": 1586454246.1354, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454231.510136}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:06 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=89.5023329302 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:06 INFO 139873125553984] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:06 INFO 139873125553984] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.37695596435\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:06 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:10 INFO 139873125553984] Epoch[39] Batch[0] avg_epoch_loss=2.377958\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:10 INFO 139873125553984] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.37795758247\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:15 INFO 139873125553984] Epoch[39] Batch[5] avg_epoch_loss=2.326301\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:15 INFO 139873125553984] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.32630113761\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:15 INFO 139873125553984] Epoch[39] Batch [5]#011Speed: 124.30 samples/sec#011loss=2.326301\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:19 INFO 139873125553984] processed a total of 1258 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13535.00509262085, \"sum\": 13535.00509262085, \"min\": 13535.00509262085}}, \"EndTime\": 1586454259.671023, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454246.135481}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:19 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=92.9430933537 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:19 INFO 139873125553984] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:19 INFO 139873125553984] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.3164124012\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:19 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:19 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_79ba5952-3551-4f93-bad7-8dfd5d31de25-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 147.71699905395508, \"sum\": 147.71699905395508, \"min\": 147.71699905395508}}, \"EndTime\": 1586454259.819324, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454259.671092}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:24 INFO 139873125553984] Epoch[40] Batch[0] avg_epoch_loss=2.300687\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:24 INFO 139873125553984] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.30068731308\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:29 INFO 139873125553984] Epoch[40] Batch[5] avg_epoch_loss=2.350140\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:29 INFO 139873125553984] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.35014001528\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:29 INFO 139873125553984] Epoch[40] Batch [5]#011Speed: 125.20 samples/sec#011loss=2.350140\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:34 INFO 139873125553984] Epoch[40] Batch[10] avg_epoch_loss=2.331761\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:34 INFO 139873125553984] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=2.30970563889\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:34 INFO 139873125553984] Epoch[40] Batch [10]#011Speed: 123.23 samples/sec#011loss=2.309706\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:34 INFO 139873125553984] processed a total of 1318 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14573.773860931396, \"sum\": 14573.773860931396, \"min\": 14573.773860931396}}, \"EndTime\": 1586454274.393229, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454259.819394}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:34 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=90.4355738398 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:34 INFO 139873125553984] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:34 INFO 139873125553984] #quality_metric: host=algo-1, epoch=40, train loss <loss>=2.33176075328\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:34 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:38 INFO 139873125553984] Epoch[41] Batch[0] avg_epoch_loss=2.415600\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:38 INFO 139873125553984] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.41559958458\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:43 INFO 139873125553984] Epoch[41] Batch[5] avg_epoch_loss=2.367776\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:43 INFO 139873125553984] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.36777623494\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:43 INFO 139873125553984] Epoch[41] Batch [5]#011Speed: 124.09 samples/sec#011loss=2.367776\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:49 INFO 139873125553984] Epoch[41] Batch[10] avg_epoch_loss=2.231629\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:49 INFO 139873125553984] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=2.06825261116\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:49 INFO 139873125553984] Epoch[41] Batch [10]#011Speed: 121.79 samples/sec#011loss=2.068253\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:49 INFO 139873125553984] processed a total of 1286 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14686.419010162354, \"sum\": 14686.419010162354, \"min\": 14686.419010162354}}, \"EndTime\": 1586454289.080174, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454274.393311}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:49 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=87.5631409007 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:49 INFO 139873125553984] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:49 INFO 139873125553984] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.23162913322\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:49 INFO 139873125553984] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:49 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/state_5cfde232-c3e9-46c6-9405-a68d29697c35-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 148.284912109375, \"sum\": 148.284912109375, \"min\": 148.284912109375}}, \"EndTime\": 1586454289.229131, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454289.080261}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:53 INFO 139873125553984] Epoch[42] Batch[0] avg_epoch_loss=2.412068\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:53 INFO 139873125553984] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.41206812859\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:58 INFO 139873125553984] Epoch[42] Batch[5] avg_epoch_loss=2.394887\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:58 INFO 139873125553984] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.39488744736\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:44:58 INFO 139873125553984] Epoch[42] Batch [5]#011Speed: 123.51 samples/sec#011loss=2.394887\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:02 INFO 139873125553984] processed a total of 1256 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13648.815155029297, \"sum\": 13648.815155029297, \"min\": 13648.815155029297}}, \"EndTime\": 1586454302.87809, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454289.229203}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:02 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=92.0217652989 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:02 INFO 139873125553984] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:02 INFO 139873125553984] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.39003145695\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:02 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:07 INFO 139873125553984] Epoch[43] Batch[0] avg_epoch_loss=2.253885\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:07 INFO 139873125553984] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=2.25388455391\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:12 INFO 139873125553984] Epoch[43] Batch[5] avg_epoch_loss=2.363202\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:12 INFO 139873125553984] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.36320185661\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:12 INFO 139873125553984] Epoch[43] Batch [5]#011Speed: 123.56 samples/sec#011loss=2.363202\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:16 INFO 139873125553984] processed a total of 1267 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13596.986055374146, \"sum\": 13596.986055374146, \"min\": 13596.986055374146}}, \"EndTime\": 1586454316.475603, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454302.878176}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:16 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=93.1816554264 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:16 INFO 139873125553984] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:16 INFO 139873125553984] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.36809859276\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:16 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:20 INFO 139873125553984] Epoch[44] Batch[0] avg_epoch_loss=2.287004\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:20 INFO 139873125553984] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.28700375557\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:25 INFO 139873125553984] Epoch[44] Batch[5] avg_epoch_loss=2.254344\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:25 INFO 139873125553984] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.25434426467\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:25 INFO 139873125553984] Epoch[44] Batch [5]#011Speed: 123.43 samples/sec#011loss=2.254344\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:30 INFO 139873125553984] processed a total of 1269 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13572.896003723145, \"sum\": 13572.896003723145, \"min\": 13572.896003723145}}, \"EndTime\": 1586454330.049137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454316.475677}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:30 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=93.4942998493 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:30 INFO 139873125553984] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:30 INFO 139873125553984] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.27596781254\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:30 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:34 INFO 139873125553984] Epoch[45] Batch[0] avg_epoch_loss=2.260971\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:34 INFO 139873125553984] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.2609705925\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:39 INFO 139873125553984] Epoch[45] Batch[5] avg_epoch_loss=2.231248\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:39 INFO 139873125553984] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.23124786218\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:39 INFO 139873125553984] Epoch[45] Batch [5]#011Speed: 123.84 samples/sec#011loss=2.231248\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:43 INFO 139873125553984] processed a total of 1262 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13626.403093338013, \"sum\": 13626.403093338013, \"min\": 13626.403093338013}}, \"EndTime\": 1586454343.676187, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454330.049218}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:43 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=92.6132090935 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:43 INFO 139873125553984] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:43 INFO 139873125553984] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.25660324097\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:43 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:47 INFO 139873125553984] Epoch[46] Batch[0] avg_epoch_loss=2.249387\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:47 INFO 139873125553984] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.249386549\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:53 INFO 139873125553984] Epoch[46] Batch[5] avg_epoch_loss=2.258422\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:53 INFO 139873125553984] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.25842237473\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:53 INFO 139873125553984] Epoch[46] Batch [5]#011Speed: 123.95 samples/sec#011loss=2.258422\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:57 INFO 139873125553984] processed a total of 1243 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13556.679010391235, \"sum\": 13556.679010391235, \"min\": 13556.679010391235}}, \"EndTime\": 1586454357.2334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454343.676265}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:57 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=91.6882499533 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:57 INFO 139873125553984] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:57 INFO 139873125553984] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.31046836376\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:45:57 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:01 INFO 139873125553984] Epoch[47] Batch[0] avg_epoch_loss=2.258405\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:01 INFO 139873125553984] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.25840520859\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:06 INFO 139873125553984] Epoch[47] Batch[5] avg_epoch_loss=2.295083\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:06 INFO 139873125553984] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=2.29508328438\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:06 INFO 139873125553984] Epoch[47] Batch [5]#011Speed: 121.19 samples/sec#011loss=2.295083\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:10 INFO 139873125553984] processed a total of 1165 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13599.448919296265, \"sum\": 13599.448919296265, \"min\": 13599.448919296265}}, \"EndTime\": 1586454370.833435, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454357.233488}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:10 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=85.6644294361 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:10 INFO 139873125553984] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:10 INFO 139873125553984] #quality_metric: host=algo-1, epoch=47, train loss <loss>=2.23940135241\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:10 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:15 INFO 139873125553984] Epoch[48] Batch[0] avg_epoch_loss=2.358633\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:15 INFO 139873125553984] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.35863256454\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:20 INFO 139873125553984] Epoch[48] Batch[5] avg_epoch_loss=2.381732\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:20 INFO 139873125553984] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.3817315499\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:20 INFO 139873125553984] Epoch[48] Batch [5]#011Speed: 123.65 samples/sec#011loss=2.381732\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:24 INFO 139873125553984] processed a total of 1248 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13624.353885650635, \"sum\": 13624.353885650635, \"min\": 13624.353885650635}}, \"EndTime\": 1586454384.458471, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454370.833522}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:24 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=91.5998052961 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:24 INFO 139873125553984] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:24 INFO 139873125553984] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.35069077015\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:24 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:28 INFO 139873125553984] Epoch[49] Batch[0] avg_epoch_loss=2.245996\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:28 INFO 139873125553984] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=2.24599575996\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:34 INFO 139873125553984] Epoch[49] Batch[5] avg_epoch_loss=2.277446\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:34 INFO 139873125553984] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.27744575342\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:34 INFO 139873125553984] Epoch[49] Batch [5]#011Speed: 121.78 samples/sec#011loss=2.277446\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:39 INFO 139873125553984] Epoch[49] Batch[10] avg_epoch_loss=2.303679\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:39 INFO 139873125553984] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=2.33515949249\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:39 INFO 139873125553984] Epoch[49] Batch [10]#011Speed: 122.77 samples/sec#011loss=2.335159\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:39 INFO 139873125553984] processed a total of 1323 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14816.922903060913, \"sum\": 14816.922903060913, \"min\": 14816.922903060913}}, \"EndTime\": 1586454399.275938, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454384.458557}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:39 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=89.2890774864 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:39 INFO 139873125553984] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:39 INFO 139873125553984] #quality_metric: host=algo-1, epoch=49, train loss <loss>=2.30367927118\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:39 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:43 INFO 139873125553984] Epoch[50] Batch[0] avg_epoch_loss=2.306439\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:43 INFO 139873125553984] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.30643892288\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:48 INFO 139873125553984] Epoch[50] Batch[5] avg_epoch_loss=2.312827\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:48 INFO 139873125553984] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.31282715003\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:48 INFO 139873125553984] Epoch[50] Batch [5]#011Speed: 123.99 samples/sec#011loss=2.312827\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:53 INFO 139873125553984] Epoch[50] Batch[10] avg_epoch_loss=2.356201\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:53 INFO 139873125553984] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=2.40824966431\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:53 INFO 139873125553984] Epoch[50] Batch [10]#011Speed: 123.68 samples/sec#011loss=2.408250\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:53 INFO 139873125553984] processed a total of 1296 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14617.666959762573, \"sum\": 14617.666959762573, \"min\": 14617.666959762573}}, \"EndTime\": 1586454413.89428, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454399.276016}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:53 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=88.6591174717 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:53 INFO 139873125553984] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:53 INFO 139873125553984] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.35620102015\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:53 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:58 INFO 139873125553984] Epoch[51] Batch[0] avg_epoch_loss=2.321716\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:46:58 INFO 139873125553984] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.32171559334\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:03 INFO 139873125553984] Epoch[51] Batch[5] avg_epoch_loss=2.334920\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:03 INFO 139873125553984] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.33491988977\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:03 INFO 139873125553984] Epoch[51] Batch [5]#011Speed: 121.91 samples/sec#011loss=2.334920\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] Epoch[51] Batch[10] avg_epoch_loss=2.340864\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=2.34799618721\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] Epoch[51] Batch [10]#011Speed: 124.11 samples/sec#011loss=2.347996\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] processed a total of 1297 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14763.870000839233, \"sum\": 14763.870000839233, \"min\": 14763.870000839233}}, \"EndTime\": 1586454428.658849, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454413.894361}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] #throughput_metric: host=algo-1, train throughput=87.8488870782 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.34086366133\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] Loading parameters from best epoch (41)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 74.28908348083496, \"sum\": 74.28908348083496, \"min\": 74.28908348083496}}, \"EndTime\": 1586454428.733748, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454428.65893}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] stopping training now\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] Final loss: 2.23162913322 (occurred at epoch 41)\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] #quality_metric: host=algo-1, train final_loss <loss>=2.23162913322\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 WARNING 139873125553984] You are using large values for `context_length` and/or `prediction_length`. The following step may take some time. If the step crashes, use an instance with more memory or reduce these two parameters.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 WARNING 139873125553984] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:08 INFO 139873125553984] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 2188.3130073547363, \"sum\": 2188.3130073547363, \"min\": 2188.3130073547363}}, \"EndTime\": 1586454430.923094, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454428.733819}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:11 INFO 139873125553984] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 2795.2609062194824, \"sum\": 2795.2609062194824, \"min\": 2795.2609062194824}}, \"EndTime\": 1586454431.529996, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454430.923171}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:11 INFO 139873125553984] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:11 INFO 139873125553984] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 94.8941707611084, \"sum\": 94.8941707611084, \"min\": 94.8941707611084}}, \"EndTime\": 1586454431.62503, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454431.530076}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:11 INFO 139873125553984] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:47:11 INFO 139873125553984] No test data passed, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 748352.178812027, \"sum\": 748352.178812027, \"min\": 748352.178812027}, \"setuptime\": {\"count\": 1, \"max\": 10.921001434326172, \"sum\": 10.921001434326172, \"min\": 10.921001434326172}}, \"EndTime\": 1586454431.762755, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1586454431.625091}\n",
      "\u001b[0m\n",
      "\n",
      "2020-04-09 17:47:20 Uploading - Uploading generated training model\n",
      "2020-04-09 17:47:20 Completed - Training job completed\n",
      "Training seconds: 810\n",
      "Billable seconds: 810\n"
     ]
    }
   ],
   "source": [
    "estimator_iq = fit_model(train_path, f'{prefix}-deepar-{tag}-IQ', str(PREDICTION_LENGTH_IQ), str(PREDICTION_LENGTH_SJ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we want to skip training and reuse a previously trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dengai/all-feat-maxscale-2020-04-09-16-57-06-70/models/dengai-deepar-all-feat-maxscale-IQ-2020-04-09-17-31-52-222/output/model.tar.gz',\n",
       " 'dengai/all-feat-maxscale-2020-04-09-16-57-06-70/models/dengai-deepar-all-feat-maxscale-SJ-2020-04-09-17-01-20-651/output/model.tar.gz',\n",
       " 'dengai/all-feat-maxscale-2020-04-09-16-57-06-70/pprocess_data/test_pp_iq.json',\n",
       " 'dengai/all-feat-maxscale-2020-04-09-16-57-06-70/pprocess_data/test_pp_sj.json',\n",
       " 'dengai/all-feat-maxscale-2020-04-09-16-57-06-70/pprocess_data/train_pp.json',\n",
       " 'dengai/all-feat-no-scale-2020-04-09-15-05-55-09/batch-transform/test_pp_iq.json.out',\n",
       " 'dengai/all-feat-no-scale-2020-04-09-15-05-55-09/batch-transform/test_pp_sj.json.out',\n",
       " 'dengai/all-feat-no-scale-2020-04-09-15-05-55-09/models/dengai-deepar-jobname-IQ-2020-04-09-15-37-29-930/output/model.tar.gz',\n",
       " 'dengai/all-feat-no-scale-2020-04-09-15-05-55-09/models/dengai-deepar-jobname-SJ-2020-04-09-15-10-12-670/output/model.tar.gz',\n",
       " 'dengai/all-feat-no-scale-2020-04-09-15-05-55-09/pprocess_data/test_pp_iq.json',\n",
       " 'dengai/all-feat-no-scale-2020-04-09-15-05-55-09/pprocess_data/test_pp_sj.json',\n",
       " 'dengai/all-feat-no-scale-2020-04-09-15-05-55-09/pprocess_data/train_pp.json',\n",
       " 'dengai/all-feat-no-scale-2020-04-09-16-56-00-89/pprocess_data/test_pp_iq.json',\n",
       " 'dengai/all-feat-no-scale-2020-04-09-16-56-00-89/pprocess_data/test_pp_sj.json',\n",
       " 'dengai/all-feat-no-scale-2020-04-09-16-56-00-89/pprocess_data/train_pp.json',\n",
       " 'dengai/raw_data/dengue_features_test.csv',\n",
       " 'dengai/raw_data/dengue_features_train.csv',\n",
       " 'dengai/raw_data/dengue_labels_train.csv',\n",
       " 'dengai/raw_data/submission_format.csv']"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "def get_model(model_file):\n",
    "    model_s3_path = f's3://{bucket}/{model_file}'\n",
    "    model = Model(model_data=model_s3_path,\n",
    "              image=image_name,\n",
    "             role=role)\n",
    "    return model\n",
    "\n",
    "sagemaker_session.list_s3_files(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34mNo handlers could be found for logger \"root\"\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 INFO 140449067149120] Estimated memory required per model 124MB.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 INFO 140449067149120] Estimated available memory 15064MB.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 INFO 140449067149120] Estimated maximum number of workers for the available memory is 120.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 INFO 140449067149120] Using 4 workers\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 INFO 140449067149120] loading entry points\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 INFO 140449067149120] Prediction endpoint operating in batch mode\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 INFO 140449067149120] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 INFO 140449067149120] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 INFO 140449067149120] loaded model class model\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 WARNING 140449067149120] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 INFO 140449067149120] nvidia-smi took: 0.0269060134888 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 INFO 140449067149120] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 INFO 140449067149120] Loading Config from /opt/ml/model/model_algo-1-config.json\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase1.time\": {\"count\": 1, \"max\": 1.477956771850586, \"sum\": 1.477956771850586, \"min\": 1.477956771850586}}, \"EndTime\": 1586454714.52161, \"Dimensions\": {}, \"StartTime\": 1586454714.413262}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:51:54 INFO 140449067149120] Deserializing model parameters from /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[17:51:55] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202184.0/RHEL5_64/generic-flavor/src/src/engine/engine.cc:55: MXNet start using engine: NaiveEngine\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 590.4541015625, \"sum\": 590.4541015625, \"min\": 590.4541015625}}, \"EndTime\": 1586454715.779751, \"Dimensions\": {}, \"StartTime\": 1586454714.521723}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase2.time\": {\"count\": 1, \"max\": 1258.1040859222412, \"sum\": 1258.1040859222412, \"min\": 1258.1040859222412}}, \"EndTime\": 1586454715.779847, \"Dimensions\": {}, \"StartTime\": 1586454715.779824}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:51:55 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:51:55 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:51:55 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:51:55 +0000] [33] [INFO] Booting worker with pid: 33\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:51:55 +0000] [34] [INFO] Booting worker with pid: 34\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:51:56 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:51:56 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\n",
      "\u001b[32m2020-04-09T17:52:02.032:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.04601478576660156, \"sum\": 0.04601478576660156, \"min\": 0.04601478576660156}}, \"EndTime\": 1586454722.471606, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1586454715.959455}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.04601478576660156, \"sum\": 0.04601478576660156, \"min\": 0.04601478576660156}}, \"EndTime\": 1586454722.471606, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1586454715.959455}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.2560615539550781, \"sum\": 0.2560615539550781, \"min\": 0.2560615539550781}}, \"EndTime\": 1586454723.095666, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1586454722.471781}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1586454723.09659, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1586454723.095741}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.2560615539550781, \"sum\": 0.2560615539550781, \"min\": 0.2560615539550781}}, \"EndTime\": 1586454723.095666, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1586454722.471781}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1586454723.09659, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1586454723.095741}\n",
      "\u001b[0m\n",
      "......................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34mNo handlers could be found for logger \"root\"\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 INFO 139755321874240] Estimated memory required per model 95MB.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 INFO 139755321874240] Estimated available memory 15097MB.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 INFO 139755321874240] Estimated maximum number of workers for the available memory is 157.\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 INFO 139755321874240] Using 4 workers\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 INFO 139755321874240] loading entry points\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 INFO 139755321874240] Prediction endpoint operating in batch mode\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 INFO 139755321874240] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 INFO 139755321874240] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 INFO 139755321874240] loaded model class model\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 WARNING 139755321874240] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 INFO 139755321874240] nvidia-smi took: 0.0252420902252 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 INFO 139755321874240] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 INFO 139755321874240] Loading Config from /opt/ml/model/model_algo-1-config.json\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase1.time\": {\"count\": 1, \"max\": 1.1129379272460938, \"sum\": 1.1129379272460938, \"min\": 1.1129379272460938}}, \"EndTime\": 1586454960.683915, \"Dimensions\": {}, \"StartTime\": 1586454960.589903}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/09/2020 17:56:00 INFO 139755321874240] Deserializing model parameters from /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[17:56:01] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202184.0/RHEL5_64/generic-flavor/src/src/engine/engine.cc:55: MXNet start using engine: NaiveEngine\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 581.4039707183838, \"sum\": 581.4039707183838, \"min\": 581.4039707183838}}, \"EndTime\": 1586454961.78756, \"Dimensions\": {}, \"StartTime\": 1586454960.684029}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase2.time\": {\"count\": 1, \"max\": 1103.6288738250732, \"sum\": 1103.6288738250732, \"min\": 1103.6288738250732}}, \"EndTime\": 1586454961.78768, \"Dimensions\": {}, \"StartTime\": 1586454961.787657}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:56:01 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:56:01 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:56:01 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:56:01 +0000] [33] [INFO] Booting worker with pid: 33\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:56:01 +0000] [34] [INFO] Booting worker with pid: 34\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:56:01 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2020-04-09 17:56:02 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.049114227294921875, \"sum\": 0.049114227294921875, \"min\": 0.049114227294921875}}, \"EndTime\": 1586454981.574567, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1586454961.834855}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.164031982421875, \"sum\": 0.164031982421875, \"min\": 0.164031982421875}}, \"EndTime\": 1586454981.97763, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1586454981.574763}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1586454981.978337, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1586454981.977706}\n",
      "\u001b[0m\n",
      "\u001b[32m2020-04-09T17:56:21.258:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def batch_transform(estimator, data_path, base_job_name):\n",
    "    s3_batch_output_path = f's3://{bucket}/{batch_transform_prefix}'\n",
    "    transformer = estimator.transformer(instance_count=1,\n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    strategy='SingleRecord',\n",
    "                                    assemble_with='Line',\n",
    "                                    output_path=s3_batch_output_path)\n",
    "    transformer.transform(data=data_path,\n",
    "                          data_type='S3Prefix',\n",
    "                          content_type=None,\n",
    "                          split_type='Line',\n",
    "                          wait=True,\n",
    "                          logs=True)\n",
    "    \n",
    "    file_name = os.path.basename(data_path)\n",
    "    output_path = f'{s3_batch_output_path}/{file_name}.out'\n",
    "    return output_path\n",
    "\n",
    "predictions_sj_path = batch_transform(estimator_sj, test_path_sj,'SJ')\n",
    "predictions_iq_path = batch_transform(estimator_iq, test_path_iq,'IQ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get results and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to decode JSON prediction\n",
    "def unjson_prediction(predictions):\n",
    "    '''Accepts a JSON prediction and returns a list of quantiles for prediction.\n",
    "    '''\n",
    "    prediction_data = json.loads(predictions)\n",
    "    predictions_quantiles = pd.DataFrame(prediction_data['quantiles'])\n",
    "    return predictions_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_sj = unjson_prediction(sagemaker.s3.S3Downloader.read_file(predictions_sj_path))\n",
    "predictions_iq = unjson_prediction(sagemaker.s3.S3Downloader.read_file(predictions_iq_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# display the prediction median against the actual data\n",
    "def display_quantiles(prediction, previous_submission_path=None):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    \n",
    "    # get the quantile values at 10 and 90%\n",
    "    p10 = prediction['0.1']\n",
    "    p90 = prediction['0.9']\n",
    "    \n",
    "    # fill the 80% confidence interval\n",
    "    plt.fill_between(p10.index, p10, p90, color='y', alpha=0.5, label='80% confidence interval')\n",
    "    \n",
    "    # plot the median prediction line\n",
    "    prediction['0.5'].plot(label='prediction median')\n",
    "    city='iq'\n",
    "    if len(prediction['0.5'])==260:\n",
    "        city='sj'\n",
    "    \n",
    "    # plot previous submission\n",
    "    if previous_submission_path:\n",
    "        try:\n",
    "            prev = pd.read_csv(previous_submission_path)\n",
    "            pd.Series(tmp[tmp.city==city].total_cases.tolist()).plot(label='prv')\n",
    "        except FileNotFoundError as err:\n",
    "            print(err)\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_submissions_to_plot = './submissions/submission_2020-04-08_13-30-20_313455.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_quantiles(predictions_sj, previous_submissions_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_quantiles(predictions_iq, previous_submissions_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating output CSV for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(predictions_sj, predictions_iq, template_file='./data/input/submission_format.csv', output_dir='./submissions'):\n",
    "    submission = pd.read_csv(template_file)\n",
    "    submission.loc[submission.city=='iq', 'total_cases'] = predictions_iq['0.5'].tolist()\n",
    "    submission.loc[submission.city=='sj', 'total_cases'] = predictions_sj['0.5'].tolist()\n",
    "    submission['total_cases'] = submission['total_cases'].round().astype(int)\n",
    "    submission.to_csv(f'{output_dir}/submission_{job_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(predictions_sj, predictions_iq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
