{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# Constants\n",
    "CITIES = {'iq': 0, 'sj': 1} # Categorical variable encoding\n",
    "PREDICTION_LENGTH = {'iq': 156, 'sj': 260} # Prediction length is fixed by the test set\n",
    "\n",
    "### Change tag to jobnames\n",
    "tag = 'only-target-optim'\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "\n",
    "model_version = f'{timestamp}-{tag}' # can be set to a specific job\n",
    "model_comments = \"baseline with only target but longer learning - optim HP\"\n",
    "\n",
    "prefix='dengai'\n",
    "raw_prefix = f'{prefix}/raw_data'\n",
    "pprocess_prefix = f'{prefix}/{model_version}/pprocess_data'\n",
    "model_prefix = f'{prefix}/{model_version}/models'\n",
    "batch_transform_prefix = f'{prefix}/{model_version}/batch-transform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info_keys = [\n",
    "    'model_version',\n",
    "    'comments',\n",
    "    \"epochs\",\n",
    "    \"time_freq\",\n",
    "    \"num_cells\",\n",
    "    \"num_layers\",\n",
    "    \"mini_batch_size\",\n",
    "    \"learning_rate\",\n",
    "    \"early_stopping_patience\",\n",
    "    'prediction_length',\n",
    "    'context_length',\n",
    "    'MAE_iq',\n",
    "    'MAE_sj',\n",
    "    'MAE_total']\n",
    "\n",
    "current_model_info = dict.fromkeys(model_info_keys)\n",
    "\n",
    "def dict_update(base_dict, update_dict):\n",
    "    base_dict.update((k, update_dict[k]) for k in base_dict.keys() & update_dict.keys())\n",
    "\n",
    "dict_update(current_model_info, {'model_version': model_version, 'comments': model_comments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sagemaker_session.list_s3_files(bucket, raw_prefix))<4:\n",
    "    ! wget -nc https://s3.amazonaws.com/drivendata-prod/data/44/public/dengue_features_train.csv -P ./data/input\n",
    "    ! wget -nc https://s3.amazonaws.com/drivendata-prod/data/44/public/dengue_labels_train.csv -P ./data/input\n",
    "    ! wget -nc https://s3.amazonaws.com/drivendata-prod/data/44/public/dengue_features_test.csv -P ./data/input\n",
    "    ! wget -nc https://s3.amazonaws.com/drivendata-prod/data/44/public/submission_format.csv -P ./data/input  \n",
    "    s3_uri = sagemaker_session.upload_data('./data/input', bucket, raw_prefix)\n",
    "    print(f'Uploaded raw files to {s3_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  dengai-only-target-optim-pprocess-2020-04-19-12-42-47-783\n",
      "Inputs:  [{'InputName': 'input_data', 'S3Input': {'S3Uri': 's3://sagemaker-eu-central-1-964501460451/dengai/raw_data', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-eu-central-1-964501460451/dengai-only-target-optim-pprocess-2020-04-19-12-42-47-783/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'output_data', 'S3Output': {'S3Uri': 's3://sagemaker-eu-central-1-964501460451/dengai/2020-04-19--12-42-only-target-optim/pprocess_data', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "........................\n",
      "\u001b[34mReceived arguments Namespace(context_length_iq=156, context_length_sj=260)\u001b[0m\n",
      "\u001b[34mReading input data from /opt/ml/processing/input/dengue_features_train.csv\u001b[0m\n",
      "\u001b[34mReading input data from /opt/ml/processing/input/dengue_labels_train.csv\u001b[0m\n",
      "\u001b[34mReading input data from /opt/ml/processing/input/dengue_features_test.csv\u001b[0m\n",
      "\u001b[34mRunning preprocessing and feature engineering transformations\u001b[0m\n",
      "\u001b[34mData sets creation for iq\u001b[0m\n",
      "\u001b[34m>> JSON created for iq. Start date: 2000-07-01 / Target: (364,) / Features: (2, 364)\u001b[0m\n",
      "\u001b[34m>> JSON created for iq. Start date: 2000-07-01 / Target: (520,) / Features: (2, 520)\u001b[0m\n",
      "\u001b[34m>> JSON created for iq. Start date: 2000-07-01 / Target: (364,) / Features: (2, 520)\u001b[0m\n",
      "\u001b[34m>> JSON created for iq. Start date: 2000-07-01 / Target: (520,) / Features: (2, 520)\u001b[0m\n",
      "\u001b[34m>> JSON created for iq. Start date: 2000-07-01 / Target: (520,) / Features: (2, 676)\u001b[0m\n",
      "\u001b[34mData sets creation for sj\u001b[0m\n",
      "\u001b[34m>> JSON created for sj. Start date: 1990-04-30 / Target: (676,) / Features: (2, 676)\u001b[0m\n",
      "\u001b[34m>> JSON created for sj. Start date: 1990-04-30 / Target: (936,) / Features: (2, 936)\u001b[0m\n",
      "\u001b[34m>> JSON created for sj. Start date: 1990-04-30 / Target: (676,) / Features: (2, 936)\u001b[0m\n",
      "\u001b[34m>> JSON created for sj. Start date: 1990-04-30 / Target: (936,) / Features: (2, 936)\u001b[0m\n",
      "\u001b[34m>> JSON created for sj. Start date: 1990-04-30 / Target: (936,) / Features: (2, 1196)\u001b[0m\n",
      "\u001b[34m>>> Wrote 16175 chars to /opt/ml/processing/output/train_pp.json\u001b[0m\n",
      "\u001b[34m>>> Wrote 30247 chars to /opt/ml/processing/output/train_pp.json\u001b[0m\n",
      "\u001b[34m>> /opt/ml/processing/output/train_pp.json saved\u001b[0m\n",
      "\u001b[34m>>> Wrote 30247 chars to /opt/ml/processing/output/train_pp_sj.json\u001b[0m\n",
      "\u001b[34m>> /opt/ml/processing/output/train_pp_sj.json saved\u001b[0m\n",
      "\u001b[34m>>> Wrote 16175 chars to /opt/ml/processing/output/train_pp_iq.json\u001b[0m\n",
      "\u001b[34m>> /opt/ml/processing/output/train_pp_iq.json saved\u001b[0m\n",
      "\u001b[34m>>> Wrote 42093 chars to /opt/ml/processing/output/train_test_pp_sj.json\u001b[0m\n",
      "\u001b[34m>> /opt/ml/processing/output/train_test_pp_sj.json saved\u001b[0m\n",
      "\u001b[34m>>> Wrote 23024 chars to /opt/ml/processing/output/train_test_pp_iq.json\u001b[0m\n",
      "\u001b[34m>> /opt/ml/processing/output/train_test_pp_iq.json saved\u001b[0m\n",
      "\u001b[34m>>> Wrote 41127 chars to /opt/ml/processing/output/validation_pp_sj.json\u001b[0m\n",
      "\u001b[34m>> /opt/ml/processing/output/validation_pp_sj.json saved\u001b[0m\n",
      "\u001b[34m>>> Wrote 22507 chars to /opt/ml/processing/output/validation_pp_iq.json\u001b[0m\n",
      "\u001b[34m>> /opt/ml/processing/output/validation_pp_iq.json saved\u001b[0m\n",
      "\u001b[34m>>> Wrote 42093 chars to /opt/ml/processing/output/submission_train_pp_sj.json\u001b[0m\n",
      "\u001b[34m>> /opt/ml/processing/output/submission_train_pp_sj.json saved\u001b[0m\n",
      "\u001b[34m>>> Wrote 23024 chars to /opt/ml/processing/output/submission_train_pp_iq.json\u001b[0m\n",
      "\u001b[34m>> /opt/ml/processing/output/submission_train_pp_iq.json saved\u001b[0m\n",
      "\u001b[34m>>> Wrote 52375 chars to /opt/ml/processing/output/submission_test_pp_sj.json\u001b[0m\n",
      "\u001b[34m>> /opt/ml/processing/output/submission_test_pp_sj.json saved\u001b[0m\n",
      "\u001b[34m>>> Wrote 29474 chars to /opt/ml/processing/output/submission_test_pp_iq.json\u001b[0m\n",
      "\u001b[34m>> /opt/ml/processing/output/submission_test_pp_iq.json saved\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor = ScriptProcessor(image_uri='964501460451.dkr.ecr.eu-central-1.amazonaws.com/sagemaker-containers:updated-sklearn_0.22.0-cpu-py3',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m4.xlarge',\n",
    "                                     instance_count=1,\n",
    "                                     command = [\"python3\"], # default required using the same as in SKLearnProcessor\n",
    "                                     volume_size_in_gb=30, # default required using the same as in SKLearnProcessor\n",
    "                                     base_job_name=f'{prefix}-{tag}-pprocess'\n",
    "                                    )\n",
    "\n",
    "sklearn_processor.run(code='src/preprocessing.py',\n",
    "                      inputs=[\n",
    "                          ProcessingInput(\n",
    "                              source=f's3://{bucket}/{raw_prefix}',\n",
    "                              input_name='input_data',\n",
    "                              destination='/opt/ml/processing/input')\n",
    "                      ],\n",
    "                      outputs=[\n",
    "                          ProcessingOutput(\n",
    "                              source='/opt/ml/processing/output',\n",
    "                              output_name='output_data',\n",
    "                              destination=f's3://{bucket}/{pprocess_prefix}')                \n",
    "                      ]\n",
    "                     )\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "output_config = preprocessing_job_description['ProcessingOutputConfig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = f's3://{bucket}/{pprocess_prefix}'\n",
    "\n",
    "train_path = f'{preprocessed_data}/train_pp.json'\n",
    "train_path_sj = f'{preprocessed_data}/train_pp_sj.json'\n",
    "train_path_iq = f'{preprocessed_data}/train_pp_iq.json'\n",
    "\n",
    "train_test_path_sj = f'{preprocessed_data}/train_test_pp_sj.json'\n",
    "train_test_path_iq = f'{preprocessed_data}/train_test_pp_iq.json'\n",
    "\n",
    "validation_path_sj = f'{preprocessed_data}/validation_pp_sj.json'\n",
    "validation_path_iq = f'{preprocessed_data}/validation_pp_iq.json'\n",
    "\n",
    "\n",
    "submission_train_path_sj = f'{preprocessed_data}/submission_train_pp_sj.json'\n",
    "submission_train_path_iq = f'{preprocessed_data}/submission_train_pp_iq.json'\n",
    "\n",
    "submission_test_path_sj = f'{preprocessed_data}/submission_test_pp_sj.json'\n",
    "submission_test_path_iq = f'{preprocessed_data}/submission_test_pp_iq.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dengai-only-target-optim-sj-2020-04-19-12-47-00-833\n",
      "dengai-only-target-optim-iq-2020-04-19-12-47-01-020\n",
      "2020-04-19 12:47:02 Starting - Launching requested ML instances......\n",
      "2020-04-19 12:47:58 Starting - Preparing the instances for training.........\n",
      "2020-04-19 12:49:22 Downloading - Downloading input data...\n",
      "2020-04-19 12:49:56 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:58 INFO 139636288943936] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:58 INFO 139636288943936] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.01', u'mini_batch_size': u'64', u'learning_rate': u'0.005', u'num_cells': u'128', u'prediction_length': u'260', u'epochs': u'500', u'time_freq': u'W', u'context_length': u'52', u'num_layers': u'2', u'cardinality': u'auto', u'early_stopping_patience': u'25'}\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:58 INFO 139636288943936] Final configuration: {u'dropout_rate': u'0.01', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'0.005', u'num_layers': u'2', u'epochs': u'500', u'embedding_dimension': u'10', u'num_cells': u'128', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'260', u'time_freq': u'W', u'context_length': u'52', u'_kvstore': u'auto', u'early_stopping_patience': u'25'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:58 INFO 139636288943936] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] Using early stopping with patience 25\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train_pp_sj.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train_pp_sj.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] Training set statistics:\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] Integer time series\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] number of time series: 1\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] number of observations: 676\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] mean target length: 676\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] min/mean/max target: 0.0/38.6568047337/461.0\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] mean abs(target): 38.6568047337\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] contains missing values: no\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] Small number of time series. Doing 640 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] Test set statistics:\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] Integer time series\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] number of time series: 1\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] number of observations: 936\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] mean target length: 936\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] min/mean/max target: 0.0/34.1805555556/461.0\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] mean abs(target): 34.1805555556\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] contains missing values: no\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] nvidia-smi took: 0.0252239704132 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 726.5071868896484, \"sum\": 726.5071868896484, \"min\": 726.5071868896484}}, \"EndTime\": 1587300599.783538, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300599.055989}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:59 INFO 139636288943936] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 2072.211980819702, \"sum\": 2072.211980819702, \"min\": 2072.211980819702}}, \"EndTime\": 1587300601.128335, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300599.783618}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:03 INFO 139636288943936] Epoch[0] Batch[0] avg_epoch_loss=6.374433\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=6.37443304062\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:09 INFO 139636288943936] Epoch[0] Batch[5] avg_epoch_loss=5.536728\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=5.53672790527\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:09 INFO 139636288943936] Epoch[0] Batch [5]#011Speed: 51.31 samples/sec#011loss=5.536728\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 139636288943936] Epoch[0] Batch[10] avg_epoch_loss=5.056442\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=4.48009872437\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 139636288943936] Epoch[0] Batch [10]#011Speed: 55.42 samples/sec#011loss=4.480099\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 139636288943936] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 500, \"sum\": 500.0, \"min\": 500}, \"update.time\": {\"count\": 1, \"max\": 14358.436107635498, \"sum\": 14358.436107635498, \"min\": 14358.436107635498}}, \"EndTime\": 1587300615.487044, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300601.128486}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=45.1298427558 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 139636288943936] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=0, train loss <loss>=5.05644191395\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_848924c5-8c44-45a3-b2d4-7f1d94eb36d6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 156.13698959350586, \"sum\": 156.13698959350586, \"min\": 156.13698959350586}}, \"EndTime\": 1587300615.643876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300615.487139}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:17 INFO 139636288943936] Epoch[1] Batch[0] avg_epoch_loss=4.259634\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=4.25963449478\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:23 INFO 139636288943936] Epoch[1] Batch[5] avg_epoch_loss=4.112575\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=4.1125746568\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:23 INFO 139636288943936] Epoch[1] Batch [5]#011Speed: 56.11 samples/sec#011loss=4.112575\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:27 INFO 139636288943936] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12115.883827209473, \"sum\": 12115.883827209473, \"min\": 12115.883827209473}}, \"EndTime\": 1587300627.760042, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300615.643997}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:27 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.5846349872 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:27 INFO 139636288943936] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=1, train loss <loss>=4.00390076637\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:27 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:27 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_25d85458-fc47-42bc-ad77-ba105f8438bb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 108.22200775146484, \"sum\": 108.22200775146484, \"min\": 108.22200775146484}}, \"EndTime\": 1587300627.869029, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300627.760124}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:29 INFO 139636288943936] Epoch[2] Batch[0] avg_epoch_loss=3.813246\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.81324625015\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:35 INFO 139636288943936] Epoch[2] Batch[5] avg_epoch_loss=3.758446\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.75844593843\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:35 INFO 139636288943936] Epoch[2] Batch [5]#011Speed: 56.11 samples/sec#011loss=3.758446\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:39 INFO 139636288943936] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12032.869100570679, \"sum\": 12032.869100570679, \"min\": 12032.869100570679}}, \"EndTime\": 1587300639.902029, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300627.869095}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:39 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.1953798433 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:39 INFO 139636288943936] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.79141395092\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:39 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:40 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_cc5d1af2-9b80-4ac7-b295-c21641c79439-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 119.17400360107422, \"sum\": 119.17400360107422, \"min\": 119.17400360107422}}, \"EndTime\": 1587300640.021751, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300639.902104}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:41 INFO 139636288943936] Epoch[3] Batch[0] avg_epoch_loss=3.722432\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.72243213654\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:47 INFO 139636288943936] Epoch[3] Batch[5] avg_epoch_loss=3.723265\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.72326521079\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:47 INFO 139636288943936] Epoch[3] Batch [5]#011Speed: 55.62 samples/sec#011loss=3.723265\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:52 INFO 139636288943936] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12153.774976730347, \"sum\": 12153.774976730347, \"min\": 12153.774976730347}}, \"EndTime\": 1587300652.175693, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300640.021843}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:52 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.5883571653 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:52 INFO 139636288943936] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.68751702309\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:52 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:52 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_ef491f96-4167-47a7-981e-b6aa95033f20-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 104.1719913482666, \"sum\": 104.1719913482666, \"min\": 104.1719913482666}}, \"EndTime\": 1587300652.280586, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300652.175778}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:54 INFO 139636288943936] Epoch[4] Batch[0] avg_epoch_loss=3.621426\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.6214261055\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:59 INFO 139636288943936] Epoch[4] Batch[5] avg_epoch_loss=3.577083\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.57708334923\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:59 INFO 139636288943936] Epoch[4] Batch [5]#011Speed: 55.96 samples/sec#011loss=3.577083\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 139636288943936] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12123.512983322144, \"sum\": 12123.512983322144, \"min\": 12123.512983322144}}, \"EndTime\": 1587300664.404231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300652.280651}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.2120724712 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 139636288943936] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.5444034338\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_f1c1e873-337a-49cb-9110-35f28f5c19ed-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 114.89200592041016, \"sum\": 114.89200592041016, \"min\": 114.89200592041016}}, \"EndTime\": 1587300664.5198, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300664.40431}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:06 INFO 139636288943936] Epoch[5] Batch[0] avg_epoch_loss=3.534114\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.53411364555\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:12 INFO 139636288943936] Epoch[5] Batch[5] avg_epoch_loss=3.482477\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.48247742653\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:12 INFO 139636288943936] Epoch[5] Batch [5]#011Speed: 56.14 samples/sec#011loss=3.482477\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:16 INFO 139636288943936] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12105.67307472229, \"sum\": 12105.67307472229, \"min\": 12105.67307472229}}, \"EndTime\": 1587300676.625621, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300664.519881}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:16 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.1238188686 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:16 INFO 139636288943936] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:16 INFO 139636288943936] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.46495022774\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:16 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:16 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_dba05197-86f1-4291-8647-52546df80b51-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.7668571472168, \"sum\": 117.7668571472168, \"min\": 117.7668571472168}}, \"EndTime\": 1587300676.744038, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300676.625699}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:18 INFO 139636288943936] Epoch[6] Batch[0] avg_epoch_loss=3.459037\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.45903682709\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:24 INFO 139636288943936] Epoch[6] Batch[5] avg_epoch_loss=3.470026\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.4700264136\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:24 INFO 139636288943936] Epoch[6] Batch [5]#011Speed: 56.24 samples/sec#011loss=3.470026\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:28 INFO 139636288943936] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12040.758848190308, \"sum\": 12040.758848190308, \"min\": 12040.758848190308}}, \"EndTime\": 1587300688.784936, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300676.74411}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:28 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.4878529871 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:28 INFO 139636288943936] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:28 INFO 139636288943936] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.4754575491\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:28 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:30 INFO 139636288943936] Epoch[7] Batch[0] avg_epoch_loss=3.421768\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.42176818848\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:36 INFO 139636288943936] Epoch[7] Batch[5] avg_epoch_loss=3.430629\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.43062853813\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:36 INFO 139636288943936] Epoch[7] Batch [5]#011Speed: 56.24 samples/sec#011loss=3.430629\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 139636288943936] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12072.284936904907, \"sum\": 12072.284936904907, \"min\": 12072.284936904907}}, \"EndTime\": 1587300700.857939, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300688.78502}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.2799433202 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 139636288943936] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.41869573593\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_ea9fbb9f-776f-4434-859f-b51a6c6648b4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 140.8689022064209, \"sum\": 140.8689022064209, \"min\": 140.8689022064209}}, \"EndTime\": 1587300700.999388, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300700.858023}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:42 INFO 139636288943936] Epoch[8] Batch[0] avg_epoch_loss=3.312049\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:42 INFO 139636288943936] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.31204891205\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:48 INFO 139636288943936] Epoch[8] Batch[5] avg_epoch_loss=3.334553\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:48 INFO 139636288943936] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.33455316226\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:48 INFO 139636288943936] Epoch[8] Batch [5]#011Speed: 56.14 samples/sec#011loss=3.334553\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:53 INFO 139636288943936] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12180.752038955688, \"sum\": 12180.752038955688, \"min\": 12180.752038955688}}, \"EndTime\": 1587300713.180304, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300700.999461}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:53 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.91434047 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:53 INFO 139636288943936] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.35074250698\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:53 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:53 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_432e8ccd-e673-40c4-a0b7-551b30594b91-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 103.06692123413086, \"sum\": 103.06692123413086, \"min\": 103.06692123413086}}, \"EndTime\": 1587300713.284023, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300713.180374}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:55 INFO 139636288943936] Epoch[9] Batch[0] avg_epoch_loss=3.345518\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:55 INFO 139636288943936] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.34551811218\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:00 INFO 139636288943936] Epoch[9] Batch[5] avg_epoch_loss=3.336221\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:00 INFO 139636288943936] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.33622078101\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:00 INFO 139636288943936] Epoch[9] Batch [5]#011Speed: 56.48 samples/sec#011loss=3.336221\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:06 INFO 139636288943936] Epoch[9] Batch[10] avg_epoch_loss=3.323547\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.30833926201\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:06 INFO 139636288943936] Epoch[9] Batch [10]#011Speed: 55.63 samples/sec#011loss=3.308339\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:06 INFO 139636288943936] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13208.554029464722, \"sum\": 13208.554029464722, \"min\": 13208.554029464722}}, \"EndTime\": 1587300726.492709, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300713.284088}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:06 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.7559179053 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:06 INFO 139636288943936] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.32354736328\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:06 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:06 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_0a5d799f-06d1-4d64-8a1c-ee25d5c55357-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 103.67298126220703, \"sum\": 103.67298126220703, \"min\": 103.67298126220703}}, \"EndTime\": 1587300726.597, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300726.49277}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:08 INFO 139636288943936] Epoch[10] Batch[0] avg_epoch_loss=3.284230\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.28422951698\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:14 INFO 139636288943936] Epoch[10] Batch[5] avg_epoch_loss=3.260563\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:14 INFO 139636288943936] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.26056305567\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:14 INFO 139636288943936] Epoch[10] Batch [5]#011Speed: 55.55 samples/sec#011loss=3.260563\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:19 INFO 139636288943936] Epoch[10] Batch[10] avg_epoch_loss=3.238755\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=3.21258640289\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:19 INFO 139636288943936] Epoch[10] Batch [10]#011Speed: 56.57 samples/sec#011loss=3.212586\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:19 INFO 139636288943936] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13232.547998428345, \"sum\": 13232.547998428345, \"min\": 13232.547998428345}}, \"EndTime\": 1587300739.829688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300726.597073}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:19 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.9521330043 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:19 INFO 139636288943936] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.23875548623\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:19 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:19 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_4e9bdf75-8aba-4577-abd6-39ed53199715-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 126.38020515441895, \"sum\": 126.38020515441895, \"min\": 126.38020515441895}}, \"EndTime\": 1587300739.956878, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300739.829769}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:21 INFO 139636288943936] Epoch[11] Batch[0] avg_epoch_loss=3.249932\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=3.24993228912\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:27 INFO 139636288943936] Epoch[11] Batch[5] avg_epoch_loss=3.304790\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.30479021867\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:27 INFO 139636288943936] Epoch[11] Batch [5]#011Speed: 55.33 samples/sec#011loss=3.304790\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:33 INFO 139636288943936] Epoch[11] Batch[10] avg_epoch_loss=3.309083\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=3.31423444748\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:33 INFO 139636288943936] Epoch[11] Batch [10]#011Speed: 56.24 samples/sec#011loss=3.314234\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:33 INFO 139636288943936] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13294.191122055054, \"sum\": 13294.191122055054, \"min\": 13294.191122055054}}, \"EndTime\": 1587300753.251196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300739.956949}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:33 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.3222921156 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:33 INFO 139636288943936] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.30908304995\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:33 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:35 INFO 139636288943936] Epoch[12] Batch[0] avg_epoch_loss=3.682778\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.68277812004\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:40 INFO 139636288943936] Epoch[12] Batch[5] avg_epoch_loss=3.433367\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=3.43336673578\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:40 INFO 139636288943936] Epoch[12] Batch [5]#011Speed: 56.34 samples/sec#011loss=3.433367\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:46 INFO 139636288943936] Epoch[12] Batch[10] avg_epoch_loss=3.353105\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=3.25679035187\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:46 INFO 139636288943936] Epoch[12] Batch [10]#011Speed: 55.96 samples/sec#011loss=3.256790\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:46 INFO 139636288943936] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13268.001079559326, \"sum\": 13268.001079559326, \"min\": 13268.001079559326}}, \"EndTime\": 1587300766.519734, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300753.251276}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:46 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.9896379179 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:46 INFO 139636288943936] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.35310474309\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:46 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:48 INFO 139636288943936] Epoch[13] Batch[0] avg_epoch_loss=3.142050\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:48 INFO 139636288943936] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.14204955101\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:54 INFO 139636288943936] Epoch[13] Batch[5] avg_epoch_loss=3.172409\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=3.17240905762\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:54 INFO 139636288943936] Epoch[13] Batch [5]#011Speed: 54.70 samples/sec#011loss=3.172409\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:58 INFO 139636288943936] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12295.531034469604, \"sum\": 12295.531034469604, \"min\": 12295.531034469604}}, \"EndTime\": 1587300778.815866, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300766.51981}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:58 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.4001833134 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:58 INFO 139636288943936] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.13928947449\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:58 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:58 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_5f3cc79a-d89d-4450-84db-85ab68ad258a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 108.8399887084961, \"sum\": 108.8399887084961, \"min\": 108.8399887084961}}, \"EndTime\": 1587300778.925465, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300778.815971}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:00 INFO 139636288943936] Epoch[14] Batch[0] avg_epoch_loss=3.057220\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:00 INFO 139636288943936] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=3.05722045898\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:06 INFO 139636288943936] Epoch[14] Batch[5] avg_epoch_loss=3.014947\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=3.01494713624\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:06 INFO 139636288943936] Epoch[14] Batch [5]#011Speed: 56.20 samples/sec#011loss=3.014947\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:12 INFO 139636288943936] Epoch[14] Batch[10] avg_epoch_loss=3.111433\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=3.22721567154\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:12 INFO 139636288943936] Epoch[14] Batch [10]#011Speed: 56.37 samples/sec#011loss=3.227216\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:12 INFO 139636288943936] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13170.786142349243, \"sum\": 13170.786142349243, \"min\": 13170.786142349243}}, \"EndTime\": 1587300792.096394, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300778.92554}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:12 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.123431761 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:12 INFO 139636288943936] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=14, train loss <loss>=3.11143283411\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:12 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:12 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_09612e60-02f5-4da4-8892-cb934539727e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 125.2439022064209, \"sum\": 125.2439022064209, \"min\": 125.2439022064209}}, \"EndTime\": 1587300792.222185, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300792.096474}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:14 INFO 139636288943936] Epoch[15] Batch[0] avg_epoch_loss=6.515021\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:14 INFO 139636288943936] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=6.51502084732\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:19 INFO 139636288943936] Epoch[15] Batch[5] avg_epoch_loss=4.726474\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=4.72647388776\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:19 INFO 139636288943936] Epoch[15] Batch [5]#011Speed: 56.31 samples/sec#011loss=4.726474\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:24 INFO 139636288943936] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12096.139192581177, \"sum\": 12096.139192581177, \"min\": 12096.139192581177}}, \"EndTime\": 1587300804.31846, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300792.222258}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:24 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.0822741027 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:24 INFO 139636288943936] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=15, train loss <loss>=4.57458004951\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:24 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:26 INFO 139636288943936] Epoch[16] Batch[0] avg_epoch_loss=3.898902\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=3.89890193939\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:31 INFO 139636288943936] Epoch[16] Batch[5] avg_epoch_loss=3.794403\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=3.79440307617\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:31 INFO 139636288943936] Epoch[16] Batch [5]#011Speed: 56.41 samples/sec#011loss=3.794403\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:36 INFO 139636288943936] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12035.365104675293, \"sum\": 12035.365104675293, \"min\": 12035.365104675293}}, \"EndTime\": 1587300816.354314, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300804.318533}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:36 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=53.1761092044 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:36 INFO 139636288943936] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=16, train loss <loss>=3.68522078991\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:36 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:38 INFO 139636288943936] Epoch[17] Batch[0] avg_epoch_loss=3.416523\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=3.41652297974\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:43 INFO 139636288943936] Epoch[17] Batch[5] avg_epoch_loss=3.434442\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=3.4344420433\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:43 INFO 139636288943936] Epoch[17] Batch [5]#011Speed: 55.38 samples/sec#011loss=3.434442\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:48 INFO 139636288943936] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12149.125814437866, \"sum\": 12149.125814437866, \"min\": 12149.125814437866}}, \"EndTime\": 1587300828.504151, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300816.354392}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:48 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.6904506805 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:48 INFO 139636288943936] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:48 INFO 139636288943936] #quality_metric: host=algo-1, epoch=17, train loss <loss>=3.39802775383\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:48 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:50 INFO 139636288943936] Epoch[18] Batch[0] avg_epoch_loss=3.258717\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.25871658325\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:56 INFO 139636288943936] Epoch[18] Batch[5] avg_epoch_loss=3.274163\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=3.2741625309\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:56 INFO 139636288943936] Epoch[18] Batch [5]#011Speed: 56.16 samples/sec#011loss=3.274163\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:01 INFO 139636288943936] Epoch[18] Batch[10] avg_epoch_loss=3.251614\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=3.22455649376\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:01 INFO 139636288943936] Epoch[18] Batch [10]#011Speed: 56.41 samples/sec#011loss=3.224556\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:01 INFO 139636288943936] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13184.192895889282, \"sum\": 13184.192895889282, \"min\": 13184.192895889282}}, \"EndTime\": 1587300841.688979, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300828.50423}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:01 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.7420974128 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:01 INFO 139636288943936] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=18, train loss <loss>=3.2516143322\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:01 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:03 INFO 139636288943936] Epoch[19] Batch[0] avg_epoch_loss=3.092423\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=3.09242343903\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:09 INFO 139636288943936] Epoch[19] Batch[5] avg_epoch_loss=3.173568\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=3.17356844743\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:09 INFO 139636288943936] Epoch[19] Batch [5]#011Speed: 56.42 samples/sec#011loss=3.173568\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:13 INFO 139636288943936] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12013.967037200928, \"sum\": 12013.967037200928, \"min\": 12013.967037200928}}, \"EndTime\": 1587300853.703528, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300841.689067}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:13 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.107899084 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:13 INFO 139636288943936] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=19, train loss <loss>=3.13236014843\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:13 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:15 INFO 139636288943936] Epoch[20] Batch[0] avg_epoch_loss=3.191162\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=3.19116163254\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:21 INFO 139636288943936] Epoch[20] Batch[5] avg_epoch_loss=3.137979\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=3.13797855377\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:21 INFO 139636288943936] Epoch[20] Batch [5]#011Speed: 56.17 samples/sec#011loss=3.137979\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 139636288943936] processed a total of 582 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 11973.320960998535, \"sum\": 11973.320960998535, \"min\": 11973.320960998535}}, \"EndTime\": 1587300865.677396, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300853.703593}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.6075569955 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 139636288943936] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=20, train loss <loss>=3.14012749195\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:27 INFO 139636288943936] Epoch[21] Batch[0] avg_epoch_loss=3.215636\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=3.21563649178\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:33 INFO 139636288943936] Epoch[21] Batch[5] avg_epoch_loss=3.194164\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=3.19416447481\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:33 INFO 139636288943936] Epoch[21] Batch [5]#011Speed: 56.32 samples/sec#011loss=3.194164\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 139636288943936] Epoch[21] Batch[10] avg_epoch_loss=3.120393\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=3.03186621666\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 139636288943936] Epoch[21] Batch [10]#011Speed: 56.67 samples/sec#011loss=3.031866\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 139636288943936] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13204.118967056274, \"sum\": 13204.118967056274, \"min\": 13204.118967056274}}, \"EndTime\": 1587300878.882121, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300865.677481}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.8927707883 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 139636288943936] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=21, train loss <loss>=3.12039253928\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:40 INFO 139636288943936] Epoch[22] Batch[0] avg_epoch_loss=3.013458\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=3.01345825195\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:46 INFO 139636288943936] Epoch[22] Batch[5] avg_epoch_loss=3.013170\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=3.01316964626\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:46 INFO 139636288943936] Epoch[22] Batch [5]#011Speed: 55.91 samples/sec#011loss=3.013170\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:50 INFO 139636288943936] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12048.197984695435, \"sum\": 12048.197984695435, \"min\": 12048.197984695435}}, \"EndTime\": 1587300890.930904, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300878.8822}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:50 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.5424860749 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:50 INFO 139636288943936] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=22, train loss <loss>=3.00958981514\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:50 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:51 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_22a3d90a-417c-4e62-8577-eec96debb5b4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 115.77105522155762, \"sum\": 115.77105522155762, \"min\": 115.77105522155762}}, \"EndTime\": 1587300891.04729, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300890.93098}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:52 INFO 139636288943936] Epoch[23] Batch[0] avg_epoch_loss=3.532187\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=3.53218722343\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:58 INFO 139636288943936] Epoch[23] Batch[5] avg_epoch_loss=3.186681\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=3.18668099244\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:58 INFO 139636288943936] Epoch[23] Batch [5]#011Speed: 56.18 samples/sec#011loss=3.186681\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:04 INFO 139636288943936] Epoch[23] Batch[10] avg_epoch_loss=3.097514\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=2.990513134\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:04 INFO 139636288943936] Epoch[23] Batch [10]#011Speed: 56.14 samples/sec#011loss=2.990513\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:04 INFO 139636288943936] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13183.88295173645, \"sum\": 13183.88295173645, \"min\": 13183.88295173645}}, \"EndTime\": 1587300904.231315, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300891.04737}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:04 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.908966084 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:04 INFO 139636288943936] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=23, train loss <loss>=3.09751378406\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:04 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:06 INFO 139636288943936] Epoch[24] Batch[0] avg_epoch_loss=2.940768\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.94076800346\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:11 INFO 139636288943936] Epoch[24] Batch[5] avg_epoch_loss=2.880907\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.88090729713\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:11 INFO 139636288943936] Epoch[24] Batch [5]#011Speed: 56.25 samples/sec#011loss=2.880907\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:17 INFO 139636288943936] Epoch[24] Batch[10] avg_epoch_loss=2.831407\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=2.77200651169\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:17 INFO 139636288943936] Epoch[24] Batch [10]#011Speed: 55.42 samples/sec#011loss=2.772007\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:18 INFO 139636288943936] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14499.006986618042, \"sum\": 14499.006986618042, \"min\": 14499.006986618042}}, \"EndTime\": 1587300918.730884, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300904.231402}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:18 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.8995564172 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:18 INFO 139636288943936] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.83666223288\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:18 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:18 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_e106742c-9bf7-4ee8-92bc-bcc0caf3af38-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.55803298950195, \"sum\": 110.55803298950195, \"min\": 110.55803298950195}}, \"EndTime\": 1587300918.842246, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300918.730949}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:20 INFO 139636288943936] Epoch[25] Batch[0] avg_epoch_loss=3.992432\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:20 INFO 139636288943936] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=3.99243235588\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:26 INFO 139636288943936] Epoch[25] Batch[5] avg_epoch_loss=3.411456\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=3.41145551205\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:26 INFO 139636288943936] Epoch[25] Batch [5]#011Speed: 55.76 samples/sec#011loss=3.411456\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:30 INFO 139636288943936] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12084.288120269775, \"sum\": 12084.288120269775, \"min\": 12084.288120269775}}, \"EndTime\": 1587300930.926697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300918.842322}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:30 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.9606887484 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:30 INFO 139636288943936] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=25, train loss <loss>=3.33417103291\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:30 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:32 INFO 139636288943936] Epoch[26] Batch[0] avg_epoch_loss=2.978060\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=2.97806024551\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:38 INFO 139636288943936] Epoch[26] Batch[5] avg_epoch_loss=2.967117\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.96711707115\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:38 INFO 139636288943936] Epoch[26] Batch [5]#011Speed: 56.30 samples/sec#011loss=2.967117\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:43 INFO 139636288943936] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12100.913047790527, \"sum\": 12100.913047790527, \"min\": 12100.913047790527}}, \"EndTime\": 1587300943.02824, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300930.926779}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:43 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.7310434633 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:43 INFO 139636288943936] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=26, train loss <loss>=2.92080991268\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:43 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:44 INFO 139636288943936] Epoch[27] Batch[0] avg_epoch_loss=2.967453\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=2.96745252609\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:50 INFO 139636288943936] Epoch[27] Batch[5] avg_epoch_loss=2.779841\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=2.77984086672\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:50 INFO 139636288943936] Epoch[27] Batch [5]#011Speed: 56.13 samples/sec#011loss=2.779841\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:56 INFO 139636288943936] Epoch[27] Batch[10] avg_epoch_loss=2.745197\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=2.70362443924\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:56 INFO 139636288943936] Epoch[27] Batch [10]#011Speed: 55.74 samples/sec#011loss=2.703624\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:56 INFO 139636288943936] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13361.279010772705, \"sum\": 13361.279010772705, \"min\": 13361.279010772705}}, \"EndTime\": 1587300956.390366, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300943.02834}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:56 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.3482817352 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:56 INFO 139636288943936] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=27, train loss <loss>=2.74519703605\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:56 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:56 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_99d42176-5987-4f17-b616-2b8cfba61876-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 106.8260669708252, \"sum\": 106.8260669708252, \"min\": 106.8260669708252}}, \"EndTime\": 1587300956.498048, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300956.39043}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:58 INFO 139636288943936] Epoch[28] Batch[0] avg_epoch_loss=3.176715\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=3.17671489716\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:04 INFO 139636288943936] Epoch[28] Batch[5] avg_epoch_loss=3.015545\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=3.01554532846\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:04 INFO 139636288943936] Epoch[28] Batch [5]#011Speed: 55.89 samples/sec#011loss=3.015545\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 139636288943936] Epoch[28] Batch[10] avg_epoch_loss=2.943239\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=2.8564719677\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 139636288943936] Epoch[28] Batch [10]#011Speed: 56.17 samples/sec#011loss=2.856472\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 139636288943936] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13223.249912261963, \"sum\": 13223.249912261963, \"min\": 13223.249912261963}}, \"EndTime\": 1587300969.721438, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300956.498123}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.7601868891 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 139636288943936] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=28, train loss <loss>=2.94323925538\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:11 INFO 139636288943936] Epoch[29] Batch[0] avg_epoch_loss=2.806994\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.80699443817\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:17 INFO 139636288943936] Epoch[29] Batch[5] avg_epoch_loss=2.808126\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.80812569459\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:17 INFO 139636288943936] Epoch[29] Batch [5]#011Speed: 55.50 samples/sec#011loss=2.808126\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:21 INFO 139636288943936] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12189.55111503601, \"sum\": 12189.55111503601, \"min\": 12189.55111503601}}, \"EndTime\": 1587300981.911648, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300969.721573}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:21 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.9292405013 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:21 INFO 139636288943936] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=29, train loss <loss>=2.74920899868\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:21 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:23 INFO 139636288943936] Epoch[30] Batch[0] avg_epoch_loss=2.535238\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=2.53523778915\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:29 INFO 139636288943936] Epoch[30] Batch[5] avg_epoch_loss=2.965253\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.96525259813\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:29 INFO 139636288943936] Epoch[30] Batch [5]#011Speed: 56.22 samples/sec#011loss=2.965253\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:33 INFO 139636288943936] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12046.06008529663, \"sum\": 12046.06008529663, \"min\": 12046.06008529663}}, \"EndTime\": 1587300993.958279, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300981.911724}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:33 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.7967846651 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:33 INFO 139636288943936] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=30, train loss <loss>=2.92022497654\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:33 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:35 INFO 139636288943936] Epoch[31] Batch[0] avg_epoch_loss=2.828296\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.82829642296\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:41 INFO 139636288943936] Epoch[31] Batch[5] avg_epoch_loss=2.712097\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.7120970885\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:41 INFO 139636288943936] Epoch[31] Batch [5]#011Speed: 56.32 samples/sec#011loss=2.712097\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:47 INFO 139636288943936] Epoch[31] Batch[10] avg_epoch_loss=2.679724\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=2.64087600708\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:47 INFO 139636288943936] Epoch[31] Batch [10]#011Speed: 55.88 samples/sec#011loss=2.640876\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:47 INFO 139636288943936] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13275.985956192017, \"sum\": 13275.985956192017, \"min\": 13275.985956192017}}, \"EndTime\": 1587301007.234804, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300993.958366}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:47 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.7133798683 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:47 INFO 139636288943936] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.67972386967\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:47 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:47 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_8b349b2b-6729-4ab2-b69a-e69d5893284b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 119.43793296813965, \"sum\": 119.43793296813965, \"min\": 119.43793296813965}}, \"EndTime\": 1587301007.354804, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301007.234885}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:49 INFO 139636288943936] Epoch[32] Batch[0] avg_epoch_loss=3.839674\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=3.83967375755\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:54 INFO 139636288943936] Epoch[32] Batch[5] avg_epoch_loss=2.996365\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.99636546771\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:54 INFO 139636288943936] Epoch[32] Batch [5]#011Speed: 56.10 samples/sec#011loss=2.996365\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:59 INFO 139636288943936] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12104.933023452759, \"sum\": 12104.933023452759, \"min\": 12104.933023452759}}, \"EndTime\": 1587301019.459877, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301007.354877}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:59 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.7878513582 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:59 INFO 139636288943936] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.91204075813\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:59 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:01 INFO 139636288943936] Epoch[33] Batch[0] avg_epoch_loss=2.687116\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=2.68711614609\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:06 INFO 139636288943936] Epoch[33] Batch[5] avg_epoch_loss=2.587636\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.58763599396\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:06 INFO 139636288943936] Epoch[33] Batch [5]#011Speed: 55.98 samples/sec#011loss=2.587636\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:11 INFO 139636288943936] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12062.44421005249, \"sum\": 12062.44421005249, \"min\": 12062.44421005249}}, \"EndTime\": 1587301031.523143, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301019.459962}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:11 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.4919609247 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:11 INFO 139636288943936] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.60999464989\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:11 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:11 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_04401a34-e677-4cfd-a8ba-47984e74e502-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.22004890441895, \"sum\": 112.22004890441895, \"min\": 112.22004890441895}}, \"EndTime\": 1587301031.636212, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301031.523223}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:13 INFO 139636288943936] Epoch[34] Batch[0] avg_epoch_loss=2.728910\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=2.72890996933\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:19 INFO 139636288943936] Epoch[34] Batch[5] avg_epoch_loss=2.597333\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.59733263652\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:19 INFO 139636288943936] Epoch[34] Batch [5]#011Speed: 55.75 samples/sec#011loss=2.597333\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:23 INFO 139636288943936] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12098.117113113403, \"sum\": 12098.117113113403, \"min\": 12098.117113113403}}, \"EndTime\": 1587301043.734474, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301031.636284}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:23 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.4950421773 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:23 INFO 139636288943936] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.54894821644\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:23 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:23 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_f20f74bd-f36c-4ddb-a46e-d41e5886e436-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 106.05597496032715, \"sum\": 106.05597496032715, \"min\": 106.05597496032715}}, \"EndTime\": 1587301043.841343, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301043.734563}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:25 INFO 139636288943936] Epoch[35] Batch[0] avg_epoch_loss=2.408467\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.40846657753\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:31 INFO 139636288943936] Epoch[35] Batch[5] avg_epoch_loss=2.436745\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.43674504757\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:31 INFO 139636288943936] Epoch[35] Batch [5]#011Speed: 56.15 samples/sec#011loss=2.436745\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:35 INFO 139636288943936] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12028.555154800415, \"sum\": 12028.555154800415, \"min\": 12028.555154800415}}, \"EndTime\": 1587301055.870045, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301043.841422}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:35 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.5434559314 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:35 INFO 139636288943936] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.32681396008\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:35 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:35 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_36942973-c0f4-4896-8d5f-60166b919265-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.94784736633301, \"sum\": 110.94784736633301, \"min\": 110.94784736633301}}, \"EndTime\": 1587301055.981776, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301055.870134}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:37 INFO 139636288943936] Epoch[36] Batch[0] avg_epoch_loss=3.021755\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:37 INFO 139636288943936] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=3.02175474167\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:43 INFO 139636288943936] Epoch[36] Batch[5] avg_epoch_loss=2.907656\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.90765623252\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:43 INFO 139636288943936] Epoch[36] Batch [5]#011Speed: 56.07 samples/sec#011loss=2.907656\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:49 INFO 139636288943936] Epoch[36] Batch[10] avg_epoch_loss=2.794182\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=2.65801339149\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:49 INFO 139636288943936] Epoch[36] Batch [10]#011Speed: 56.04 samples/sec#011loss=2.658013\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:49 INFO 139636288943936] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13258.384943008423, \"sum\": 13258.384943008423, \"min\": 13258.384943008423}}, \"EndTime\": 1587301069.240325, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301055.981875}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:49 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.3633037134 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:49 INFO 139636288943936] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.79418221387\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:49 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:51 INFO 139636288943936] Epoch[37] Batch[0] avg_epoch_loss=2.530812\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.53081154823\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:57 INFO 139636288943936] Epoch[37] Batch[5] avg_epoch_loss=2.436093\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.43609348933\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:57 INFO 139636288943936] Epoch[37] Batch [5]#011Speed: 54.81 samples/sec#011loss=2.436093\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:01 INFO 139636288943936] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12387.532949447632, \"sum\": 12387.532949447632, \"min\": 12387.532949447632}}, \"EndTime\": 1587301081.62833, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301069.240398}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:01 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.4221488735 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:01 INFO 139636288943936] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.38325362206\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:01 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:03 INFO 139636288943936] Epoch[38] Batch[0] avg_epoch_loss=3.629972\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=3.62997198105\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:09 INFO 139636288943936] Epoch[38] Batch[5] avg_epoch_loss=2.733289\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.73328896364\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:09 INFO 139636288943936] Epoch[38] Batch [5]#011Speed: 56.09 samples/sec#011loss=2.733289\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:13 INFO 139636288943936] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12098.011016845703, \"sum\": 12098.011016845703, \"min\": 12098.011016845703}}, \"EndTime\": 1587301093.727025, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301081.628415}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:13 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.4874381807 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:13 INFO 139636288943936] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.61077516079\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:13 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:15 INFO 139636288943936] Epoch[39] Batch[0] avg_epoch_loss=2.311432\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.31143188477\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:21 INFO 139636288943936] Epoch[39] Batch[5] avg_epoch_loss=2.308053\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.30805250009\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:21 INFO 139636288943936] Epoch[39] Batch [5]#011Speed: 55.59 samples/sec#011loss=2.308053\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:25 INFO 139636288943936] processed a total of 591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12178.089141845703, \"sum\": 12178.089141845703, \"min\": 12178.089141845703}}, \"EndTime\": 1587301105.905791, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301093.727108}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:25 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.5291084164 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:25 INFO 139636288943936] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.45327262878\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:25 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:27 INFO 139636288943936] Epoch[40] Batch[0] avg_epoch_loss=2.477133\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.47713303566\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:33 INFO 139636288943936] Epoch[40] Batch[5] avg_epoch_loss=2.652937\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.652937452\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:33 INFO 139636288943936] Epoch[40] Batch [5]#011Speed: 56.09 samples/sec#011loss=2.652937\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:39 INFO 139636288943936] Epoch[40] Batch[10] avg_epoch_loss=2.654393\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=2.65614023209\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:39 INFO 139636288943936] Epoch[40] Batch [10]#011Speed: 56.61 samples/sec#011loss=2.656140\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:39 INFO 139636288943936] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13254.40502166748, \"sum\": 13254.40502166748, \"min\": 13254.40502166748}}, \"EndTime\": 1587301119.160841, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301105.905921}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:39 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.964425439 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:39 INFO 139636288943936] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=40, train loss <loss>=2.65439326113\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:39 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:41 INFO 139636288943936] Epoch[41] Batch[0] avg_epoch_loss=2.612188\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.61218810081\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:46 INFO 139636288943936] Epoch[41] Batch[5] avg_epoch_loss=2.427757\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.42775674661\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:46 INFO 139636288943936] Epoch[41] Batch [5]#011Speed: 55.48 samples/sec#011loss=2.427757\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:52 INFO 139636288943936] Epoch[41] Batch[10] avg_epoch_loss=2.484475\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=2.55253648758\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:52 INFO 139636288943936] Epoch[41] Batch [10]#011Speed: 56.26 samples/sec#011loss=2.552536\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:52 INFO 139636288943936] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13316.897869110107, \"sum\": 13316.897869110107, \"min\": 13316.897869110107}}, \"EndTime\": 1587301132.478244, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301119.16092}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:52 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.8609828495 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:52 INFO 139636288943936] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.48447481069\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:52 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:54 INFO 139636288943936] Epoch[42] Batch[0] avg_epoch_loss=3.465567\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=3.46556711197\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:59 INFO 139636288943936] Epoch[42] Batch[5] avg_epoch_loss=3.031941\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=3.03194089731\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:59 INFO 139636288943936] Epoch[42] Batch [5]#011Speed: 56.26 samples/sec#011loss=3.031941\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:04 INFO 139636288943936] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12004.478931427002, \"sum\": 12004.478931427002, \"min\": 12004.478931427002}}, \"EndTime\": 1587301144.483356, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301132.478332}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:04 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.6469167033 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:04 INFO 139636288943936] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.9674002409\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:04 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:06 INFO 139636288943936] Epoch[43] Batch[0] avg_epoch_loss=3.019870\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=3.01987028122\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:12 INFO 139636288943936] Epoch[43] Batch[5] avg_epoch_loss=2.816707\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.81670657794\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:12 INFO 139636288943936] Epoch[43] Batch [5]#011Speed: 56.15 samples/sec#011loss=2.816707\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:17 INFO 139636288943936] Epoch[43] Batch[10] avg_epoch_loss=2.646539\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.44233698845\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:17 INFO 139636288943936] Epoch[43] Batch [10]#011Speed: 56.08 samples/sec#011loss=2.442337\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:17 INFO 139636288943936] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13229.2799949646, \"sum\": 13229.2799949646, \"min\": 13229.2799949646}}, \"EndTime\": 1587301157.713311, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301144.483424}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:17 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.9817464437 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:17 INFO 139636288943936] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.64653858272\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:17 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:19 INFO 139636288943936] Epoch[44] Batch[0] avg_epoch_loss=2.206290\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.20629048347\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:25 INFO 139636288943936] Epoch[44] Batch[5] avg_epoch_loss=2.197485\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.19748489062\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:25 INFO 139636288943936] Epoch[44] Batch [5]#011Speed: 56.32 samples/sec#011loss=2.197485\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:29 INFO 139636288943936] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 11963.713884353638, \"sum\": 11963.713884353638, \"min\": 11963.713884353638}}, \"EndTime\": 1587301169.677733, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301157.713411}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:29 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.0703037987 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:29 INFO 139636288943936] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.31031527519\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:29 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:29 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_64a2ff9e-d1d3-45ed-a476-bd69a81ad52a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 114.30692672729492, \"sum\": 114.30692672729492, \"min\": 114.30692672729492}}, \"EndTime\": 1587301169.792691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301169.677879}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:31 INFO 139636288943936] Epoch[45] Batch[0] avg_epoch_loss=2.700508\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.70050787926\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:37 INFO 139636288943936] Epoch[45] Batch[5] avg_epoch_loss=2.457900\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:37 INFO 139636288943936] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.45789996783\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:37 INFO 139636288943936] Epoch[45] Batch [5]#011Speed: 56.80 samples/sec#011loss=2.457900\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:42 INFO 139636288943936] Epoch[45] Batch[10] avg_epoch_loss=2.490105\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:42 INFO 139636288943936] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=2.5287519455\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:42 INFO 139636288943936] Epoch[45] Batch [10]#011Speed: 56.85 samples/sec#011loss=2.528752\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:42 INFO 139636288943936] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13074.260950088501, \"sum\": 13074.260950088501, \"min\": 13074.260950088501}}, \"EndTime\": 1587301182.867094, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301169.792765}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:42 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.1800952289 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:42 INFO 139636288943936] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:42 INFO 139636288943936] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.49010541222\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:42 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:44 INFO 139636288943936] Epoch[46] Batch[0] avg_epoch_loss=2.310298\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.31029844284\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:50 INFO 139636288943936] Epoch[46] Batch[5] avg_epoch_loss=2.206811\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.20681142807\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:50 INFO 139636288943936] Epoch[46] Batch [5]#011Speed: 55.90 samples/sec#011loss=2.206811\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:56 INFO 139636288943936] Epoch[46] Batch[10] avg_epoch_loss=2.340280\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=2.50044159889\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:56 INFO 139636288943936] Epoch[46] Batch [10]#011Speed: 56.64 samples/sec#011loss=2.500442\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:56 INFO 139636288943936] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13230.861902236938, \"sum\": 13230.861902236938, \"min\": 13230.861902236938}}, \"EndTime\": 1587301196.098517, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301182.86719}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:56 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.9759642858 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:56 INFO 139636288943936] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.34027968753\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:56 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:57 INFO 139636288943936] Epoch[47] Batch[0] avg_epoch_loss=4.018559\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=4.01855897903\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:03 INFO 139636288943936] Epoch[47] Batch[5] avg_epoch_loss=3.485331\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=3.48533093929\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:03 INFO 139636288943936] Epoch[47] Batch [5]#011Speed: 55.54 samples/sec#011loss=3.485331\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:08 INFO 139636288943936] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12089.632034301758, \"sum\": 12089.632034301758, \"min\": 12089.632034301758}}, \"EndTime\": 1587301208.188651, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301196.098597}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:08 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.4411648243 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:08 INFO 139636288943936] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=47, train loss <loss>=3.327171278\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:08 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:09 INFO 139636288943936] Epoch[48] Batch[0] avg_epoch_loss=3.081806\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=3.08180642128\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:15 INFO 139636288943936] Epoch[48] Batch[5] avg_epoch_loss=3.149516\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=3.14951646328\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:15 INFO 139636288943936] Epoch[48] Batch [5]#011Speed: 56.19 samples/sec#011loss=3.149516\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:20 INFO 139636288943936] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12070.986032485962, \"sum\": 12070.986032485962, \"min\": 12070.986032485962}}, \"EndTime\": 1587301220.260362, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301208.188723}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:20 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.4393013222 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:20 INFO 139636288943936] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:20 INFO 139636288943936] #quality_metric: host=algo-1, epoch=48, train loss <loss>=3.09330425262\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:20 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:22 INFO 139636288943936] Epoch[49] Batch[0] avg_epoch_loss=2.875232\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:22 INFO 139636288943936] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=2.87523150444\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:27 INFO 139636288943936] Epoch[49] Batch[5] avg_epoch_loss=2.757696\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.75769551595\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:27 INFO 139636288943936] Epoch[49] Batch [5]#011Speed: 55.96 samples/sec#011loss=2.757696\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:32 INFO 139636288943936] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12092.971801757812, \"sum\": 12092.971801757812, \"min\": 12092.971801757812}}, \"EndTime\": 1587301232.354053, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301220.260437}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:32 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.1785363178 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:32 INFO 139636288943936] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=49, train loss <loss>=2.63541994095\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:32 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:34 INFO 139636288943936] Epoch[50] Batch[0] avg_epoch_loss=2.483282\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:34 INFO 139636288943936] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.48328185081\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:39 INFO 139636288943936] Epoch[50] Batch[5] avg_epoch_loss=2.232074\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.23207437992\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:39 INFO 139636288943936] Epoch[50] Batch [5]#011Speed: 56.38 samples/sec#011loss=2.232074\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:45 INFO 139636288943936] Epoch[50] Batch[10] avg_epoch_loss=2.313718\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=2.41169028282\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:45 INFO 139636288943936] Epoch[50] Batch [10]#011Speed: 56.15 samples/sec#011loss=2.411690\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:45 INFO 139636288943936] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13293.796062469482, \"sum\": 13293.796062469482, \"min\": 13293.796062469482}}, \"EndTime\": 1587301245.648671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301232.354136}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:45 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.2263985158 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:45 INFO 139636288943936] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.31371797215\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:45 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:47 INFO 139636288943936] Epoch[51] Batch[0] avg_epoch_loss=2.643466\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.64346575737\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:53 INFO 139636288943936] Epoch[51] Batch[5] avg_epoch_loss=2.691310\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.69131008784\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:53 INFO 139636288943936] Epoch[51] Batch [5]#011Speed: 55.84 samples/sec#011loss=2.691310\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:57 INFO 139636288943936] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12123.388051986694, \"sum\": 12123.388051986694, \"min\": 12123.388051986694}}, \"EndTime\": 1587301257.772558, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301245.648751}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:57 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.0578583541 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:57 INFO 139636288943936] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.60725080967\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:57 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:59 INFO 139636288943936] Epoch[52] Batch[0] avg_epoch_loss=2.608775\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.60877537727\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:05 INFO 139636288943936] Epoch[52] Batch[5] avg_epoch_loss=2.439201\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:05 INFO 139636288943936] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.43920099735\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:05 INFO 139636288943936] Epoch[52] Batch [5]#011Speed: 55.89 samples/sec#011loss=2.439201\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:09 INFO 139636288943936] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12112.598896026611, \"sum\": 12112.598896026611, \"min\": 12112.598896026611}}, \"EndTime\": 1587301269.885908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301257.772633}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:09 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.506703519 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:09 INFO 139636288943936] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.35945658684\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:09 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:11 INFO 139636288943936] Epoch[53] Batch[0] avg_epoch_loss=2.114041\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.11404132843\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:17 INFO 139636288943936] Epoch[53] Batch[5] avg_epoch_loss=2.025385\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.0253851215\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:17 INFO 139636288943936] Epoch[53] Batch [5]#011Speed: 55.74 samples/sec#011loss=2.025385\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:21 INFO 139636288943936] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12067.839860916138, \"sum\": 12067.839860916138, \"min\": 12067.839860916138}}, \"EndTime\": 1587301281.954373, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301269.885971}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:21 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.5414104182 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:21 INFO 139636288943936] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.19616538286\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:21 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:22 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_bf8d3160-46bc-46f4-9765-f37571fa5936-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 135.21909713745117, \"sum\": 135.21909713745117, \"min\": 135.21909713745117}}, \"EndTime\": 1587301282.090169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301281.954459}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:23 INFO 139636288943936] Epoch[54] Batch[0] avg_epoch_loss=2.036167\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.03616690636\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:29 INFO 139636288943936] Epoch[54] Batch[5] avg_epoch_loss=2.079171\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.07917076349\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:29 INFO 139636288943936] Epoch[54] Batch [5]#011Speed: 56.38 samples/sec#011loss=2.079171\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:34 INFO 139636288943936] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12039.716005325317, \"sum\": 12039.716005325317, \"min\": 12039.716005325317}}, \"EndTime\": 1587301294.130029, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301282.090243}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:34 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.4093344174 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:34 INFO 139636288943936] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:34 INFO 139636288943936] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.03613764048\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:34 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:34 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_8f2cedbd-465b-43c4-9343-3c4d25147421-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 106.63914680480957, \"sum\": 106.63914680480957, \"min\": 106.63914680480957}}, \"EndTime\": 1587301294.237401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301294.130111}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:36 INFO 139636288943936] Epoch[55] Batch[0] avg_epoch_loss=2.014937\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.0149371624\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:41 INFO 139636288943936] Epoch[55] Batch[5] avg_epoch_loss=1.987602\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=1.98760157824\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:41 INFO 139636288943936] Epoch[55] Batch [5]#011Speed: 56.52 samples/sec#011loss=1.987602\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:47 INFO 139636288943936] Epoch[55] Batch[10] avg_epoch_loss=2.060473\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=2.14791784286\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:47 INFO 139636288943936] Epoch[55] Batch [10]#011Speed: 55.77 samples/sec#011loss=2.147918\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:47 INFO 139636288943936] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13207.660913467407, \"sum\": 13207.660913467407, \"min\": 13207.660913467407}}, \"EndTime\": 1587301307.445201, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301294.237474}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:47 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.4404414172 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:47 INFO 139636288943936] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.06047260761\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:47 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:49 INFO 139636288943936] Epoch[56] Batch[0] avg_epoch_loss=1.833370\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=1.83336961269\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:54 INFO 139636288943936] Epoch[56] Batch[5] avg_epoch_loss=1.917404\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=1.9174041748\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:54 INFO 139636288943936] Epoch[56] Batch [5]#011Speed: 56.16 samples/sec#011loss=1.917404\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:59 INFO 139636288943936] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12054.883003234863, \"sum\": 12054.883003234863, \"min\": 12054.883003234863}}, \"EndTime\": 1587301319.500843, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301307.445314}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:59 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.4263228148 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:59 INFO 139636288943936] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=56, train loss <loss>=1.86069097519\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:59 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:59 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_7109f46f-f4c7-4abb-8100-79b1debf398d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.41219329833984, \"sum\": 109.41219329833984, \"min\": 109.41219329833984}}, \"EndTime\": 1587301319.611089, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301319.50093}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:01 INFO 139636288943936] Epoch[57] Batch[0] avg_epoch_loss=1.737360\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=1.73736035824\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:07 INFO 139636288943936] Epoch[57] Batch[5] avg_epoch_loss=1.975475\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:07 INFO 139636288943936] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=1.97547479471\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:07 INFO 139636288943936] Epoch[57] Batch [5]#011Speed: 56.29 samples/sec#011loss=1.975475\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:11 INFO 139636288943936] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12037.661075592041, \"sum\": 12037.661075592041, \"min\": 12037.661075592041}}, \"EndTime\": 1587301331.648908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301319.611174}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:11 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.4214158354 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:11 INFO 139636288943936] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=57, train loss <loss>=1.9070826292\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:11 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:13 INFO 139636288943936] Epoch[58] Batch[0] avg_epoch_loss=2.168183\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.16818284988\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:19 INFO 139636288943936] Epoch[58] Batch[5] avg_epoch_loss=1.920461\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=1.92046117783\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:19 INFO 139636288943936] Epoch[58] Batch [5]#011Speed: 55.57 samples/sec#011loss=1.920461\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:24 INFO 139636288943936] Epoch[58] Batch[10] avg_epoch_loss=1.808009\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=1.67306609154\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:24 INFO 139636288943936] Epoch[58] Batch [10]#011Speed: 56.18 samples/sec#011loss=1.673066\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:24 INFO 139636288943936] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13326.796054840088, \"sum\": 13326.796054840088, \"min\": 13326.796054840088}}, \"EndTime\": 1587301344.976283, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301331.648992}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:24 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.5988906476 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:24 INFO 139636288943936] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=58, train loss <loss>=1.80800886588\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:24 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:25 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_f9f42274-a4d5-4cf2-aabd-abd8e0a1084d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.84794998168945, \"sum\": 110.84794998168945, \"min\": 110.84794998168945}}, \"EndTime\": 1587301345.087748, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301344.976358}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:26 INFO 139636288943936] Epoch[59] Batch[0] avg_epoch_loss=1.934139\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=1.93413853645\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:32 INFO 139636288943936] Epoch[59] Batch[5] avg_epoch_loss=2.039457\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.03945662578\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:32 INFO 139636288943936] Epoch[59] Batch [5]#011Speed: 56.12 samples/sec#011loss=2.039457\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:38 INFO 139636288943936] Epoch[59] Batch[10] avg_epoch_loss=1.963242\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=1.87178440094\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:38 INFO 139636288943936] Epoch[59] Batch [10]#011Speed: 56.60 samples/sec#011loss=1.871784\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:38 INFO 139636288943936] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13171.672105789185, \"sum\": 13171.672105789185, \"min\": 13171.672105789185}}, \"EndTime\": 1587301358.259587, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301345.087824}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:38 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.423742505 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:38 INFO 139636288943936] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=59, train loss <loss>=1.96324197813\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:38 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:40 INFO 139636288943936] Epoch[60] Batch[0] avg_epoch_loss=1.702157\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=1.70215749741\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:45 INFO 139636288943936] Epoch[60] Batch[5] avg_epoch_loss=1.752701\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=1.75270118316\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:45 INFO 139636288943936] Epoch[60] Batch [5]#011Speed: 56.05 samples/sec#011loss=1.752701\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:51 INFO 139636288943936] Epoch[60] Batch[10] avg_epoch_loss=1.917089\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=2.11435425282\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:51 INFO 139636288943936] Epoch[60] Batch [10]#011Speed: 55.76 samples/sec#011loss=2.114354\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:51 INFO 139636288943936] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13262.324094772339, \"sum\": 13262.324094772339, \"min\": 13262.324094772339}}, \"EndTime\": 1587301371.522763, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301358.259663}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:51 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.3121966014 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:51 INFO 139636288943936] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=60, train loss <loss>=1.91708894209\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:51 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:53 INFO 139636288943936] Epoch[61] Batch[0] avg_epoch_loss=2.041023\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.04102301598\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:59 INFO 139636288943936] Epoch[61] Batch[5] avg_epoch_loss=2.148026\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.14802630742\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:59 INFO 139636288943936] Epoch[61] Batch [5]#011Speed: 56.12 samples/sec#011loss=2.148026\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:04 INFO 139636288943936] Epoch[61] Batch[10] avg_epoch_loss=2.084039\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=2.00725476742\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:04 INFO 139636288943936] Epoch[61] Batch [10]#011Speed: 55.26 samples/sec#011loss=2.007255\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:04 INFO 139636288943936] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13360.833883285522, \"sum\": 13360.833883285522, \"min\": 13360.833883285522}}, \"EndTime\": 1587301384.88414, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301371.522841}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:04 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.2001697327 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:04 INFO 139636288943936] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.08403924378\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:04 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:06 INFO 139636288943936] Epoch[62] Batch[0] avg_epoch_loss=1.978071\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=1.97807097435\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:12 INFO 139636288943936] Epoch[62] Batch[5] avg_epoch_loss=1.899619\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=1.89961868525\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:12 INFO 139636288943936] Epoch[62] Batch [5]#011Speed: 56.16 samples/sec#011loss=1.899619\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:17 INFO 139636288943936] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12158.713817596436, \"sum\": 12158.713817596436, \"min\": 12158.713817596436}}, \"EndTime\": 1587301397.043342, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301384.88422}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:17 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.6366087144 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:17 INFO 139636288943936] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=62, train loss <loss>=1.90031703711\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:17 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:18 INFO 139636288943936] Epoch[63] Batch[0] avg_epoch_loss=2.671373\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.67137336731\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:24 INFO 139636288943936] Epoch[63] Batch[5] avg_epoch_loss=1.951277\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=1.95127673944\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:24 INFO 139636288943936] Epoch[63] Batch [5]#011Speed: 56.18 samples/sec#011loss=1.951277\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:29 INFO 139636288943936] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12166.897058486938, \"sum\": 12166.897058486938, \"min\": 12166.897058486938}}, \"EndTime\": 1587301409.210855, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301397.043421}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:29 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.5327456193 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:29 INFO 139636288943936] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=63, train loss <loss>=1.83644584417\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:29 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:31 INFO 139636288943936] Epoch[64] Batch[0] avg_epoch_loss=1.628401\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=1.6284006834\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:36 INFO 139636288943936] Epoch[64] Batch[5] avg_epoch_loss=1.798977\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=1.79897691806\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:36 INFO 139636288943936] Epoch[64] Batch [5]#011Speed: 56.16 samples/sec#011loss=1.798977\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:42 INFO 139636288943936] Epoch[64] Batch[10] avg_epoch_loss=1.759987\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:42 INFO 139636288943936] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=1.7131986618\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:42 INFO 139636288943936] Epoch[64] Batch [10]#011Speed: 56.52 samples/sec#011loss=1.713199\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:42 INFO 139636288943936] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13199.169158935547, \"sum\": 13199.169158935547, \"min\": 13199.169158935547}}, \"EndTime\": 1587301422.410523, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301409.210938}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:42 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.9269466857 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:42 INFO 139636288943936] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:42 INFO 139636288943936] #quality_metric: host=algo-1, epoch=64, train loss <loss>=1.75998680158\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:42 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:42 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_42cd0cff-f908-4ba5-aa7e-995d48222853-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.27094650268555, \"sum\": 117.27094650268555, \"min\": 117.27094650268555}}, \"EndTime\": 1587301422.528412, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301422.410604}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:44 INFO 139636288943936] Epoch[65] Batch[0] avg_epoch_loss=3.212423\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=3.21242260933\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:50 INFO 139636288943936] Epoch[65] Batch[5] avg_epoch_loss=2.403620\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.40361960729\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:50 INFO 139636288943936] Epoch[65] Batch [5]#011Speed: 55.48 samples/sec#011loss=2.403620\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:54 INFO 139636288943936] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12044.56615447998, \"sum\": 12044.56615447998, \"min\": 12044.56615447998}}, \"EndTime\": 1587301434.573111, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301422.528484}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:54 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.1465874984 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:54 INFO 139636288943936] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.22910190821\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:54 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:56 INFO 139636288943936] Epoch[66] Batch[0] avg_epoch_loss=2.044559\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.04455924034\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:02 INFO 139636288943936] Epoch[66] Batch[5] avg_epoch_loss=1.970254\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=1.97025388479\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:02 INFO 139636288943936] Epoch[66] Batch [5]#011Speed: 55.59 samples/sec#011loss=1.970254\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:07 INFO 139636288943936] Epoch[66] Batch[10] avg_epoch_loss=1.858051\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:07 INFO 139636288943936] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=1.72340710163\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:07 INFO 139636288943936] Epoch[66] Batch [10]#011Speed: 56.35 samples/sec#011loss=1.723407\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:07 INFO 139636288943936] processed a total of 700 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13368.637084960938, \"sum\": 13368.637084960938, \"min\": 13368.637084960938}}, \"EndTime\": 1587301447.942447, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301434.573195}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:07 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.3608972664 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:07 INFO 139636288943936] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:07 INFO 139636288943936] #quality_metric: host=algo-1, epoch=66, train loss <loss>=1.85805080154\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:07 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:09 INFO 139636288943936] Epoch[67] Batch[0] avg_epoch_loss=1.726912\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=1.72691214085\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:15 INFO 139636288943936] Epoch[67] Batch[5] avg_epoch_loss=1.925800\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=1.92580014467\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:15 INFO 139636288943936] Epoch[67] Batch [5]#011Speed: 56.43 samples/sec#011loss=1.925800\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:20 INFO 139636288943936] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12110.01181602478, \"sum\": 12110.01181602478, \"min\": 12110.01181602478}}, \"EndTime\": 1587301460.052982, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301447.942529}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:20 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.1877259428 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:20 INFO 139636288943936] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:20 INFO 139636288943936] #quality_metric: host=algo-1, epoch=67, train loss <loss>=1.80819056034\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:20 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:21 INFO 139636288943936] Epoch[68] Batch[0] avg_epoch_loss=2.385092\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.3850915432\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:27 INFO 139636288943936] Epoch[68] Batch[5] avg_epoch_loss=1.785063\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=1.7850625515\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:27 INFO 139636288943936] Epoch[68] Batch [5]#011Speed: 56.47 samples/sec#011loss=1.785063\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:32 INFO 139636288943936] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 11979.005098342896, \"sum\": 11979.005098342896, \"min\": 11979.005098342896}}, \"EndTime\": 1587301472.032792, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301460.053057}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:32 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=53.426304585 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:32 INFO 139636288943936] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=68, train loss <loss>=1.71261132956\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:32 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:32 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_994c5d67-6084-404d-979b-a15402f18143-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 118.44611167907715, \"sum\": 118.44611167907715, \"min\": 118.44611167907715}}, \"EndTime\": 1587301472.151895, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301472.032867}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:33 INFO 139636288943936] Epoch[69] Batch[0] avg_epoch_loss=1.682843\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=1.68284296989\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:39 INFO 139636288943936] Epoch[69] Batch[5] avg_epoch_loss=1.714894\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=1.71489413579\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:39 INFO 139636288943936] Epoch[69] Batch [5]#011Speed: 56.21 samples/sec#011loss=1.714894\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:44 INFO 139636288943936] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12024.258136749268, \"sum\": 12024.258136749268, \"min\": 12024.258136749268}}, \"EndTime\": 1587301484.176525, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301472.152162}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:44 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=53.1419226034 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:44 INFO 139636288943936] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=69, train loss <loss>=1.73532203436\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:44 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:45 INFO 139636288943936] Epoch[70] Batch[0] avg_epoch_loss=1.836340\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=1.83633959293\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:51 INFO 139636288943936] Epoch[70] Batch[5] avg_epoch_loss=1.700182\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=1.70018217961\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:51 INFO 139636288943936] Epoch[70] Batch [5]#011Speed: 55.99 samples/sec#011loss=1.700182\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:56 INFO 139636288943936] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12061.880826950073, \"sum\": 12061.880826950073, \"min\": 12061.880826950073}}, \"EndTime\": 1587301496.2391, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301484.176598}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:56 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.3181384829 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:56 INFO 139636288943936] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=70, train loss <loss>=1.66144301891\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:56 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:56 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_837a6d7d-ba42-461b-8d1e-2c46e2d0852e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 104.48503494262695, \"sum\": 104.48503494262695, \"min\": 104.48503494262695}}, \"EndTime\": 1587301496.344418, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301496.239186}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:58 INFO 139636288943936] Epoch[71] Batch[0] avg_epoch_loss=2.135317\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.13531684875\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:03 INFO 139636288943936] Epoch[71] Batch[5] avg_epoch_loss=1.840695\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=1.84069488446\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:03 INFO 139636288943936] Epoch[71] Batch [5]#011Speed: 55.55 samples/sec#011loss=1.840695\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:08 INFO 139636288943936] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12095.570087432861, \"sum\": 12095.570087432861, \"min\": 12095.570087432861}}, \"EndTime\": 1587301508.440134, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301496.344494}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:08 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.9193240644 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:08 INFO 139636288943936] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=71, train loss <loss>=1.76431362629\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:08 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:10 INFO 139636288943936] Epoch[72] Batch[0] avg_epoch_loss=1.630014\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=1.63001441956\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:15 INFO 139636288943936] Epoch[72] Batch[5] avg_epoch_loss=1.583677\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=1.58367737134\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:15 INFO 139636288943936] Epoch[72] Batch [5]#011Speed: 56.03 samples/sec#011loss=1.583677\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:21 INFO 139636288943936] Epoch[72] Batch[10] avg_epoch_loss=1.603815\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=1.62798094749\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:21 INFO 139636288943936] Epoch[72] Batch [10]#011Speed: 55.95 samples/sec#011loss=1.627981\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:21 INFO 139636288943936] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13254.921197891235, \"sum\": 13254.921197891235, \"min\": 13254.921197891235}}, \"EndTime\": 1587301521.695836, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301508.44021}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:21 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.6607544771 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:21 INFO 139636288943936] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=72, train loss <loss>=1.6038153605\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:21 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:21 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_c0b41023-f80d-4353-8175-96e48c320dc2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 105.17215728759766, \"sum\": 105.17215728759766, \"min\": 105.17215728759766}}, \"EndTime\": 1587301521.801624, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301521.695911}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:23 INFO 139636288943936] Epoch[73] Batch[0] avg_epoch_loss=2.892428\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.89242815971\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:29 INFO 139636288943936] Epoch[73] Batch[5] avg_epoch_loss=2.263365\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.26336451372\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:29 INFO 139636288943936] Epoch[73] Batch [5]#011Speed: 56.16 samples/sec#011loss=2.263365\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:33 INFO 139636288943936] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12052.332878112793, \"sum\": 12052.332878112793, \"min\": 12052.332878112793}}, \"EndTime\": 1587301533.854099, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301521.801696}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:33 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.6863616348 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:33 INFO 139636288943936] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.14994730949\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:33 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:35 INFO 139636288943936] Epoch[74] Batch[0] avg_epoch_loss=2.042167\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.04216742516\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:41 INFO 139636288943936] Epoch[74] Batch[5] avg_epoch_loss=1.906716\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=1.90671628714\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:41 INFO 139636288943936] Epoch[74] Batch [5]#011Speed: 56.04 samples/sec#011loss=1.906716\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:45 INFO 139636288943936] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12037.231922149658, \"sum\": 12037.231922149658, \"min\": 12037.231922149658}}, \"EndTime\": 1587301545.891959, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301533.854181}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:45 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=53.0013642677 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:45 INFO 139636288943936] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=74, train loss <loss>=1.81404098272\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:45 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:47 INFO 139636288943936] Epoch[75] Batch[0] avg_epoch_loss=1.538798\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=1.53879821301\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:53 INFO 139636288943936] Epoch[75] Batch[5] avg_epoch_loss=1.627216\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=1.62721570333\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:53 INFO 139636288943936] Epoch[75] Batch [5]#011Speed: 56.28 samples/sec#011loss=1.627216\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:58 INFO 139636288943936] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12132.688045501709, \"sum\": 12132.688045501709, \"min\": 12132.688045501709}}, \"EndTime\": 1587301558.025476, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301545.892113}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:58 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.502290844 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:58 INFO 139636288943936] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=75, train loss <loss>=1.83868646622\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:58 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:59 INFO 139636288943936] Epoch[76] Batch[0] avg_epoch_loss=1.791681\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=1.79168093204\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:05 INFO 139636288943936] Epoch[76] Batch[5] avg_epoch_loss=1.612797\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:05 INFO 139636288943936] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=1.61279720068\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:05 INFO 139636288943936] Epoch[76] Batch [5]#011Speed: 56.22 samples/sec#011loss=1.612797\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:10 INFO 139636288943936] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12079.90312576294, \"sum\": 12079.90312576294, \"min\": 12079.90312576294}}, \"EndTime\": 1587301570.106111, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301558.025552}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:10 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.993284207 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:10 INFO 139636288943936] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=76, train loss <loss>=1.59081240892\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:10 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:10 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_8cb88eae-c0fa-46ee-9329-2acc94be5114-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 102.94604301452637, \"sum\": 102.94604301452637, \"min\": 102.94604301452637}}, \"EndTime\": 1587301570.209768, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301570.106192}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:12 INFO 139636288943936] Epoch[77] Batch[0] avg_epoch_loss=1.612361\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=1.61236059666\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:17 INFO 139636288943936] Epoch[77] Batch[5] avg_epoch_loss=1.608714\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=1.60871388515\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:17 INFO 139636288943936] Epoch[77] Batch [5]#011Speed: 56.01 samples/sec#011loss=1.608714\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:23 INFO 139636288943936] Epoch[77] Batch[10] avg_epoch_loss=1.579240\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=1.5438709259\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:23 INFO 139636288943936] Epoch[77] Batch [10]#011Speed: 56.22 samples/sec#011loss=1.543871\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:23 INFO 139636288943936] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13221.198081970215, \"sum\": 13221.198081970215, \"min\": 13221.198081970215}}, \"EndTime\": 1587301583.431134, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301570.209873}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:23 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.4821567357 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:23 INFO 139636288943936] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=77, train loss <loss>=1.57923981276\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:23 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:23 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_1e8c5ce6-0453-4248-9351-65f8e03f4969-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 113.47389221191406, \"sum\": 113.47389221191406, \"min\": 113.47389221191406}}, \"EndTime\": 1587301583.545359, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301583.431257}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:25 INFO 139636288943936] Epoch[78] Batch[0] avg_epoch_loss=1.341079\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=1.34107875824\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:31 INFO 139636288943936] Epoch[78] Batch[5] avg_epoch_loss=1.578124\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=1.57812392712\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:31 INFO 139636288943936] Epoch[78] Batch [5]#011Speed: 55.94 samples/sec#011loss=1.578124\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:36 INFO 139636288943936] Epoch[78] Batch[10] avg_epoch_loss=1.593574\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=1.61211493015\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:36 INFO 139636288943936] Epoch[78] Batch [10]#011Speed: 54.89 samples/sec#011loss=1.612115\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:36 INFO 139636288943936] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13377.942085266113, \"sum\": 13377.942085266113, \"min\": 13377.942085266113}}, \"EndTime\": 1587301596.923485, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301583.545432}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:36 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.7081381181 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:36 INFO 139636288943936] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=78, train loss <loss>=1.59357438304\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:36 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:38 INFO 139636288943936] Epoch[79] Batch[0] avg_epoch_loss=1.752282\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=1.75228214264\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:44 INFO 139636288943936] Epoch[79] Batch[5] avg_epoch_loss=1.694706\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=1.69470576445\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:44 INFO 139636288943936] Epoch[79] Batch [5]#011Speed: 56.17 samples/sec#011loss=1.694706\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:50 INFO 139636288943936] Epoch[79] Batch[10] avg_epoch_loss=1.658408\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=1.61485085487\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:50 INFO 139636288943936] Epoch[79] Batch [10]#011Speed: 53.96 samples/sec#011loss=1.614851\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:50 INFO 139636288943936] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13449.421882629395, \"sum\": 13449.421882629395, \"min\": 13449.421882629395}}, \"EndTime\": 1587301610.373539, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301596.923552}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:50 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.4850019557 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:50 INFO 139636288943936] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=79, train loss <loss>=1.65840807828\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:50 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:52 INFO 139636288943936] Epoch[80] Batch[0] avg_epoch_loss=1.633543\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=1.63354325294\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:57 INFO 139636288943936] Epoch[80] Batch[5] avg_epoch_loss=1.571595\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=1.5715945363\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:06:57 INFO 139636288943936] Epoch[80] Batch [5]#011Speed: 56.03 samples/sec#011loss=1.571595\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:02 INFO 139636288943936] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12148.506879806519, \"sum\": 12148.506879806519, \"min\": 12148.506879806519}}, \"EndTime\": 1587301622.522588, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301610.37362}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:02 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.6930587855 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:02 INFO 139636288943936] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=80, train loss <loss>=1.5578841567\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:02 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:02 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_c32503da-0d79-40d6-a999-f318d98dad8c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 123.35801124572754, \"sum\": 123.35801124572754, \"min\": 123.35801124572754}}, \"EndTime\": 1587301622.646748, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301622.522673}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:04 INFO 139636288943936] Epoch[81] Batch[0] avg_epoch_loss=1.372268\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=1.37226784229\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:10 INFO 139636288943936] Epoch[81] Batch[5] avg_epoch_loss=1.600285\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=1.60028467576\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:10 INFO 139636288943936] Epoch[81] Batch [5]#011Speed: 56.46 samples/sec#011loss=1.600285\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:15 INFO 139636288943936] Epoch[81] Batch[10] avg_epoch_loss=1.512520\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=1.40720310211\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:15 INFO 139636288943936] Epoch[81] Batch [10]#011Speed: 56.41 samples/sec#011loss=1.407203\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:15 INFO 139636288943936] processed a total of 700 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13173.564910888672, \"sum\": 13173.564910888672, \"min\": 13173.564910888672}}, \"EndTime\": 1587301635.820487, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301622.646851}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:15 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=53.1362330339 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:15 INFO 139636288943936] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=81, train loss <loss>=1.5125203241\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:15 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:15 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_7ba01b6d-eb56-4f65-8017-1429e0d4e904-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 119.31395530700684, \"sum\": 119.31395530700684, \"min\": 119.31395530700684}}, \"EndTime\": 1587301635.940375, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301635.820567}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:17 INFO 139636288943936] Epoch[82] Batch[0] avg_epoch_loss=1.746406\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=1.74640595913\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:23 INFO 139636288943936] Epoch[82] Batch[5] avg_epoch_loss=1.433768\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=1.43376847108\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:23 INFO 139636288943936] Epoch[82] Batch [5]#011Speed: 55.67 samples/sec#011loss=1.433768\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:28 INFO 139636288943936] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12088.720083236694, \"sum\": 12088.720083236694, \"min\": 12088.720083236694}}, \"EndTime\": 1587301648.029241, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301635.94046}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:28 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.0314993825 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:28 INFO 139636288943936] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:28 INFO 139636288943936] #quality_metric: host=algo-1, epoch=82, train loss <loss>=1.36719491482\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:28 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:28 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_7a40781a-a0f3-4a75-86c3-87a22a84f1c1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 107.39493370056152, \"sum\": 107.39493370056152, \"min\": 107.39493370056152}}, \"EndTime\": 1587301648.137442, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301648.029317}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:29 INFO 139636288943936] Epoch[83] Batch[0] avg_epoch_loss=2.729721\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.72972083092\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:35 INFO 139636288943936] Epoch[83] Batch[5] avg_epoch_loss=2.101742\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.10174169143\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:35 INFO 139636288943936] Epoch[83] Batch [5]#011Speed: 56.34 samples/sec#011loss=2.101742\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:41 INFO 139636288943936] Epoch[83] Batch[10] avg_epoch_loss=1.840816\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=1.52770409584\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:41 INFO 139636288943936] Epoch[83] Batch [10]#011Speed: 55.96 samples/sec#011loss=1.527704\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:41 INFO 139636288943936] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13206.403970718384, \"sum\": 13206.403970718384, \"min\": 13206.403970718384}}, \"EndTime\": 1587301661.343995, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301648.137523}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:41 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.5809311215 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:41 INFO 139636288943936] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=83, train loss <loss>=1.84081551162\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:41 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:43 INFO 139636288943936] Epoch[84] Batch[0] avg_epoch_loss=1.742649\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=1.74264931679\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:48 INFO 139636288943936] Epoch[84] Batch[5] avg_epoch_loss=1.572536\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:48 INFO 139636288943936] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=1.57253644864\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:48 INFO 139636288943936] Epoch[84] Batch [5]#011Speed: 55.58 samples/sec#011loss=1.572536\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:53 INFO 139636288943936] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12099.155902862549, \"sum\": 12099.155902862549, \"min\": 12099.155902862549}}, \"EndTime\": 1587301673.443744, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301661.344094}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:53 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.0854556701 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:53 INFO 139636288943936] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=84, train loss <loss>=1.53534921408\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:53 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:55 INFO 139636288943936] Epoch[85] Batch[0] avg_epoch_loss=1.378961\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:07:55 INFO 139636288943936] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=1.37896132469\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:00 INFO 139636288943936] Epoch[85] Batch[5] avg_epoch_loss=1.446164\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:00 INFO 139636288943936] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=1.44616421064\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:00 INFO 139636288943936] Epoch[85] Batch [5]#011Speed: 56.20 samples/sec#011loss=1.446164\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:06 INFO 139636288943936] Epoch[85] Batch[10] avg_epoch_loss=1.558525\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=1.69335889816\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:06 INFO 139636288943936] Epoch[85] Batch [10]#011Speed: 55.65 samples/sec#011loss=1.693359\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:06 INFO 139636288943936] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13267.996788024902, \"sum\": 13267.996788024902, \"min\": 13267.996788024902}}, \"EndTime\": 1587301686.71255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301673.44387}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:06 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.8734863542 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:06 INFO 139636288943936] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=85, train loss <loss>=1.55852543224\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:06 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:08 INFO 139636288943936] Epoch[86] Batch[0] avg_epoch_loss=1.360103\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=1.36010348797\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:14 INFO 139636288943936] Epoch[86] Batch[5] avg_epoch_loss=1.424634\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:14 INFO 139636288943936] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=1.42463421822\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:14 INFO 139636288943936] Epoch[86] Batch [5]#011Speed: 56.42 samples/sec#011loss=1.424634\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:20 INFO 139636288943936] Epoch[86] Batch[10] avg_epoch_loss=1.382071\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:20 INFO 139636288943936] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=1.33099452257\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:20 INFO 139636288943936] Epoch[86] Batch [10]#011Speed: 55.87 samples/sec#011loss=1.330995\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:20 INFO 139636288943936] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13303.01308631897, \"sum\": 13303.01308631897, \"min\": 13303.01308631897}}, \"EndTime\": 1587301700.016168, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301686.712722}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:20 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.7103414245 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:20 INFO 139636288943936] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:20 INFO 139636288943936] #quality_metric: host=algo-1, epoch=86, train loss <loss>=1.3820707202\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:20 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:21 INFO 139636288943936] Epoch[87] Batch[0] avg_epoch_loss=1.903228\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=1.90322780609\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:27 INFO 139636288943936] Epoch[87] Batch[5] avg_epoch_loss=1.620818\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=1.62081819773\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:27 INFO 139636288943936] Epoch[87] Batch [5]#011Speed: 56.14 samples/sec#011loss=1.620818\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:33 INFO 139636288943936] Epoch[87] Batch[10] avg_epoch_loss=1.516238\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=1.390741539\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:33 INFO 139636288943936] Epoch[87] Batch [10]#011Speed: 56.48 samples/sec#011loss=1.390742\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:33 INFO 139636288943936] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13228.190898895264, \"sum\": 13228.190898895264, \"min\": 13228.190898895264}}, \"EndTime\": 1587301713.244935, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301700.016249}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:33 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.2882537679 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:33 INFO 139636288943936] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=87, train loss <loss>=1.51623789831\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:33 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:35 INFO 139636288943936] Epoch[88] Batch[0] avg_epoch_loss=1.335545\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=1.3355448246\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:40 INFO 139636288943936] Epoch[88] Batch[5] avg_epoch_loss=1.494889\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=1.49488933881\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:40 INFO 139636288943936] Epoch[88] Batch [5]#011Speed: 56.16 samples/sec#011loss=1.494889\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:45 INFO 139636288943936] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12071.550846099854, \"sum\": 12071.550846099854, \"min\": 12071.550846099854}}, \"EndTime\": 1587301725.316976, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301713.245012}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:45 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.5255659413 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:45 INFO 139636288943936] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=88, train loss <loss>=1.45504354239\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:45 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:47 INFO 139636288943936] Epoch[89] Batch[0] avg_epoch_loss=1.820079\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=1.82007920742\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:52 INFO 139636288943936] Epoch[89] Batch[5] avg_epoch_loss=1.479954\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=1.47995370626\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:52 INFO 139636288943936] Epoch[89] Batch [5]#011Speed: 55.08 samples/sec#011loss=1.479954\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:58 INFO 139636288943936] Epoch[89] Batch[10] avg_epoch_loss=1.450666\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=1.41551966667\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:58 INFO 139636288943936] Epoch[89] Batch [10]#011Speed: 56.19 samples/sec#011loss=1.415520\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:58 INFO 139636288943936] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13329.993963241577, \"sum\": 13329.993963241577, \"min\": 13329.993963241577}}, \"EndTime\": 1587301738.6476, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301725.317061}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:58 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.6867732429 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:58 INFO 139636288943936] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=89, train loss <loss>=1.45066550645\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:08:58 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:00 INFO 139636288943936] Epoch[90] Batch[0] avg_epoch_loss=2.705109\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:00 INFO 139636288943936] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.70510864258\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:06 INFO 139636288943936] Epoch[90] Batch[5] avg_epoch_loss=2.006441\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.00644109646\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:06 INFO 139636288943936] Epoch[90] Batch [5]#011Speed: 55.77 samples/sec#011loss=2.006441\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:10 INFO 139636288943936] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12081.82692527771, \"sum\": 12081.82692527771, \"min\": 12081.82692527771}}, \"EndTime\": 1587301750.730258, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301738.647674}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:10 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.9716037482 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:10 INFO 139636288943936] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=90, train loss <loss>=1.88751229048\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:10 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:12 INFO 139636288943936] Epoch[91] Batch[0] avg_epoch_loss=1.650010\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=1.65001022816\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:18 INFO 139636288943936] Epoch[91] Batch[5] avg_epoch_loss=1.637086\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=1.63708587488\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:18 INFO 139636288943936] Epoch[91] Batch [5]#011Speed: 56.11 samples/sec#011loss=1.637086\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:23 INFO 139636288943936] Epoch[91] Batch[10] avg_epoch_loss=1.516720\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=1.37228150368\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:23 INFO 139636288943936] Epoch[91] Batch [10]#011Speed: 56.16 samples/sec#011loss=1.372282\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:23 INFO 139636288943936] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13249.316930770874, \"sum\": 13249.316930770874, \"min\": 13249.316930770874}}, \"EndTime\": 1587301763.980166, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301750.730339}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:23 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.8700820056 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:23 INFO 139636288943936] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=91, train loss <loss>=1.5167202516\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:23 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:25 INFO 139636288943936] Epoch[92] Batch[0] avg_epoch_loss=1.263489\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=1.26348948479\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:31 INFO 139636288943936] Epoch[92] Batch[5] avg_epoch_loss=1.225203\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=1.22520295779\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:31 INFO 139636288943936] Epoch[92] Batch [5]#011Speed: 56.38 samples/sec#011loss=1.225203\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:35 INFO 139636288943936] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 11955.34086227417, \"sum\": 11955.34086227417, \"min\": 11955.34086227417}}, \"EndTime\": 1587301775.93612, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301763.980253}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:35 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.6881027985 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:35 INFO 139636288943936] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=92, train loss <loss>=1.6525257349\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:35 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:37 INFO 139636288943936] Epoch[93] Batch[0] avg_epoch_loss=1.961444\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:37 INFO 139636288943936] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=1.96144413948\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:43 INFO 139636288943936] Epoch[93] Batch[5] avg_epoch_loss=1.687610\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=1.68760965268\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:43 INFO 139636288943936] Epoch[93] Batch [5]#011Speed: 56.11 samples/sec#011loss=1.687610\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:47 INFO 139636288943936] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12018.529891967773, \"sum\": 12018.529891967773, \"min\": 12018.529891967773}}, \"EndTime\": 1587301787.955323, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301775.936205}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:47 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.6697487182 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:47 INFO 139636288943936] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=93, train loss <loss>=1.6322807312\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:47 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:49 INFO 139636288943936] Epoch[94] Batch[0] avg_epoch_loss=1.571041\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=1.57104110718\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:55 INFO 139636288943936] Epoch[94] Batch[5] avg_epoch_loss=1.477832\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:55 INFO 139636288943936] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=1.47783176104\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:09:55 INFO 139636288943936] Epoch[94] Batch [5]#011Speed: 56.36 samples/sec#011loss=1.477832\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:01 INFO 139636288943936] Epoch[94] Batch[10] avg_epoch_loss=1.433599\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=1.38051974773\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:01 INFO 139636288943936] Epoch[94] Batch [10]#011Speed: 55.96 samples/sec#011loss=1.380520\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:01 INFO 139636288943936] processed a total of 692 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13271.544933319092, \"sum\": 13271.544933319092, \"min\": 13271.544933319092}}, \"EndTime\": 1587301801.227464, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301787.955396}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:01 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.1408723763 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:01 INFO 139636288943936] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=94, train loss <loss>=1.43359902772\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:01 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:03 INFO 139636288943936] Epoch[95] Batch[0] avg_epoch_loss=1.646222\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=1.64622175694\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:08 INFO 139636288943936] Epoch[95] Batch[5] avg_epoch_loss=1.494155\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=1.49415479104\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:08 INFO 139636288943936] Epoch[95] Batch [5]#011Speed: 56.26 samples/sec#011loss=1.494155\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:13 INFO 139636288943936] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12096.198081970215, \"sum\": 12096.198081970215, \"min\": 12096.198081970215}}, \"EndTime\": 1587301813.324267, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301801.227607}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:13 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.3299950997 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:13 INFO 139636288943936] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=95, train loss <loss>=1.45677183867\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:13 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:15 INFO 139636288943936] Epoch[96] Batch[0] avg_epoch_loss=1.262240\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=1.26223993301\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:20 INFO 139636288943936] Epoch[96] Batch[5] avg_epoch_loss=1.359409\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:20 INFO 139636288943936] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=1.35940869649\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:20 INFO 139636288943936] Epoch[96] Batch [5]#011Speed: 55.78 samples/sec#011loss=1.359409\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:26 INFO 139636288943936] Epoch[96] Batch[10] avg_epoch_loss=1.377330\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=1.39883573055\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:26 INFO 139636288943936] Epoch[96] Batch [10]#011Speed: 56.09 samples/sec#011loss=1.398836\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:26 INFO 139636288943936] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13261.023044586182, \"sum\": 13261.023044586182, \"min\": 13261.023044586182}}, \"EndTime\": 1587301826.585806, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301813.324342}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:26 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.2414997131 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:26 INFO 139636288943936] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=96, train loss <loss>=1.37733007561\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:26 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:28 INFO 139636288943936] Epoch[97] Batch[0] avg_epoch_loss=1.649558\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:28 INFO 139636288943936] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=1.64955770969\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:34 INFO 139636288943936] Epoch[97] Batch[5] avg_epoch_loss=1.404837\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:34 INFO 139636288943936] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=1.40483748913\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:34 INFO 139636288943936] Epoch[97] Batch [5]#011Speed: 55.65 samples/sec#011loss=1.404837\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:38 INFO 139636288943936] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12144.66905593872, \"sum\": 12144.66905593872, \"min\": 12144.66905593872}}, \"EndTime\": 1587301838.731083, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301826.585914}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:38 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.2034298066 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:38 INFO 139636288943936] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=97, train loss <loss>=1.38268148899\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:38 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:40 INFO 139636288943936] Epoch[98] Batch[0] avg_epoch_loss=1.187569\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=1.18756914139\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:46 INFO 139636288943936] Epoch[98] Batch[5] avg_epoch_loss=1.362118\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=1.36211766799\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:46 INFO 139636288943936] Epoch[98] Batch [5]#011Speed: 56.42 samples/sec#011loss=1.362118\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:50 INFO 139636288943936] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12145.608186721802, \"sum\": 12145.608186721802, \"min\": 12145.608186721802}}, \"EndTime\": 1587301850.877304, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301838.731168}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:50 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.3761094858 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:50 INFO 139636288943936] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=98, train loss <loss>=1.36440058947\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:50 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:50 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_7e0db196-e22f-417d-a33a-6b6157f0689a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.2901439666748, \"sum\": 112.2901439666748, \"min\": 112.2901439666748}}, \"EndTime\": 1587301850.990366, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301850.877381}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:52 INFO 139636288943936] Epoch[99] Batch[0] avg_epoch_loss=1.562918\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=1.56291759014\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:58 INFO 139636288943936] Epoch[99] Batch[5] avg_epoch_loss=1.252679\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=1.25267944733\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:10:58 INFO 139636288943936] Epoch[99] Batch [5]#011Speed: 55.97 samples/sec#011loss=1.252679\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:04 INFO 139636288943936] Epoch[99] Batch[10] avg_epoch_loss=1.341511\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=1.4481095314\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:04 INFO 139636288943936] Epoch[99] Batch [10]#011Speed: 55.77 samples/sec#011loss=1.448110\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:04 INFO 139636288943936] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13267.773151397705, \"sum\": 13267.773151397705, \"min\": 13267.773151397705}}, \"EndTime\": 1587301864.258281, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301850.990438}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:04 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.5730734516 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:04 INFO 139636288943936] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=99, train loss <loss>=1.34151130373\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:04 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:04 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_7f2e3da9-c619-4978-98d7-42dc5067c768-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 104.33197021484375, \"sum\": 104.33197021484375, \"min\": 104.33197021484375}}, \"EndTime\": 1587301864.36346, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301864.258398}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:06 INFO 139636288943936] Epoch[100] Batch[0] avg_epoch_loss=1.958207\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=1.95820713043\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:11 INFO 139636288943936] Epoch[100] Batch[5] avg_epoch_loss=1.761812\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=1.76181213061\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:11 INFO 139636288943936] Epoch[100] Batch [5]#011Speed: 56.09 samples/sec#011loss=1.761812\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:17 INFO 139636288943936] Epoch[100] Batch[10] avg_epoch_loss=1.602513\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=1.41135401726\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:17 INFO 139636288943936] Epoch[100] Batch [10]#011Speed: 56.46 samples/sec#011loss=1.411354\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:17 INFO 139636288943936] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13168.864965438843, \"sum\": 13168.864965438843, \"min\": 13168.864965438843}}, \"EndTime\": 1587301877.532457, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301864.363535}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:17 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.1306240021 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:17 INFO 139636288943936] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=100, train loss <loss>=1.60251298818\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:17 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:19 INFO 139636288943936] Epoch[101] Batch[0] avg_epoch_loss=1.577048\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=1.57704782486\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:25 INFO 139636288943936] Epoch[101] Batch[5] avg_epoch_loss=1.648994\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=1.64899434646\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:25 INFO 139636288943936] Epoch[101] Batch [5]#011Speed: 55.18 samples/sec#011loss=1.648994\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:30 INFO 139636288943936] Epoch[101] Batch[10] avg_epoch_loss=1.637961\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=1.62472007275\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:30 INFO 139636288943936] Epoch[101] Batch [10]#011Speed: 56.55 samples/sec#011loss=1.624720\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:30 INFO 139636288943936] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13371.309041976929, \"sum\": 13371.309041976929, \"min\": 13371.309041976929}}, \"EndTime\": 1587301890.904272, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301877.532532}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:30 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.7606710174 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:30 INFO 139636288943936] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=101, train loss <loss>=1.63796058568\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:30 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:32 INFO 139636288943936] Epoch[102] Batch[0] avg_epoch_loss=2.385168\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.38516783714\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:38 INFO 139636288943936] Epoch[102] Batch[5] avg_epoch_loss=1.895122\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=1.89512232939\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:38 INFO 139636288943936] Epoch[102] Batch [5]#011Speed: 56.21 samples/sec#011loss=1.895122\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:44 INFO 139636288943936] Epoch[102] Batch[10] avg_epoch_loss=1.780753\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=1.64351017475\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:44 INFO 139636288943936] Epoch[102] Batch [10]#011Speed: 55.94 samples/sec#011loss=1.643510\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:44 INFO 139636288943936] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13262.974977493286, \"sum\": 13262.974977493286, \"min\": 13262.974977493286}}, \"EndTime\": 1587301904.167838, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301890.904355}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:44 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.7223070262 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:44 INFO 139636288943936] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=102, train loss <loss>=1.78075316819\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:44 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:46 INFO 139636288943936] Epoch[103] Batch[0] avg_epoch_loss=1.674379\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=1.67437946796\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:51 INFO 139636288943936] Epoch[103] Batch[5] avg_epoch_loss=1.534458\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=1.53445802132\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:51 INFO 139636288943936] Epoch[103] Batch [5]#011Speed: 55.67 samples/sec#011loss=1.534458\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:56 INFO 139636288943936] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12423.716068267822, \"sum\": 12423.716068267822, \"min\": 12423.716068267822}}, \"EndTime\": 1587301916.592152, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301904.167949}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:56 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.9845945766 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:56 INFO 139636288943936] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=103, train loss <loss>=1.43827102184\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:56 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:58 INFO 139636288943936] Epoch[104] Batch[0] avg_epoch_loss=1.306050\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:11:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=1.30604958534\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:04 INFO 139636288943936] Epoch[104] Batch[5] avg_epoch_loss=1.426873\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=1.4268728892\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:04 INFO 139636288943936] Epoch[104] Batch [5]#011Speed: 55.19 samples/sec#011loss=1.426873\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:09 INFO 139636288943936] Epoch[104] Batch[10] avg_epoch_loss=1.278517\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=1.10049097538\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:09 INFO 139636288943936] Epoch[104] Batch [10]#011Speed: 55.82 samples/sec#011loss=1.100491\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:09 INFO 139636288943936] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13403.383016586304, \"sum\": 13403.383016586304, \"min\": 13403.383016586304}}, \"EndTime\": 1587301929.996033, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301916.592227}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:09 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.852159225 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:09 INFO 139636288943936] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=104, train loss <loss>=1.27851747383\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:09 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:10 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_677cdff4-e785-4ffe-8cd9-770f95c82f30-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 118.1478500366211, \"sum\": 118.1478500366211, \"min\": 118.1478500366211}}, \"EndTime\": 1587301930.114717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301929.996106}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:11 INFO 139636288943936] Epoch[105] Batch[0] avg_epoch_loss=1.116628\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=1.1166280508\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:17 INFO 139636288943936] Epoch[105] Batch[5] avg_epoch_loss=1.579415\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=1.5794146657\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:17 INFO 139636288943936] Epoch[105] Batch [5]#011Speed: 55.77 samples/sec#011loss=1.579415\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:23 INFO 139636288943936] Epoch[105] Batch[10] avg_epoch_loss=1.495160\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=1.39405488968\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:23 INFO 139636288943936] Epoch[105] Batch [10]#011Speed: 55.78 samples/sec#011loss=1.394055\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:23 INFO 139636288943936] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13270.357131958008, \"sum\": 13270.357131958008, \"min\": 13270.357131958008}}, \"EndTime\": 1587301943.385201, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301930.114782}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:23 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.6041672771 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:23 INFO 139636288943936] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=105, train loss <loss>=1.49516022205\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:23 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:25 INFO 139636288943936] Epoch[106] Batch[0] avg_epoch_loss=1.657361\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=1.65736079216\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:30 INFO 139636288943936] Epoch[106] Batch[5] avg_epoch_loss=1.476390\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=1.47638998429\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:30 INFO 139636288943936] Epoch[106] Batch [5]#011Speed: 56.04 samples/sec#011loss=1.476390\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:36 INFO 139636288943936] Epoch[106] Batch[10] avg_epoch_loss=1.404158\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=1.31748006344\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:36 INFO 139636288943936] Epoch[106] Batch [10]#011Speed: 56.55 samples/sec#011loss=1.317480\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:36 INFO 139636288943936] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13199.053049087524, \"sum\": 13199.053049087524, \"min\": 13199.053049087524}}, \"EndTime\": 1587301956.585057, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301943.385271}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:36 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.0939814544 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:36 INFO 139636288943936] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=106, train loss <loss>=1.40415820208\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:36 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:38 INFO 139636288943936] Epoch[107] Batch[0] avg_epoch_loss=1.375657\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=1.37565660477\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:44 INFO 139636288943936] Epoch[107] Batch[5] avg_epoch_loss=1.404785\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=1.40478463968\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:44 INFO 139636288943936] Epoch[107] Batch [5]#011Speed: 56.34 samples/sec#011loss=1.404785\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:49 INFO 139636288943936] Epoch[107] Batch[10] avg_epoch_loss=1.346286\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=1.27608668804\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:49 INFO 139636288943936] Epoch[107] Batch [10]#011Speed: 56.34 samples/sec#011loss=1.276087\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:49 INFO 139636288943936] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13225.245952606201, \"sum\": 13225.245952606201, \"min\": 13225.245952606201}}, \"EndTime\": 1587301969.810903, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301956.585139}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:49 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.1139088716 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:49 INFO 139636288943936] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=107, train loss <loss>=1.34628557075\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:49 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:51 INFO 139636288943936] Epoch[108] Batch[0] avg_epoch_loss=1.526993\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=1.52699279785\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:57 INFO 139636288943936] Epoch[108] Batch[5] avg_epoch_loss=1.249351\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=1.24935132265\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:12:57 INFO 139636288943936] Epoch[108] Batch [5]#011Speed: 55.92 samples/sec#011loss=1.249351\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:03 INFO 139636288943936] Epoch[108] Batch[10] avg_epoch_loss=1.274804\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=1.30534739494\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:03 INFO 139636288943936] Epoch[108] Batch [10]#011Speed: 56.13 samples/sec#011loss=1.305347\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:03 INFO 139636288943936] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13303.522109985352, \"sum\": 13303.522109985352, \"min\": 13303.522109985352}}, \"EndTime\": 1587301983.115034, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301969.810979}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:03 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.8358681555 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:03 INFO 139636288943936] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=108, train loss <loss>=1.27480408278\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:03 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:03 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_7ba70963-f2c7-4859-8528-22e32a1da99e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 104.32791709899902, \"sum\": 104.32791709899902, \"min\": 104.32791709899902}}, \"EndTime\": 1587301983.220034, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301983.115141}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:04 INFO 139636288943936] Epoch[109] Batch[0] avg_epoch_loss=1.088913\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=1.08891320229\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:10 INFO 139636288943936] Epoch[109] Batch[5] avg_epoch_loss=1.398164\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=1.39816439152\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:10 INFO 139636288943936] Epoch[109] Batch [5]#011Speed: 55.57 samples/sec#011loss=1.398164\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:15 INFO 139636288943936] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12096.02403640747, \"sum\": 12096.02403640747, \"min\": 12096.02403640747}}, \"EndTime\": 1587301995.316211, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301983.220115}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:15 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.8342326239 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:15 INFO 139636288943936] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=109, train loss <loss>=1.34876401424\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:15 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:17 INFO 139636288943936] Epoch[110] Batch[0] avg_epoch_loss=1.084907\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=1.08490669727\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:22 INFO 139636288943936] Epoch[110] Batch[5] avg_epoch_loss=1.231434\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:22 INFO 139636288943936] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=1.23143448432\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:22 INFO 139636288943936] Epoch[110] Batch [5]#011Speed: 55.64 samples/sec#011loss=1.231434\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:28 INFO 139636288943936] Epoch[110] Batch[10] avg_epoch_loss=1.329955\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:28 INFO 139636288943936] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=1.44817888737\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:28 INFO 139636288943936] Epoch[110] Batch [10]#011Speed: 56.33 samples/sec#011loss=1.448179\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:28 INFO 139636288943936] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13265.604972839355, \"sum\": 13265.604972839355, \"min\": 13265.604972839355}}, \"EndTime\": 1587302008.582786, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301995.316399}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:28 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.1291182211 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:28 INFO 139636288943936] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:28 INFO 139636288943936] #quality_metric: host=algo-1, epoch=110, train loss <loss>=1.32995466752\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:28 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:30 INFO 139636288943936] Epoch[111] Batch[0] avg_epoch_loss=1.453950\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=1.45394980907\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:36 INFO 139636288943936] Epoch[111] Batch[5] avg_epoch_loss=1.442970\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=1.44297029575\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:36 INFO 139636288943936] Epoch[111] Batch [5]#011Speed: 56.05 samples/sec#011loss=1.442970\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:41 INFO 139636288943936] Epoch[111] Batch[10] avg_epoch_loss=1.407190\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=1.36425304413\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:41 INFO 139636288943936] Epoch[111] Batch [10]#011Speed: 56.16 samples/sec#011loss=1.364253\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:41 INFO 139636288943936] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13249.161005020142, \"sum\": 13249.161005020142, \"min\": 13249.161005020142}}, \"EndTime\": 1587302021.83257, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302008.582885}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:41 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.8139524237 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:41 INFO 139636288943936] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=111, train loss <loss>=1.40718972683\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:41 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:43 INFO 139636288943936] Epoch[112] Batch[0] avg_epoch_loss=1.331967\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=1.33196735382\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:49 INFO 139636288943936] Epoch[112] Batch[5] avg_epoch_loss=1.247452\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=1.24745196104\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:49 INFO 139636288943936] Epoch[112] Batch [5]#011Speed: 56.21 samples/sec#011loss=1.247452\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:55 INFO 139636288943936] Epoch[112] Batch[10] avg_epoch_loss=1.271980\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:55 INFO 139636288943936] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=1.30141322613\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:55 INFO 139636288943936] Epoch[112] Batch [10]#011Speed: 54.63 samples/sec#011loss=1.301413\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:55 INFO 139636288943936] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13389.477968215942, \"sum\": 13389.477968215942, \"min\": 13389.477968215942}}, \"EndTime\": 1587302035.22255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302021.832653}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:55 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.2920280441 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:55 INFO 139636288943936] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:55 INFO 139636288943936] #quality_metric: host=algo-1, epoch=112, train loss <loss>=1.27197980881\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:55 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:55 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_4b1b76c1-cbb2-4c91-8869-60e719e432b4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 104.80499267578125, \"sum\": 104.80499267578125, \"min\": 104.80499267578125}}, \"EndTime\": 1587302035.327981, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302035.222627}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:57 INFO 139636288943936] Epoch[113] Batch[0] avg_epoch_loss=1.914698\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:13:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=1.91469788551\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:02 INFO 139636288943936] Epoch[113] Batch[5] avg_epoch_loss=1.423892\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=1.42389216026\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:02 INFO 139636288943936] Epoch[113] Batch [5]#011Speed: 55.79 samples/sec#011loss=1.423892\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:08 INFO 139636288943936] Epoch[113] Batch[10] avg_epoch_loss=1.343992\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=1.24811270237\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:08 INFO 139636288943936] Epoch[113] Batch [10]#011Speed: 56.13 samples/sec#011loss=1.248113\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:08 INFO 139636288943936] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13248.748064041138, \"sum\": 13248.748064041138, \"min\": 13248.748064041138}}, \"EndTime\": 1587302048.576872, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302035.328054}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:08 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.0420228863 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:08 INFO 139636288943936] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=113, train loss <loss>=1.34399240667\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:08 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:10 INFO 139636288943936] Epoch[114] Batch[0] avg_epoch_loss=1.260638\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=1.26063799858\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:16 INFO 139636288943936] Epoch[114] Batch[5] avg_epoch_loss=1.299661\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:16 INFO 139636288943936] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=1.29966143767\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:16 INFO 139636288943936] Epoch[114] Batch [5]#011Speed: 55.94 samples/sec#011loss=1.299661\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:21 INFO 139636288943936] Epoch[114] Batch[10] avg_epoch_loss=1.324830\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=1.35503249168\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:21 INFO 139636288943936] Epoch[114] Batch [10]#011Speed: 55.77 samples/sec#011loss=1.355032\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:21 INFO 139636288943936] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13322.898149490356, \"sum\": 13322.898149490356, \"min\": 13322.898149490356}}, \"EndTime\": 1587302061.900266, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302048.576951}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:21 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.5649316493 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:21 INFO 139636288943936] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=114, train loss <loss>=1.32483009859\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:21 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:23 INFO 139636288943936] Epoch[115] Batch[0] avg_epoch_loss=1.434473\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=1.43447339535\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:29 INFO 139636288943936] Epoch[115] Batch[5] avg_epoch_loss=1.196392\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=1.19639199972\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:29 INFO 139636288943936] Epoch[115] Batch [5]#011Speed: 55.93 samples/sec#011loss=1.196392\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:34 INFO 139636288943936] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12128.638982772827, \"sum\": 12128.638982772827, \"min\": 12128.638982772827}}, \"EndTime\": 1587302074.029479, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302061.90034}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:34 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.7777148177 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:34 INFO 139636288943936] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:34 INFO 139636288943936] #quality_metric: host=algo-1, epoch=115, train loss <loss>=1.20152989626\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:34 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:34 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_b98b8d28-0a51-4d1c-9a14-1eebdfdc76a5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.16187477111816, \"sum\": 112.16187477111816, \"min\": 112.16187477111816}}, \"EndTime\": 1587302074.142572, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302074.029566}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:35 INFO 139636288943936] Epoch[116] Batch[0] avg_epoch_loss=1.290600\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=1.29059994221\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:41 INFO 139636288943936] Epoch[116] Batch[5] avg_epoch_loss=1.269592\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=1.2695915103\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:41 INFO 139636288943936] Epoch[116] Batch [5]#011Speed: 56.55 samples/sec#011loss=1.269592\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:46 INFO 139636288943936] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 11951.144218444824, \"sum\": 11951.144218444824, \"min\": 11951.144218444824}}, \"EndTime\": 1587302086.093864, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302074.14265}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:46 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.295696992 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:46 INFO 139636288943936] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=116, train loss <loss>=1.22954982519\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:46 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:47 INFO 139636288943936] Epoch[117] Batch[0] avg_epoch_loss=1.404549\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=1.40454924107\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:53 INFO 139636288943936] Epoch[117] Batch[5] avg_epoch_loss=1.259998\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=1.25999846061\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:53 INFO 139636288943936] Epoch[117] Batch [5]#011Speed: 56.06 samples/sec#011loss=1.259998\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:58 INFO 139636288943936] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12068.435907363892, \"sum\": 12068.435907363892, \"min\": 12068.435907363892}}, \"EndTime\": 1587302098.163069, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302086.093949}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:58 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.6274488546 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:58 INFO 139636288943936] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=117, train loss <loss>=1.25460563898\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:14:58 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:00 INFO 139636288943936] Epoch[118] Batch[0] avg_epoch_loss=1.085657\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:00 INFO 139636288943936] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=1.08565688133\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:05 INFO 139636288943936] Epoch[118] Batch[5] avg_epoch_loss=1.271269\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:05 INFO 139636288943936] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=1.27126910289\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:05 INFO 139636288943936] Epoch[118] Batch [5]#011Speed: 56.12 samples/sec#011loss=1.271269\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:11 INFO 139636288943936] Epoch[118] Batch[10] avg_epoch_loss=1.254913\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=1.23528552055\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:11 INFO 139636288943936] Epoch[118] Batch [10]#011Speed: 55.82 samples/sec#011loss=1.235286\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:11 INFO 139636288943936] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13286.996126174927, \"sum\": 13286.996126174927, \"min\": 13286.996126174927}}, \"EndTime\": 1587302111.45066, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302098.163147}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:11 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.5000707785 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:11 INFO 139636288943936] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=118, train loss <loss>=1.2549129291\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:11 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:13 INFO 139636288943936] Epoch[119] Batch[0] avg_epoch_loss=1.589015\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=1.58901548386\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:18 INFO 139636288943936] Epoch[119] Batch[5] avg_epoch_loss=1.281234\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=1.28123386701\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:18 INFO 139636288943936] Epoch[119] Batch [5]#011Speed: 56.10 samples/sec#011loss=1.281234\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:23 INFO 139636288943936] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12084.827184677124, \"sum\": 12084.827184677124, \"min\": 12084.827184677124}}, \"EndTime\": 1587302123.536047, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302111.450733}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:23 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.3862325069 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:23 INFO 139636288943936] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=119, train loss <loss>=1.21280586123\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:23 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:25 INFO 139636288943936] Epoch[120] Batch[0] avg_epoch_loss=1.048015\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=1.04801487923\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:31 INFO 139636288943936] Epoch[120] Batch[5] avg_epoch_loss=1.426435\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=1.4264348944\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:31 INFO 139636288943936] Epoch[120] Batch [5]#011Speed: 56.37 samples/sec#011loss=1.426435\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:36 INFO 139636288943936] Epoch[120] Batch[10] avg_epoch_loss=1.326958\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=1.20758550167\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:36 INFO 139636288943936] Epoch[120] Batch [10]#011Speed: 55.79 samples/sec#011loss=1.207586\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:36 INFO 139636288943936] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13216.92705154419, \"sum\": 13216.92705154419, \"min\": 13216.92705154419}}, \"EndTime\": 1587302136.753651, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302123.536128}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:36 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.1623769882 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:36 INFO 139636288943936] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=120, train loss <loss>=1.32695789771\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:36 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:38 INFO 139636288943936] Epoch[121] Batch[0] avg_epoch_loss=1.305904\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=1.30590426922\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:44 INFO 139636288943936] Epoch[121] Batch[5] avg_epoch_loss=1.174630\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=1.17462960879\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:44 INFO 139636288943936] Epoch[121] Batch [5]#011Speed: 56.09 samples/sec#011loss=1.174630\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:49 INFO 139636288943936] Epoch[121] Batch[10] avg_epoch_loss=1.301000\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=1.45264368057\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:49 INFO 139636288943936] Epoch[121] Batch [10]#011Speed: 56.28 samples/sec#011loss=1.452644\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:49 INFO 139636288943936] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13215.3160572052, \"sum\": 13215.3160572052, \"min\": 13215.3160572052}}, \"EndTime\": 1587302149.969798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302136.753755}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:49 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.1848261421 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:49 INFO 139636288943936] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=121, train loss <loss>=1.30099964142\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:49 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:51 INFO 139636288943936] Epoch[122] Batch[0] avg_epoch_loss=1.742253\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=1.74225330353\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:57 INFO 139636288943936] Epoch[122] Batch[5] avg_epoch_loss=1.428862\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=1.42886247238\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:15:57 INFO 139636288943936] Epoch[122] Batch [5]#011Speed: 56.05 samples/sec#011loss=1.428862\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:02 INFO 139636288943936] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12216.230869293213, \"sum\": 12216.230869293213, \"min\": 12216.230869293213}}, \"EndTime\": 1587302162.186561, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302149.969903}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:02 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.3600583632 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:02 INFO 139636288943936] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=122, train loss <loss>=1.37555822134\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:02 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:04 INFO 139636288943936] Epoch[123] Batch[0] avg_epoch_loss=1.192022\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=1.19202208519\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:09 INFO 139636288943936] Epoch[123] Batch[5] avg_epoch_loss=1.216603\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=1.21660345793\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:09 INFO 139636288943936] Epoch[123] Batch [5]#011Speed: 56.23 samples/sec#011loss=1.216603\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:15 INFO 139636288943936] Epoch[123] Batch[10] avg_epoch_loss=1.207866\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=1.19738070965\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:15 INFO 139636288943936] Epoch[123] Batch [10]#011Speed: 56.11 samples/sec#011loss=1.197381\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:15 INFO 139636288943936] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13218.883037567139, \"sum\": 13218.883037567139, \"min\": 13218.883037567139}}, \"EndTime\": 1587302175.406274, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302162.186645}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:15 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.7602121593 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:15 INFO 139636288943936] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=123, train loss <loss>=1.20786584507\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:15 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:17 INFO 139636288943936] Epoch[124] Batch[0] avg_epoch_loss=2.864593\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=2.8645927906\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:23 INFO 139636288943936] Epoch[124] Batch[5] avg_epoch_loss=2.006920\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=2.00691996018\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:23 INFO 139636288943936] Epoch[124] Batch [5]#011Speed: 55.21 samples/sec#011loss=2.006920\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:27 INFO 139636288943936] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12206.3889503479, \"sum\": 12206.3889503479, \"min\": 12206.3889503479}}, \"EndTime\": 1587302187.613354, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302175.406363}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:27 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.1033364271 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:27 INFO 139636288943936] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=124, train loss <loss>=1.83642423153\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:27 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:29 INFO 139636288943936] Epoch[125] Batch[0] avg_epoch_loss=1.601576\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=1.60157608986\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:35 INFO 139636288943936] Epoch[125] Batch[5] avg_epoch_loss=1.549260\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=1.54925998052\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:35 INFO 139636288943936] Epoch[125] Batch [5]#011Speed: 56.27 samples/sec#011loss=1.549260\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:39 INFO 139636288943936] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12033.509969711304, \"sum\": 12033.509969711304, \"min\": 12033.509969711304}}, \"EndTime\": 1587302199.647518, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302187.613439}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:39 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.2728760693 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:39 INFO 139636288943936] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=125, train loss <loss>=1.49291501045\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:39 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:41 INFO 139636288943936] Epoch[126] Batch[0] avg_epoch_loss=1.280814\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=1.28081417084\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:47 INFO 139636288943936] Epoch[126] Batch[5] avg_epoch_loss=1.400916\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=1.40091605981\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:47 INFO 139636288943936] Epoch[126] Batch [5]#011Speed: 56.28 samples/sec#011loss=1.400916\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:51 INFO 139636288943936] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12101.96304321289, \"sum\": 12101.96304321289, \"min\": 12101.96304321289}}, \"EndTime\": 1587302211.750136, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302199.647624}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:51 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.3960006717 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:51 INFO 139636288943936] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=126, train loss <loss>=1.44127305746\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:51 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:53 INFO 139636288943936] Epoch[127] Batch[0] avg_epoch_loss=1.215927\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=1.21592712402\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:59 INFO 139636288943936] Epoch[127] Batch[5] avg_epoch_loss=1.142839\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=1.14283897479\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:16:59 INFO 139636288943936] Epoch[127] Batch [5]#011Speed: 55.94 samples/sec#011loss=1.142839\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:05 INFO 139636288943936] Epoch[127] Batch[10] avg_epoch_loss=1.188214\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:05 INFO 139636288943936] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=1.24266331196\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:05 INFO 139636288943936] Epoch[127] Batch [10]#011Speed: 55.72 samples/sec#011loss=1.242663\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:05 INFO 139636288943936] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13306.303977966309, \"sum\": 13306.303977966309, \"min\": 13306.303977966309}}, \"EndTime\": 1587302225.057168, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302211.750215}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:05 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.7503576072 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:05 INFO 139636288943936] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:05 INFO 139636288943936] #quality_metric: host=algo-1, epoch=127, train loss <loss>=1.1882136735\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:05 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:05 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_a5543cff-aa6d-42af-a3ca-3681d3e82217-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.42697525024414, \"sum\": 109.42697525024414, \"min\": 109.42697525024414}}, \"EndTime\": 1587302225.167183, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302225.057265}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:06 INFO 139636288943936] Epoch[128] Batch[0] avg_epoch_loss=1.099465\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=1.09946489334\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:12 INFO 139636288943936] Epoch[128] Batch[5] avg_epoch_loss=1.136280\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=1.13628012935\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:12 INFO 139636288943936] Epoch[128] Batch [5]#011Speed: 55.98 samples/sec#011loss=1.136280\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:18 INFO 139636288943936] Epoch[128] Batch[10] avg_epoch_loss=1.263553\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=1.4162812233\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:18 INFO 139636288943936] Epoch[128] Batch [10]#011Speed: 56.51 samples/sec#011loss=1.416281\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:18 INFO 139636288943936] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13190.339088439941, \"sum\": 13190.339088439941, \"min\": 13190.339088439941}}, \"EndTime\": 1587302238.357661, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302225.16726}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:18 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.7329320327 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:18 INFO 139636288943936] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=128, train loss <loss>=1.26355335387\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:18 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:20 INFO 139636288943936] Epoch[129] Batch[0] avg_epoch_loss=1.390588\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:20 INFO 139636288943936] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=1.39058792591\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:25 INFO 139636288943936] Epoch[129] Batch[5] avg_epoch_loss=1.278580\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=1.27858004967\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:25 INFO 139636288943936] Epoch[129] Batch [5]#011Speed: 55.30 samples/sec#011loss=1.278580\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:30 INFO 139636288943936] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12168.732166290283, \"sum\": 12168.732166290283, \"min\": 12168.732166290283}}, \"EndTime\": 1587302250.527139, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302238.35774}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:30 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.1002265112 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:30 INFO 139636288943936] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=129, train loss <loss>=1.23021377325\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:30 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:32 INFO 139636288943936] Epoch[130] Batch[0] avg_epoch_loss=1.152638\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=1.15263772011\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:38 INFO 139636288943936] Epoch[130] Batch[5] avg_epoch_loss=1.054647\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=1.05464720726\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:38 INFO 139636288943936] Epoch[130] Batch [5]#011Speed: 55.85 samples/sec#011loss=1.054647\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:43 INFO 139636288943936] Epoch[130] Batch[10] avg_epoch_loss=1.404998\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=1.82541873455\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:43 INFO 139636288943936] Epoch[130] Batch [10]#011Speed: 56.45 samples/sec#011loss=1.825419\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:43 INFO 139636288943936] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13205.516815185547, \"sum\": 13205.516815185547, \"min\": 13205.516815185547}}, \"EndTime\": 1587302263.733337, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302250.527218}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:43 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.2214232087 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:43 INFO 139636288943936] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=130, train loss <loss>=1.40499790148\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:43 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:45 INFO 139636288943936] Epoch[131] Batch[0] avg_epoch_loss=1.359020\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=1.35901987553\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:51 INFO 139636288943936] Epoch[131] Batch[5] avg_epoch_loss=1.709652\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=1.70965200663\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:51 INFO 139636288943936] Epoch[131] Batch [5]#011Speed: 56.39 samples/sec#011loss=1.709652\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:57 INFO 139636288943936] Epoch[131] Batch[10] avg_epoch_loss=1.681268\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=1.64720721245\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:57 INFO 139636288943936] Epoch[131] Batch [10]#011Speed: 55.79 samples/sec#011loss=1.647207\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:57 INFO 139636288943936] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13272.4449634552, \"sum\": 13272.4449634552, \"min\": 13272.4449634552}}, \"EndTime\": 1587302277.006409, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302263.733415}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:57 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.6716701019 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:57 INFO 139636288943936] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=131, train loss <loss>=1.68126800927\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:57 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:58 INFO 139636288943936] Epoch[132] Batch[0] avg_epoch_loss=1.480185\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:17:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=1.48018491268\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:04 INFO 139636288943936] Epoch[132] Batch[5] avg_epoch_loss=1.431409\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=1.43140904109\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:04 INFO 139636288943936] Epoch[132] Batch [5]#011Speed: 55.75 samples/sec#011loss=1.431409\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:09 INFO 139636288943936] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12183.956861495972, \"sum\": 12183.956861495972, \"min\": 12183.956861495972}}, \"EndTime\": 1587302289.190974, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302277.006534}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:09 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.214341957 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:09 INFO 139636288943936] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=132, train loss <loss>=1.35776137114\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:09 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:10 INFO 139636288943936] Epoch[133] Batch[0] avg_epoch_loss=1.115078\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=1.11507844925\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:16 INFO 139636288943936] Epoch[133] Batch[5] avg_epoch_loss=1.264790\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:16 INFO 139636288943936] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=1.26479043563\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:16 INFO 139636288943936] Epoch[133] Batch [5]#011Speed: 55.92 samples/sec#011loss=1.264790\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:22 INFO 139636288943936] Epoch[133] Batch[10] avg_epoch_loss=1.428910\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:22 INFO 139636288943936] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=1.6258541584\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:22 INFO 139636288943936] Epoch[133] Batch [10]#011Speed: 55.60 samples/sec#011loss=1.625854\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:22 INFO 139636288943936] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13266.282081604004, \"sum\": 13266.282081604004, \"min\": 13266.282081604004}}, \"EndTime\": 1587302302.457859, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302289.191061}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:22 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.3928086639 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:22 INFO 139636288943936] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:22 INFO 139636288943936] #quality_metric: host=algo-1, epoch=133, train loss <loss>=1.42891030962\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:22 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:24 INFO 139636288943936] Epoch[134] Batch[0] avg_epoch_loss=1.413442\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=1.41344189644\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:29 INFO 139636288943936] Epoch[134] Batch[5] avg_epoch_loss=1.301046\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=1.3010459741\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:29 INFO 139636288943936] Epoch[134] Batch [5]#011Speed: 56.35 samples/sec#011loss=1.301046\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:34 INFO 139636288943936] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12137.235879898071, \"sum\": 12137.235879898071, \"min\": 12137.235879898071}}, \"EndTime\": 1587302314.5957, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302302.457942}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:34 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.0107601778 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:34 INFO 139636288943936] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:34 INFO 139636288943936] #quality_metric: host=algo-1, epoch=134, train loss <loss>=1.2719622612\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:34 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:36 INFO 139636288943936] Epoch[135] Batch[0] avg_epoch_loss=1.087773\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=1.08777320385\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:42 INFO 139636288943936] Epoch[135] Batch[5] avg_epoch_loss=1.085098\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:42 INFO 139636288943936] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=1.08509766062\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:42 INFO 139636288943936] Epoch[135] Batch [5]#011Speed: 56.29 samples/sec#011loss=1.085098\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:47 INFO 139636288943936] Epoch[135] Batch[10] avg_epoch_loss=1.139929\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=1.20572619438\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:47 INFO 139636288943936] Epoch[135] Batch [10]#011Speed: 56.19 samples/sec#011loss=1.205726\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:47 INFO 139636288943936] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13212.443828582764, \"sum\": 13212.443828582764, \"min\": 13212.443828582764}}, \"EndTime\": 1587302327.809017, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302314.59581}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:47 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.7412386394 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:47 INFO 139636288943936] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=135, train loss <loss>=1.13992881233\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:47 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:47 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_e8271e7e-6b10-4eeb-b8eb-95f14a7f3829-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 145.54882049560547, \"sum\": 145.54882049560547, \"min\": 145.54882049560547}}, \"EndTime\": 1587302327.955162, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302327.809099}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:49 INFO 139636288943936] Epoch[136] Batch[0] avg_epoch_loss=1.590240\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=1.59023952484\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:55 INFO 139636288943936] Epoch[136] Batch[5] avg_epoch_loss=2.006110\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:55 INFO 139636288943936] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=2.00611001253\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:18:55 INFO 139636288943936] Epoch[136] Batch [5]#011Speed: 55.54 samples/sec#011loss=2.006110\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:01 INFO 139636288943936] Epoch[136] Batch[10] avg_epoch_loss=1.800247\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=1.55321116447\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:01 INFO 139636288943936] Epoch[136] Batch [10]#011Speed: 56.45 samples/sec#011loss=1.553211\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:01 INFO 139636288943936] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13242.811918258667, \"sum\": 13242.811918258667, \"min\": 13242.811918258667}}, \"EndTime\": 1587302341.198114, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302327.955235}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:01 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.0071045183 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:01 INFO 139636288943936] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=136, train loss <loss>=1.80024689978\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:01 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:03 INFO 139636288943936] Epoch[137] Batch[0] avg_epoch_loss=1.568705\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=1.5687046051\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:08 INFO 139636288943936] Epoch[137] Batch[5] avg_epoch_loss=1.596152\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=1.59615216653\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:08 INFO 139636288943936] Epoch[137] Batch [5]#011Speed: 55.27 samples/sec#011loss=1.596152\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:13 INFO 139636288943936] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12241.49489402771, \"sum\": 12241.49489402771, \"min\": 12241.49489402771}}, \"EndTime\": 1587302353.440298, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302341.198241}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:13 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.1989784764 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:13 INFO 139636288943936] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=137, train loss <loss>=1.53635283709\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:13 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:15 INFO 139636288943936] Epoch[138] Batch[0] avg_epoch_loss=1.275345\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=1.27534544468\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:20 INFO 139636288943936] Epoch[138] Batch[5] avg_epoch_loss=1.203100\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:20 INFO 139636288943936] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=1.20310006539\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:20 INFO 139636288943936] Epoch[138] Batch [5]#011Speed: 56.38 samples/sec#011loss=1.203100\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:26 INFO 139636288943936] Epoch[138] Batch[10] avg_epoch_loss=1.076800\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=0.925240468979\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:26 INFO 139636288943936] Epoch[138] Batch [10]#011Speed: 56.19 samples/sec#011loss=0.925240\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:26 INFO 139636288943936] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13210.87908744812, \"sum\": 13210.87908744812, \"min\": 13210.87908744812}}, \"EndTime\": 1587302366.651802, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302353.440382}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:26 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.59589264 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:26 INFO 139636288943936] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=138, train loss <loss>=1.07680024884\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:26 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:26 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_53be8f83-61ac-454c-bef8-e34fd36ec2d2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 111.52887344360352, \"sum\": 111.52887344360352, \"min\": 111.52887344360352}}, \"EndTime\": 1587302366.763859, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302366.65188}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:28 INFO 139636288943936] Epoch[139] Batch[0] avg_epoch_loss=2.110816\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:28 INFO 139636288943936] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=2.11081600189\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:34 INFO 139636288943936] Epoch[139] Batch[5] avg_epoch_loss=1.644363\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:34 INFO 139636288943936] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=1.64436280727\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:34 INFO 139636288943936] Epoch[139] Batch [5]#011Speed: 56.36 samples/sec#011loss=1.644363\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:39 INFO 139636288943936] Epoch[139] Batch[10] avg_epoch_loss=1.400753\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=1.10842193365\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:39 INFO 139636288943936] Epoch[139] Batch [10]#011Speed: 56.73 samples/sec#011loss=1.108422\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:39 INFO 139636288943936] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13145.133972167969, \"sum\": 13145.133972167969, \"min\": 13145.133972167969}}, \"EndTime\": 1587302379.909135, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302366.763933}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:39 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.208265296 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:39 INFO 139636288943936] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=139, train loss <loss>=1.40075331926\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:39 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:41 INFO 139636288943936] Epoch[140] Batch[0] avg_epoch_loss=1.414198\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=1.41419827938\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:47 INFO 139636288943936] Epoch[140] Batch[5] avg_epoch_loss=1.132701\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=1.13270141681\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:47 INFO 139636288943936] Epoch[140] Batch [5]#011Speed: 56.11 samples/sec#011loss=1.132701\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:53 INFO 139636288943936] Epoch[140] Batch[10] avg_epoch_loss=1.091923\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=1.04298912287\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:53 INFO 139636288943936] Epoch[140] Batch [10]#011Speed: 55.68 samples/sec#011loss=1.042989\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:53 INFO 139636288943936] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13340.08002281189, \"sum\": 13340.08002281189, \"min\": 13340.08002281189}}, \"EndTime\": 1587302393.249687, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302379.90921}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:53 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.1986438866 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:53 INFO 139636288943936] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=140, train loss <loss>=1.09192310138\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:53 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:55 INFO 139636288943936] Epoch[141] Batch[0] avg_epoch_loss=1.034890\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:19:55 INFO 139636288943936] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=1.03489005566\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:00 INFO 139636288943936] Epoch[141] Batch[5] avg_epoch_loss=1.265620\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:00 INFO 139636288943936] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=1.26561963558\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:00 INFO 139636288943936] Epoch[141] Batch [5]#011Speed: 56.24 samples/sec#011loss=1.265620\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:05 INFO 139636288943936] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12090.008974075317, \"sum\": 12090.008974075317, \"min\": 12090.008974075317}}, \"EndTime\": 1587302405.340216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302393.249766}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:05 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.5222244236 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:05 INFO 139636288943936] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:05 INFO 139636288943936] #quality_metric: host=algo-1, epoch=141, train loss <loss>=1.16967613697\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:05 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:07 INFO 139636288943936] Epoch[142] Batch[0] avg_epoch_loss=0.964906\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:07 INFO 139636288943936] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=0.964905738831\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:12 INFO 139636288943936] Epoch[142] Batch[5] avg_epoch_loss=1.051639\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=1.05163858334\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:12 INFO 139636288943936] Epoch[142] Batch [5]#011Speed: 56.42 samples/sec#011loss=1.051639\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:18 INFO 139636288943936] Epoch[142] Batch[10] avg_epoch_loss=1.043582\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=1.03391399384\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:18 INFO 139636288943936] Epoch[142] Batch [10]#011Speed: 56.13 samples/sec#011loss=1.033914\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:18 INFO 139636288943936] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13219.501972198486, \"sum\": 13219.501972198486, \"min\": 13219.501972198486}}, \"EndTime\": 1587302418.560373, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302405.340286}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:18 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.8501623025 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:18 INFO 139636288943936] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=142, train loss <loss>=1.04358195175\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:18 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:18 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_51b31610-f23f-40e4-9b1a-238d7aacab5e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 102.1578311920166, \"sum\": 102.1578311920166, \"min\": 102.1578311920166}}, \"EndTime\": 1587302418.663186, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302418.560453}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:20 INFO 139636288943936] Epoch[143] Batch[0] avg_epoch_loss=1.364076\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:20 INFO 139636288943936] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=1.3640755415\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:26 INFO 139636288943936] Epoch[143] Batch[5] avg_epoch_loss=1.125669\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=1.12566876411\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:26 INFO 139636288943936] Epoch[143] Batch [5]#011Speed: 55.27 samples/sec#011loss=1.125669\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:30 INFO 139636288943936] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12208.97102355957, \"sum\": 12208.97102355957, \"min\": 12208.97102355957}}, \"EndTime\": 1587302430.872302, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302418.663258}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:30 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.2732355957 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:30 INFO 139636288943936] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=143, train loss <loss>=1.12487299442\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:30 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:32 INFO 139636288943936] Epoch[144] Batch[0] avg_epoch_loss=1.004125\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=1.00412511826\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:38 INFO 139636288943936] Epoch[144] Batch[5] avg_epoch_loss=1.064406\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=1.06440633535\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:38 INFO 139636288943936] Epoch[144] Batch [5]#011Speed: 56.03 samples/sec#011loss=1.064406\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:44 INFO 139636288943936] Epoch[144] Batch[10] avg_epoch_loss=1.091559\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=1.12414143085\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:44 INFO 139636288943936] Epoch[144] Batch [10]#011Speed: 56.12 samples/sec#011loss=1.124141\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:44 INFO 139636288943936] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13250.516891479492, \"sum\": 13250.516891479492, \"min\": 13250.516891479492}}, \"EndTime\": 1587302444.123365, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302430.872387}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:44 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.4882267073 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:44 INFO 139636288943936] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=144, train loss <loss>=1.09155865149\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:44 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:45 INFO 139636288943936] Epoch[145] Batch[0] avg_epoch_loss=1.278580\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=1.27858042717\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:51 INFO 139636288943936] Epoch[145] Batch[5] avg_epoch_loss=1.037940\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=1.03794005513\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:51 INFO 139636288943936] Epoch[145] Batch [5]#011Speed: 56.01 samples/sec#011loss=1.037940\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:56 INFO 139636288943936] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12194.91195678711, \"sum\": 12194.91195678711, \"min\": 12194.91195678711}}, \"EndTime\": 1587302456.31879, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302444.12343}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:56 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.4804214646 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:56 INFO 139636288943936] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=145, train loss <loss>=1.08607800007\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:56 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:58 INFO 139636288943936] Epoch[146] Batch[0] avg_epoch_loss=0.751417\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:20:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=0.751416802406\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:03 INFO 139636288943936] Epoch[146] Batch[5] avg_epoch_loss=1.154158\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=1.15415825446\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:03 INFO 139636288943936] Epoch[146] Batch [5]#011Speed: 55.74 samples/sec#011loss=1.154158\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:09 INFO 139636288943936] Epoch[146] Batch[10] avg_epoch_loss=1.035903\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=0.893995916843\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:09 INFO 139636288943936] Epoch[146] Batch [10]#011Speed: 56.39 samples/sec#011loss=0.893996\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:09 INFO 139636288943936] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13234.460830688477, \"sum\": 13234.460830688477, \"min\": 13234.460830688477}}, \"EndTime\": 1587302469.553986, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302456.318859}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:09 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.2647239882 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:09 INFO 139636288943936] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=146, train loss <loss>=1.03590264645\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:09 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:09 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_20672fbb-e37c-4787-ac00-d124d8c26d3c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 134.47904586791992, \"sum\": 134.47904586791992, \"min\": 134.47904586791992}}, \"EndTime\": 1587302469.689416, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302469.554069}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:11 INFO 139636288943936] Epoch[147] Batch[0] avg_epoch_loss=1.246370\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=1.2463696003\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:17 INFO 139636288943936] Epoch[147] Batch[5] avg_epoch_loss=1.156367\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=1.15636668603\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:17 INFO 139636288943936] Epoch[147] Batch [5]#011Speed: 55.84 samples/sec#011loss=1.156367\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:22 INFO 139636288943936] Epoch[147] Batch[10] avg_epoch_loss=1.089401\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:22 INFO 139636288943936] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=1.0090426445\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:22 INFO 139636288943936] Epoch[147] Batch [10]#011Speed: 56.23 samples/sec#011loss=1.009043\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:22 INFO 139636288943936] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13238.465070724487, \"sum\": 13238.465070724487, \"min\": 13238.465070724487}}, \"EndTime\": 1587302482.928118, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302469.689583}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:22 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.3255576967 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:22 INFO 139636288943936] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:22 INFO 139636288943936] #quality_metric: host=algo-1, epoch=147, train loss <loss>=1.08940121261\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:22 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:24 INFO 139636288943936] Epoch[148] Batch[0] avg_epoch_loss=1.098509\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=1.09850931168\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:30 INFO 139636288943936] Epoch[148] Batch[5] avg_epoch_loss=1.155577\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=1.15557652712\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:30 INFO 139636288943936] Epoch[148] Batch [5]#011Speed: 56.35 samples/sec#011loss=1.155577\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:36 INFO 139636288943936] Epoch[148] Batch[10] avg_epoch_loss=1.107949\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=1.05079653263\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:36 INFO 139636288943936] Epoch[148] Batch [10]#011Speed: 56.29 samples/sec#011loss=1.050797\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:36 INFO 139636288943936] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13243.023157119751, \"sum\": 13243.023157119751, \"min\": 13243.023157119751}}, \"EndTime\": 1587302496.171683, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302482.928189}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:36 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.3085432984 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:36 INFO 139636288943936] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=148, train loss <loss>=1.1079492569\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:36 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:38 INFO 139636288943936] Epoch[149] Batch[0] avg_epoch_loss=1.107839\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=1.10783946514\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:43 INFO 139636288943936] Epoch[149] Batch[5] avg_epoch_loss=1.060655\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=1.06065466007\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:43 INFO 139636288943936] Epoch[149] Batch [5]#011Speed: 55.70 samples/sec#011loss=1.060655\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:48 INFO 139636288943936] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12156.961917877197, \"sum\": 12156.961917877197, \"min\": 12156.961917877197}}, \"EndTime\": 1587302508.329208, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302496.171764}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:48 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.657102119 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:48 INFO 139636288943936] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:48 INFO 139636288943936] #quality_metric: host=algo-1, epoch=149, train loss <loss>=1.04818835258\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:48 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:50 INFO 139636288943936] Epoch[150] Batch[0] avg_epoch_loss=1.418776\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=1.41877555847\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:56 INFO 139636288943936] Epoch[150] Batch[5] avg_epoch_loss=1.269689\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=1.26968930165\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:21:56 INFO 139636288943936] Epoch[150] Batch [5]#011Speed: 54.82 samples/sec#011loss=1.269689\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:01 INFO 139636288943936] Epoch[150] Batch[10] avg_epoch_loss=1.185245\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=1.08391201496\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:01 INFO 139636288943936] Epoch[150] Batch [10]#011Speed: 56.16 samples/sec#011loss=1.083912\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:01 INFO 139636288943936] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13396.338939666748, \"sum\": 13396.338939666748, \"min\": 13396.338939666748}}, \"EndTime\": 1587302521.726137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302508.329295}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:01 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=47.9977689508 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:01 INFO 139636288943936] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=150, train loss <loss>=1.18524508043\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:01 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:03 INFO 139636288943936] Epoch[151] Batch[0] avg_epoch_loss=1.610469\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=1.61046922207\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:09 INFO 139636288943936] Epoch[151] Batch[5] avg_epoch_loss=1.378999\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=1.37899917364\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:09 INFO 139636288943936] Epoch[151] Batch [5]#011Speed: 56.19 samples/sec#011loss=1.378999\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:13 INFO 139636288943936] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12143.022060394287, \"sum\": 12143.022060394287, \"min\": 12143.022060394287}}, \"EndTime\": 1587302533.869696, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302521.726217}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:13 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.7045249576 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:13 INFO 139636288943936] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=151, train loss <loss>=1.29122592211\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:13 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:15 INFO 139636288943936] Epoch[152] Batch[0] avg_epoch_loss=1.193515\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=1.19351494312\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:21 INFO 139636288943936] Epoch[152] Batch[5] avg_epoch_loss=1.063577\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=1.0635770758\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:21 INFO 139636288943936] Epoch[152] Batch [5]#011Speed: 56.02 samples/sec#011loss=1.063577\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:26 INFO 139636288943936] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12178.424835205078, \"sum\": 12178.424835205078, \"min\": 12178.424835205078}}, \"EndTime\": 1587302546.048821, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302533.869771}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:26 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.9091645183 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:26 INFO 139636288943936] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=152, train loss <loss>=1.03446646929\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:26 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:26 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_91b1dbd4-0410-47d8-a95e-af0567cae4ba-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 114.26091194152832, \"sum\": 114.26091194152832, \"min\": 114.26091194152832}}, \"EndTime\": 1587302546.163745, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302546.048908}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:27 INFO 139636288943936] Epoch[153] Batch[0] avg_epoch_loss=1.138947\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=1.13894712925\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:33 INFO 139636288943936] Epoch[153] Batch[5] avg_epoch_loss=1.325845\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=1.32584517201\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:33 INFO 139636288943936] Epoch[153] Batch [5]#011Speed: 56.42 samples/sec#011loss=1.325845\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:39 INFO 139636288943936] Epoch[153] Batch[10] avg_epoch_loss=1.072372\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=0.768205118179\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:39 INFO 139636288943936] Epoch[153] Batch [10]#011Speed: 56.54 samples/sec#011loss=0.768205\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:39 INFO 139636288943936] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13160.731077194214, \"sum\": 13160.731077194214, \"min\": 13160.731077194214}}, \"EndTime\": 1587302559.324618, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302546.163826}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:39 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.5408917858 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:39 INFO 139636288943936] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=153, train loss <loss>=1.07237242027\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:39 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:41 INFO 139636288943936] Epoch[154] Batch[0] avg_epoch_loss=1.049094\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=1.04909360409\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:46 INFO 139636288943936] Epoch[154] Batch[5] avg_epoch_loss=1.048645\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=1.04864545663\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:46 INFO 139636288943936] Epoch[154] Batch [5]#011Speed: 55.93 samples/sec#011loss=1.048645\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:51 INFO 139636288943936] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12111.460208892822, \"sum\": 12111.460208892822, \"min\": 12111.460208892822}}, \"EndTime\": 1587302571.436685, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302559.324698}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:51 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.6951507253 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:51 INFO 139636288943936] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=154, train loss <loss>=1.10071446896\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:51 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:53 INFO 139636288943936] Epoch[155] Batch[0] avg_epoch_loss=0.723915\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=0.72391474247\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:59 INFO 139636288943936] Epoch[155] Batch[5] avg_epoch_loss=0.966556\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=0.966556191444\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:22:59 INFO 139636288943936] Epoch[155] Batch [5]#011Speed: 55.45 samples/sec#011loss=0.966556\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:04 INFO 139636288943936] Epoch[155] Batch[10] avg_epoch_loss=0.987452\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=1.01252636909\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:04 INFO 139636288943936] Epoch[155] Batch [10]#011Speed: 56.18 samples/sec#011loss=1.012526\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:04 INFO 139636288943936] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13329.998970031738, \"sum\": 13329.998970031738, \"min\": 13329.998970031738}}, \"EndTime\": 1587302584.767258, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302571.436798}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:04 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.3867188546 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:04 INFO 139636288943936] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=155, train loss <loss>=0.98745172674\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:04 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:04 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_7feaadd8-6d41-4ba2-82fe-b814b3662c25-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 106.58693313598633, \"sum\": 106.58693313598633, \"min\": 106.58693313598633}}, \"EndTime\": 1587302584.874512, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302584.767328}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:06 INFO 139636288943936] Epoch[156] Batch[0] avg_epoch_loss=1.132406\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=1.13240635395\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:12 INFO 139636288943936] Epoch[156] Batch[5] avg_epoch_loss=0.939367\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=0.939366559188\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:12 INFO 139636288943936] Epoch[156] Batch [5]#011Speed: 56.16 samples/sec#011loss=0.939367\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:18 INFO 139636288943936] Epoch[156] Batch[10] avg_epoch_loss=1.035762\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=1.15143699646\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:18 INFO 139636288943936] Epoch[156] Batch [10]#011Speed: 56.35 samples/sec#011loss=1.151437\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:18 INFO 139636288943936] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13250.700950622559, \"sum\": 13250.700950622559, \"min\": 13250.700950622559}}, \"EndTime\": 1587302598.125369, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302584.874595}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:18 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.3175320502 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:18 INFO 139636288943936] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=156, train loss <loss>=1.03576221249\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:18 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:19 INFO 139636288943936] Epoch[157] Batch[0] avg_epoch_loss=1.116666\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=1.11666584015\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:25 INFO 139636288943936] Epoch[157] Batch[5] avg_epoch_loss=1.053870\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=1.05387036006\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:25 INFO 139636288943936] Epoch[157] Batch [5]#011Speed: 55.34 samples/sec#011loss=1.053870\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:31 INFO 139636288943936] Epoch[157] Batch[10] avg_epoch_loss=1.102286\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=1.16038421392\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:31 INFO 139636288943936] Epoch[157] Batch [10]#011Speed: 52.59 samples/sec#011loss=1.160384\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:31 INFO 139636288943936] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13653.42903137207, \"sum\": 13653.42903137207, \"min\": 13653.42903137207}}, \"EndTime\": 1587302611.779441, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302598.125458}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:31 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=47.8263998122 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:31 INFO 139636288943936] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=157, train loss <loss>=1.10228574818\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:31 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:33 INFO 139636288943936] Epoch[158] Batch[0] avg_epoch_loss=1.774292\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=1.7742921114\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:39 INFO 139636288943936] Epoch[158] Batch[5] avg_epoch_loss=1.572953\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=1.57295282682\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:39 INFO 139636288943936] Epoch[158] Batch [5]#011Speed: 56.01 samples/sec#011loss=1.572953\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:44 INFO 139636288943936] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12405.978202819824, \"sum\": 12405.978202819824, \"min\": 12405.978202819824}}, \"EndTime\": 1587302624.186001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302611.779518}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:44 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.942640162 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:44 INFO 139636288943936] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=158, train loss <loss>=1.49977837801\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:44 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:45 INFO 139636288943936] Epoch[159] Batch[0] avg_epoch_loss=1.374979\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=1.37497937679\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:51 INFO 139636288943936] Epoch[159] Batch[5] avg_epoch_loss=1.395285\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=1.39528522889\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:51 INFO 139636288943936] Epoch[159] Batch [5]#011Speed: 55.53 samples/sec#011loss=1.395285\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:56 INFO 139636288943936] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12168.093919754028, \"sum\": 12168.093919754028, \"min\": 12168.093919754028}}, \"EndTime\": 1587302636.354755, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302624.186088}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:56 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.4316742912 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:56 INFO 139636288943936] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=159, train loss <loss>=1.37826895714\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:56 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:58 INFO 139636288943936] Epoch[160] Batch[0] avg_epoch_loss=1.312463\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:23:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=1.31246340275\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:03 INFO 139636288943936] Epoch[160] Batch[5] avg_epoch_loss=1.258899\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=1.2588994503\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:03 INFO 139636288943936] Epoch[160] Batch [5]#011Speed: 55.55 samples/sec#011loss=1.258899\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:09 INFO 139636288943936] Epoch[160] Batch[10] avg_epoch_loss=1.243840\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=1.22576928139\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:09 INFO 139636288943936] Epoch[160] Batch [10]#011Speed: 56.24 samples/sec#011loss=1.225769\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:09 INFO 139636288943936] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13329.271078109741, \"sum\": 13329.271078109741, \"min\": 13329.271078109741}}, \"EndTime\": 1587302649.684577, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302636.354839}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:09 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.2392415635 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:09 INFO 139636288943936] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=160, train loss <loss>=1.24384028261\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:09 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:11 INFO 139636288943936] Epoch[161] Batch[0] avg_epoch_loss=1.853270\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=1.85326957703\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:17 INFO 139636288943936] Epoch[161] Batch[5] avg_epoch_loss=1.494188\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=1.49418783188\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:17 INFO 139636288943936] Epoch[161] Batch [5]#011Speed: 55.84 samples/sec#011loss=1.494188\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:21 INFO 139636288943936] processed a total of 596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12071.282148361206, \"sum\": 12071.282148361206, \"min\": 12071.282148361206}}, \"EndTime\": 1587302661.756463, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302649.684662}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:21 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.3727626767 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:21 INFO 139636288943936] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=161, train loss <loss>=1.51439458132\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:21 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:23 INFO 139636288943936] Epoch[162] Batch[0] avg_epoch_loss=1.552263\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=1.55226290226\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:29 INFO 139636288943936] Epoch[162] Batch[5] avg_epoch_loss=1.441346\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=1.44134551287\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:29 INFO 139636288943936] Epoch[162] Batch [5]#011Speed: 55.61 samples/sec#011loss=1.441346\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:33 INFO 139636288943936] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12092.710971832275, \"sum\": 12092.710971832275, \"min\": 12092.710971832275}}, \"EndTime\": 1587302673.849875, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302661.756538}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:33 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.1046630878 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:33 INFO 139636288943936] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=162, train loss <loss>=1.36747380495\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:33 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:35 INFO 139636288943936] Epoch[163] Batch[0] avg_epoch_loss=1.330068\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=1.33006834984\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:41 INFO 139636288943936] Epoch[163] Batch[5] avg_epoch_loss=1.099850\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=1.09985009829\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:41 INFO 139636288943936] Epoch[163] Batch [5]#011Speed: 56.51 samples/sec#011loss=1.099850\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:47 INFO 139636288943936] Epoch[163] Batch[10] avg_epoch_loss=1.037873\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=0.963500058651\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:47 INFO 139636288943936] Epoch[163] Batch [10]#011Speed: 56.38 samples/sec#011loss=0.963500\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:47 INFO 139636288943936] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13200.50311088562, \"sum\": 13200.50311088562, \"min\": 13200.50311088562}}, \"EndTime\": 1587302687.051123, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302673.849957}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:47 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.2400885654 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:47 INFO 139636288943936] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=163, train loss <loss>=1.03787280755\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:47 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:48 INFO 139636288943936] Epoch[164] Batch[0] avg_epoch_loss=1.320461\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:48 INFO 139636288943936] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=1.32046103477\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:54 INFO 139636288943936] Epoch[164] Batch[5] avg_epoch_loss=1.170791\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=1.17079052329\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:24:54 INFO 139636288943936] Epoch[164] Batch [5]#011Speed: 55.51 samples/sec#011loss=1.170791\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:00 INFO 139636288943936] Epoch[164] Batch[10] avg_epoch_loss=1.070709\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:00 INFO 139636288943936] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=0.950610953569\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:00 INFO 139636288943936] Epoch[164] Batch [10]#011Speed: 56.59 samples/sec#011loss=0.950611\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:00 INFO 139636288943936] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13230.572938919067, \"sum\": 13230.572938919067, \"min\": 13230.572938919067}}, \"EndTime\": 1587302700.282346, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302687.051204}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:00 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.750284898 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:00 INFO 139636288943936] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:00 INFO 139636288943936] #quality_metric: host=algo-1, epoch=164, train loss <loss>=1.07070890069\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:00 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:02 INFO 139636288943936] Epoch[165] Batch[0] avg_epoch_loss=1.268613\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=1.26861321926\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:07 INFO 139636288943936] Epoch[165] Batch[5] avg_epoch_loss=1.142077\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:07 INFO 139636288943936] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=1.14207730691\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:07 INFO 139636288943936] Epoch[165] Batch [5]#011Speed: 56.23 samples/sec#011loss=1.142077\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:12 INFO 139636288943936] processed a total of 596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12043.045043945312, \"sum\": 12043.045043945312, \"min\": 12043.045043945312}}, \"EndTime\": 1587302712.325998, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302700.282423}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:12 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.4886059442 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:12 INFO 139636288943936] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=165, train loss <loss>=1.09270737171\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:12 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:14 INFO 139636288943936] Epoch[166] Batch[0] avg_epoch_loss=1.015928\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:14 INFO 139636288943936] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=1.01592814922\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:19 INFO 139636288943936] Epoch[166] Batch[5] avg_epoch_loss=1.024183\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=1.024183472\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:19 INFO 139636288943936] Epoch[166] Batch [5]#011Speed: 55.89 samples/sec#011loss=1.024183\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:25 INFO 139636288943936] Epoch[166] Batch[10] avg_epoch_loss=1.013779\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=1.00129369497\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:25 INFO 139636288943936] Epoch[166] Batch [10]#011Speed: 54.67 samples/sec#011loss=1.001294\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:25 INFO 139636288943936] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13422.897100448608, \"sum\": 13422.897100448608, \"min\": 13422.897100448608}}, \"EndTime\": 1587302725.749565, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302712.326084}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:25 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.031708275 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:25 INFO 139636288943936] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=166, train loss <loss>=1.0137790279\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:25 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:27 INFO 139636288943936] Epoch[167] Batch[0] avg_epoch_loss=0.871589\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=0.871589243412\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:33 INFO 139636288943936] Epoch[167] Batch[5] avg_epoch_loss=0.924584\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=0.924584209919\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:33 INFO 139636288943936] Epoch[167] Batch [5]#011Speed: 55.83 samples/sec#011loss=0.924584\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:39 INFO 139636288943936] Epoch[167] Batch[10] avg_epoch_loss=0.987507\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=1.06301339865\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:39 INFO 139636288943936] Epoch[167] Batch [10]#011Speed: 56.42 samples/sec#011loss=1.063013\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:39 INFO 139636288943936] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13390.97785949707, \"sum\": 13390.97785949707, \"min\": 13390.97785949707}}, \"EndTime\": 1587302739.1412, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302725.749653}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:39 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.510525126 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:39 INFO 139636288943936] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=167, train loss <loss>=0.987506568432\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:39 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:40 INFO 139636288943936] Epoch[168] Batch[0] avg_epoch_loss=1.008489\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=1.00848925114\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:46 INFO 139636288943936] Epoch[168] Batch[5] avg_epoch_loss=0.965810\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=0.965809722741\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:46 INFO 139636288943936] Epoch[168] Batch [5]#011Speed: 55.92 samples/sec#011loss=0.965810\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:51 INFO 139636288943936] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12113.528966903687, \"sum\": 12113.528966903687, \"min\": 12113.528966903687}}, \"EndTime\": 1587302751.255289, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302739.141272}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:51 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.1725539235 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:51 INFO 139636288943936] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=168, train loss <loss>=0.994668531418\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:51 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:53 INFO 139636288943936] Epoch[169] Batch[0] avg_epoch_loss=0.784421\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=0.784420669079\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:58 INFO 139636288943936] Epoch[169] Batch[5] avg_epoch_loss=0.987061\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=0.987060795228\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:25:58 INFO 139636288943936] Epoch[169] Batch [5]#011Speed: 55.56 samples/sec#011loss=0.987061\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:03 INFO 139636288943936] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12212.51916885376, \"sum\": 12212.51916885376, \"min\": 12212.51916885376}}, \"EndTime\": 1587302763.468325, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302751.255369}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:03 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.439581827 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:03 INFO 139636288943936] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=169, train loss <loss>=0.946290808916\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:03 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:03 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_13500604-40ea-4d15-8584-cd0b7368cc8d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 120.0869083404541, \"sum\": 120.0869083404541, \"min\": 120.0869083404541}}, \"EndTime\": 1587302763.589055, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302763.4684}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:05 INFO 139636288943936] Epoch[170] Batch[0] avg_epoch_loss=1.117180\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:05 INFO 139636288943936] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=1.11718046665\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:11 INFO 139636288943936] Epoch[170] Batch[5] avg_epoch_loss=1.040432\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=1.04043240348\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:11 INFO 139636288943936] Epoch[170] Batch [5]#011Speed: 55.81 samples/sec#011loss=1.040432\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:16 INFO 139636288943936] Epoch[170] Batch[10] avg_epoch_loss=0.959059\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:16 INFO 139636288943936] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=0.861410057545\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:16 INFO 139636288943936] Epoch[170] Batch [10]#011Speed: 56.24 samples/sec#011loss=0.861410\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:16 INFO 139636288943936] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13229.60090637207, \"sum\": 13229.60090637207, \"min\": 13229.60090637207}}, \"EndTime\": 1587302776.819009, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302763.589328}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:16 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.0558962797 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:16 INFO 139636288943936] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:16 INFO 139636288943936] #quality_metric: host=algo-1, epoch=170, train loss <loss>=0.959058609876\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:16 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:18 INFO 139636288943936] Epoch[171] Batch[0] avg_epoch_loss=1.403762\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=1.4037617445\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:24 INFO 139636288943936] Epoch[171] Batch[5] avg_epoch_loss=1.177527\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=1.17752746741\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:24 INFO 139636288943936] Epoch[171] Batch [5]#011Speed: 55.88 samples/sec#011loss=1.177527\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:28 INFO 139636288943936] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12130.954027175903, \"sum\": 12130.954027175903, \"min\": 12130.954027175903}}, \"EndTime\": 1587302788.950602, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302776.819159}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:28 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.7895244897 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:28 INFO 139636288943936] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:28 INFO 139636288943936] #quality_metric: host=algo-1, epoch=171, train loss <loss>=1.09270478487\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:28 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:30 INFO 139636288943936] Epoch[172] Batch[0] avg_epoch_loss=1.041181\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=1.04118132591\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:36 INFO 139636288943936] Epoch[172] Batch[5] avg_epoch_loss=1.085846\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=1.08584645391\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:36 INFO 139636288943936] Epoch[172] Batch [5]#011Speed: 56.18 samples/sec#011loss=1.085846\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:40 INFO 139636288943936] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12018.963098526001, \"sum\": 12018.963098526001, \"min\": 12018.963098526001}}, \"EndTime\": 1587302800.970221, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302788.950671}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:40 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.2518127288 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:40 INFO 139636288943936] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=172, train loss <loss>=1.05720350146\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:40 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:42 INFO 139636288943936] Epoch[173] Batch[0] avg_epoch_loss=1.407070\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:42 INFO 139636288943936] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=1.40707015991\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:48 INFO 139636288943936] Epoch[173] Batch[5] avg_epoch_loss=1.088803\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:48 INFO 139636288943936] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=1.08880251646\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:48 INFO 139636288943936] Epoch[173] Batch [5]#011Speed: 55.50 samples/sec#011loss=1.088803\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:53 INFO 139636288943936] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12261.452198028564, \"sum\": 12261.452198028564, \"min\": 12261.452198028564}}, \"EndTime\": 1587302813.232334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302800.970306}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:53 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.7876908154 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:53 INFO 139636288943936] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=173, train loss <loss>=1.01069828868\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:53 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:55 INFO 139636288943936] Epoch[174] Batch[0] avg_epoch_loss=0.950492\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:26:55 INFO 139636288943936] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=0.950491547585\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:00 INFO 139636288943936] Epoch[174] Batch[5] avg_epoch_loss=0.972977\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:00 INFO 139636288943936] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=0.972977260749\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:00 INFO 139636288943936] Epoch[174] Batch [5]#011Speed: 56.07 samples/sec#011loss=0.972977\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:06 INFO 139636288943936] Epoch[174] Batch[10] avg_epoch_loss=0.991367\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=1.01343567371\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:06 INFO 139636288943936] Epoch[174] Batch [10]#011Speed: 55.98 samples/sec#011loss=1.013436\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:06 INFO 139636288943936] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13325.01196861267, \"sum\": 13325.01196861267, \"min\": 13325.01196861267}}, \"EndTime\": 1587302826.558172, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302813.232409}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:06 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.3295567861 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:06 INFO 139636288943936] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=174, train loss <loss>=0.99136744846\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:06 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:08 INFO 139636288943936] Epoch[175] Batch[0] avg_epoch_loss=1.007619\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=1.00761890411\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:14 INFO 139636288943936] Epoch[175] Batch[5] avg_epoch_loss=0.973186\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:14 INFO 139636288943936] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=0.973186055819\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:14 INFO 139636288943936] Epoch[175] Batch [5]#011Speed: 55.79 samples/sec#011loss=0.973186\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:19 INFO 139636288943936] Epoch[175] Batch[10] avg_epoch_loss=0.949654\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=0.921415758133\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:19 INFO 139636288943936] Epoch[175] Batch [10]#011Speed: 55.76 samples/sec#011loss=0.921416\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:19 INFO 139636288943936] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13346.158027648926, \"sum\": 13346.158027648926, \"min\": 13346.158027648926}}, \"EndTime\": 1587302839.905056, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302826.558282}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:19 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.4749953107 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:19 INFO 139636288943936] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=175, train loss <loss>=0.949654102325\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:19 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:21 INFO 139636288943936] Epoch[176] Batch[0] avg_epoch_loss=0.768964\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=0.768963932991\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:27 INFO 139636288943936] Epoch[176] Batch[5] avg_epoch_loss=1.056981\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=1.05698101719\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:27 INFO 139636288943936] Epoch[176] Batch [5]#011Speed: 55.07 samples/sec#011loss=1.056981\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:32 INFO 139636288943936] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12251.252889633179, \"sum\": 12251.252889633179, \"min\": 12251.252889633179}}, \"EndTime\": 1587302852.156869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302839.905143}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:32 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.7698453101 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:32 INFO 139636288943936] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=176, train loss <loss>=0.984707027674\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:32 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:34 INFO 139636288943936] Epoch[177] Batch[0] avg_epoch_loss=0.861183\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:34 INFO 139636288943936] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=0.861182570457\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:39 INFO 139636288943936] Epoch[177] Batch[5] avg_epoch_loss=0.932315\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=0.932314644257\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:39 INFO 139636288943936] Epoch[177] Batch [5]#011Speed: 56.17 samples/sec#011loss=0.932315\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:44 INFO 139636288943936] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12265.375137329102, \"sum\": 12265.375137329102, \"min\": 12265.375137329102}}, \"EndTime\": 1587302864.422961, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302852.15694}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:44 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.7929194547 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:44 INFO 139636288943936] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=177, train loss <loss>=0.973649132252\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:44 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:46 INFO 139636288943936] Epoch[178] Batch[0] avg_epoch_loss=0.810081\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=0.810081362724\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:52 INFO 139636288943936] Epoch[178] Batch[5] avg_epoch_loss=1.033549\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=1.03354934851\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:52 INFO 139636288943936] Epoch[178] Batch [5]#011Speed: 56.16 samples/sec#011loss=1.033549\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:57 INFO 139636288943936] Epoch[178] Batch[10] avg_epoch_loss=1.000521\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=0.960886096954\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:57 INFO 139636288943936] Epoch[178] Batch [10]#011Speed: 55.00 samples/sec#011loss=0.960886\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:57 INFO 139636288943936] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13423.752069473267, \"sum\": 13423.752069473267, \"min\": 13423.752069473267}}, \"EndTime\": 1587302877.847422, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302864.423037}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:57 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.7936792746 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:57 INFO 139636288943936] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=178, train loss <loss>=1.0005205978\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:57 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:59 INFO 139636288943936] Epoch[179] Batch[0] avg_epoch_loss=1.842638\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:27:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=1.84263825417\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:05 INFO 139636288943936] Epoch[179] Batch[5] avg_epoch_loss=1.551780\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:05 INFO 139636288943936] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=1.55177966754\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:05 INFO 139636288943936] Epoch[179] Batch [5]#011Speed: 55.71 samples/sec#011loss=1.551780\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:11 INFO 139636288943936] Epoch[179] Batch[10] avg_epoch_loss=1.521229\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=1.48456909657\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:11 INFO 139636288943936] Epoch[179] Batch [10]#011Speed: 55.70 samples/sec#011loss=1.484569\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:11 INFO 139636288943936] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13404.263973236084, \"sum\": 13404.263973236084, \"min\": 13404.263973236084}}, \"EndTime\": 1587302891.25217, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302877.847503}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:11 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.5804824883 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:11 INFO 139636288943936] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=179, train loss <loss>=1.521229408\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:11 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:13 INFO 139636288943936] Epoch[180] Batch[0] avg_epoch_loss=1.303008\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=1.30300843716\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:18 INFO 139636288943936] Epoch[180] Batch[5] avg_epoch_loss=1.348325\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=1.34832489491\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:18 INFO 139636288943936] Epoch[180] Batch [5]#011Speed: 55.77 samples/sec#011loss=1.348325\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:24 INFO 139636288943936] Epoch[180] Batch[10] avg_epoch_loss=1.343356\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=1.33739337921\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:24 INFO 139636288943936] Epoch[180] Batch [10]#011Speed: 56.02 samples/sec#011loss=1.337393\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:24 INFO 139636288943936] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13318.315982818604, \"sum\": 13318.315982818604, \"min\": 13318.315982818604}}, \"EndTime\": 1587302904.570989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302891.25225}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:24 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.429131855 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:24 INFO 139636288943936] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=180, train loss <loss>=1.34335602414\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:24 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:26 INFO 139636288943936] Epoch[181] Batch[0] avg_epoch_loss=1.390275\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=1.39027535915\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:32 INFO 139636288943936] Epoch[181] Batch[5] avg_epoch_loss=1.267093\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=1.26709312201\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:32 INFO 139636288943936] Epoch[181] Batch [5]#011Speed: 56.10 samples/sec#011loss=1.267093\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:38 INFO 139636288943936] Epoch[181] Batch[10] avg_epoch_loss=1.212666\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=1.1473533988\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:38 INFO 139636288943936] Epoch[181] Batch [10]#011Speed: 53.69 samples/sec#011loss=1.147353\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:38 INFO 139636288943936] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13636.399030685425, \"sum\": 13636.399030685425, \"min\": 13636.399030685425}}, \"EndTime\": 1587302918.207969, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302904.571067}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:38 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=47.6661379147 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:38 INFO 139636288943936] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=181, train loss <loss>=1.21266597509\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:38 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:40 INFO 139636288943936] Epoch[182] Batch[0] avg_epoch_loss=0.929674\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=0.929673671722\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:45 INFO 139636288943936] Epoch[182] Batch[5] avg_epoch_loss=0.966406\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=0.966406404972\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:45 INFO 139636288943936] Epoch[182] Batch [5]#011Speed: 55.97 samples/sec#011loss=0.966406\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:51 INFO 139636288943936] Epoch[182] Batch[10] avg_epoch_loss=1.018522\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=1.08106071949\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:51 INFO 139636288943936] Epoch[182] Batch [10]#011Speed: 56.41 samples/sec#011loss=1.081061\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:51 INFO 139636288943936] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13286.813974380493, \"sum\": 13286.813974380493, \"min\": 13286.813974380493}}, \"EndTime\": 1587302931.495397, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302918.20805}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:51 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.3933852945 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:51 INFO 139636288943936] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=182, train loss <loss>=1.01852200248\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:51 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:53 INFO 139636288943936] Epoch[183] Batch[0] avg_epoch_loss=1.432389\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=1.43238902092\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:59 INFO 139636288943936] Epoch[183] Batch[5] avg_epoch_loss=1.099856\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=1.09985588988\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:28:59 INFO 139636288943936] Epoch[183] Batch [5]#011Speed: 54.85 samples/sec#011loss=1.099856\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:03 INFO 139636288943936] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12293.694972991943, \"sum\": 12293.694972991943, \"min\": 12293.694972991943}}, \"EndTime\": 1587302943.789716, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302931.495483}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:03 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.5366765816 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:03 INFO 139636288943936] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=183, train loss <loss>=1.02605113983\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:03 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:05 INFO 139636288943936] Epoch[184] Batch[0] avg_epoch_loss=0.752175\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:05 INFO 139636288943936] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=0.752175450325\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:11 INFO 139636288943936] Epoch[184] Batch[5] avg_epoch_loss=0.983930\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=0.983929763238\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:11 INFO 139636288943936] Epoch[184] Batch [5]#011Speed: 55.55 samples/sec#011loss=0.983930\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:17 INFO 139636288943936] Epoch[184] Batch[10] avg_epoch_loss=1.041579\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=1.11075839996\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:17 INFO 139636288943936] Epoch[184] Batch [10]#011Speed: 56.28 samples/sec#011loss=1.110758\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:17 INFO 139636288943936] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13302.421808242798, \"sum\": 13302.421808242798, \"min\": 13302.421808242798}}, \"EndTime\": 1587302957.092926, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302943.789898}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:17 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.3366219607 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:17 INFO 139636288943936] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=184, train loss <loss>=1.04157914357\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:17 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:18 INFO 139636288943936] Epoch[185] Batch[0] avg_epoch_loss=1.004986\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=1.00498628616\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:24 INFO 139636288943936] Epoch[185] Batch[5] avg_epoch_loss=0.928291\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=0.928290764491\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:24 INFO 139636288943936] Epoch[185] Batch [5]#011Speed: 55.83 samples/sec#011loss=0.928291\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:30 INFO 139636288943936] Epoch[185] Batch[10] avg_epoch_loss=0.944818\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=0.964651751518\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:30 INFO 139636288943936] Epoch[185] Batch [10]#011Speed: 55.71 samples/sec#011loss=0.964652\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:30 INFO 139636288943936] processed a total of 692 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13300.29010772705, \"sum\": 13300.29010772705, \"min\": 13300.29010772705}}, \"EndTime\": 1587302970.393769, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302957.093007}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:30 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.0283695185 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:30 INFO 139636288943936] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=185, train loss <loss>=0.944818485867\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:30 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:30 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_c42dc505-4ae7-411d-9d76-19e31292ddfe-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 103.0130386352539, \"sum\": 103.0130386352539, \"min\": 103.0130386352539}}, \"EndTime\": 1587302970.497434, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302970.393874}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:32 INFO 139636288943936] Epoch[186] Batch[0] avg_epoch_loss=1.243168\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=1.2431678772\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:38 INFO 139636288943936] Epoch[186] Batch[5] avg_epoch_loss=1.068749\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=1.06874916951\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:38 INFO 139636288943936] Epoch[186] Batch [5]#011Speed: 56.19 samples/sec#011loss=1.068749\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:43 INFO 139636288943936] Epoch[186] Batch[10] avg_epoch_loss=0.985954\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=0.886600732803\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:43 INFO 139636288943936] Epoch[186] Batch [10]#011Speed: 56.61 samples/sec#011loss=0.886601\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:43 INFO 139636288943936] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13164.577960968018, \"sum\": 13164.577960968018, \"min\": 13164.577960968018}}, \"EndTime\": 1587302983.662147, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302970.497507}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:43 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.3744410553 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:43 INFO 139636288943936] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=186, train loss <loss>=0.985954425552\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:43 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:45 INFO 139636288943936] Epoch[187] Batch[0] avg_epoch_loss=1.218095\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=1.21809494495\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:51 INFO 139636288943936] Epoch[187] Batch[5] avg_epoch_loss=1.126416\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=1.12641644478\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:51 INFO 139636288943936] Epoch[187] Batch [5]#011Speed: 56.64 samples/sec#011loss=1.126416\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:55 INFO 139636288943936] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12024.54400062561, \"sum\": 12024.54400062561, \"min\": 12024.54400062561}}, \"EndTime\": 1587302995.687264, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302983.662228}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:55 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.5586018667 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:55 INFO 139636288943936] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:55 INFO 139636288943936] #quality_metric: host=algo-1, epoch=187, train loss <loss>=1.04731115103\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:55 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:57 INFO 139636288943936] Epoch[188] Batch[0] avg_epoch_loss=0.901016\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:29:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=0.901015996933\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:03 INFO 139636288943936] Epoch[188] Batch[5] avg_epoch_loss=0.882623\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=0.882623106241\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:03 INFO 139636288943936] Epoch[188] Batch [5]#011Speed: 55.82 samples/sec#011loss=0.882623\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:09 INFO 139636288943936] Epoch[188] Batch[10] avg_epoch_loss=0.960435\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=1.05381011963\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:09 INFO 139636288943936] Epoch[188] Batch [10]#011Speed: 55.96 samples/sec#011loss=1.053810\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:09 INFO 139636288943936] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13325.901985168457, \"sum\": 13325.901985168457, \"min\": 13325.901985168457}}, \"EndTime\": 1587303009.013866, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587302995.687352}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:09 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.0033797111 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:09 INFO 139636288943936] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=188, train loss <loss>=0.960435385054\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:09 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:10 INFO 139636288943936] Epoch[189] Batch[0] avg_epoch_loss=0.775348\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=0.775347650051\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:16 INFO 139636288943936] Epoch[189] Batch[5] avg_epoch_loss=0.988397\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:16 INFO 139636288943936] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=0.988397270441\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:16 INFO 139636288943936] Epoch[189] Batch [5]#011Speed: 55.83 samples/sec#011loss=0.988397\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:22 INFO 139636288943936] Epoch[189] Batch[10] avg_epoch_loss=0.928246\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:22 INFO 139636288943936] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=0.856064432859\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:22 INFO 139636288943936] Epoch[189] Batch [10]#011Speed: 55.61 samples/sec#011loss=0.856064\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:22 INFO 139636288943936] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13255.638122558594, \"sum\": 13255.638122558594, \"min\": 13255.638122558594}}, \"EndTime\": 1587303022.270156, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303009.013949}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:22 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.3561694768 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:22 INFO 139636288943936] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:22 INFO 139636288943936] #quality_metric: host=algo-1, epoch=189, train loss <loss>=0.928245980631\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:22 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:22 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_d89ebfdb-a26d-41b5-900c-dc7a97148a18-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 108.5209846496582, \"sum\": 108.5209846496582, \"min\": 108.5209846496582}}, \"EndTime\": 1587303022.379564, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303022.270282}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:24 INFO 139636288943936] Epoch[190] Batch[0] avg_epoch_loss=1.041112\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=1.04111242294\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:29 INFO 139636288943936] Epoch[190] Batch[5] avg_epoch_loss=1.176082\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=1.17608177662\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:29 INFO 139636288943936] Epoch[190] Batch [5]#011Speed: 55.41 samples/sec#011loss=1.176082\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:35 INFO 139636288943936] Epoch[190] Batch[10] avg_epoch_loss=1.050181\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=0.89909902215\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:35 INFO 139636288943936] Epoch[190] Batch [10]#011Speed: 55.65 samples/sec#011loss=0.899099\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:35 INFO 139636288943936] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13325.361967086792, \"sum\": 13325.361967086792, \"min\": 13325.361967086792}}, \"EndTime\": 1587303035.705064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303022.379641}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:35 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.178384879 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:35 INFO 139636288943936] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=190, train loss <loss>=1.05018052459\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:35 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:37 INFO 139636288943936] Epoch[191] Batch[0] avg_epoch_loss=1.124598\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:37 INFO 139636288943936] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=1.12459814548\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:43 INFO 139636288943936] Epoch[191] Batch[5] avg_epoch_loss=1.015702\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=1.01570195953\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:43 INFO 139636288943936] Epoch[191] Batch [5]#011Speed: 55.23 samples/sec#011loss=1.015702\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:49 INFO 139636288943936] Epoch[191] Batch[10] avg_epoch_loss=0.979779\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=0.936672151089\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:49 INFO 139636288943936] Epoch[191] Batch [10]#011Speed: 55.83 samples/sec#011loss=0.936672\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:49 INFO 139636288943936] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13378.427028656006, \"sum\": 13378.427028656006, \"min\": 13378.427028656006}}, \"EndTime\": 1587303049.084001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303035.705143}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:49 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.3789934904 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:49 INFO 139636288943936] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=191, train loss <loss>=0.97977931933\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:49 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:50 INFO 139636288943936] Epoch[192] Batch[0] avg_epoch_loss=0.759458\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=0.759458124638\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:56 INFO 139636288943936] Epoch[192] Batch[5] avg_epoch_loss=0.954687\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=0.954686661561\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:30:56 INFO 139636288943936] Epoch[192] Batch [5]#011Speed: 55.09 samples/sec#011loss=0.954687\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:02 INFO 139636288943936] Epoch[192] Batch[10] avg_epoch_loss=1.033684\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=1.12848051786\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:02 INFO 139636288943936] Epoch[192] Batch [10]#011Speed: 55.86 samples/sec#011loss=1.128481\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:02 INFO 139636288943936] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13342.213153839111, \"sum\": 13342.213153839111, \"min\": 13342.213153839111}}, \"EndTime\": 1587303062.426856, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303049.084126}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:02 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.166828277 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:02 INFO 139636288943936] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=192, train loss <loss>=1.03368386897\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:02 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:04 INFO 139636288943936] Epoch[193] Batch[0] avg_epoch_loss=0.821638\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=0.821638464928\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:10 INFO 139636288943936] Epoch[193] Batch[5] avg_epoch_loss=0.926119\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=0.926118681828\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:10 INFO 139636288943936] Epoch[193] Batch [5]#011Speed: 55.68 samples/sec#011loss=0.926119\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:15 INFO 139636288943936] Epoch[193] Batch[10] avg_epoch_loss=0.957460\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=0.995069372654\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:15 INFO 139636288943936] Epoch[193] Batch [10]#011Speed: 55.42 samples/sec#011loss=0.995069\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:15 INFO 139636288943936] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13367.862939834595, \"sum\": 13367.862939834595, \"min\": 13367.862939834595}}, \"EndTime\": 1587303075.795313, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303062.426938}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:15 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.1945165807 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:15 INFO 139636288943936] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=193, train loss <loss>=0.957459904931\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:15 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:17 INFO 139636288943936] Epoch[194] Batch[0] avg_epoch_loss=1.287105\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=1.28710532188\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:23 INFO 139636288943936] Epoch[194] Batch[5] avg_epoch_loss=1.083132\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=1.08313214779\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:23 INFO 139636288943936] Epoch[194] Batch [5]#011Speed: 55.84 samples/sec#011loss=1.083132\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:27 INFO 139636288943936] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12187.879085540771, \"sum\": 12187.879085540771, \"min\": 12187.879085540771}}, \"EndTime\": 1587303087.983841, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303075.795403}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:27 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.2645093455 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:27 INFO 139636288943936] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=194, train loss <loss>=1.03411480188\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:27 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:29 INFO 139636288943936] Epoch[195] Batch[0] avg_epoch_loss=0.875319\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=0.875319480896\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:35 INFO 139636288943936] Epoch[195] Batch[5] avg_epoch_loss=0.922440\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=0.922440419594\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:35 INFO 139636288943936] Epoch[195] Batch [5]#011Speed: 55.62 samples/sec#011loss=0.922440\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:41 INFO 139636288943936] Epoch[195] Batch[10] avg_epoch_loss=1.025643\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=1.14948515892\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:41 INFO 139636288943936] Epoch[195] Batch [10]#011Speed: 55.92 samples/sec#011loss=1.149485\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:41 INFO 139636288943936] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13291.981935501099, \"sum\": 13291.981935501099, \"min\": 13291.981935501099}}, \"EndTime\": 1587303101.27643, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303087.983926}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:41 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.6755362316 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:41 INFO 139636288943936] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=195, train loss <loss>=1.02564257383\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:41 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:43 INFO 139636288943936] Epoch[196] Batch[0] avg_epoch_loss=1.908285\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=1.90828490257\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:48 INFO 139636288943936] Epoch[196] Batch[5] avg_epoch_loss=1.389460\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:48 INFO 139636288943936] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=1.38945959012\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:48 INFO 139636288943936] Epoch[196] Batch [5]#011Speed: 55.35 samples/sec#011loss=1.389460\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:54 INFO 139636288943936] Epoch[196] Batch[10] avg_epoch_loss=1.320251\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=1.23719975948\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:54 INFO 139636288943936] Epoch[196] Batch [10]#011Speed: 55.98 samples/sec#011loss=1.237200\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:54 INFO 139636288943936] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13319.857835769653, \"sum\": 13319.857835769653, \"min\": 13319.857835769653}}, \"EndTime\": 1587303114.59686, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303101.276504}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:54 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.249382607 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:54 INFO 139636288943936] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=196, train loss <loss>=1.32025057619\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:54 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:56 INFO 139636288943936] Epoch[197] Batch[0] avg_epoch_loss=1.431869\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:31:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=1.43186879158\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:02 INFO 139636288943936] Epoch[197] Batch[5] avg_epoch_loss=1.267997\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=1.26799690723\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:02 INFO 139636288943936] Epoch[197] Batch [5]#011Speed: 54.64 samples/sec#011loss=1.267997\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:06 INFO 139636288943936] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12248.49820137024, \"sum\": 12248.49820137024, \"min\": 12248.49820137024}}, \"EndTime\": 1587303126.845978, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303114.596927}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:06 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.6179509683 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:06 INFO 139636288943936] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=197, train loss <loss>=1.18542094827\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:06 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:08 INFO 139636288943936] Epoch[198] Batch[0] avg_epoch_loss=1.130822\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=1.13082230091\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:14 INFO 139636288943936] Epoch[198] Batch[5] avg_epoch_loss=0.979757\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:14 INFO 139636288943936] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=0.979756623507\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:14 INFO 139636288943936] Epoch[198] Batch [5]#011Speed: 55.59 samples/sec#011loss=0.979757\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:19 INFO 139636288943936] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12236.171007156372, \"sum\": 12236.171007156372, \"min\": 12236.171007156372}}, \"EndTime\": 1587303139.082869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303126.846064}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:19 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.1977979553 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:19 INFO 139636288943936] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=198, train loss <loss>=0.995803356171\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:19 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:20 INFO 139636288943936] Epoch[199] Batch[0] avg_epoch_loss=1.626396\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:20 INFO 139636288943936] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=1.62639570236\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:26 INFO 139636288943936] Epoch[199] Batch[5] avg_epoch_loss=1.200355\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=1.20035546025\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:26 INFO 139636288943936] Epoch[199] Batch [5]#011Speed: 55.00 samples/sec#011loss=1.200355\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:32 INFO 139636288943936] Epoch[199] Batch[10] avg_epoch_loss=1.064511\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=0.901497495174\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:32 INFO 139636288943936] Epoch[199] Batch [10]#011Speed: 56.02 samples/sec#011loss=0.901497\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:32 INFO 139636288943936] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13356.262922286987, \"sum\": 13356.262922286987, \"min\": 13356.262922286987}}, \"EndTime\": 1587303152.440023, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303139.082945}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:32 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.2648492841 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:32 INFO 139636288943936] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=199, train loss <loss>=1.06451093067\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:32 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:34 INFO 139636288943936] Epoch[200] Batch[0] avg_epoch_loss=1.392033\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:34 INFO 139636288943936] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=1.39203321934\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:40 INFO 139636288943936] Epoch[200] Batch[5] avg_epoch_loss=1.199648\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=1.19964776436\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:40 INFO 139636288943936] Epoch[200] Batch [5]#011Speed: 55.86 samples/sec#011loss=1.199648\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:45 INFO 139636288943936] Epoch[200] Batch[10] avg_epoch_loss=1.158431\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=1.1089712739\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:45 INFO 139636288943936] Epoch[200] Batch [10]#011Speed: 56.33 samples/sec#011loss=1.108971\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:45 INFO 139636288943936] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13286.3130569458, \"sum\": 13286.3130569458, \"min\": 13286.3130569458}}, \"EndTime\": 1587303165.726925, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303152.440102}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:45 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.2016007157 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:45 INFO 139636288943936] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=200, train loss <loss>=1.15843117779\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:45 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:47 INFO 139636288943936] Epoch[201] Batch[0] avg_epoch_loss=1.245343\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=1.24534344673\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:53 INFO 139636288943936] Epoch[201] Batch[5] avg_epoch_loss=1.006394\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=1.00639404853\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:53 INFO 139636288943936] Epoch[201] Batch [5]#011Speed: 55.81 samples/sec#011loss=1.006394\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:57 INFO 139636288943936] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12201.500177383423, \"sum\": 12201.500177383423, \"min\": 12201.500177383423}}, \"EndTime\": 1587303177.928935, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303165.727004}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:57 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.2225889616 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:57 INFO 139636288943936] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=201, train loss <loss>=0.970616650581\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:57 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:59 INFO 139636288943936] Epoch[202] Batch[0] avg_epoch_loss=1.013827\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:32:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=1.01382672787\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:05 INFO 139636288943936] Epoch[202] Batch[5] avg_epoch_loss=0.941664\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:05 INFO 139636288943936] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=0.941664268573\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:05 INFO 139636288943936] Epoch[202] Batch [5]#011Speed: 55.72 samples/sec#011loss=0.941664\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:10 INFO 139636288943936] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12124.166011810303, \"sum\": 12124.166011810303, \"min\": 12124.166011810303}}, \"EndTime\": 1587303190.054005, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303177.929044}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:10 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.1370030108 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:10 INFO 139636288943936] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=202, train loss <loss>=0.963133990765\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:10 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:11 INFO 139636288943936] Epoch[203] Batch[0] avg_epoch_loss=0.830845\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=0.830845177174\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:17 INFO 139636288943936] Epoch[203] Batch[5] avg_epoch_loss=0.872041\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=0.872040897608\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:17 INFO 139636288943936] Epoch[203] Batch [5]#011Speed: 55.80 samples/sec#011loss=0.872041\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:23 INFO 139636288943936] Epoch[203] Batch[10] avg_epoch_loss=0.938290\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=1.01778948307\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:23 INFO 139636288943936] Epoch[203] Batch [10]#011Speed: 55.48 samples/sec#011loss=1.017789\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:23 INFO 139636288943936] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13420.028924942017, \"sum\": 13420.028924942017, \"min\": 13420.028924942017}}, \"EndTime\": 1587303203.474667, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303190.054092}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:23 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.1798112182 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:23 INFO 139636288943936] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=203, train loss <loss>=0.938290254636\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:23 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:25 INFO 139636288943936] Epoch[204] Batch[0] avg_epoch_loss=1.034379\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=1.03437852859\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:31 INFO 139636288943936] Epoch[204] Batch[5] avg_epoch_loss=0.928832\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=0.928831785917\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:31 INFO 139636288943936] Epoch[204] Batch [5]#011Speed: 55.42 samples/sec#011loss=0.928832\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:36 INFO 139636288943936] Epoch[204] Batch[10] avg_epoch_loss=0.889264\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=204, batch=10 train loss <loss>=0.841782796383\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:36 INFO 139636288943936] Epoch[204] Batch [10]#011Speed: 55.83 samples/sec#011loss=0.841783\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:36 INFO 139636288943936] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13359.81798171997, \"sum\": 13359.81798171997, \"min\": 13359.81798171997}}, \"EndTime\": 1587303216.834987, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303203.474742}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:36 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.8026255149 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:36 INFO 139636288943936] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=204, train loss <loss>=0.889264063402\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:36 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:36 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_6be1f7c2-f54a-4ab1-8a3a-db7b4699e783-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 104.27093505859375, \"sum\": 104.27093505859375, \"min\": 104.27093505859375}}, \"EndTime\": 1587303216.939905, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303216.835067}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:38 INFO 139636288943936] Epoch[205] Batch[0] avg_epoch_loss=0.933890\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=0.933890044689\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:44 INFO 139636288943936] Epoch[205] Batch[5] avg_epoch_loss=0.993813\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=0.993813365698\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:44 INFO 139636288943936] Epoch[205] Batch [5]#011Speed: 55.99 samples/sec#011loss=0.993813\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:50 INFO 139636288943936] Epoch[205] Batch[10] avg_epoch_loss=0.912589\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=0.815119254589\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:50 INFO 139636288943936] Epoch[205] Batch [10]#011Speed: 55.24 samples/sec#011loss=0.815119\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:50 INFO 139636288943936] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13339.28894996643, \"sum\": 13339.28894996643, \"min\": 13339.28894996643}}, \"EndTime\": 1587303230.279333, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303216.939981}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:50 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.6528844936 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:50 INFO 139636288943936] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=205, train loss <loss>=0.912588769739\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:50 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:52 INFO 139636288943936] Epoch[206] Batch[0] avg_epoch_loss=1.234457\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=1.23445653915\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:57 INFO 139636288943936] Epoch[206] Batch[5] avg_epoch_loss=1.443163\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=1.44316279888\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:33:57 INFO 139636288943936] Epoch[206] Batch [5]#011Speed: 55.32 samples/sec#011loss=1.443163\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:02 INFO 139636288943936] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12174.823999404907, \"sum\": 12174.823999404907, \"min\": 12174.823999404907}}, \"EndTime\": 1587303242.454638, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303230.279403}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:02 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.9068415967 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:02 INFO 139636288943936] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=206, train loss <loss>=1.43511229753\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:02 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:04 INFO 139636288943936] Epoch[207] Batch[0] avg_epoch_loss=1.203756\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=1.20375645161\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:10 INFO 139636288943936] Epoch[207] Batch[5] avg_epoch_loss=1.408481\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=1.40848124027\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:10 INFO 139636288943936] Epoch[207] Batch [5]#011Speed: 55.45 samples/sec#011loss=1.408481\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:15 INFO 139636288943936] Epoch[207] Batch[10] avg_epoch_loss=1.317814\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=1.2090139389\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:15 INFO 139636288943936] Epoch[207] Batch [10]#011Speed: 55.84 samples/sec#011loss=1.209014\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:15 INFO 139636288943936] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13423.168897628784, \"sum\": 13423.168897628784, \"min\": 13423.168897628784}}, \"EndTime\": 1587303255.879453, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303242.455431}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:15 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.8387654063 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:15 INFO 139636288943936] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=207, train loss <loss>=1.3178142851\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:15 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:17 INFO 139636288943936] Epoch[208] Batch[0] avg_epoch_loss=1.189810\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:17 INFO 139636288943936] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=1.18980967999\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:23 INFO 139636288943936] Epoch[208] Batch[5] avg_epoch_loss=1.075270\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=1.07526965936\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:23 INFO 139636288943936] Epoch[208] Batch [5]#011Speed: 55.45 samples/sec#011loss=1.075270\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:29 INFO 139636288943936] Epoch[208] Batch[10] avg_epoch_loss=0.979467\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=0.864503598213\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:29 INFO 139636288943936] Epoch[208] Batch [10]#011Speed: 55.82 samples/sec#011loss=0.864504\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:29 INFO 139636288943936] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13397.344827651978, \"sum\": 13397.344827651978, \"min\": 13397.344827651978}}, \"EndTime\": 1587303269.277309, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303255.879532}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:29 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.8305233881 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:29 INFO 139636288943936] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=208, train loss <loss>=0.979466904293\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:29 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:31 INFO 139636288943936] Epoch[209] Batch[0] avg_epoch_loss=1.253369\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=1.25336921215\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:36 INFO 139636288943936] Epoch[209] Batch[5] avg_epoch_loss=1.056028\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=1.0560284555\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:36 INFO 139636288943936] Epoch[209] Batch [5]#011Speed: 55.95 samples/sec#011loss=1.056028\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:41 INFO 139636288943936] processed a total of 586 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12020.677089691162, \"sum\": 12020.677089691162, \"min\": 12020.677089691162}}, \"EndTime\": 1587303281.29862, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303269.277389}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:41 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.7488358579 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:41 INFO 139636288943936] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=209, train loss <loss>=1.04955886006\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:41 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:43 INFO 139636288943936] Epoch[210] Batch[0] avg_epoch_loss=0.975839\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=0.97583937645\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:48 INFO 139636288943936] Epoch[210] Batch[5] avg_epoch_loss=1.000175\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:48 INFO 139636288943936] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=1.00017527739\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:48 INFO 139636288943936] Epoch[210] Batch [5]#011Speed: 56.23 samples/sec#011loss=1.000175\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:54 INFO 139636288943936] Epoch[210] Batch[10] avg_epoch_loss=0.949533\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=0.888761198521\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:54 INFO 139636288943936] Epoch[210] Batch [10]#011Speed: 55.96 samples/sec#011loss=0.888761\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:54 INFO 139636288943936] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13222.795963287354, \"sum\": 13222.795963287354, \"min\": 13222.795963287354}}, \"EndTime\": 1587303294.522017, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303281.298701}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:54 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.1400295959 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:54 INFO 139636288943936] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=210, train loss <loss>=0.949532514269\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:54 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:56 INFO 139636288943936] Epoch[211] Batch[0] avg_epoch_loss=0.881073\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:34:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=0.881072759628\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:02 INFO 139636288943936] Epoch[211] Batch[5] avg_epoch_loss=1.093410\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=1.0934103032\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:02 INFO 139636288943936] Epoch[211] Batch [5]#011Speed: 55.67 samples/sec#011loss=1.093410\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:06 INFO 139636288943936] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12156.272172927856, \"sum\": 12156.272172927856, \"min\": 12156.272172927856}}, \"EndTime\": 1587303306.678901, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303294.522099}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:06 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.1534949442 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:06 INFO 139636288943936] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=211, train loss <loss>=1.00772372484\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:06 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:08 INFO 139636288943936] Epoch[212] Batch[0] avg_epoch_loss=0.798807\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=0.798806846142\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:14 INFO 139636288943936] Epoch[212] Batch[5] avg_epoch_loss=0.790200\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:14 INFO 139636288943936] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=0.790199806293\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:14 INFO 139636288943936] Epoch[212] Batch [5]#011Speed: 56.15 samples/sec#011loss=0.790200\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:19 INFO 139636288943936] Epoch[212] Batch[10] avg_epoch_loss=0.967149\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=1.17948840857\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:19 INFO 139636288943936] Epoch[212] Batch [10]#011Speed: 56.30 samples/sec#011loss=1.179488\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:19 INFO 139636288943936] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13267.377853393555, \"sum\": 13267.377853393555, \"min\": 13267.377853393555}}, \"EndTime\": 1587303319.946891, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303306.678982}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:19 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.0469720797 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:19 INFO 139636288943936] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=212, train loss <loss>=0.967149170962\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:19 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:21 INFO 139636288943936] Epoch[213] Batch[0] avg_epoch_loss=0.870839\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=0.870839476585\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:27 INFO 139636288943936] Epoch[213] Batch[5] avg_epoch_loss=0.856644\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=0.856644451618\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:27 INFO 139636288943936] Epoch[213] Batch [5]#011Speed: 55.18 samples/sec#011loss=0.856644\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:33 INFO 139636288943936] Epoch[213] Batch[10] avg_epoch_loss=0.904724\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=0.962419009209\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:33 INFO 139636288943936] Epoch[213] Batch [10]#011Speed: 55.17 samples/sec#011loss=0.962419\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:33 INFO 139636288943936] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13408.16617012024, \"sum\": 13408.16617012024, \"min\": 13408.16617012024}}, \"EndTime\": 1587303333.355793, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303319.947011}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:33 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.5961715308 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:33 INFO 139636288943936] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=213, train loss <loss>=0.904723795978\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:33 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:35 INFO 139636288943936] Epoch[214] Batch[0] avg_epoch_loss=1.088789\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=1.08878910542\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:40 INFO 139636288943936] Epoch[214] Batch[5] avg_epoch_loss=0.979287\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=0.979287008444\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:40 INFO 139636288943936] Epoch[214] Batch [5]#011Speed: 56.08 samples/sec#011loss=0.979287\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:45 INFO 139636288943936] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12146.256923675537, \"sum\": 12146.256923675537, \"min\": 12146.256923675537}}, \"EndTime\": 1587303345.502636, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303333.355879}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:45 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.7850567894 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:45 INFO 139636288943936] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=214, train loss <loss>=0.886793529987\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:45 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:45 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_65670541-0c94-4051-b387-f7724f8d0460-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 103.87396812438965, \"sum\": 103.87396812438965, \"min\": 103.87396812438965}}, \"EndTime\": 1587303345.607154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303345.502706}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:47 INFO 139636288943936] Epoch[215] Batch[0] avg_epoch_loss=0.799466\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=0.799465894699\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:53 INFO 139636288943936] Epoch[215] Batch[5] avg_epoch_loss=0.953883\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=0.953882694244\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:53 INFO 139636288943936] Epoch[215] Batch [5]#011Speed: 53.55 samples/sec#011loss=0.953883\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:59 INFO 139636288943936] Epoch[215] Batch[10] avg_epoch_loss=0.878569\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=0.788193404675\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:59 INFO 139636288943936] Epoch[215] Batch [10]#011Speed: 55.11 samples/sec#011loss=0.788193\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:59 INFO 139636288943936] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13712.461948394775, \"sum\": 13712.461948394775, \"min\": 13712.461948394775}}, \"EndTime\": 1587303359.319762, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303345.607236}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:59 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=47.1100293707 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:59 INFO 139636288943936] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=215, train loss <loss>=0.878569380804\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:59 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:35:59 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_a54f220d-8230-4086-b7f0-c7ef38b32ca0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 107.84292221069336, \"sum\": 107.84292221069336, \"min\": 107.84292221069336}}, \"EndTime\": 1587303359.428203, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303359.319842}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:01 INFO 139636288943936] Epoch[216] Batch[0] avg_epoch_loss=1.381334\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=1.38133370876\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:07 INFO 139636288943936] Epoch[216] Batch[5] avg_epoch_loss=1.456397\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:07 INFO 139636288943936] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=1.45639725526\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:07 INFO 139636288943936] Epoch[216] Batch [5]#011Speed: 55.54 samples/sec#011loss=1.456397\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:11 INFO 139636288943936] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12201.268911361694, \"sum\": 12201.268911361694, \"min\": 12201.268911361694}}, \"EndTime\": 1587303371.629616, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303359.428276}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:11 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.3875414999 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:11 INFO 139636288943936] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=216, train loss <loss>=1.49453251362\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:11 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:13 INFO 139636288943936] Epoch[217] Batch[0] avg_epoch_loss=1.635431\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=1.63543093204\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:19 INFO 139636288943936] Epoch[217] Batch[5] avg_epoch_loss=1.432040\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=1.43204009533\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:19 INFO 139636288943936] Epoch[217] Batch [5]#011Speed: 55.71 samples/sec#011loss=1.432040\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:23 INFO 139636288943936] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12155.826807022095, \"sum\": 12155.826807022095, \"min\": 12155.826807022095}}, \"EndTime\": 1587303383.786107, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303371.629704}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:23 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.4845730853 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:23 INFO 139636288943936] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=217, train loss <loss>=1.3886379838\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:23 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:25 INFO 139636288943936] Epoch[218] Batch[0] avg_epoch_loss=1.200431\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=1.20043087006\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:31 INFO 139636288943936] Epoch[218] Batch[5] avg_epoch_loss=1.080189\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=1.08018907905\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:31 INFO 139636288943936] Epoch[218] Batch [5]#011Speed: 55.24 samples/sec#011loss=1.080189\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:37 INFO 139636288943936] Epoch[218] Batch[10] avg_epoch_loss=0.969454\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:37 INFO 139636288943936] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=0.836572527885\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:37 INFO 139636288943936] Epoch[218] Batch [10]#011Speed: 55.69 samples/sec#011loss=0.836573\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:37 INFO 139636288943936] processed a total of 699 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13459.280967712402, \"sum\": 13459.280967712402, \"min\": 13459.280967712402}}, \"EndTime\": 1587303397.246043, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303383.786193}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:37 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.9339765633 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:37 INFO 139636288943936] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:37 INFO 139636288943936] #quality_metric: host=algo-1, epoch=218, train loss <loss>=0.969454283064\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:37 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:39 INFO 139636288943936] Epoch[219] Batch[0] avg_epoch_loss=0.805030\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=0.805029809475\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:44 INFO 139636288943936] Epoch[219] Batch[5] avg_epoch_loss=1.173724\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=1.17372437318\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:44 INFO 139636288943936] Epoch[219] Batch [5]#011Speed: 55.77 samples/sec#011loss=1.173724\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:49 INFO 139636288943936] processed a total of 593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12162.758111953735, \"sum\": 12162.758111953735, \"min\": 12162.758111953735}}, \"EndTime\": 1587303409.409408, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303397.24612}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:49 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.7548000319 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:49 INFO 139636288943936] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=219, train loss <loss>=1.03862444162\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:49 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:51 INFO 139636288943936] Epoch[220] Batch[0] avg_epoch_loss=1.050653\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=1.05065262318\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:57 INFO 139636288943936] Epoch[220] Batch[5] avg_epoch_loss=1.019785\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=1.01978453\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:36:57 INFO 139636288943936] Epoch[220] Batch [5]#011Speed: 55.83 samples/sec#011loss=1.019785\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:02 INFO 139636288943936] Epoch[220] Batch[10] avg_epoch_loss=0.985988\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=0.945431649685\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:02 INFO 139636288943936] Epoch[220] Batch [10]#011Speed: 55.08 samples/sec#011loss=0.945432\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:02 INFO 139636288943936] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13410.377979278564, \"sum\": 13410.377979278564, \"min\": 13410.377979278564}}, \"EndTime\": 1587303422.820509, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303409.409485}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:02 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.3029536984 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:02 INFO 139636288943936] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=220, train loss <loss>=0.985987766223\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:02 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:04 INFO 139636288943936] Epoch[221] Batch[0] avg_epoch_loss=0.795435\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=0.79543530941\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:10 INFO 139636288943936] Epoch[221] Batch[5] avg_epoch_loss=0.853217\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=0.853216916323\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:10 INFO 139636288943936] Epoch[221] Batch [5]#011Speed: 54.80 samples/sec#011loss=0.853217\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:15 INFO 139636288943936] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12323.681116104126, \"sum\": 12323.681116104126, \"min\": 12323.681116104126}}, \"EndTime\": 1587303435.144762, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303422.820626}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:15 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.3638808935 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:15 INFO 139636288943936] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=221, train loss <loss>=0.9541487813\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:15 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:16 INFO 139636288943936] Epoch[222] Batch[0] avg_epoch_loss=0.616425\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:16 INFO 139636288943936] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=0.616425454617\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:22 INFO 139636288943936] Epoch[222] Batch[5] avg_epoch_loss=0.846714\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:22 INFO 139636288943936] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=0.846713970105\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:22 INFO 139636288943936] Epoch[222] Batch [5]#011Speed: 55.49 samples/sec#011loss=0.846714\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:27 INFO 139636288943936] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12165.624856948853, \"sum\": 12165.624856948853, \"min\": 12165.624856948853}}, \"EndTime\": 1587303447.311082, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303435.144846}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:27 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.8119798351 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:27 INFO 139636288943936] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=222, train loss <loss>=0.81943808794\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:27 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:27 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_0349379a-0b35-45e2-9439-0bf713fdf310-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 107.86199569702148, \"sum\": 107.86199569702148, \"min\": 107.86199569702148}}, \"EndTime\": 1587303447.419797, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303447.311166}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:29 INFO 139636288943936] Epoch[223] Batch[0] avg_epoch_loss=1.138381\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=1.13838136196\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:35 INFO 139636288943936] Epoch[223] Batch[5] avg_epoch_loss=0.850305\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=0.850304941336\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:35 INFO 139636288943936] Epoch[223] Batch [5]#011Speed: 55.70 samples/sec#011loss=0.850305\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:40 INFO 139636288943936] Epoch[223] Batch[10] avg_epoch_loss=0.827088\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=0.799228560925\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:40 INFO 139636288943936] Epoch[223] Batch [10]#011Speed: 55.76 samples/sec#011loss=0.799229\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:40 INFO 139636288943936] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13354.886054992676, \"sum\": 13354.886054992676, \"min\": 13354.886054992676}}, \"EndTime\": 1587303460.774845, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303447.419877}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:40 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.5210404488 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:40 INFO 139636288943936] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=223, train loss <loss>=0.827088404786\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:40 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:42 INFO 139636288943936] Epoch[224] Batch[0] avg_epoch_loss=1.182779\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:42 INFO 139636288943936] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=1.18277871609\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:48 INFO 139636288943936] Epoch[224] Batch[5] avg_epoch_loss=0.942975\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:48 INFO 139636288943936] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=0.942974795898\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:48 INFO 139636288943936] Epoch[224] Batch [5]#011Speed: 55.78 samples/sec#011loss=0.942975\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:52 INFO 139636288943936] processed a total of 587 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12083.104848861694, \"sum\": 12083.104848861694, \"min\": 12083.104848861694}}, \"EndTime\": 1587303472.858864, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303460.774928}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:52 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.5797132493 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:52 INFO 139636288943936] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=224, train loss <loss>=0.919022870064\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:52 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:54 INFO 139636288943936] Epoch[225] Batch[0] avg_epoch_loss=1.033821\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:37:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=1.03382146358\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:00 INFO 139636288943936] Epoch[225] Batch[5] avg_epoch_loss=0.958438\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:00 INFO 139636288943936] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=0.958438346783\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:00 INFO 139636288943936] Epoch[225] Batch [5]#011Speed: 53.75 samples/sec#011loss=0.958438\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:06 INFO 139636288943936] Epoch[225] Batch[10] avg_epoch_loss=0.852243\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=0.724807989597\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:06 INFO 139636288943936] Epoch[225] Batch [10]#011Speed: 55.32 samples/sec#011loss=0.724808\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:06 INFO 139636288943936] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13567.17300415039, \"sum\": 13567.17300415039, \"min\": 13567.17300415039}}, \"EndTime\": 1587303486.426671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303472.85894}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:06 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=47.7618978072 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:06 INFO 139636288943936] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=225, train loss <loss>=0.852242729881\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:06 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:08 INFO 139636288943936] Epoch[226] Batch[0] avg_epoch_loss=0.944748\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=0.944747745991\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:13 INFO 139636288943936] Epoch[226] Batch[5] avg_epoch_loss=1.022383\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=1.02238260706\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:13 INFO 139636288943936] Epoch[226] Batch [5]#011Speed: 55.73 samples/sec#011loss=1.022383\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:18 INFO 139636288943936] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12098.021984100342, \"sum\": 12098.021984100342, \"min\": 12098.021984100342}}, \"EndTime\": 1587303498.525333, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303486.426754}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:18 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.9914334316 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:18 INFO 139636288943936] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=226, train loss <loss>=0.94230260849\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:18 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:20 INFO 139636288943936] Epoch[227] Batch[0] avg_epoch_loss=0.924674\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:20 INFO 139636288943936] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=0.924673736095\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:26 INFO 139636288943936] Epoch[227] Batch[5] avg_epoch_loss=0.832204\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=0.832203735908\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:26 INFO 139636288943936] Epoch[227] Batch [5]#011Speed: 55.60 samples/sec#011loss=0.832204\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:32 INFO 139636288943936] Epoch[227] Batch[10] avg_epoch_loss=0.848561\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=0.868189871311\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:32 INFO 139636288943936] Epoch[227] Batch [10]#011Speed: 55.10 samples/sec#011loss=0.868190\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:32 INFO 139636288943936] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13483.525037765503, \"sum\": 13483.525037765503, \"min\": 13483.525037765503}}, \"EndTime\": 1587303512.0095, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303498.525419}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:32 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.0963777949 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:32 INFO 139636288943936] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=227, train loss <loss>=0.848561070182\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:32 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:33 INFO 139636288943936] Epoch[228] Batch[0] avg_epoch_loss=1.242142\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=1.24214196205\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:39 INFO 139636288943936] Epoch[228] Batch[5] avg_epoch_loss=1.031484\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=1.03148414691\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:39 INFO 139636288943936] Epoch[228] Batch [5]#011Speed: 55.77 samples/sec#011loss=1.031484\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:44 INFO 139636288943936] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12119.7829246521, \"sum\": 12119.7829246521, \"min\": 12119.7829246521}}, \"EndTime\": 1587303524.1299, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303512.00962}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:44 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.5878757389 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:44 INFO 139636288943936] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=228, train loss <loss>=0.976075738668\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:44 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:45 INFO 139636288943936] Epoch[229] Batch[0] avg_epoch_loss=0.989427\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=0.989427030087\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:51 INFO 139636288943936] Epoch[229] Batch[5] avg_epoch_loss=0.901272\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=0.901271919409\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:51 INFO 139636288943936] Epoch[229] Batch [5]#011Speed: 55.87 samples/sec#011loss=0.901272\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:56 INFO 139636288943936] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12097.981929779053, \"sum\": 12097.981929779053, \"min\": 12097.981929779053}}, \"EndTime\": 1587303536.228579, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303524.129976}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:56 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.8425335474 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:56 INFO 139636288943936] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=229, train loss <loss>=0.919072145224\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:56 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:58 INFO 139636288943936] Epoch[230] Batch[0] avg_epoch_loss=0.901691\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:38:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=0.901690602303\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:03 INFO 139636288943936] Epoch[230] Batch[5] avg_epoch_loss=0.927785\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=0.927784740925\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:03 INFO 139636288943936] Epoch[230] Batch [5]#011Speed: 54.04 samples/sec#011loss=0.927785\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:08 INFO 139636288943936] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12365.667819976807, \"sum\": 12365.667819976807, \"min\": 12365.667819976807}}, \"EndTime\": 1587303548.594786, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303536.228657}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:08 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.1087527032 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:08 INFO 139636288943936] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=230, train loss <loss>=0.88032875061\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:08 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:10 INFO 139636288943936] Epoch[231] Batch[0] avg_epoch_loss=0.840279\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=0.840279459953\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:16 INFO 139636288943936] Epoch[231] Batch[5] avg_epoch_loss=0.900390\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:16 INFO 139636288943936] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=0.900389740864\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:16 INFO 139636288943936] Epoch[231] Batch [5]#011Speed: 55.23 samples/sec#011loss=0.900390\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:21 INFO 139636288943936] Epoch[231] Batch[10] avg_epoch_loss=0.823894\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=231, batch=10 train loss <loss>=0.732099190354\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:21 INFO 139636288943936] Epoch[231] Batch [10]#011Speed: 55.81 samples/sec#011loss=0.732099\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:21 INFO 139636288943936] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13333.869934082031, \"sum\": 13333.869934082031, \"min\": 13333.869934082031}}, \"EndTime\": 1587303561.929488, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303548.594869}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:21 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.3726103771 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:21 INFO 139636288943936] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=231, train loss <loss>=0.823894036087\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:21 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:23 INFO 139636288943936] Epoch[232] Batch[0] avg_epoch_loss=0.930257\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=0.930256724358\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:29 INFO 139636288943936] Epoch[232] Batch[5] avg_epoch_loss=1.007200\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=1.0072003901\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:29 INFO 139636288943936] Epoch[232] Batch [5]#011Speed: 55.82 samples/sec#011loss=1.007200\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:35 INFO 139636288943936] Epoch[232] Batch[10] avg_epoch_loss=0.927194\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=0.831185340881\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:35 INFO 139636288943936] Epoch[232] Batch [10]#011Speed: 55.40 samples/sec#011loss=0.831185\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:35 INFO 139636288943936] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13319.567918777466, \"sum\": 13319.567918777466, \"min\": 13319.567918777466}}, \"EndTime\": 1587303575.249655, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303561.929567}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:35 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.6526874027 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:35 INFO 139636288943936] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=232, train loss <loss>=0.927193549546\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:35 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:37 INFO 139636288943936] Epoch[233] Batch[0] avg_epoch_loss=0.768475\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:37 INFO 139636288943936] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=0.768475472927\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:42 INFO 139636288943936] Epoch[233] Batch[5] avg_epoch_loss=0.900683\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:42 INFO 139636288943936] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=0.900683303674\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:42 INFO 139636288943936] Epoch[233] Batch [5]#011Speed: 55.69 samples/sec#011loss=0.900683\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:47 INFO 139636288943936] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12195.421934127808, \"sum\": 12195.421934127808, \"min\": 12195.421934127808}}, \"EndTime\": 1587303587.445686, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303575.249737}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:47 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.9862516583 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:47 INFO 139636288943936] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=233, train loss <loss>=0.873780798912\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:47 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:49 INFO 139636288943936] Epoch[234] Batch[0] avg_epoch_loss=1.143190\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=1.14318978786\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:54 INFO 139636288943936] Epoch[234] Batch[5] avg_epoch_loss=0.818385\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=0.818384687106\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:54 INFO 139636288943936] Epoch[234] Batch [5]#011Speed: 56.42 samples/sec#011loss=0.818385\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:59 INFO 139636288943936] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12004.908084869385, \"sum\": 12004.908084869385, \"min\": 12004.908084869385}}, \"EndTime\": 1587303599.451223, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303587.44576}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:59 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.0622239395 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:59 INFO 139636288943936] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=234, train loss <loss>=0.821254658699\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:39:59 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:01 INFO 139636288943936] Epoch[235] Batch[0] avg_epoch_loss=0.876663\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=0.876662611961\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:07 INFO 139636288943936] Epoch[235] Batch[5] avg_epoch_loss=0.922480\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:07 INFO 139636288943936] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=0.922479728858\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:07 INFO 139636288943936] Epoch[235] Batch [5]#011Speed: 55.83 samples/sec#011loss=0.922480\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:11 INFO 139636288943936] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12137.407064437866, \"sum\": 12137.407064437866, \"min\": 12137.407064437866}}, \"EndTime\": 1587303611.589651, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303599.451331}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:11 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.740393244 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:11 INFO 139636288943936] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:11 INFO 139636288943936] #quality_metric: host=algo-1, epoch=235, train loss <loss>=0.840304076672\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:11 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:13 INFO 139636288943936] Epoch[236] Batch[0] avg_epoch_loss=0.882767\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=0.882766962051\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:19 INFO 139636288943936] Epoch[236] Batch[5] avg_epoch_loss=0.827017\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=0.827017237743\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:19 INFO 139636288943936] Epoch[236] Batch [5]#011Speed: 55.84 samples/sec#011loss=0.827017\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:24 INFO 139636288943936] Epoch[236] Batch[10] avg_epoch_loss=0.825758\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=0.824247634411\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:24 INFO 139636288943936] Epoch[236] Batch [10]#011Speed: 55.93 samples/sec#011loss=0.824248\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:24 INFO 139636288943936] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13277.60100364685, \"sum\": 13277.60100364685, \"min\": 13277.60100364685}}, \"EndTime\": 1587303624.86813, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303611.589726}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:24 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.2344561516 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:24 INFO 139636288943936] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=236, train loss <loss>=0.825758327137\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:24 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:26 INFO 139636288943936] Epoch[237] Batch[0] avg_epoch_loss=0.854974\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=0.85497379303\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:32 INFO 139636288943936] Epoch[237] Batch[5] avg_epoch_loss=0.862409\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=0.862408737342\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:32 INFO 139636288943936] Epoch[237] Batch [5]#011Speed: 54.88 samples/sec#011loss=0.862409\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:37 INFO 139636288943936] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12240.99087715149, \"sum\": 12240.99087715149, \"min\": 12240.99087715149}}, \"EndTime\": 1587303637.109659, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303624.868211}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:37 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.2827127061 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:37 INFO 139636288943936] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:37 INFO 139636288943936] #quality_metric: host=algo-1, epoch=237, train loss <loss>=0.904375070333\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:37 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:38 INFO 139636288943936] Epoch[238] Batch[0] avg_epoch_loss=0.831204\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=0.831203997135\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:44 INFO 139636288943936] Epoch[238] Batch[5] avg_epoch_loss=0.669244\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:44 INFO 139636288943936] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=0.669243981441\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:44 INFO 139636288943936] Epoch[238] Batch [5]#011Speed: 55.71 samples/sec#011loss=0.669244\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:49 INFO 139636288943936] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12130.864143371582, \"sum\": 12130.864143371582, \"min\": 12130.864143371582}}, \"EndTime\": 1587303649.241104, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303637.10974}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:49 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.9439717892 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:49 INFO 139636288943936] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=238, train loss <loss>=0.786993712187\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:49 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:49 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_5d26feba-5897-425c-a14f-7b71c39b8da3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 103.88398170471191, \"sum\": 103.88398170471191, \"min\": 103.88398170471191}}, \"EndTime\": 1587303649.345612, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303649.241178}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:51 INFO 139636288943936] Epoch[239] Batch[0] avg_epoch_loss=0.607819\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=0.607818543911\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:56 INFO 139636288943936] Epoch[239] Batch[5] avg_epoch_loss=0.917674\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=0.917673508326\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:40:56 INFO 139636288943936] Epoch[239] Batch [5]#011Speed: 55.53 samples/sec#011loss=0.917674\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:01 INFO 139636288943936] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12177.592992782593, \"sum\": 12177.592992782593, \"min\": 12177.592992782593}}, \"EndTime\": 1587303661.523349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303649.345692}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:01 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.3379046813 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:01 INFO 139636288943936] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=239, train loss <loss>=0.830089771748\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:01 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:03 INFO 139636288943936] Epoch[240] Batch[0] avg_epoch_loss=0.754990\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=0.754989922047\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:09 INFO 139636288943936] Epoch[240] Batch[5] avg_epoch_loss=0.957067\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=0.957066655159\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:09 INFO 139636288943936] Epoch[240] Batch [5]#011Speed: 55.43 samples/sec#011loss=0.957067\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:13 INFO 139636288943936] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12140.918970108032, \"sum\": 12140.918970108032, \"min\": 12140.918970108032}}, \"EndTime\": 1587303673.665232, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303661.523422}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:13 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.2420468279 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:13 INFO 139636288943936] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=240, train loss <loss>=0.851296764612\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:13 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:15 INFO 139636288943936] Epoch[241] Batch[0] avg_epoch_loss=0.792557\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=0.792557179928\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:21 INFO 139636288943936] Epoch[241] Batch[5] avg_epoch_loss=0.778655\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=0.778655012449\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:21 INFO 139636288943936] Epoch[241] Batch [5]#011Speed: 55.74 samples/sec#011loss=0.778655\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:25 INFO 139636288943936] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12156.927824020386, \"sum\": 12156.927824020386, \"min\": 12156.927824020386}}, \"EndTime\": 1587303685.823561, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303673.665496}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:25 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.4927970841 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:25 INFO 139636288943936] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=241, train loss <loss>=0.857706326246\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:25 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:27 INFO 139636288943936] Epoch[242] Batch[0] avg_epoch_loss=0.886571\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=0.886570572853\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:33 INFO 139636288943936] Epoch[242] Batch[5] avg_epoch_loss=0.740754\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=0.740753730138\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:33 INFO 139636288943936] Epoch[242] Batch [5]#011Speed: 55.23 samples/sec#011loss=0.740754\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:39 INFO 139636288943936] Epoch[242] Batch[10] avg_epoch_loss=0.816543\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=242, batch=10 train loss <loss>=0.907490897179\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:39 INFO 139636288943936] Epoch[242] Batch [10]#011Speed: 56.32 samples/sec#011loss=0.907491\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:39 INFO 139636288943936] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13366.796016693115, \"sum\": 13366.796016693115, \"min\": 13366.796016693115}}, \"EndTime\": 1587303699.190898, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303685.823636}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:39 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.2534246215 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:39 INFO 139636288943936] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=242, train loss <loss>=0.81654335152\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:39 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:40 INFO 139636288943936] Epoch[243] Batch[0] avg_epoch_loss=1.368123\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=1.36812341213\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:46 INFO 139636288943936] Epoch[243] Batch[5] avg_epoch_loss=1.010078\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=1.01007798314\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:46 INFO 139636288943936] Epoch[243] Batch [5]#011Speed: 55.52 samples/sec#011loss=1.010078\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:52 INFO 139636288943936] Epoch[243] Batch[10] avg_epoch_loss=0.869022\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=0.699755609035\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:52 INFO 139636288943936] Epoch[243] Batch [10]#011Speed: 55.13 samples/sec#011loss=0.699756\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:52 INFO 139636288943936] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13362.622022628784, \"sum\": 13362.622022628784, \"min\": 13362.622022628784}}, \"EndTime\": 1587303712.55413, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303699.190988}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:52 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=47.9691755341 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:52 INFO 139636288943936] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=243, train loss <loss>=0.869022358548\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:52 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:54 INFO 139636288943936] Epoch[244] Batch[0] avg_epoch_loss=0.849690\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:41:54 INFO 139636288943936] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=0.849690496922\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:00 INFO 139636288943936] Epoch[244] Batch[5] avg_epoch_loss=0.920950\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:00 INFO 139636288943936] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=0.92094997565\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:00 INFO 139636288943936] Epoch[244] Batch [5]#011Speed: 55.64 samples/sec#011loss=0.920950\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:05 INFO 139636288943936] Epoch[244] Batch[10] avg_epoch_loss=0.923219\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:05 INFO 139636288943936] #quality_metric: host=algo-1, epoch=244, batch=10 train loss <loss>=0.925942659378\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:05 INFO 139636288943936] Epoch[244] Batch [10]#011Speed: 55.07 samples/sec#011loss=0.925943\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:05 INFO 139636288943936] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13381.761074066162, \"sum\": 13381.761074066162, \"min\": 13381.761074066162}}, \"EndTime\": 1587303725.936478, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303712.554215}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:05 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.4984248765 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:05 INFO 139636288943936] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:05 INFO 139636288943936] #quality_metric: host=algo-1, epoch=244, train loss <loss>=0.923219377344\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:05 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:07 INFO 139636288943936] Epoch[245] Batch[0] avg_epoch_loss=0.988714\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:07 INFO 139636288943936] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=0.988713622093\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:13 INFO 139636288943936] Epoch[245] Batch[5] avg_epoch_loss=0.799665\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=0.799665043751\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:13 INFO 139636288943936] Epoch[245] Batch [5]#011Speed: 55.36 samples/sec#011loss=0.799665\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:19 INFO 139636288943936] Epoch[245] Batch[10] avg_epoch_loss=0.913968\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=245, batch=10 train loss <loss>=1.05113193989\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:19 INFO 139636288943936] Epoch[245] Batch [10]#011Speed: 53.50 samples/sec#011loss=1.051132\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:19 INFO 139636288943936] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13642.660856246948, \"sum\": 13642.660856246948, \"min\": 13642.660856246948}}, \"EndTime\": 1587303739.579629, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303725.936557}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:19 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.010746643 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:19 INFO 139636288943936] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:19 INFO 139636288943936] #quality_metric: host=algo-1, epoch=245, train loss <loss>=0.913968178359\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:19 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:21 INFO 139636288943936] Epoch[246] Batch[0] avg_epoch_loss=1.060826\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=1.06082606316\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:27 INFO 139636288943936] Epoch[246] Batch[5] avg_epoch_loss=1.418489\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=1.41848947604\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:27 INFO 139636288943936] Epoch[246] Batch [5]#011Speed: 55.84 samples/sec#011loss=1.418489\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:32 INFO 139636288943936] Epoch[246] Batch[10] avg_epoch_loss=1.383611\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=1.34175596237\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:32 INFO 139636288943936] Epoch[246] Batch [10]#011Speed: 55.03 samples/sec#011loss=1.341756\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:32 INFO 139636288943936] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13414.584875106812, \"sum\": 13414.584875106812, \"min\": 13414.584875106812}}, \"EndTime\": 1587303752.994776, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303739.579711}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:32 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=47.9324484091 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:32 INFO 139636288943936] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=246, train loss <loss>=1.38361060619\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:32 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:34 INFO 139636288943936] Epoch[247] Batch[0] avg_epoch_loss=1.563710\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:34 INFO 139636288943936] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=1.56371021271\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:40 INFO 139636288943936] Epoch[247] Batch[5] avg_epoch_loss=1.322150\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=1.32215005159\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:40 INFO 139636288943936] Epoch[247] Batch [5]#011Speed: 56.09 samples/sec#011loss=1.322150\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:45 INFO 139636288943936] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12078.782081604004, \"sum\": 12078.782081604004, \"min\": 12078.782081604004}}, \"EndTime\": 1587303765.074169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303752.994861}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:45 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.7562036787 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:45 INFO 139636288943936] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=247, train loss <loss>=1.21082956195\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:45 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:46 INFO 139636288943936] Epoch[248] Batch[0] avg_epoch_loss=0.857153\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=0.857153117657\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:52 INFO 139636288943936] Epoch[248] Batch[5] avg_epoch_loss=0.915364\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=0.915364354849\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:52 INFO 139636288943936] Epoch[248] Batch [5]#011Speed: 55.38 samples/sec#011loss=0.915364\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:58 INFO 139636288943936] Epoch[248] Batch[10] avg_epoch_loss=0.847024\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=0.765015530586\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:58 INFO 139636288943936] Epoch[248] Batch [10]#011Speed: 54.85 samples/sec#011loss=0.765016\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:59 INFO 139636288943936] processed a total of 706 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14551.696062088013, \"sum\": 14551.696062088013, \"min\": 14551.696062088013}}, \"EndTime\": 1587303779.626445, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303765.074242}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:59 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.5163450407 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:59 INFO 139636288943936] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=248, train loss <loss>=0.837071061134\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:42:59 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:01 INFO 139636288943936] Epoch[249] Batch[0] avg_epoch_loss=1.599719\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=1.59971868992\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:07 INFO 139636288943936] Epoch[249] Batch[5] avg_epoch_loss=1.130730\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:07 INFO 139636288943936] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=1.13073001305\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:07 INFO 139636288943936] Epoch[249] Batch [5]#011Speed: 55.12 samples/sec#011loss=1.130730\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:13 INFO 139636288943936] Epoch[249] Batch[10] avg_epoch_loss=0.989391\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=0.819784462452\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:13 INFO 139636288943936] Epoch[249] Batch [10]#011Speed: 55.50 samples/sec#011loss=0.819784\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:13 INFO 139636288943936] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13454.973936080933, \"sum\": 13454.973936080933, \"min\": 13454.973936080933}}, \"EndTime\": 1587303793.082004, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303779.626513}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:13 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.241090367 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:13 INFO 139636288943936] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=249, train loss <loss>=0.989391126416\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:13 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:14 INFO 139636288943936] Epoch[250] Batch[0] avg_epoch_loss=0.923536\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:14 INFO 139636288943936] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=0.923535943031\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:20 INFO 139636288943936] Epoch[250] Batch[5] avg_epoch_loss=0.768073\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:20 INFO 139636288943936] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=0.76807320118\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:20 INFO 139636288943936] Epoch[250] Batch [5]#011Speed: 55.51 samples/sec#011loss=0.768073\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:26 INFO 139636288943936] Epoch[250] Batch[10] avg_epoch_loss=0.868699\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=250, batch=10 train loss <loss>=0.989450418949\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:26 INFO 139636288943936] Epoch[250] Batch [10]#011Speed: 55.55 samples/sec#011loss=0.989450\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:26 INFO 139636288943936] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13341.876029968262, \"sum\": 13341.876029968262, \"min\": 13341.876029968262}}, \"EndTime\": 1587303806.424727, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303793.082091}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:26 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.9431903989 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:26 INFO 139636288943936] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:26 INFO 139636288943936] #quality_metric: host=algo-1, epoch=250, train loss <loss>=0.868699209257\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:26 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:28 INFO 139636288943936] Epoch[251] Batch[0] avg_epoch_loss=0.744110\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:28 INFO 139636288943936] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=0.744110107422\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:34 INFO 139636288943936] Epoch[251] Batch[5] avg_epoch_loss=0.723365\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:34 INFO 139636288943936] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=0.723365485668\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:34 INFO 139636288943936] Epoch[251] Batch [5]#011Speed: 55.49 samples/sec#011loss=0.723365\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:38 INFO 139636288943936] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12255.497932434082, \"sum\": 12255.497932434082, \"min\": 12255.497932434082}}, \"EndTime\": 1587303818.680875, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303806.424813}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:38 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.8547361255 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:38 INFO 139636288943936] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:38 INFO 139636288943936] #quality_metric: host=algo-1, epoch=251, train loss <loss>=0.739157736301\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:38 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:38 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_f36c6fe1-ca1d-4c7b-a9ef-fe110bc0f6c9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 104.20513153076172, \"sum\": 104.20513153076172, \"min\": 104.20513153076172}}, \"EndTime\": 1587303818.786032, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303818.680949}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:40 INFO 139636288943936] Epoch[252] Batch[0] avg_epoch_loss=1.043642\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:40 INFO 139636288943936] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=1.04364156723\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:46 INFO 139636288943936] Epoch[252] Batch[5] avg_epoch_loss=0.904889\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=0.904888639847\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:46 INFO 139636288943936] Epoch[252] Batch [5]#011Speed: 55.82 samples/sec#011loss=0.904889\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:50 INFO 139636288943936] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12136.111974716187, \"sum\": 12136.111974716187, \"min\": 12136.111974716187}}, \"EndTime\": 1587303830.922298, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303818.786114}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:50 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.4162712762 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:50 INFO 139636288943936] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=252, train loss <loss>=0.860727143288\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:50 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:52 INFO 139636288943936] Epoch[253] Batch[0] avg_epoch_loss=1.260718\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=1.26071763039\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:58 INFO 139636288943936] Epoch[253] Batch[5] avg_epoch_loss=0.876628\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:58 INFO 139636288943936] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=0.876628388961\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:43:58 INFO 139636288943936] Epoch[253] Batch [5]#011Speed: 55.38 samples/sec#011loss=0.876628\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:04 INFO 139636288943936] Epoch[253] Batch[10] avg_epoch_loss=0.819038\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=0.749929469824\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:04 INFO 139636288943936] Epoch[253] Batch [10]#011Speed: 52.93 samples/sec#011loss=0.749929\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:04 INFO 139636288943936] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13672.343015670776, \"sum\": 13672.343015670776, \"min\": 13672.343015670776}}, \"EndTime\": 1587303844.595205, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303830.922381}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:04 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=47.8333890793 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:04 INFO 139636288943936] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=253, train loss <loss>=0.819037971171\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:04 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:06 INFO 139636288943936] Epoch[254] Batch[0] avg_epoch_loss=0.956879\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=0.9568785429\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:12 INFO 139636288943936] Epoch[254] Batch[5] avg_epoch_loss=1.495215\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=1.49521497885\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:12 INFO 139636288943936] Epoch[254] Batch [5]#011Speed: 55.68 samples/sec#011loss=1.495215\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:16 INFO 139636288943936] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12201.975107192993, \"sum\": 12201.975107192993, \"min\": 12201.975107192993}}, \"EndTime\": 1587303856.797697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303844.595284}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:16 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.3845975709 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:16 INFO 139636288943936] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:16 INFO 139636288943936] #quality_metric: host=algo-1, epoch=254, train loss <loss>=1.36124534607\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:16 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:18 INFO 139636288943936] Epoch[255] Batch[0] avg_epoch_loss=1.265822\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=1.26582241058\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:24 INFO 139636288943936] Epoch[255] Batch[5] avg_epoch_loss=1.256688\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=1.25668817759\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:24 INFO 139636288943936] Epoch[255] Batch [5]#011Speed: 55.46 samples/sec#011loss=1.256688\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:30 INFO 139636288943936] Epoch[255] Batch[10] avg_epoch_loss=1.181376\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=1.0910012126\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:30 INFO 139636288943936] Epoch[255] Batch [10]#011Speed: 56.10 samples/sec#011loss=1.091001\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:30 INFO 139636288943936] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13325.05488395691, \"sum\": 13325.05488395691, \"min\": 13325.05488395691}}, \"EndTime\": 1587303870.123498, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303856.797784}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:30 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.5547196669 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:30 INFO 139636288943936] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=255, train loss <loss>=1.18137592077\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:30 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:32 INFO 139636288943936] Epoch[256] Batch[0] avg_epoch_loss=1.500516\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=1.50051593781\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:37 INFO 139636288943936] Epoch[256] Batch[5] avg_epoch_loss=1.357842\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:37 INFO 139636288943936] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=1.35784183939\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:37 INFO 139636288943936] Epoch[256] Batch [5]#011Speed: 56.32 samples/sec#011loss=1.357842\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:43 INFO 139636288943936] Epoch[256] Batch[10] avg_epoch_loss=1.468147\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=1.6005130887\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:43 INFO 139636288943936] Epoch[256] Batch [10]#011Speed: 56.04 samples/sec#011loss=1.600513\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:43 INFO 139636288943936] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13350.980043411255, \"sum\": 13350.980043411255, \"min\": 13350.980043411255}}, \"EndTime\": 1587303883.474978, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303870.123577}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:43 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.5353631961 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:43 INFO 139636288943936] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=256, train loss <loss>=1.46814695272\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:43 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:45 INFO 139636288943936] Epoch[257] Batch[0] avg_epoch_loss=1.567723\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=1.5677229166\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:51 INFO 139636288943936] Epoch[257] Batch[5] avg_epoch_loss=1.405131\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=1.40513110161\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:51 INFO 139636288943936] Epoch[257] Batch [5]#011Speed: 55.73 samples/sec#011loss=1.405131\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:55 INFO 139636288943936] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12080.768823623657, \"sum\": 12080.768823623657, \"min\": 12080.768823623657}}, \"EndTime\": 1587303895.556317, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303883.475047}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:55 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.0723994326 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:55 INFO 139636288943936] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:55 INFO 139636288943936] #quality_metric: host=algo-1, epoch=257, train loss <loss>=1.33141987324\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:55 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:57 INFO 139636288943936] Epoch[258] Batch[0] avg_epoch_loss=1.200904\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:44:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=1.20090436935\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:03 INFO 139636288943936] Epoch[258] Batch[5] avg_epoch_loss=1.075754\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=1.07575364908\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:03 INFO 139636288943936] Epoch[258] Batch [5]#011Speed: 55.33 samples/sec#011loss=1.075754\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:08 INFO 139636288943936] Epoch[258] Batch[10] avg_epoch_loss=1.002076\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=0.913662195206\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:08 INFO 139636288943936] Epoch[258] Batch [10]#011Speed: 55.96 samples/sec#011loss=0.913662\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:08 INFO 139636288943936] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13349.152088165283, \"sum\": 13349.152088165283, \"min\": 13349.152088165283}}, \"EndTime\": 1587303908.906154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303895.556396}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:08 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.5645433425 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:08 INFO 139636288943936] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=258, train loss <loss>=1.0020757155\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:08 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:10 INFO 139636288943936] Epoch[259] Batch[0] avg_epoch_loss=0.767205\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=0.767205238342\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:16 INFO 139636288943936] Epoch[259] Batch[5] avg_epoch_loss=0.912463\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:16 INFO 139636288943936] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=0.912462621927\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:16 INFO 139636288943936] Epoch[259] Batch [5]#011Speed: 56.09 samples/sec#011loss=0.912463\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:22 INFO 139636288943936] Epoch[259] Batch[10] avg_epoch_loss=0.915931\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:22 INFO 139636288943936] #quality_metric: host=algo-1, epoch=259, batch=10 train loss <loss>=0.920093977451\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:22 INFO 139636288943936] Epoch[259] Batch [10]#011Speed: 56.58 samples/sec#011loss=0.920094\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:22 INFO 139636288943936] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13160.227060317993, \"sum\": 13160.227060317993, \"min\": 13160.227060317993}}, \"EndTime\": 1587303922.066983, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303908.906237}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:22 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.1627475242 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:22 INFO 139636288943936] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:22 INFO 139636288943936] #quality_metric: host=algo-1, epoch=259, train loss <loss>=0.915931419893\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:22 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:23 INFO 139636288943936] Epoch[260] Batch[0] avg_epoch_loss=1.272865\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=1.27286541462\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:29 INFO 139636288943936] Epoch[260] Batch[5] avg_epoch_loss=0.967984\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:29 INFO 139636288943936] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=0.967983504136\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:29 INFO 139636288943936] Epoch[260] Batch [5]#011Speed: 55.80 samples/sec#011loss=0.967984\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:34 INFO 139636288943936] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12183.495044708252, \"sum\": 12183.495044708252, \"min\": 12183.495044708252}}, \"EndTime\": 1587303934.251196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303922.067071}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:34 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=52.3654238839 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:34 INFO 139636288943936] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:34 INFO 139636288943936] #quality_metric: host=algo-1, epoch=260, train loss <loss>=0.91101437211\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:34 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:36 INFO 139636288943936] Epoch[261] Batch[0] avg_epoch_loss=0.699962\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:36 INFO 139636288943936] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=0.699961602688\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:41 INFO 139636288943936] Epoch[261] Batch[5] avg_epoch_loss=0.776417\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=0.776417046785\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:41 INFO 139636288943936] Epoch[261] Batch [5]#011Speed: 54.70 samples/sec#011loss=0.776417\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:47 INFO 139636288943936] Epoch[261] Batch[10] avg_epoch_loss=0.813309\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=0.857578456402\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:47 INFO 139636288943936] Epoch[261] Batch [10]#011Speed: 55.26 samples/sec#011loss=0.857578\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:47 INFO 139636288943936] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13492.450952529907, \"sum\": 13492.450952529907, \"min\": 13492.450952529907}}, \"EndTime\": 1587303947.744309, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303934.251277}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:47 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.7675881431 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:47 INFO 139636288943936] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:47 INFO 139636288943936] #quality_metric: host=algo-1, epoch=261, train loss <loss>=0.813308596611\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:47 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:49 INFO 139636288943936] Epoch[262] Batch[0] avg_epoch_loss=0.984068\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:49 INFO 139636288943936] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=0.984068155289\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:55 INFO 139636288943936] Epoch[262] Batch[5] avg_epoch_loss=0.871210\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:55 INFO 139636288943936] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=0.871210157871\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:45:55 INFO 139636288943936] Epoch[262] Batch [5]#011Speed: 55.36 samples/sec#011loss=0.871210\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:01 INFO 139636288943936] Epoch[262] Batch[10] avg_epoch_loss=0.793873\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=262, batch=10 train loss <loss>=0.7010679245\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:01 INFO 139636288943936] Epoch[262] Batch [10]#011Speed: 55.92 samples/sec#011loss=0.701068\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:01 INFO 139636288943936] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13437.290906906128, \"sum\": 13437.290906906128, \"min\": 13437.290906906128}}, \"EndTime\": 1587303961.18213, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303947.744389}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:01 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.2654169713 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:01 INFO 139636288943936] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:01 INFO 139636288943936] #quality_metric: host=algo-1, epoch=262, train loss <loss>=0.793872779066\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:01 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:03 INFO 139636288943936] Epoch[263] Batch[0] avg_epoch_loss=0.823146\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:03 INFO 139636288943936] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=0.823146104813\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:08 INFO 139636288943936] Epoch[263] Batch[5] avg_epoch_loss=0.811677\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:08 INFO 139636288943936] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=0.811677277088\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:08 INFO 139636288943936] Epoch[263] Batch [5]#011Speed: 55.33 samples/sec#011loss=0.811677\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:13 INFO 139636288943936] processed a total of 588 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12373.487949371338, \"sum\": 12373.487949371338, \"min\": 12373.487949371338}}, \"EndTime\": 1587303973.556309, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303961.18222}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:13 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=47.520462541 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:13 INFO 139636288943936] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:13 INFO 139636288943936] #quality_metric: host=algo-1, epoch=263, train loss <loss>=0.810275453329\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:13 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:15 INFO 139636288943936] Epoch[264] Batch[0] avg_epoch_loss=1.555647\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=1.5556473732\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:21 INFO 139636288943936] Epoch[264] Batch[5] avg_epoch_loss=0.965385\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:21 INFO 139636288943936] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=0.965384701888\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:21 INFO 139636288943936] Epoch[264] Batch [5]#011Speed: 55.02 samples/sec#011loss=0.965385\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:25 INFO 139636288943936] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12254.42099571228, \"sum\": 12254.42099571228, \"min\": 12254.42099571228}}, \"EndTime\": 1587303985.811402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303973.556395}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:25 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.0829379885 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:25 INFO 139636288943936] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=264, train loss <loss>=0.869595485926\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:25 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:27 INFO 139636288943936] Epoch[265] Batch[0] avg_epoch_loss=0.735545\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:27 INFO 139636288943936] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=0.73554456234\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:33 INFO 139636288943936] Epoch[265] Batch[5] avg_epoch_loss=0.752374\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=0.752373963594\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:33 INFO 139636288943936] Epoch[265] Batch [5]#011Speed: 55.12 samples/sec#011loss=0.752374\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:39 INFO 139636288943936] Epoch[265] Batch[10] avg_epoch_loss=0.795240\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=265, batch=10 train loss <loss>=0.846679985523\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:39 INFO 139636288943936] Epoch[265] Batch [10]#011Speed: 55.86 samples/sec#011loss=0.846680\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:39 INFO 139636288943936] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13407.665014266968, \"sum\": 13407.665014266968, \"min\": 13407.665014266968}}, \"EndTime\": 1587303999.21967, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303985.811483}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:39 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.3742818679 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:39 INFO 139636288943936] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=265, train loss <loss>=0.795240337198\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:39 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:41 INFO 139636288943936] Epoch[266] Batch[0] avg_epoch_loss=1.076368\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:41 INFO 139636288943936] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=1.07636761665\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:46 INFO 139636288943936] Epoch[266] Batch[5] avg_epoch_loss=0.999962\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=0.999962309996\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:46 INFO 139636288943936] Epoch[266] Batch [5]#011Speed: 55.77 samples/sec#011loss=0.999962\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:51 INFO 139636288943936] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12181.787967681885, \"sum\": 12181.787967681885, \"min\": 12181.787967681885}}, \"EndTime\": 1587304011.402026, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587303999.219756}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:51 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.2384271507 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:51 INFO 139636288943936] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:51 INFO 139636288943936] #quality_metric: host=algo-1, epoch=266, train loss <loss>=0.880346751213\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:51 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:53 INFO 139636288943936] Epoch[267] Batch[0] avg_epoch_loss=0.728291\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:53 INFO 139636288943936] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=0.728290975094\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:59 INFO 139636288943936] Epoch[267] Batch[5] avg_epoch_loss=0.764873\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=0.764872779449\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:46:59 INFO 139636288943936] Epoch[267] Batch [5]#011Speed: 55.41 samples/sec#011loss=0.764873\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:04 INFO 139636288943936] Epoch[267] Batch[10] avg_epoch_loss=0.784041\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=267, batch=10 train loss <loss>=0.807043683529\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:04 INFO 139636288943936] Epoch[267] Batch [10]#011Speed: 55.14 samples/sec#011loss=0.807044\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:04 INFO 139636288943936] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13454.24509048462, \"sum\": 13454.24509048462, \"min\": 13454.24509048462}}, \"EndTime\": 1587304024.856907, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304011.40211}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:04 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.9804126467 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:04 INFO 139636288943936] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=267, train loss <loss>=0.784041372212\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:04 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:06 INFO 139636288943936] Epoch[268] Batch[0] avg_epoch_loss=0.784644\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:06 INFO 139636288943936] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=0.78464370966\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:12 INFO 139636288943936] Epoch[268] Batch[5] avg_epoch_loss=0.790342\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=0.790342122316\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:12 INFO 139636288943936] Epoch[268] Batch [5]#011Speed: 55.60 samples/sec#011loss=0.790342\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:18 INFO 139636288943936] Epoch[268] Batch[10] avg_epoch_loss=0.778081\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=268, batch=10 train loss <loss>=0.763366830349\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:18 INFO 139636288943936] Epoch[268] Batch [10]#011Speed: 55.89 samples/sec#011loss=0.763367\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:18 INFO 139636288943936] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13373.625993728638, \"sum\": 13373.625993728638, \"min\": 13373.625993728638}}, \"EndTime\": 1587304038.230987, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304024.856983}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:18 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.1261383268 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:18 INFO 139636288943936] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=268, train loss <loss>=0.778080625968\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:18 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:20 INFO 139636288943936] Epoch[269] Batch[0] avg_epoch_loss=0.683570\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:20 INFO 139636288943936] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=0.683570086956\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:25 INFO 139636288943936] Epoch[269] Batch[5] avg_epoch_loss=0.803492\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:25 INFO 139636288943936] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=0.80349162221\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:25 INFO 139636288943936] Epoch[269] Batch [5]#011Speed: 55.20 samples/sec#011loss=0.803492\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:31 INFO 139636288943936] Epoch[269] Batch[10] avg_epoch_loss=0.782992\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=269, batch=10 train loss <loss>=0.758391654491\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:31 INFO 139636288943936] Epoch[269] Batch [10]#011Speed: 55.87 samples/sec#011loss=0.758392\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:31 INFO 139636288943936] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13376.943111419678, \"sum\": 13376.943111419678, \"min\": 13376.943111419678}}, \"EndTime\": 1587304051.608465, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304038.231061}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:31 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.8333033314 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:31 INFO 139636288943936] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:31 INFO 139636288943936] #quality_metric: host=algo-1, epoch=269, train loss <loss>=0.782991636883\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:31 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:33 INFO 139636288943936] Epoch[270] Batch[0] avg_epoch_loss=0.673966\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:33 INFO 139636288943936] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=0.673965573311\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:39 INFO 139636288943936] Epoch[270] Batch[5] avg_epoch_loss=0.725407\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:39 INFO 139636288943936] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=0.725406974554\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:39 INFO 139636288943936] Epoch[270] Batch [5]#011Speed: 55.71 samples/sec#011loss=0.725407\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:45 INFO 139636288943936] Epoch[270] Batch[10] avg_epoch_loss=0.798802\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=270, batch=10 train loss <loss>=0.88687595129\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:45 INFO 139636288943936] Epoch[270] Batch [10]#011Speed: 55.89 samples/sec#011loss=0.886876\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:45 INFO 139636288943936] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13396.849870681763, \"sum\": 13396.849870681763, \"min\": 13396.849870681763}}, \"EndTime\": 1587304065.005874, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304051.608543}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:45 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.4591816409 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:45 INFO 139636288943936] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:45 INFO 139636288943936] #quality_metric: host=algo-1, epoch=270, train loss <loss>=0.79880196398\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:45 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:46 INFO 139636288943936] Epoch[271] Batch[0] avg_epoch_loss=0.982618\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:46 INFO 139636288943936] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=0.982617914677\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:52 INFO 139636288943936] Epoch[271] Batch[5] avg_epoch_loss=1.052825\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:52 INFO 139636288943936] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=1.0528246363\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:52 INFO 139636288943936] Epoch[271] Batch [5]#011Speed: 55.70 samples/sec#011loss=1.052825\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:57 INFO 139636288943936] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12268.877983093262, \"sum\": 12268.877983093262, \"min\": 12268.877983093262}}, \"EndTime\": 1587304077.275229, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304065.005953}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:57 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=51.7565104378 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:57 INFO 139636288943936] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:57 INFO 139636288943936] #quality_metric: host=algo-1, epoch=271, train loss <loss>=1.0006513834\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:57 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:59 INFO 139636288943936] Epoch[272] Batch[0] avg_epoch_loss=0.862754\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:47:59 INFO 139636288943936] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=0.862754464149\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:04 INFO 139636288943936] Epoch[272] Batch[5] avg_epoch_loss=0.806723\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=0.806722988685\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:04 INFO 139636288943936] Epoch[272] Batch [5]#011Speed: 55.38 samples/sec#011loss=0.806723\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:10 INFO 139636288943936] Epoch[272] Batch[10] avg_epoch_loss=0.703840\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=272, batch=10 train loss <loss>=0.580379873514\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:10 INFO 139636288943936] Epoch[272] Batch [10]#011Speed: 55.85 samples/sec#011loss=0.580380\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:10 INFO 139636288943936] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13329.48112487793, \"sum\": 13329.48112487793, \"min\": 13329.48112487793}}, \"EndTime\": 1587304090.605308, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304077.275296}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:10 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.2137170067 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:10 INFO 139636288943936] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:10 INFO 139636288943936] #quality_metric: host=algo-1, epoch=272, train loss <loss>=0.703839754516\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:10 INFO 139636288943936] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:10 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/state_a70aac9a-b6ce-4711-a158-3f1f22818e0d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 137.2201442718506, \"sum\": 137.2201442718506, \"min\": 137.2201442718506}}, \"EndTime\": 1587304090.743211, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304090.605404}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:12 INFO 139636288943936] Epoch[273] Batch[0] avg_epoch_loss=0.590580\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:12 INFO 139636288943936] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=0.590580046177\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:18 INFO 139636288943936] Epoch[273] Batch[5] avg_epoch_loss=1.687604\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=1.68760427833\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:18 INFO 139636288943936] Epoch[273] Batch [5]#011Speed: 54.72 samples/sec#011loss=1.687604\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:23 INFO 139636288943936] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12269.679069519043, \"sum\": 12269.679069519043, \"min\": 12269.679069519043}}, \"EndTime\": 1587304103.013043, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304090.743296}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:23 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.3080851766 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:23 INFO 139636288943936] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:23 INFO 139636288943936] #quality_metric: host=algo-1, epoch=273, train loss <loss>=1.69469289184\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:23 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:24 INFO 139636288943936] Epoch[274] Batch[0] avg_epoch_loss=1.844882\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=1.84488248825\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:30 INFO 139636288943936] Epoch[274] Batch[5] avg_epoch_loss=1.613389\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=1.61338885625\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:30 INFO 139636288943936] Epoch[274] Batch [5]#011Speed: 55.85 samples/sec#011loss=1.613389\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:35 INFO 139636288943936] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12338.793992996216, \"sum\": 12338.793992996216, \"min\": 12338.793992996216}}, \"EndTime\": 1587304115.352535, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304103.013118}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:35 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.8146762658 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:35 INFO 139636288943936] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:35 INFO 139636288943936] #quality_metric: host=algo-1, epoch=274, train loss <loss>=1.61213129759\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:35 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:37 INFO 139636288943936] Epoch[275] Batch[0] avg_epoch_loss=1.465233\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:37 INFO 139636288943936] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=1.46523272991\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:43 INFO 139636288943936] Epoch[275] Batch[5] avg_epoch_loss=1.314948\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:43 INFO 139636288943936] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=1.31494764487\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:43 INFO 139636288943936] Epoch[275] Batch [5]#011Speed: 55.74 samples/sec#011loss=1.314948\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:48 INFO 139636288943936] Epoch[275] Batch[10] avg_epoch_loss=1.169138\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:48 INFO 139636288943936] #quality_metric: host=algo-1, epoch=275, batch=10 train loss <loss>=0.994166755676\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:48 INFO 139636288943936] Epoch[275] Batch [10]#011Speed: 55.83 samples/sec#011loss=0.994167\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:48 INFO 139636288943936] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13417.176008224487, \"sum\": 13417.176008224487, \"min\": 13417.176008224487}}, \"EndTime\": 1587304128.770346, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304115.352617}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:48 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.2335902431 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:48 INFO 139636288943936] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:48 INFO 139636288943936] #quality_metric: host=algo-1, epoch=275, train loss <loss>=1.16913814978\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:48 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:50 INFO 139636288943936] Epoch[276] Batch[0] avg_epoch_loss=1.113197\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:50 INFO 139636288943936] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=1.11319744587\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:56 INFO 139636288943936] Epoch[276] Batch[5] avg_epoch_loss=0.961138\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:56 INFO 139636288943936] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=0.961138049761\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:48:56 INFO 139636288943936] Epoch[276] Batch [5]#011Speed: 55.18 samples/sec#011loss=0.961138\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:02 INFO 139636288943936] Epoch[276] Batch[10] avg_epoch_loss=0.953349\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=276, batch=10 train loss <loss>=0.944001245499\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:02 INFO 139636288943936] Epoch[276] Batch [10]#011Speed: 55.91 samples/sec#011loss=0.944001\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:02 INFO 139636288943936] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13317.609071731567, \"sum\": 13317.609071731567, \"min\": 13317.609071731567}}, \"EndTime\": 1587304142.088637, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304128.770449}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:02 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=49.0322109134 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:02 INFO 139636288943936] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:02 INFO 139636288943936] #quality_metric: host=algo-1, epoch=276, train loss <loss>=0.953348593278\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:02 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:04 INFO 139636288943936] Epoch[277] Batch[0] avg_epoch_loss=1.683781\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:04 INFO 139636288943936] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=1.68378078938\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:09 INFO 139636288943936] Epoch[277] Batch[5] avg_epoch_loss=1.213679\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:09 INFO 139636288943936] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=1.21367936333\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:09 INFO 139636288943936] Epoch[277] Batch [5]#011Speed: 55.52 samples/sec#011loss=1.213679\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:15 INFO 139636288943936] Epoch[277] Batch[10] avg_epoch_loss=1.199164\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:15 INFO 139636288943936] #quality_metric: host=algo-1, epoch=277, batch=10 train loss <loss>=1.18174498081\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:15 INFO 139636288943936] Epoch[277] Batch [10]#011Speed: 55.83 samples/sec#011loss=1.181745\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:16 INFO 139636288943936] processed a total of 708 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14613.628149032593, \"sum\": 14613.628149032593, \"min\": 14613.628149032593}}, \"EndTime\": 1587304156.702825, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304142.088766}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:16 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=48.447573595 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:16 INFO 139636288943936] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:16 INFO 139636288943936] #quality_metric: host=algo-1, epoch=277, train loss <loss>=1.24985416234\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:16 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:18 INFO 139636288943936] Epoch[278] Batch[0] avg_epoch_loss=1.143897\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:18 INFO 139636288943936] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=1.14389705658\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:24 INFO 139636288943936] Epoch[278] Batch[5] avg_epoch_loss=1.204649\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:24 INFO 139636288943936] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=1.20464920998\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:24 INFO 139636288943936] Epoch[278] Batch [5]#011Speed: 55.71 samples/sec#011loss=1.204649\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:28 INFO 139636288943936] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12058.557033538818, \"sum\": 12058.557033538818, \"min\": 12058.557033538818}}, \"EndTime\": 1587304168.762229, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304156.702894}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:28 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=50.5030199224 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:28 INFO 139636288943936] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:28 INFO 139636288943936] #quality_metric: host=algo-1, epoch=278, train loss <loss>=1.12380393147\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:28 INFO 139636288943936] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:30 INFO 139636288943936] Epoch[279] Batch[0] avg_epoch_loss=0.862008\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:30 INFO 139636288943936] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=0.862007975578\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:32 WARNING 139636288943936] Exit signal caught in epoch 279, batch 2. Skipping remaining batches in epoch.\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:32 INFO 139636288943936] processed a total of 192 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4206.735849380493, \"sum\": 4206.735849380493, \"min\": 4206.735849380493}}, \"EndTime\": 1587304172.969516, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304168.762316}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:32 INFO 139636288943936] #throughput_metric: host=algo-1, train throughput=45.6399237417 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:32 INFO 139636288943936] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:32 INFO 139636288943936] #quality_metric: host=algo-1, epoch=279, train loss <loss>=0.794559081395\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:32 WARNING 139636288943936] Exit signal caught in epoch 279. Skipping remaining epochs.\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:32 INFO 139636288943936] Final loss: 0.703839754516 (occurred at epoch 272)\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:32 INFO 139636288943936] #quality_metric: host=algo-1, train final_loss <loss>=0.703839754516\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:32 WARNING 139636288943936] You are using large values for `context_length` and/or `prediction_length`. The following step may take some time. If the step crashes, use an instance with more memory or reduce these two parameters.\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:32 INFO 139636288943936] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:32 WARNING 139636288943936] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:32 INFO 139636288943936] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 1108.8309288024902, \"sum\": 1108.8309288024902, \"min\": 1108.8309288024902}}, \"EndTime\": 1587304174.079728, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304172.969586}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:34 INFO 139636288943936] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 1637.3200416564941, \"sum\": 1637.3200416564941, \"min\": 1637.3200416564941}}, \"EndTime\": 1587304174.608173, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304174.079795}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:34 INFO 139636288943936] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:34 INFO 139636288943936] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 79.4219970703125, \"sum\": 79.4219970703125, \"min\": 79.4219970703125}}, \"EndTime\": 1587304174.687728, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304174.608251}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:34 INFO 139636288943936] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:49:34 WARNING 139636288943936] Exit signal caught, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 3575929.190158844, \"sum\": 3575929.190158844, \"min\": 3575929.190158844}, \"setuptime\": {\"count\": 1, \"max\": 8.785009384155273, \"sum\": 8.785009384155273, \"min\": 8.785009384155273}}, \"EndTime\": 1587304174.79416, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587304174.687784}\n",
      "\u001b[0m\n",
      "\n",
      "2020-04-19 13:49:49 Stopping - Stopping the training job\n",
      "2020-04-19 13:49:49 Uploading - Uploading generated training model\n",
      "2020-04-19 13:50:06 MaxRuntimeExceeded - Training job runtime exceeded MaxRuntimeInSeconds provided\n",
      "Training seconds: 3626\n",
      "Billable seconds: 1111\n",
      "Managed Spot Training savings: 69.4%\n",
      "2020-04-19 13:05:25 Starting - Preparing the instances for training\n",
      "2020-04-19 13:05:25 Downloading - Downloading input data\n",
      "2020-04-19 13:05:25 Training - Training image download completed. Training in progress.\n",
      "2020-04-19 13:05:25 Uploading - Uploading generated training model\n",
      "2020-04-19 13:05:25 Completed - Training job completed\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.01', u'mini_batch_size': u'64', u'learning_rate': u'0.005', u'num_cells': u'64', u'prediction_length': u'156', u'epochs': u'500', u'time_freq': u'W', u'context_length': u'32', u'num_layers': u'2', u'cardinality': u'auto', u'early_stopping_patience': u'25'}\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] Final configuration: {u'dropout_rate': u'0.01', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'0.005', u'num_layers': u'2', u'epochs': u'500', u'embedding_dimension': u'10', u'num_cells': u'64', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'156', u'time_freq': u'W', u'context_length': u'32', u'_kvstore': u'auto', u'early_stopping_patience': u'25'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] Using early stopping with patience 25\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train_pp_iq.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train_pp_iq.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] Training set statistics:\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] Integer time series\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] number of time series: 1\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] number of observations: 364\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] mean target length: 364\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] min/mean/max target: 0.0/6.54395604396/116.0\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] mean abs(target): 6.54395604396\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] contains missing values: no\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] Small number of time series. Doing 640 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] Test set statistics:\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] Integer time series\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] number of time series: 1\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] number of observations: 520\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] mean target length: 520\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] min/mean/max target: 0.0/7.56538461538/116.0\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] mean abs(target): 7.56538461538\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] contains missing values: no\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] nvidia-smi took: 0.0252158641815 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 457.827091217041, \"sum\": 457.827091217041, \"min\": 457.827091217041}}, \"EndTime\": 1587300586.678094, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300586.219293}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:46 INFO 140632068241216] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 1236.5381717681885, \"sum\": 1236.5381717681885, \"min\": 1236.5381717681885}}, \"EndTime\": 1587300587.455974, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300586.678174}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:48 INFO 140632068241216] Epoch[0] Batch[0] avg_epoch_loss=5.169224\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=5.16922426224\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:50 INFO 140632068241216] Epoch[0] Batch[5] avg_epoch_loss=4.162246\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:50 INFO 140632068241216] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=4.16224590937\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:50 INFO 140632068241216] Epoch[0] Batch [5]#011Speed: 159.73 samples/sec#011loss=4.162246\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:52 INFO 140632068241216] Epoch[0] Batch[10] avg_epoch_loss=3.747341\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.24945602417\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:52 INFO 140632068241216] Epoch[0] Batch [10]#011Speed: 144.33 samples/sec#011loss=3.249456\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:52 INFO 140632068241216] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 500, \"sum\": 500.0, \"min\": 500}, \"update.time\": {\"count\": 1, \"max\": 5353.253126144409, \"sum\": 5353.253126144409, \"min\": 5353.253126144409}}, \"EndTime\": 1587300592.809453, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300587.456088}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:52 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=119.736253862 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:52 INFO 140632068241216] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.7473414161\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:52 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:52 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_d7b1e108-a2c6-4485-b074-3aad2573140f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 67.96002388000488, \"sum\": 67.96002388000488, \"min\": 67.96002388000488}}, \"EndTime\": 1587300592.878139, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300592.809589}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:53 INFO 140632068241216] Epoch[1] Batch[0] avg_epoch_loss=2.991413\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:53 INFO 140632068241216] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=2.99141287804\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:55 INFO 140632068241216] Epoch[1] Batch[5] avg_epoch_loss=2.996836\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:55 INFO 140632068241216] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=2.99683638414\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:55 INFO 140632068241216] Epoch[1] Batch [5]#011Speed: 164.32 samples/sec#011loss=2.996836\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:57 INFO 140632068241216] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4390.866994857788, \"sum\": 4390.866994857788, \"min\": 4390.866994857788}}, \"EndTime\": 1587300597.269157, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300592.87822}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:57 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.296669167 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:57 INFO 140632068241216] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=1, train loss <loss>=2.92997961044\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:57 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:57 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_ab310af2-8bd3-447d-9a69-69b1f7fb3949-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 65.9480094909668, \"sum\": 65.9480094909668, \"min\": 65.9480094909668}}, \"EndTime\": 1587300597.3361, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300597.269263}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:58 INFO 140632068241216] Epoch[2] Batch[0] avg_epoch_loss=2.830801\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:49:58 INFO 140632068241216] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=2.83080124855\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:00 INFO 140632068241216] Epoch[2] Batch[5] avg_epoch_loss=2.701239\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:00 INFO 140632068241216] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=2.70123914878\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:00 INFO 140632068241216] Epoch[2] Batch [5]#011Speed: 163.45 samples/sec#011loss=2.701239\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:01 INFO 140632068241216] processed a total of 592 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4321.5930461883545, \"sum\": 4321.5930461883545, \"min\": 4321.5930461883545}}, \"EndTime\": 1587300601.657831, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300597.336174}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:01 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=136.980944637 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:01 INFO 140632068241216] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:01 INFO 140632068241216] #quality_metric: host=algo-1, epoch=2, train loss <loss>=2.65191218853\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:01 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:01 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_116fe61b-3975-4be3-a4c4-b63bff5ff7fc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 70.83010673522949, \"sum\": 70.83010673522949, \"min\": 70.83010673522949}}, \"EndTime\": 1587300601.729452, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300601.657971}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:02 INFO 140632068241216] Epoch[3] Batch[0] avg_epoch_loss=2.594539\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:02 INFO 140632068241216] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=2.59453868866\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:04 INFO 140632068241216] Epoch[3] Batch[5] avg_epoch_loss=2.512702\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:04 INFO 140632068241216] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=2.51270234585\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:04 INFO 140632068241216] Epoch[3] Batch [5]#011Speed: 160.76 samples/sec#011loss=2.512702\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:06 INFO 140632068241216] Epoch[3] Batch[10] avg_epoch_loss=2.482108\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=2.44539475441\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:06 INFO 140632068241216] Epoch[3] Batch [10]#011Speed: 168.13 samples/sec#011loss=2.445395\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:06 INFO 140632068241216] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4771.770000457764, \"sum\": 4771.770000457764, \"min\": 4771.770000457764}}, \"EndTime\": 1587300606.501378, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300601.729532}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:06 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=139.567636312 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:06 INFO 140632068241216] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=3, train loss <loss>=2.4821079861\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:06 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:06 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_98151d5c-cd97-4bd8-8290-74266352dcb7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 66.58101081848145, \"sum\": 66.58101081848145, \"min\": 66.58101081848145}}, \"EndTime\": 1587300606.568669, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300606.501444}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:07 INFO 140632068241216] Epoch[4] Batch[0] avg_epoch_loss=2.373363\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:07 INFO 140632068241216] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=2.37336301804\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:09 INFO 140632068241216] Epoch[4] Batch[5] avg_epoch_loss=2.369431\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:09 INFO 140632068241216] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=2.36943149567\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:09 INFO 140632068241216] Epoch[4] Batch [5]#011Speed: 165.23 samples/sec#011loss=2.369431\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:10 INFO 140632068241216] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4294.469833374023, \"sum\": 4294.469833374023, \"min\": 4294.469833374023}}, \"EndTime\": 1587300610.863291, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300606.568749}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:10 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.929173921 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:10 INFO 140632068241216] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=4, train loss <loss>=2.34895207882\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:10 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:10 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_27d35075-063c-427e-93fd-7146cbd8b7bd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 69.43297386169434, \"sum\": 69.43297386169434, \"min\": 69.43297386169434}}, \"EndTime\": 1587300610.93345, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300610.863365}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:11 INFO 140632068241216] Epoch[5] Batch[0] avg_epoch_loss=2.288398\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:11 INFO 140632068241216] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=2.28839755058\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:13 INFO 140632068241216] Epoch[5] Batch[5] avg_epoch_loss=2.292831\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:13 INFO 140632068241216] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=2.29283082485\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:13 INFO 140632068241216] Epoch[5] Batch [5]#011Speed: 165.50 samples/sec#011loss=2.292831\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 140632068241216] processed a total of 591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4432.047128677368, \"sum\": 4432.047128677368, \"min\": 4432.047128677368}}, \"EndTime\": 1587300615.365646, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300610.933524}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=133.343084008 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 140632068241216] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 140632068241216] #quality_metric: host=algo-1, epoch=5, train loss <loss>=2.31426582336\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:15 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_61c0b901-d658-4739-a2dd-3b46546b5ff4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 73.90213012695312, \"sum\": 73.90213012695312, \"min\": 73.90213012695312}}, \"EndTime\": 1587300615.440137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300615.36573}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:16 INFO 140632068241216] Epoch[6] Batch[0] avg_epoch_loss=2.278157\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:16 INFO 140632068241216] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=2.27815675735\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:18 INFO 140632068241216] Epoch[6] Batch[5] avg_epoch_loss=2.232398\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:18 INFO 140632068241216] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=2.23239839077\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:18 INFO 140632068241216] Epoch[6] Batch [5]#011Speed: 168.39 samples/sec#011loss=2.232398\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:20 INFO 140632068241216] Epoch[6] Batch[10] avg_epoch_loss=2.200643\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:20 INFO 140632068241216] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=2.16253709793\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:20 INFO 140632068241216] Epoch[6] Batch [10]#011Speed: 169.36 samples/sec#011loss=2.162537\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:20 INFO 140632068241216] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4641.180992126465, \"sum\": 4641.180992126465, \"min\": 4641.180992126465}}, \"EndTime\": 1587300620.081461, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300615.440215}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:20 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.986199317 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:20 INFO 140632068241216] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:20 INFO 140632068241216] #quality_metric: host=algo-1, epoch=6, train loss <loss>=2.20064325766\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:20 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:20 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_16cf7fe4-cb41-4bce-8d46-11f4297d5989-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 73.03094863891602, \"sum\": 73.03094863891602, \"min\": 73.03094863891602}}, \"EndTime\": 1587300620.155018, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300620.081539}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:21 INFO 140632068241216] Epoch[7] Batch[0] avg_epoch_loss=1.938951\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:21 INFO 140632068241216] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=1.93895149231\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:22 INFO 140632068241216] Epoch[7] Batch[5] avg_epoch_loss=2.107724\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:22 INFO 140632068241216] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=2.10772363345\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:22 INFO 140632068241216] Epoch[7] Batch [5]#011Speed: 170.63 samples/sec#011loss=2.107724\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:24 INFO 140632068241216] Epoch[7] Batch[10] avg_epoch_loss=2.102713\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=2.09670112133\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:24 INFO 140632068241216] Epoch[7] Batch [10]#011Speed: 166.43 samples/sec#011loss=2.096701\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:24 INFO 140632068241216] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4690.484046936035, \"sum\": 4690.484046936035, \"min\": 4690.484046936035}}, \"EndTime\": 1587300624.845671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300620.1551}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:24 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=139.853524879 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:24 INFO 140632068241216] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=7, train loss <loss>=2.10271340067\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:24 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:24 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_7caec73a-924d-4664-a7e0-136a67a72bdd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 86.69590950012207, \"sum\": 86.69590950012207, \"min\": 86.69590950012207}}, \"EndTime\": 1587300624.932929, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300624.845752}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:25 INFO 140632068241216] Epoch[8] Batch[0] avg_epoch_loss=2.484911\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:25 INFO 140632068241216] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=2.4849114418\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:27 INFO 140632068241216] Epoch[8] Batch[5] avg_epoch_loss=2.272548\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:27 INFO 140632068241216] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=2.27254835765\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:27 INFO 140632068241216] Epoch[8] Batch [5]#011Speed: 167.14 samples/sec#011loss=2.272548\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:29 INFO 140632068241216] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4286.456108093262, \"sum\": 4286.456108093262, \"min\": 4286.456108093262}}, \"EndTime\": 1587300629.219526, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300624.933003}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:29 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.404538296 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:29 INFO 140632068241216] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:29 INFO 140632068241216] #quality_metric: host=algo-1, epoch=8, train loss <loss>=2.20767781734\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:29 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:30 INFO 140632068241216] Epoch[9] Batch[0] avg_epoch_loss=2.170937\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:30 INFO 140632068241216] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=2.17093658447\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:32 INFO 140632068241216] Epoch[9] Batch[5] avg_epoch_loss=2.100766\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:32 INFO 140632068241216] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=2.10076590379\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:32 INFO 140632068241216] Epoch[9] Batch [5]#011Speed: 163.89 samples/sec#011loss=2.100766\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:33 INFO 140632068241216] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4335.234880447388, \"sum\": 4335.234880447388, \"min\": 4335.234880447388}}, \"EndTime\": 1587300633.555349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300629.2196}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:33 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.392156555 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:33 INFO 140632068241216] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:33 INFO 140632068241216] #quality_metric: host=algo-1, epoch=9, train loss <loss>=2.05890122652\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:33 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:33 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_0791d11f-9b3f-41e1-8f7e-4194ef5e7e94-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 69.1070556640625, \"sum\": 69.1070556640625, \"min\": 69.1070556640625}}, \"EndTime\": 1587300633.625577, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300633.555446}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:34 INFO 140632068241216] Epoch[10] Batch[0] avg_epoch_loss=2.000682\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:34 INFO 140632068241216] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=2.00068163872\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:36 INFO 140632068241216] Epoch[10] Batch[5] avg_epoch_loss=1.940908\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=1.94090801477\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:36 INFO 140632068241216] Epoch[10] Batch [5]#011Speed: 170.22 samples/sec#011loss=1.940908\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:37 INFO 140632068241216] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4294.044971466064, \"sum\": 4294.044971466064, \"min\": 4294.044971466064}}, \"EndTime\": 1587300637.919759, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300633.62565}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:37 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=148.339927566 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:37 INFO 140632068241216] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:37 INFO 140632068241216] #quality_metric: host=algo-1, epoch=10, train loss <loss>=1.92337852716\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:37 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:38 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_526e9932-1ae7-4338-a9d8-d74fcd3d2d59-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 104.03704643249512, \"sum\": 104.03704643249512, \"min\": 104.03704643249512}}, \"EndTime\": 1587300638.024418, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300637.919865}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:38 INFO 140632068241216] Epoch[11] Batch[0] avg_epoch_loss=1.856025\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:38 INFO 140632068241216] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=1.85602545738\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:40 INFO 140632068241216] Epoch[11] Batch[5] avg_epoch_loss=1.746696\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=1.74669633309\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:40 INFO 140632068241216] Epoch[11] Batch [5]#011Speed: 166.18 samples/sec#011loss=1.746696\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:42 INFO 140632068241216] Epoch[11] Batch[10] avg_epoch_loss=1.737741\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:42 INFO 140632068241216] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=1.7269944191\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:42 INFO 140632068241216] Epoch[11] Batch [10]#011Speed: 168.93 samples/sec#011loss=1.726994\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:42 INFO 140632068241216] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4656.667947769165, \"sum\": 4656.667947769165, \"min\": 4656.667947769165}}, \"EndTime\": 1587300642.681233, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300638.024497}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:42 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.722280085 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:42 INFO 140632068241216] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:42 INFO 140632068241216] #quality_metric: host=algo-1, epoch=11, train loss <loss>=1.73774091764\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:42 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:42 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_7b0d9e78-0fcb-4c11-822f-ceca29265371-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 66.01500511169434, \"sum\": 66.01500511169434, \"min\": 66.01500511169434}}, \"EndTime\": 1587300642.747893, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300642.681312}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:43 INFO 140632068241216] Epoch[12] Batch[0] avg_epoch_loss=2.294484\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=2.29448390007\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:45 INFO 140632068241216] Epoch[12] Batch[5] avg_epoch_loss=2.215765\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:45 INFO 140632068241216] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.21576460203\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:45 INFO 140632068241216] Epoch[12] Batch [5]#011Speed: 160.55 samples/sec#011loss=2.215765\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:47 INFO 140632068241216] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4389.296054840088, \"sum\": 4389.296054840088, \"min\": 4389.296054840088}}, \"EndTime\": 1587300647.137338, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300642.747973}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:47 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.971376526 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:47 INFO 140632068241216] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:47 INFO 140632068241216] #quality_metric: host=algo-1, epoch=12, train loss <loss>=2.15345594883\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:47 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:47 INFO 140632068241216] Epoch[13] Batch[0] avg_epoch_loss=2.062767\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:47 INFO 140632068241216] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=2.06276679039\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:49 INFO 140632068241216] Epoch[13] Batch[5] avg_epoch_loss=2.017313\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:49 INFO 140632068241216] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=2.01731270552\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:49 INFO 140632068241216] Epoch[13] Batch [5]#011Speed: 166.51 samples/sec#011loss=2.017313\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:51 INFO 140632068241216] Epoch[13] Batch[10] avg_epoch_loss=1.961331\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:51 INFO 140632068241216] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=1.89415333271\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:51 INFO 140632068241216] Epoch[13] Batch [10]#011Speed: 169.82 samples/sec#011loss=1.894153\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:51 INFO 140632068241216] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4628.110885620117, \"sum\": 4628.110885620117, \"min\": 4628.110885620117}}, \"EndTime\": 1587300651.766155, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300647.137398}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:51 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.090535343 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:51 INFO 140632068241216] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:51 INFO 140632068241216] #quality_metric: host=algo-1, epoch=13, train loss <loss>=1.96133117242\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:51 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:52 INFO 140632068241216] Epoch[14] Batch[0] avg_epoch_loss=1.851087\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=1.85108685493\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:54 INFO 140632068241216] Epoch[14] Batch[5] avg_epoch_loss=1.791654\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=1.79165363312\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:54 INFO 140632068241216] Epoch[14] Batch [5]#011Speed: 167.90 samples/sec#011loss=1.791654\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:55 INFO 140632068241216] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4221.120834350586, \"sum\": 4221.120834350586, \"min\": 4221.120834350586}}, \"EndTime\": 1587300655.987894, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300651.766235}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:55 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.639233793 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:55 INFO 140632068241216] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:55 INFO 140632068241216] #quality_metric: host=algo-1, epoch=14, train loss <loss>=1.81337823868\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:55 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:56 INFO 140632068241216] Epoch[15] Batch[0] avg_epoch_loss=1.959757\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:56 INFO 140632068241216] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=1.9597568512\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:58 INFO 140632068241216] Epoch[15] Batch[5] avg_epoch_loss=1.828504\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:58 INFO 140632068241216] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=1.82850364844\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:50:58 INFO 140632068241216] Epoch[15] Batch [5]#011Speed: 171.01 samples/sec#011loss=1.828504\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:00 INFO 140632068241216] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4241.0728931427, \"sum\": 4241.0728931427, \"min\": 4241.0728931427}}, \"EndTime\": 1587300660.229504, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300655.987976}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:00 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.063164018 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:00 INFO 140632068241216] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:00 INFO 140632068241216] #quality_metric: host=algo-1, epoch=15, train loss <loss>=1.76969772577\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:00 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:01 INFO 140632068241216] Epoch[16] Batch[0] avg_epoch_loss=1.999686\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:01 INFO 140632068241216] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=1.99968624115\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:03 INFO 140632068241216] Epoch[16] Batch[5] avg_epoch_loss=1.808309\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=1.80830917756\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:03 INFO 140632068241216] Epoch[16] Batch [5]#011Speed: 170.07 samples/sec#011loss=1.808309\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 140632068241216] Epoch[16] Batch[10] avg_epoch_loss=1.754087\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 140632068241216] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=1.68902134895\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 140632068241216] Epoch[16] Batch [10]#011Speed: 168.54 samples/sec#011loss=1.689021\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 140632068241216] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4674.968004226685, \"sum\": 4674.968004226685, \"min\": 4674.968004226685}}, \"EndTime\": 1587300664.904991, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300660.229586}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.821336121 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 140632068241216] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 140632068241216] #quality_metric: host=algo-1, epoch=16, train loss <loss>=1.75408743728\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:04 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:05 INFO 140632068241216] Epoch[17] Batch[0] avg_epoch_loss=1.673312\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:05 INFO 140632068241216] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=1.67331218719\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:07 INFO 140632068241216] Epoch[17] Batch[5] avg_epoch_loss=1.617359\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:07 INFO 140632068241216] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=1.6173594594\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:07 INFO 140632068241216] Epoch[17] Batch [5]#011Speed: 169.53 samples/sec#011loss=1.617359\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:09 INFO 140632068241216] Epoch[17] Batch[10] avg_epoch_loss=1.665016\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:09 INFO 140632068241216] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=1.72220411301\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:09 INFO 140632068241216] Epoch[17] Batch [10]#011Speed: 171.18 samples/sec#011loss=1.722204\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:09 INFO 140632068241216] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4590.480089187622, \"sum\": 4590.480089187622, \"min\": 4590.480089187622}}, \"EndTime\": 1587300669.49634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300664.905055}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:09 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.079262569 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:09 INFO 140632068241216] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:09 INFO 140632068241216] #quality_metric: host=algo-1, epoch=17, train loss <loss>=1.66501612013\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:09 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:09 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_54412455-6702-4430-b09f-10bd4038219d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 81.00390434265137, \"sum\": 81.00390434265137, \"min\": 81.00390434265137}}, \"EndTime\": 1587300669.577897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300669.496417}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:10 INFO 140632068241216] Epoch[18] Batch[0] avg_epoch_loss=1.805138\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=1.80513811111\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:12 INFO 140632068241216] Epoch[18] Batch[5] avg_epoch_loss=1.767117\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:12 INFO 140632068241216] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=1.76711682479\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:12 INFO 140632068241216] Epoch[18] Batch [5]#011Speed: 170.13 samples/sec#011loss=1.767117\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:13 INFO 140632068241216] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4213.423013687134, \"sum\": 4213.423013687134, \"min\": 4213.423013687134}}, \"EndTime\": 1587300673.791708, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300669.578099}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:13 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=150.230293168 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:13 INFO 140632068241216] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:13 INFO 140632068241216] #quality_metric: host=algo-1, epoch=18, train loss <loss>=1.71723487377\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:13 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:14 INFO 140632068241216] Epoch[19] Batch[0] avg_epoch_loss=1.741590\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:14 INFO 140632068241216] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=1.74159049988\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:16 INFO 140632068241216] Epoch[19] Batch[5] avg_epoch_loss=1.643726\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:16 INFO 140632068241216] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=1.64372609059\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:16 INFO 140632068241216] Epoch[19] Batch [5]#011Speed: 168.08 samples/sec#011loss=1.643726\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:18 INFO 140632068241216] Epoch[19] Batch[10] avg_epoch_loss=1.624886\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:18 INFO 140632068241216] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=1.60227844715\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:18 INFO 140632068241216] Epoch[19] Batch [10]#011Speed: 168.82 samples/sec#011loss=1.602278\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:18 INFO 140632068241216] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4649.271011352539, \"sum\": 4649.271011352539, \"min\": 4649.271011352539}}, \"EndTime\": 1587300678.441557, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300673.791774}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:18 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.18052216 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:18 INFO 140632068241216] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:18 INFO 140632068241216] #quality_metric: host=algo-1, epoch=19, train loss <loss>=1.62488625266\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:18 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:18 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_f9ded22d-a79b-430f-8d62-19b25a63c986-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 94.91109848022461, \"sum\": 94.91109848022461, \"min\": 94.91109848022461}}, \"EndTime\": 1587300678.537011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300678.441632}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:19 INFO 140632068241216] Epoch[20] Batch[0] avg_epoch_loss=1.597722\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=1.59772193432\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:21 INFO 140632068241216] Epoch[20] Batch[5] avg_epoch_loss=1.670304\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:21 INFO 140632068241216] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=1.67030433814\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:21 INFO 140632068241216] Epoch[20] Batch [5]#011Speed: 166.11 samples/sec#011loss=1.670304\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:22 INFO 140632068241216] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4258.018016815186, \"sum\": 4258.018016815186, \"min\": 4258.018016815186}}, \"EndTime\": 1587300682.79517, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300678.537084}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:22 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=148.656494211 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:22 INFO 140632068241216] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:22 INFO 140632068241216] #quality_metric: host=algo-1, epoch=20, train loss <loss>=1.6485640645\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:22 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:23 INFO 140632068241216] Epoch[21] Batch[0] avg_epoch_loss=1.518672\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:23 INFO 140632068241216] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=1.51867246628\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:25 INFO 140632068241216] Epoch[21] Batch[5] avg_epoch_loss=1.516484\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:25 INFO 140632068241216] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=1.51648366451\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:25 INFO 140632068241216] Epoch[21] Batch [5]#011Speed: 168.12 samples/sec#011loss=1.516484\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:27 INFO 140632068241216] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4221.226930618286, \"sum\": 4221.226930618286, \"min\": 4221.226930618286}}, \"EndTime\": 1587300687.017004, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300682.795249}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:27 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.555867572 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:27 INFO 140632068241216] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:27 INFO 140632068241216] #quality_metric: host=algo-1, epoch=21, train loss <loss>=1.46024165154\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:27 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:27 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_8bc11532-1194-4021-9e5e-b82e6ef66567-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 60.804128646850586, \"sum\": 60.804128646850586, \"min\": 60.804128646850586}}, \"EndTime\": 1587300687.07859, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300687.017088}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:27 INFO 140632068241216] Epoch[22] Batch[0] avg_epoch_loss=1.520384\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:27 INFO 140632068241216] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=1.52038395405\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:29 INFO 140632068241216] Epoch[22] Batch[5] avg_epoch_loss=1.450820\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:29 INFO 140632068241216] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=1.4508197705\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:29 INFO 140632068241216] Epoch[22] Batch [5]#011Speed: 168.77 samples/sec#011loss=1.450820\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:31 INFO 140632068241216] Epoch[22] Batch[10] avg_epoch_loss=1.530319\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=1.62571907043\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:31 INFO 140632068241216] Epoch[22] Batch [10]#011Speed: 169.37 samples/sec#011loss=1.625719\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:31 INFO 140632068241216] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4612.308025360107, \"sum\": 4612.308025360107, \"min\": 4612.308025360107}}, \"EndTime\": 1587300691.691042, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300687.07867}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:31 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.224561482 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:31 INFO 140632068241216] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=22, train loss <loss>=1.53031945229\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:31 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:32 INFO 140632068241216] Epoch[23] Batch[0] avg_epoch_loss=1.592426\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:32 INFO 140632068241216] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=1.592425704\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:34 INFO 140632068241216] Epoch[23] Batch[5] avg_epoch_loss=1.519535\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:34 INFO 140632068241216] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=1.5195350647\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:34 INFO 140632068241216] Epoch[23] Batch [5]#011Speed: 168.90 samples/sec#011loss=1.519535\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:36 INFO 140632068241216] Epoch[23] Batch[10] avg_epoch_loss=1.513213\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=1.50562689304\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:36 INFO 140632068241216] Epoch[23] Batch [10]#011Speed: 169.37 samples/sec#011loss=1.505627\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:36 INFO 140632068241216] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4620.270013809204, \"sum\": 4620.270013809204, \"min\": 4620.270013809204}}, \"EndTime\": 1587300696.311912, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300691.69112}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:36 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.330157575 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:36 INFO 140632068241216] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=23, train loss <loss>=1.51321316849\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:36 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:37 INFO 140632068241216] Epoch[24] Batch[0] avg_epoch_loss=1.392550\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:37 INFO 140632068241216] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=1.39255034924\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:39 INFO 140632068241216] Epoch[24] Batch[5] avg_epoch_loss=1.390043\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:39 INFO 140632068241216] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=1.39004260302\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:39 INFO 140632068241216] Epoch[24] Batch [5]#011Speed: 168.16 samples/sec#011loss=1.390043\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 140632068241216] Epoch[24] Batch[10] avg_epoch_loss=1.383288\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=1.37518317699\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 140632068241216] Epoch[24] Batch [10]#011Speed: 171.30 samples/sec#011loss=1.375183\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 140632068241216] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4600.15082359314, \"sum\": 4600.15082359314, \"min\": 4600.15082359314}}, \"EndTime\": 1587300700.912657, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300696.311986}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=139.556938209 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 140632068241216] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=24, train loss <loss>=1.38328831846\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:40 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_58838ea6-9e49-4b45-af77-d960b6ab7640-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 63.6439323425293, \"sum\": 63.6439323425293, \"min\": 63.6439323425293}}, \"EndTime\": 1587300700.976978, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300700.912738}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:41 INFO 140632068241216] Epoch[25] Batch[0] avg_epoch_loss=1.411122\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=1.41112196445\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:43 INFO 140632068241216] Epoch[25] Batch[5] avg_epoch_loss=1.389462\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=1.38946221272\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:43 INFO 140632068241216] Epoch[25] Batch [5]#011Speed: 169.63 samples/sec#011loss=1.389462\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:45 INFO 140632068241216] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4263.318061828613, \"sum\": 4263.318061828613, \"min\": 4263.318061828613}}, \"EndTime\": 1587300705.240445, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300700.977054}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:45 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.607683267 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:45 INFO 140632068241216] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:45 INFO 140632068241216] #quality_metric: host=algo-1, epoch=25, train loss <loss>=1.34751967192\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:45 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:45 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_f1e33938-5830-4845-abc6-b6c50c8f2d28-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 62.25705146789551, \"sum\": 62.25705146789551, \"min\": 62.25705146789551}}, \"EndTime\": 1587300705.303363, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300705.240529}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:46 INFO 140632068241216] Epoch[26] Batch[0] avg_epoch_loss=1.274425\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=1.27442467213\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:48 INFO 140632068241216] Epoch[26] Batch[5] avg_epoch_loss=1.284595\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=1.28459546963\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:48 INFO 140632068241216] Epoch[26] Batch [5]#011Speed: 168.57 samples/sec#011loss=1.284595\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:49 INFO 140632068241216] Epoch[26] Batch[10] avg_epoch_loss=1.174979\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:49 INFO 140632068241216] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=1.04343978167\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:49 INFO 140632068241216] Epoch[26] Batch [10]#011Speed: 173.45 samples/sec#011loss=1.043440\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:49 INFO 140632068241216] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4563.222885131836, \"sum\": 4563.222885131836, \"min\": 4563.222885131836}}, \"EndTime\": 1587300709.866733, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300705.303442}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:49 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.686149316 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:49 INFO 140632068241216] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:49 INFO 140632068241216] #quality_metric: host=algo-1, epoch=26, train loss <loss>=1.17497924783\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:49 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:49 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_29b645af-0811-45b1-b8ef-ac2abf664d81-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 59.387922286987305, \"sum\": 59.387922286987305, \"min\": 59.387922286987305}}, \"EndTime\": 1587300709.926748, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300709.866816}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:50 INFO 140632068241216] Epoch[27] Batch[0] avg_epoch_loss=1.465795\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:50 INFO 140632068241216] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=1.46579504013\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:52 INFO 140632068241216] Epoch[27] Batch[5] avg_epoch_loss=1.363005\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=1.36300462484\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:52 INFO 140632068241216] Epoch[27] Batch [5]#011Speed: 169.73 samples/sec#011loss=1.363005\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:54 INFO 140632068241216] Epoch[27] Batch[10] avg_epoch_loss=1.307009\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=1.2398150444\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:54 INFO 140632068241216] Epoch[27] Batch [10]#011Speed: 172.39 samples/sec#011loss=1.239815\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:54 INFO 140632068241216] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4571.556806564331, \"sum\": 4571.556806564331, \"min\": 4571.556806564331}}, \"EndTime\": 1587300714.498443, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300709.926821}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:54 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.398661005 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:54 INFO 140632068241216] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=27, train loss <loss>=1.30700936101\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:54 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:55 INFO 140632068241216] Epoch[28] Batch[0] avg_epoch_loss=2.033782\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:55 INFO 140632068241216] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=2.03378200531\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:57 INFO 140632068241216] Epoch[28] Batch[5] avg_epoch_loss=1.637557\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=1.63755698999\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:57 INFO 140632068241216] Epoch[28] Batch [5]#011Speed: 168.68 samples/sec#011loss=1.637557\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:58 INFO 140632068241216] processed a total of 589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4262.846946716309, \"sum\": 4262.846946716309, \"min\": 4262.846946716309}}, \"EndTime\": 1587300718.761798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300714.49852}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:58 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.167140713 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:58 INFO 140632068241216] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:58 INFO 140632068241216] #quality_metric: host=algo-1, epoch=28, train loss <loss>=1.51872155666\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:58 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:59 INFO 140632068241216] Epoch[29] Batch[0] avg_epoch_loss=1.804715\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:51:59 INFO 140632068241216] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=1.80471539497\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:01 INFO 140632068241216] Epoch[29] Batch[5] avg_epoch_loss=1.777769\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:01 INFO 140632068241216] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=1.77776861191\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:01 INFO 140632068241216] Epoch[29] Batch [5]#011Speed: 164.78 samples/sec#011loss=1.777769\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:03 INFO 140632068241216] Epoch[29] Batch[10] avg_epoch_loss=1.628656\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=1.44972035885\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:03 INFO 140632068241216] Epoch[29] Batch [10]#011Speed: 169.14 samples/sec#011loss=1.449720\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:03 INFO 140632068241216] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4669.895887374878, \"sum\": 4669.895887374878, \"min\": 4669.895887374878}}, \"EndTime\": 1587300723.432172, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300718.761869}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:03 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.757786855 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:03 INFO 140632068241216] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=29, train loss <loss>=1.62865576961\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:03 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:04 INFO 140632068241216] Epoch[30] Batch[0] avg_epoch_loss=1.387737\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:04 INFO 140632068241216] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=1.38773739338\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:06 INFO 140632068241216] Epoch[30] Batch[5] avg_epoch_loss=1.372189\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=1.37218854825\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:06 INFO 140632068241216] Epoch[30] Batch [5]#011Speed: 169.79 samples/sec#011loss=1.372189\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:08 INFO 140632068241216] Epoch[30] Batch[10] avg_epoch_loss=1.364803\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=1.35594079494\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:08 INFO 140632068241216] Epoch[30] Batch [10]#011Speed: 172.78 samples/sec#011loss=1.355941\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:08 INFO 140632068241216] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4606.065988540649, \"sum\": 4606.065988540649, \"min\": 4606.065988540649}}, \"EndTime\": 1587300728.045073, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300723.432248}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:08 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.285753624 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:08 INFO 140632068241216] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=30, train loss <loss>=1.36480320584\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:08 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:08 INFO 140632068241216] Epoch[31] Batch[0] avg_epoch_loss=1.583968\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=1.58396828175\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:10 INFO 140632068241216] Epoch[31] Batch[5] avg_epoch_loss=1.447708\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=1.44770811001\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:10 INFO 140632068241216] Epoch[31] Batch [5]#011Speed: 168.23 samples/sec#011loss=1.447708\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:12 INFO 140632068241216] Epoch[31] Batch[10] avg_epoch_loss=1.377066\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:12 INFO 140632068241216] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=1.29229543209\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:12 INFO 140632068241216] Epoch[31] Batch [10]#011Speed: 168.23 samples/sec#011loss=1.292295\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:12 INFO 140632068241216] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4676.501989364624, \"sum\": 4676.501989364624, \"min\": 4676.501989364624}}, \"EndTime\": 1587300732.722104, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300728.045148}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:12 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.045432227 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:12 INFO 140632068241216] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:12 INFO 140632068241216] #quality_metric: host=algo-1, epoch=31, train loss <loss>=1.37706598369\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:12 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:13 INFO 140632068241216] Epoch[32] Batch[0] avg_epoch_loss=1.210889\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:13 INFO 140632068241216] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=1.21088922024\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:15 INFO 140632068241216] Epoch[32] Batch[5] avg_epoch_loss=1.210534\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:15 INFO 140632068241216] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=1.21053421497\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:15 INFO 140632068241216] Epoch[32] Batch [5]#011Speed: 163.94 samples/sec#011loss=1.210534\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:17 INFO 140632068241216] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4313.949108123779, \"sum\": 4313.949108123779, \"min\": 4313.949108123779}}, \"EndTime\": 1587300737.036559, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300732.722194}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:17 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=148.352034882 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:17 INFO 140632068241216] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=32, train loss <loss>=1.22641700506\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:17 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:17 INFO 140632068241216] Epoch[33] Batch[0] avg_epoch_loss=1.059517\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=1.05951738358\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:19 INFO 140632068241216] Epoch[33] Batch[5] avg_epoch_loss=1.188339\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=1.18833919366\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:19 INFO 140632068241216] Epoch[33] Batch [5]#011Speed: 171.90 samples/sec#011loss=1.188339\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:21 INFO 140632068241216] Epoch[33] Batch[10] avg_epoch_loss=1.208830\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:21 INFO 140632068241216] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=1.2334199667\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:21 INFO 140632068241216] Epoch[33] Batch [10]#011Speed: 169.94 samples/sec#011loss=1.233420\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:21 INFO 140632068241216] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4613.742113113403, \"sum\": 4613.742113113403, \"min\": 4613.742113113403}}, \"EndTime\": 1587300741.650979, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300737.036636}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:21 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.880019549 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:21 INFO 140632068241216] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:21 INFO 140632068241216] #quality_metric: host=algo-1, epoch=33, train loss <loss>=1.20883045413\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:21 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:22 INFO 140632068241216] Epoch[34] Batch[0] avg_epoch_loss=1.331936\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:22 INFO 140632068241216] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=1.3319362402\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:24 INFO 140632068241216] Epoch[34] Batch[5] avg_epoch_loss=1.215638\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=1.2156376044\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:24 INFO 140632068241216] Epoch[34] Batch [5]#011Speed: 171.56 samples/sec#011loss=1.215638\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:25 INFO 140632068241216] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4224.228858947754, \"sum\": 4224.228858947754, \"min\": 4224.228858947754}}, \"EndTime\": 1587300745.875698, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300741.651055}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:25 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.691330059 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:25 INFO 140632068241216] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:25 INFO 140632068241216] #quality_metric: host=algo-1, epoch=34, train loss <loss>=1.13729866743\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:25 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:25 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_adb2a96c-16d2-4ad6-86a3-6d24f997a7ea-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 62.16096878051758, \"sum\": 62.16096878051758, \"min\": 62.16096878051758}}, \"EndTime\": 1587300745.938538, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300745.875769}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:26 INFO 140632068241216] Epoch[35] Batch[0] avg_epoch_loss=1.114351\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:26 INFO 140632068241216] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=1.11435103416\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:28 INFO 140632068241216] Epoch[35] Batch[5] avg_epoch_loss=1.147459\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:28 INFO 140632068241216] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=1.14745869239\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:28 INFO 140632068241216] Epoch[35] Batch [5]#011Speed: 169.15 samples/sec#011loss=1.147459\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:30 INFO 140632068241216] Epoch[35] Batch[10] avg_epoch_loss=1.102594\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:30 INFO 140632068241216] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=1.04875586033\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:30 INFO 140632068241216] Epoch[35] Batch [10]#011Speed: 166.59 samples/sec#011loss=1.048756\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:30 INFO 140632068241216] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4644.63996887207, \"sum\": 4644.63996887207, \"min\": 4644.63996887207}}, \"EndTime\": 1587300750.583325, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300745.938617}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:30 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.019521052 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:30 INFO 140632068241216] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:30 INFO 140632068241216] #quality_metric: host=algo-1, epoch=35, train loss <loss>=1.10259376873\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:30 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:30 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_ca27edc4-eff7-4a0e-b6c6-9328f8ae2874-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.48195266723633, \"sum\": 61.48195266723633, \"min\": 61.48195266723633}}, \"EndTime\": 1587300750.645687, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300750.583392}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:31 INFO 140632068241216] Epoch[36] Batch[0] avg_epoch_loss=1.075482\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=1.07548213005\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:33 INFO 140632068241216] Epoch[36] Batch[5] avg_epoch_loss=1.075478\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:33 INFO 140632068241216] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=1.07547834516\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:33 INFO 140632068241216] Epoch[36] Batch [5]#011Speed: 168.79 samples/sec#011loss=1.075478\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:35 INFO 140632068241216] Epoch[36] Batch[10] avg_epoch_loss=1.020928\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:35 INFO 140632068241216] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=0.955466580391\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:35 INFO 140632068241216] Epoch[36] Batch [10]#011Speed: 168.85 samples/sec#011loss=0.955467\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:35 INFO 140632068241216] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4661.764860153198, \"sum\": 4661.764860153198, \"min\": 4661.764860153198}}, \"EndTime\": 1587300755.307584, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300750.645758}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:35 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.721832786 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:35 INFO 140632068241216] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:35 INFO 140632068241216] #quality_metric: host=algo-1, epoch=36, train loss <loss>=1.02092754299\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:35 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:35 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_7aceec1b-7fac-42da-84ee-4591b6942aaf-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 59.771060943603516, \"sum\": 59.771060943603516, \"min\": 59.771060943603516}}, \"EndTime\": 1587300755.368046, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300755.307668}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:36 INFO 140632068241216] Epoch[37] Batch[0] avg_epoch_loss=0.847558\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=0.847558379173\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:38 INFO 140632068241216] Epoch[37] Batch[5] avg_epoch_loss=1.062586\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:38 INFO 140632068241216] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=1.06258605917\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:38 INFO 140632068241216] Epoch[37] Batch [5]#011Speed: 169.87 samples/sec#011loss=1.062586\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:40 INFO 140632068241216] Epoch[37] Batch[10] avg_epoch_loss=1.042181\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=1.01769429445\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:40 INFO 140632068241216] Epoch[37] Batch [10]#011Speed: 168.97 samples/sec#011loss=1.017694\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:40 INFO 140632068241216] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4635.925054550171, \"sum\": 4635.925054550171, \"min\": 4635.925054550171}}, \"EndTime\": 1587300760.004109, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300755.36812}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:40 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.02968201 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:40 INFO 140632068241216] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=37, train loss <loss>=1.04218071157\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:40 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:40 INFO 140632068241216] Epoch[38] Batch[0] avg_epoch_loss=0.877959\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=0.877958834171\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:42 INFO 140632068241216] Epoch[38] Batch[5] avg_epoch_loss=0.996244\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:42 INFO 140632068241216] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=0.996244460344\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:42 INFO 140632068241216] Epoch[38] Batch [5]#011Speed: 169.83 samples/sec#011loss=0.996244\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:44 INFO 140632068241216] Epoch[38] Batch[10] avg_epoch_loss=0.961614\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:44 INFO 140632068241216] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=0.920057857037\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:44 INFO 140632068241216] Epoch[38] Batch [10]#011Speed: 173.03 samples/sec#011loss=0.920058\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:44 INFO 140632068241216] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4668.360948562622, \"sum\": 4668.360948562622, \"min\": 4668.360948562622}}, \"EndTime\": 1587300764.673142, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300760.00419}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:44 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=137.304031308 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:44 INFO 140632068241216] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:44 INFO 140632068241216] #quality_metric: host=algo-1, epoch=38, train loss <loss>=0.961614186114\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:44 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:44 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_8a9b73ca-280a-42cc-9b50-adb1ceecbef6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 59.557199478149414, \"sum\": 59.557199478149414, \"min\": 59.557199478149414}}, \"EndTime\": 1587300764.733342, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300764.673214}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:45 INFO 140632068241216] Epoch[39] Batch[0] avg_epoch_loss=2.983977\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:45 INFO 140632068241216] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.98397731781\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:47 INFO 140632068241216] Epoch[39] Batch[5] avg_epoch_loss=2.112140\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:47 INFO 140632068241216] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.11213990053\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:47 INFO 140632068241216] Epoch[39] Batch [5]#011Speed: 167.00 samples/sec#011loss=2.112140\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:48 INFO 140632068241216] processed a total of 596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4239.4700050354, \"sum\": 4239.4700050354, \"min\": 4239.4700050354}}, \"EndTime\": 1587300768.972959, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300764.73342}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:48 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.57973663 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:48 INFO 140632068241216] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.09174509048\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:48 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:49 INFO 140632068241216] Epoch[40] Batch[0] avg_epoch_loss=1.946152\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:49 INFO 140632068241216] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=1.94615244865\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:51 INFO 140632068241216] Epoch[40] Batch[5] avg_epoch_loss=1.843356\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:51 INFO 140632068241216] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=1.8433560729\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:51 INFO 140632068241216] Epoch[40] Batch [5]#011Speed: 166.60 samples/sec#011loss=1.843356\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:53 INFO 140632068241216] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4257.453918457031, \"sum\": 4257.453918457031, \"min\": 4257.453918457031}}, \"EndTime\": 1587300773.230964, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300768.973034}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:53 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.502010887 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:53 INFO 140632068241216] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:53 INFO 140632068241216] #quality_metric: host=algo-1, epoch=40, train loss <loss>=1.7384454608\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:53 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:54 INFO 140632068241216] Epoch[41] Batch[0] avg_epoch_loss=1.484401\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=1.48440122604\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:55 INFO 140632068241216] Epoch[41] Batch[5] avg_epoch_loss=1.477597\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:55 INFO 140632068241216] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=1.4775968194\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:55 INFO 140632068241216] Epoch[41] Batch [5]#011Speed: 167.63 samples/sec#011loss=1.477597\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:57 INFO 140632068241216] processed a total of 584 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4259.914875030518, \"sum\": 4259.914875030518, \"min\": 4259.914875030518}}, \"EndTime\": 1587300777.491621, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300773.23104}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:57 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=137.088012966 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:57 INFO 140632068241216] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=41, train loss <loss>=1.34016594291\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:57 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:58 INFO 140632068241216] Epoch[42] Batch[0] avg_epoch_loss=1.537871\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:52:58 INFO 140632068241216] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=1.53787112236\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:00 INFO 140632068241216] Epoch[42] Batch[5] avg_epoch_loss=1.526565\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:00 INFO 140632068241216] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=1.52656517426\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:00 INFO 140632068241216] Epoch[42] Batch [5]#011Speed: 169.82 samples/sec#011loss=1.526565\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:01 INFO 140632068241216] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4310.318946838379, \"sum\": 4310.318946838379, \"min\": 4310.318946838379}}, \"EndTime\": 1587300781.802773, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300777.491703}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:01 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.460922861 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:01 INFO 140632068241216] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:01 INFO 140632068241216] #quality_metric: host=algo-1, epoch=42, train loss <loss>=1.39774968624\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:01 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:02 INFO 140632068241216] Epoch[43] Batch[0] avg_epoch_loss=1.161471\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:02 INFO 140632068241216] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=1.16147089005\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:04 INFO 140632068241216] Epoch[43] Batch[5] avg_epoch_loss=1.156875\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:04 INFO 140632068241216] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=1.15687523286\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:04 INFO 140632068241216] Epoch[43] Batch [5]#011Speed: 170.13 samples/sec#011loss=1.156875\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:06 INFO 140632068241216] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4216.679096221924, \"sum\": 4216.679096221924, \"min\": 4216.679096221924}}, \"EndTime\": 1587300786.020019, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300781.802848}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:06 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=150.351300989 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:06 INFO 140632068241216] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=43, train loss <loss>=1.19179643393\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:06 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:06 INFO 140632068241216] Epoch[44] Batch[0] avg_epoch_loss=1.812667\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=1.81266736984\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:08 INFO 140632068241216] Epoch[44] Batch[5] avg_epoch_loss=1.357161\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=1.35716056824\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:08 INFO 140632068241216] Epoch[44] Batch [5]#011Speed: 168.11 samples/sec#011loss=1.357161\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:10 INFO 140632068241216] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4286.700963973999, \"sum\": 4286.700963973999, \"min\": 4286.700963973999}}, \"EndTime\": 1587300790.307435, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300786.020093}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:10 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.897015398 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:10 INFO 140632068241216] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=44, train loss <loss>=1.24212184548\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:10 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:11 INFO 140632068241216] Epoch[45] Batch[0] avg_epoch_loss=1.045741\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:11 INFO 140632068241216] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=1.04574131966\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:13 INFO 140632068241216] Epoch[45] Batch[5] avg_epoch_loss=0.995057\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:13 INFO 140632068241216] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=0.995057294766\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:13 INFO 140632068241216] Epoch[45] Batch [5]#011Speed: 164.89 samples/sec#011loss=0.995057\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:14 INFO 140632068241216] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4269.315958023071, \"sum\": 4269.315958023071, \"min\": 4269.315958023071}}, \"EndTime\": 1587300794.577517, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300790.307512}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:14 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.857661527 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:14 INFO 140632068241216] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:14 INFO 140632068241216] #quality_metric: host=algo-1, epoch=45, train loss <loss>=0.940661263466\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:14 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:14 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_ec435599-774c-47eb-9bc4-0b250ea8a8b4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 70.11294364929199, \"sum\": 70.11294364929199, \"min\": 70.11294364929199}}, \"EndTime\": 1587300794.648368, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300794.577598}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:15 INFO 140632068241216] Epoch[46] Batch[0] avg_epoch_loss=0.912251\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:15 INFO 140632068241216] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=0.912250578403\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:17 INFO 140632068241216] Epoch[46] Batch[5] avg_epoch_loss=0.867462\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=0.867462138335\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:17 INFO 140632068241216] Epoch[46] Batch [5]#011Speed: 162.31 samples/sec#011loss=0.867462\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:18 INFO 140632068241216] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4293.390989303589, \"sum\": 4293.390989303589, \"min\": 4293.390989303589}}, \"EndTime\": 1587300798.941914, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300794.64845}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:18 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.801179899 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:18 INFO 140632068241216] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:18 INFO 140632068241216] #quality_metric: host=algo-1, epoch=46, train loss <loss>=0.912081664801\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:18 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:19 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_f4396421-727e-4bbd-bf17-f923bbde1758-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 62.516212463378906, \"sum\": 62.516212463378906, \"min\": 62.516212463378906}}, \"EndTime\": 1587300799.005066, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300798.941997}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:19 INFO 140632068241216] Epoch[47] Batch[0] avg_epoch_loss=0.838466\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=0.838465988636\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:21 INFO 140632068241216] Epoch[47] Batch[5] avg_epoch_loss=0.824411\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:21 INFO 140632068241216] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=0.824411114057\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:21 INFO 140632068241216] Epoch[47] Batch [5]#011Speed: 169.61 samples/sec#011loss=0.824411\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:23 INFO 140632068241216] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4235.349893569946, \"sum\": 4235.349893569946, \"min\": 4235.349893569946}}, \"EndTime\": 1587300803.240557, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300799.005143}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:23 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.563497241 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:23 INFO 140632068241216] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:23 INFO 140632068241216] #quality_metric: host=algo-1, epoch=47, train loss <loss>=0.816897535324\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:23 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:23 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_f159bd9a-7dc2-4096-aafb-81ad372cef55-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 68.0990219116211, \"sum\": 68.0990219116211, \"min\": 68.0990219116211}}, \"EndTime\": 1587300803.30945, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300803.240634}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:24 INFO 140632068241216] Epoch[48] Batch[0] avg_epoch_loss=0.958532\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=0.958531856537\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:26 INFO 140632068241216] Epoch[48] Batch[5] avg_epoch_loss=0.891686\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:26 INFO 140632068241216] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=0.891685555379\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:26 INFO 140632068241216] Epoch[48] Batch [5]#011Speed: 168.41 samples/sec#011loss=0.891686\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:27 INFO 140632068241216] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4216.387033462524, \"sum\": 4216.387033462524, \"min\": 4216.387033462524}}, \"EndTime\": 1587300807.525986, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300803.309531}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:27 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.009571289 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:27 INFO 140632068241216] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:27 INFO 140632068241216] #quality_metric: host=algo-1, epoch=48, train loss <loss>=0.916743308306\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:27 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:28 INFO 140632068241216] Epoch[49] Batch[0] avg_epoch_loss=1.163189\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:28 INFO 140632068241216] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=1.16318917274\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:30 INFO 140632068241216] Epoch[49] Batch[5] avg_epoch_loss=0.985202\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:30 INFO 140632068241216] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=0.985201865435\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:30 INFO 140632068241216] Epoch[49] Batch [5]#011Speed: 168.38 samples/sec#011loss=0.985202\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:31 INFO 140632068241216] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4285.88604927063, \"sum\": 4285.88604927063, \"min\": 4285.88604927063}}, \"EndTime\": 1587300811.812614, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300807.526061}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:31 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=148.623085675 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:31 INFO 140632068241216] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=49, train loss <loss>=0.912839126587\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:31 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:32 INFO 140632068241216] Epoch[50] Batch[0] avg_epoch_loss=0.835938\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:32 INFO 140632068241216] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=0.835938096046\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:34 INFO 140632068241216] Epoch[50] Batch[5] avg_epoch_loss=0.816625\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:34 INFO 140632068241216] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=0.816624780496\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:34 INFO 140632068241216] Epoch[50] Batch [5]#011Speed: 169.02 samples/sec#011loss=0.816625\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:36 INFO 140632068241216] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4229.095935821533, \"sum\": 4229.095935821533, \"min\": 4229.095935821533}}, \"EndTime\": 1587300816.042285, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300811.812697}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:36 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.342698407 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:36 INFO 140632068241216] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=50, train loss <loss>=0.773165565729\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:36 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:36 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_ceb31833-0833-4f69-8d9c-c1100b745d80-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 64.46695327758789, \"sum\": 64.46695327758789, \"min\": 64.46695327758789}}, \"EndTime\": 1587300816.10748, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300816.04235}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:36 INFO 140632068241216] Epoch[51] Batch[0] avg_epoch_loss=0.818580\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=0.818580210209\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:38 INFO 140632068241216] Epoch[51] Batch[5] avg_epoch_loss=0.722371\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:38 INFO 140632068241216] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=0.722370793422\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:38 INFO 140632068241216] Epoch[51] Batch [5]#011Speed: 169.73 samples/sec#011loss=0.722371\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:40 INFO 140632068241216] Epoch[51] Batch[10] avg_epoch_loss=0.752592\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=0.788857662678\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:40 INFO 140632068241216] Epoch[51] Batch [10]#011Speed: 172.25 samples/sec#011loss=0.788858\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:40 INFO 140632068241216] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4613.24405670166, \"sum\": 4613.24405670166, \"min\": 4613.24405670166}}, \"EndTime\": 1587300820.721107, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300816.107781}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:40 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.762129944 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:40 INFO 140632068241216] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=51, train loss <loss>=0.752592097629\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:40 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:40 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_6b0bb46d-5d96-4f97-900b-8272d8c10bf4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 89.51306343078613, \"sum\": 89.51306343078613, \"min\": 89.51306343078613}}, \"EndTime\": 1587300820.811174, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300820.721186}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:41 INFO 140632068241216] Epoch[52] Batch[0] avg_epoch_loss=1.610729\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=1.61072945595\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:43 INFO 140632068241216] Epoch[52] Batch[5] avg_epoch_loss=1.528525\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=1.52852517366\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:43 INFO 140632068241216] Epoch[52] Batch [5]#011Speed: 169.87 samples/sec#011loss=1.528525\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:45 INFO 140632068241216] Epoch[52] Batch[10] avg_epoch_loss=1.405779\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:45 INFO 140632068241216] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=1.25848337412\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:45 INFO 140632068241216] Epoch[52] Batch [10]#011Speed: 167.55 samples/sec#011loss=1.258483\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:45 INFO 140632068241216] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4666.352987289429, \"sum\": 4666.352987289429, \"min\": 4666.352987289429}}, \"EndTime\": 1587300825.477662, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300820.811247}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:45 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.863148822 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:45 INFO 140632068241216] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:45 INFO 140632068241216] #quality_metric: host=algo-1, epoch=52, train loss <loss>=1.40577890114\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:45 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:46 INFO 140632068241216] Epoch[53] Batch[0] avg_epoch_loss=1.225052\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=1.22505164146\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:48 INFO 140632068241216] Epoch[53] Batch[5] avg_epoch_loss=1.187110\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=1.1871102651\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:48 INFO 140632068241216] Epoch[53] Batch [5]#011Speed: 164.49 samples/sec#011loss=1.187110\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:49 INFO 140632068241216] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4401.226043701172, \"sum\": 4401.226043701172, \"min\": 4401.226043701172}}, \"EndTime\": 1587300829.879421, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300825.477741}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:49 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.183120546 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:49 INFO 140632068241216] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:49 INFO 140632068241216] #quality_metric: host=algo-1, epoch=53, train loss <loss>=1.10904980898\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:49 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:50 INFO 140632068241216] Epoch[54] Batch[0] avg_epoch_loss=0.887101\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:50 INFO 140632068241216] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=0.887100756168\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:52 INFO 140632068241216] Epoch[54] Batch[5] avg_epoch_loss=0.838315\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=0.838314662377\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:52 INFO 140632068241216] Epoch[54] Batch [5]#011Speed: 170.02 samples/sec#011loss=0.838315\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:54 INFO 140632068241216] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4245.808124542236, \"sum\": 4245.808124542236, \"min\": 4245.808124542236}}, \"EndTime\": 1587300834.125955, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300829.879489}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:54 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=150.260769878 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:54 INFO 140632068241216] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=54, train loss <loss>=0.766685718298\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:54 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:54 INFO 140632068241216] Epoch[55] Batch[0] avg_epoch_loss=0.831985\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=0.83198517561\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:56 INFO 140632068241216] Epoch[55] Batch[5] avg_epoch_loss=0.782515\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:56 INFO 140632068241216] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=0.782515297333\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:56 INFO 140632068241216] Epoch[55] Batch [5]#011Speed: 171.06 samples/sec#011loss=0.782515\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:58 INFO 140632068241216] Epoch[55] Batch[10] avg_epoch_loss=0.710337\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:58 INFO 140632068241216] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=0.623724126816\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:58 INFO 140632068241216] Epoch[55] Batch [10]#011Speed: 170.27 samples/sec#011loss=0.623724\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:58 INFO 140632068241216] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4607.943773269653, \"sum\": 4607.943773269653, \"min\": 4607.943773269653}}, \"EndTime\": 1587300838.73467, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300834.126029}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:58 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.265490594 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:58 INFO 140632068241216] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:58 INFO 140632068241216] #quality_metric: host=algo-1, epoch=55, train loss <loss>=0.710337492553\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:58 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:58 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_05c1200c-008a-478f-943e-3490b6539ee4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 70.0998306274414, \"sum\": 70.0998306274414, \"min\": 70.0998306274414}}, \"EndTime\": 1587300838.805322, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300838.734747}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:59 INFO 140632068241216] Epoch[56] Batch[0] avg_epoch_loss=0.598896\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:53:59 INFO 140632068241216] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=0.598895847797\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:01 INFO 140632068241216] Epoch[56] Batch[5] avg_epoch_loss=0.795130\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:01 INFO 140632068241216] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=0.795129944881\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:01 INFO 140632068241216] Epoch[56] Batch [5]#011Speed: 170.29 samples/sec#011loss=0.795130\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:03 INFO 140632068241216] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4262.740850448608, \"sum\": 4262.740850448608, \"min\": 4262.740850448608}}, \"EndTime\": 1587300843.068196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300838.805393}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:03 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.318975246 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:03 INFO 140632068241216] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=56, train loss <loss>=0.821479541063\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:03 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:03 INFO 140632068241216] Epoch[57] Batch[0] avg_epoch_loss=0.797193\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=0.797192513943\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:05 INFO 140632068241216] Epoch[57] Batch[5] avg_epoch_loss=0.735144\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:05 INFO 140632068241216] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=0.735143701235\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:05 INFO 140632068241216] Epoch[57] Batch [5]#011Speed: 168.84 samples/sec#011loss=0.735144\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:07 INFO 140632068241216] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4214.181900024414, \"sum\": 4214.181900024414, \"min\": 4214.181900024414}}, \"EndTime\": 1587300847.282989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300843.068274}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:07 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.169453723 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:07 INFO 140632068241216] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:07 INFO 140632068241216] #quality_metric: host=algo-1, epoch=57, train loss <loss>=0.702352309227\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:07 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:07 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_83eda451-914a-40c5-bb87-77f4d4dac034-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 67.63601303100586, \"sum\": 67.63601303100586, \"min\": 67.63601303100586}}, \"EndTime\": 1587300847.351332, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300847.283052}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:08 INFO 140632068241216] Epoch[58] Batch[0] avg_epoch_loss=1.471116\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=1.47111582756\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:10 INFO 140632068241216] Epoch[58] Batch[5] avg_epoch_loss=0.947762\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=0.947761952877\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:10 INFO 140632068241216] Epoch[58] Batch [5]#011Speed: 169.15 samples/sec#011loss=0.947762\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:11 INFO 140632068241216] Epoch[58] Batch[10] avg_epoch_loss=0.862394\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:11 INFO 140632068241216] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=0.759952104092\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:11 INFO 140632068241216] Epoch[58] Batch [10]#011Speed: 173.16 samples/sec#011loss=0.759952\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:11 INFO 140632068241216] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4583.328008651733, \"sum\": 4583.328008651733, \"min\": 4583.328008651733}}, \"EndTime\": 1587300851.934818, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300847.351421}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:11 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.596518502 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:11 INFO 140632068241216] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:11 INFO 140632068241216] #quality_metric: host=algo-1, epoch=58, train loss <loss>=0.862393839793\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:11 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:12 INFO 140632068241216] Epoch[59] Batch[0] avg_epoch_loss=0.815776\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:12 INFO 140632068241216] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=0.815775811672\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:14 INFO 140632068241216] Epoch[59] Batch[5] avg_epoch_loss=0.830943\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:14 INFO 140632068241216] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=0.830942759911\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:14 INFO 140632068241216] Epoch[59] Batch [5]#011Speed: 170.13 samples/sec#011loss=0.830943\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:16 INFO 140632068241216] Epoch[59] Batch[10] avg_epoch_loss=0.809079\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:16 INFO 140632068241216] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=0.782841897011\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:16 INFO 140632068241216] Epoch[59] Batch [10]#011Speed: 163.79 samples/sec#011loss=0.782842\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:16 INFO 140632068241216] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4694.751977920532, \"sum\": 4694.751977920532, \"min\": 4694.751977920532}}, \"EndTime\": 1587300856.630165, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300851.934895}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:16 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.116813314 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:16 INFO 140632068241216] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:16 INFO 140632068241216] #quality_metric: host=algo-1, epoch=59, train loss <loss>=0.80907873132\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:16 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:17 INFO 140632068241216] Epoch[60] Batch[0] avg_epoch_loss=0.715017\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=0.71501737833\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:19 INFO 140632068241216] Epoch[60] Batch[5] avg_epoch_loss=0.601873\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=0.601873422662\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:19 INFO 140632068241216] Epoch[60] Batch [5]#011Speed: 170.81 samples/sec#011loss=0.601873\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:20 INFO 140632068241216] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4218.343019485474, \"sum\": 4218.343019485474, \"min\": 4218.343019485474}}, \"EndTime\": 1587300860.849082, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300856.630245}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:20 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=149.817211933 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:20 INFO 140632068241216] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:20 INFO 140632068241216] #quality_metric: host=algo-1, epoch=60, train loss <loss>=0.698754844069\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:20 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:20 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_9e67c879-5b4d-4736-bb68-07dacee6b6ef-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 66.57910346984863, \"sum\": 66.57910346984863, \"min\": 66.57910346984863}}, \"EndTime\": 1587300860.916422, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300860.849166}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:21 INFO 140632068241216] Epoch[61] Batch[0] avg_epoch_loss=0.635195\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:21 INFO 140632068241216] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=0.63519525528\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:23 INFO 140632068241216] Epoch[61] Batch[5] avg_epoch_loss=0.640629\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:23 INFO 140632068241216] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=0.640628616015\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:23 INFO 140632068241216] Epoch[61] Batch [5]#011Speed: 170.02 samples/sec#011loss=0.640629\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 140632068241216] Epoch[61] Batch[10] avg_epoch_loss=0.600682\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 140632068241216] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=0.552746760845\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 140632068241216] Epoch[61] Batch [10]#011Speed: 171.66 samples/sec#011loss=0.552747\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 140632068241216] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4610.304117202759, \"sum\": 4610.304117202759, \"min\": 4610.304117202759}}, \"EndTime\": 1587300865.526869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300860.916498}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.756853913 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 140632068241216] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 140632068241216] #quality_metric: host=algo-1, epoch=61, train loss <loss>=0.600682318211\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:25 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_0e5c3f2c-347b-47aa-b318-426a471c677d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 106.75406455993652, \"sum\": 106.75406455993652, \"min\": 106.75406455993652}}, \"EndTime\": 1587300865.634157, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300865.526944}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:26 INFO 140632068241216] Epoch[62] Batch[0] avg_epoch_loss=0.898535\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:26 INFO 140632068241216] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=0.898535013199\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:28 INFO 140632068241216] Epoch[62] Batch[5] avg_epoch_loss=0.765435\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:28 INFO 140632068241216] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=0.76543456316\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:28 INFO 140632068241216] Epoch[62] Batch [5]#011Speed: 171.86 samples/sec#011loss=0.765435\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:30 INFO 140632068241216] Epoch[62] Batch[10] avg_epoch_loss=0.676584\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:30 INFO 140632068241216] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=0.569963431358\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:30 INFO 140632068241216] Epoch[62] Batch [10]#011Speed: 170.51 samples/sec#011loss=0.569963\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:30 INFO 140632068241216] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4641.127824783325, \"sum\": 4641.127824783325, \"min\": 4641.127824783325}}, \"EndTime\": 1587300870.275432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300865.634237}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:30 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.341534385 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:30 INFO 140632068241216] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:30 INFO 140632068241216] #quality_metric: host=algo-1, epoch=62, train loss <loss>=0.676584048705\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:30 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:31 INFO 140632068241216] Epoch[63] Batch[0] avg_epoch_loss=0.877217\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=0.877217292786\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:32 INFO 140632068241216] Epoch[63] Batch[5] avg_epoch_loss=0.832408\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:32 INFO 140632068241216] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=0.832407792409\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:32 INFO 140632068241216] Epoch[63] Batch [5]#011Speed: 169.53 samples/sec#011loss=0.832408\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:34 INFO 140632068241216] processed a total of 571 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3848.3338356018066, \"sum\": 3848.3338356018066, \"min\": 3848.3338356018066}}, \"EndTime\": 1587300874.124364, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300870.275504}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:34 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=148.371378405 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:34 INFO 140632068241216] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:34 INFO 140632068241216] #quality_metric: host=algo-1, epoch=63, train loss <loss>=0.785510586368\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:34 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:34 INFO 140632068241216] Epoch[64] Batch[0] avg_epoch_loss=0.684967\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:34 INFO 140632068241216] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=0.684966564178\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:36 INFO 140632068241216] Epoch[64] Batch[5] avg_epoch_loss=0.693183\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=0.693182865779\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:36 INFO 140632068241216] Epoch[64] Batch [5]#011Speed: 168.42 samples/sec#011loss=0.693183\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 140632068241216] Epoch[64] Batch[10] avg_epoch_loss=0.628223\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 140632068241216] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=0.550270402431\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 140632068241216] Epoch[64] Batch [10]#011Speed: 171.38 samples/sec#011loss=0.550270\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 140632068241216] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4610.828161239624, \"sum\": 4610.828161239624, \"min\": 4610.828161239624}}, \"EndTime\": 1587300878.735716, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300874.124436}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=139.88407309 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 140632068241216] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 140632068241216] #quality_metric: host=algo-1, epoch=64, train loss <loss>=0.628222655166\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:38 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:39 INFO 140632068241216] Epoch[65] Batch[0] avg_epoch_loss=0.649180\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:39 INFO 140632068241216] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=0.649179577827\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:41 INFO 140632068241216] Epoch[65] Batch[5] avg_epoch_loss=0.654325\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=0.654324869315\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:41 INFO 140632068241216] Epoch[65] Batch [5]#011Speed: 169.78 samples/sec#011loss=0.654325\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:43 INFO 140632068241216] Epoch[65] Batch[10] avg_epoch_loss=0.607577\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=0.551480484009\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:43 INFO 140632068241216] Epoch[65] Batch [10]#011Speed: 166.91 samples/sec#011loss=0.551480\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:43 INFO 140632068241216] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4712.637901306152, \"sum\": 4712.637901306152, \"min\": 4712.637901306152}}, \"EndTime\": 1587300883.448855, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300878.735789}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:43 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.652705276 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:43 INFO 140632068241216] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=65, train loss <loss>=0.607577421448\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:43 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:44 INFO 140632068241216] Epoch[66] Batch[0] avg_epoch_loss=0.898948\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:44 INFO 140632068241216] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=0.898947536945\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:46 INFO 140632068241216] Epoch[66] Batch[5] avg_epoch_loss=0.959790\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=0.95979042848\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:46 INFO 140632068241216] Epoch[66] Batch [5]#011Speed: 165.35 samples/sec#011loss=0.959790\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:48 INFO 140632068241216] Epoch[66] Batch[10] avg_epoch_loss=0.880807\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=0.786027133465\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:48 INFO 140632068241216] Epoch[66] Batch [10]#011Speed: 167.48 samples/sec#011loss=0.786027\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:48 INFO 140632068241216] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4734.911918640137, \"sum\": 4734.911918640137, \"min\": 4734.911918640137}}, \"EndTime\": 1587300888.184324, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300883.448935}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:48 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.188235248 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:48 INFO 140632068241216] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=66, train loss <loss>=0.880807112564\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:48 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:49 INFO 140632068241216] Epoch[67] Batch[0] avg_epoch_loss=0.783618\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:49 INFO 140632068241216] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=0.783618271351\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:50 INFO 140632068241216] Epoch[67] Batch[5] avg_epoch_loss=0.680848\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:50 INFO 140632068241216] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=0.680848300457\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:50 INFO 140632068241216] Epoch[67] Batch [5]#011Speed: 169.92 samples/sec#011loss=0.680848\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:52 INFO 140632068241216] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4229.089975357056, \"sum\": 4229.089975357056, \"min\": 4229.089975357056}}, \"EndTime\": 1587300892.413984, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300888.1844}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:52 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.545006924 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:52 INFO 140632068241216] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=67, train loss <loss>=0.691737508774\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:52 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:53 INFO 140632068241216] Epoch[68] Batch[0] avg_epoch_loss=0.558807\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:53 INFO 140632068241216] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=0.558806598186\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:55 INFO 140632068241216] Epoch[68] Batch[5] avg_epoch_loss=0.522815\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:55 INFO 140632068241216] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=0.522815028826\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:55 INFO 140632068241216] Epoch[68] Batch [5]#011Speed: 169.25 samples/sec#011loss=0.522815\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:57 INFO 140632068241216] Epoch[68] Batch[10] avg_epoch_loss=0.534826\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=0.549239838123\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:57 INFO 140632068241216] Epoch[68] Batch [10]#011Speed: 167.98 samples/sec#011loss=0.549240\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:57 INFO 140632068241216] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4680.913925170898, \"sum\": 4680.913925170898, \"min\": 4680.913925170898}}, \"EndTime\": 1587300897.095492, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300892.414069}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:57 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.344577665 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:57 INFO 140632068241216] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=68, train loss <loss>=0.53482630578\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:57 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:57 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_5cdf194b-560e-4247-b8f2-252f09bc5cd3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 91.20917320251465, \"sum\": 91.20917320251465, \"min\": 91.20917320251465}}, \"EndTime\": 1587300897.187299, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300897.09557}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:58 INFO 140632068241216] Epoch[69] Batch[0] avg_epoch_loss=1.010731\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:58 INFO 140632068241216] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=1.01073122025\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:59 INFO 140632068241216] Epoch[69] Batch[5] avg_epoch_loss=0.811031\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:59 INFO 140632068241216] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=0.811031321685\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:54:59 INFO 140632068241216] Epoch[69] Batch [5]#011Speed: 169.22 samples/sec#011loss=0.811031\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:01 INFO 140632068241216] processed a total of 595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4208.822011947632, \"sum\": 4208.822011947632, \"min\": 4208.822011947632}}, \"EndTime\": 1587300901.396268, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300897.187379}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:01 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.36572654 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:01 INFO 140632068241216] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:01 INFO 140632068241216] #quality_metric: host=algo-1, epoch=69, train loss <loss>=0.751529669762\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:01 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:02 INFO 140632068241216] Epoch[70] Batch[0] avg_epoch_loss=0.538332\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:02 INFO 140632068241216] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=0.53833180666\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:04 INFO 140632068241216] Epoch[70] Batch[5] avg_epoch_loss=0.533585\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:04 INFO 140632068241216] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=0.533585290114\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:04 INFO 140632068241216] Epoch[70] Batch [5]#011Speed: 167.78 samples/sec#011loss=0.533585\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:05 INFO 140632068241216] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4303.796052932739, \"sum\": 4303.796052932739, \"min\": 4303.796052932739}}, \"EndTime\": 1587300905.700594, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300901.396346}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:05 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.357483675 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:05 INFO 140632068241216] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:05 INFO 140632068241216] #quality_metric: host=algo-1, epoch=70, train loss <loss>=0.594372576475\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:05 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:06 INFO 140632068241216] Epoch[71] Batch[0] avg_epoch_loss=0.577556\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=0.57755625248\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:08 INFO 140632068241216] Epoch[71] Batch[5] avg_epoch_loss=0.586422\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=0.586421822508\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:08 INFO 140632068241216] Epoch[71] Batch [5]#011Speed: 167.75 samples/sec#011loss=0.586422\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:10 INFO 140632068241216] Epoch[71] Batch[10] avg_epoch_loss=0.536177\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=0.475883877277\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:10 INFO 140632068241216] Epoch[71] Batch [10]#011Speed: 171.68 samples/sec#011loss=0.475884\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:10 INFO 140632068241216] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4614.719867706299, \"sum\": 4614.719867706299, \"min\": 4614.719867706299}}, \"EndTime\": 1587300910.315925, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300905.70068}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:10 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.283461248 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:10 INFO 140632068241216] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=71, train loss <loss>=0.536177301949\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:10 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:11 INFO 140632068241216] Epoch[72] Batch[0] avg_epoch_loss=0.865346\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:11 INFO 140632068241216] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=0.865345954895\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:13 INFO 140632068241216] Epoch[72] Batch[5] avg_epoch_loss=0.823577\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:13 INFO 140632068241216] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=0.823577105999\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:13 INFO 140632068241216] Epoch[72] Batch [5]#011Speed: 168.84 samples/sec#011loss=0.823577\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:14 INFO 140632068241216] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4256.887912750244, \"sum\": 4256.887912750244, \"min\": 4256.887912750244}}, \"EndTime\": 1587300914.573367, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300910.316002}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:14 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.35373939 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:14 INFO 140632068241216] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:14 INFO 140632068241216] #quality_metric: host=algo-1, epoch=72, train loss <loss>=0.802168911695\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:14 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:15 INFO 140632068241216] Epoch[73] Batch[0] avg_epoch_loss=0.782373\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:15 INFO 140632068241216] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=0.782373428345\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:17 INFO 140632068241216] Epoch[73] Batch[5] avg_epoch_loss=0.733379\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=0.733379433552\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:17 INFO 140632068241216] Epoch[73] Batch [5]#011Speed: 162.40 samples/sec#011loss=0.733379\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:19 INFO 140632068241216] Epoch[73] Batch[10] avg_epoch_loss=0.645619\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=0.540306693316\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:19 INFO 140632068241216] Epoch[73] Batch [10]#011Speed: 168.20 samples/sec#011loss=0.540307\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:19 INFO 140632068241216] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4728.907108306885, \"sum\": 4728.907108306885, \"min\": 4728.907108306885}}, \"EndTime\": 1587300919.30282, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300914.573442}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:19 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=139.352455322 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:19 INFO 140632068241216] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=73, train loss <loss>=0.645619097081\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:19 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:20 INFO 140632068241216] Epoch[74] Batch[0] avg_epoch_loss=0.398265\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:20 INFO 140632068241216] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=0.398265302181\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:22 INFO 140632068241216] Epoch[74] Batch[5] avg_epoch_loss=0.542974\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:22 INFO 140632068241216] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=0.542973697186\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:22 INFO 140632068241216] Epoch[74] Batch [5]#011Speed: 170.46 samples/sec#011loss=0.542974\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:23 INFO 140632068241216] Epoch[74] Batch[10] avg_epoch_loss=0.489816\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:23 INFO 140632068241216] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=0.426026630285\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:23 INFO 140632068241216] Epoch[74] Batch [10]#011Speed: 163.38 samples/sec#011loss=0.426027\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:23 INFO 140632068241216] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4680.292129516602, \"sum\": 4680.292129516602, \"min\": 4680.292129516602}}, \"EndTime\": 1587300923.983741, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300919.302889}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:23 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=136.953725866 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:23 INFO 140632068241216] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:23 INFO 140632068241216] #quality_metric: host=algo-1, epoch=74, train loss <loss>=0.489815939504\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:23 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:24 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_210c0192-912a-4682-921e-fce117d6b994-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 66.33305549621582, \"sum\": 66.33305549621582, \"min\": 66.33305549621582}}, \"EndTime\": 1587300924.050757, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300923.98383}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:24 INFO 140632068241216] Epoch[75] Batch[0] avg_epoch_loss=0.501879\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=0.501878798008\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:26 INFO 140632068241216] Epoch[75] Batch[5] avg_epoch_loss=0.524058\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:26 INFO 140632068241216] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=0.52405783534\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:26 INFO 140632068241216] Epoch[75] Batch [5]#011Speed: 170.72 samples/sec#011loss=0.524058\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:28 INFO 140632068241216] Epoch[75] Batch[10] avg_epoch_loss=0.451639\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:28 INFO 140632068241216] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=0.364736482501\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:28 INFO 140632068241216] Epoch[75] Batch [10]#011Speed: 170.43 samples/sec#011loss=0.364736\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:28 INFO 140632068241216] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4605.326890945435, \"sum\": 4605.326890945435, \"min\": 4605.326890945435}}, \"EndTime\": 1587300928.656208, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300924.050823}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:28 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.177256647 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:28 INFO 140632068241216] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:28 INFO 140632068241216] #quality_metric: host=algo-1, epoch=75, train loss <loss>=0.451639038595\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:28 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:28 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_1a30dcbc-4b6c-436b-96e3-12fe81cb1380-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 105.21316528320312, \"sum\": 105.21316528320312, \"min\": 105.21316528320312}}, \"EndTime\": 1587300928.761973, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300928.656286}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:29 INFO 140632068241216] Epoch[76] Batch[0] avg_epoch_loss=0.549446\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:29 INFO 140632068241216] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=0.549445509911\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:31 INFO 140632068241216] Epoch[76] Batch[5] avg_epoch_loss=0.501317\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=0.501316914956\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:31 INFO 140632068241216] Epoch[76] Batch [5]#011Speed: 169.94 samples/sec#011loss=0.501317\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:33 INFO 140632068241216] Epoch[76] Batch[10] avg_epoch_loss=0.464096\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:33 INFO 140632068241216] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=0.419431656599\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:33 INFO 140632068241216] Epoch[76] Batch [10]#011Speed: 164.48 samples/sec#011loss=0.419432\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:33 INFO 140632068241216] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4680.458068847656, \"sum\": 4680.458068847656, \"min\": 4680.458068847656}}, \"EndTime\": 1587300933.442572, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300928.762047}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:33 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.426666199 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:33 INFO 140632068241216] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:33 INFO 140632068241216] #quality_metric: host=algo-1, epoch=76, train loss <loss>=0.464096342975\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:33 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:34 INFO 140632068241216] Epoch[77] Batch[0] avg_epoch_loss=0.340439\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:34 INFO 140632068241216] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=0.340439110994\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:36 INFO 140632068241216] Epoch[77] Batch[5] avg_epoch_loss=0.698755\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=0.698754573862\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:36 INFO 140632068241216] Epoch[77] Batch [5]#011Speed: 168.63 samples/sec#011loss=0.698755\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:37 INFO 140632068241216] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4269.582986831665, \"sum\": 4269.582986831665, \"min\": 4269.582986831665}}, \"EndTime\": 1587300937.713032, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300933.442651}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:37 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.738543183 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:37 INFO 140632068241216] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:37 INFO 140632068241216] #quality_metric: host=algo-1, epoch=77, train loss <loss>=0.678453603387\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:37 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:38 INFO 140632068241216] Epoch[78] Batch[0] avg_epoch_loss=0.588571\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:38 INFO 140632068241216] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=0.588570535183\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:40 INFO 140632068241216] Epoch[78] Batch[5] avg_epoch_loss=0.580124\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=0.580123861631\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:40 INFO 140632068241216] Epoch[78] Batch [5]#011Speed: 168.69 samples/sec#011loss=0.580124\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:41 INFO 140632068241216] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4212.3401165008545, \"sum\": 4212.3401165008545, \"min\": 4212.3401165008545}}, \"EndTime\": 1587300941.926084, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300937.713104}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:41 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=149.793748171 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:41 INFO 140632068241216] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=78, train loss <loss>=0.503802397847\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:41 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:42 INFO 140632068241216] Epoch[79] Batch[0] avg_epoch_loss=0.489924\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:42 INFO 140632068241216] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=0.489923536777\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:44 INFO 140632068241216] Epoch[79] Batch[5] avg_epoch_loss=0.490463\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:44 INFO 140632068241216] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=0.490462755164\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:44 INFO 140632068241216] Epoch[79] Batch [5]#011Speed: 168.61 samples/sec#011loss=0.490463\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:46 INFO 140632068241216] Epoch[79] Batch[10] avg_epoch_loss=0.525253\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=0.567000466585\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:46 INFO 140632068241216] Epoch[79] Batch [10]#011Speed: 157.49 samples/sec#011loss=0.567000\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:46 INFO 140632068241216] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4824.9831199646, \"sum\": 4824.9831199646, \"min\": 4824.9831199646}}, \"EndTime\": 1587300946.751675, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300941.926162}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:46 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=132.846792212 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:46 INFO 140632068241216] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=79, train loss <loss>=0.525252623992\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:46 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:47 INFO 140632068241216] Epoch[80] Batch[0] avg_epoch_loss=0.486739\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:47 INFO 140632068241216] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=0.486738711596\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:49 INFO 140632068241216] Epoch[80] Batch[5] avg_epoch_loss=0.499070\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:49 INFO 140632068241216] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=0.499070319037\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:49 INFO 140632068241216] Epoch[80] Batch [5]#011Speed: 168.37 samples/sec#011loss=0.499070\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:51 INFO 140632068241216] Epoch[80] Batch[10] avg_epoch_loss=0.486915\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:51 INFO 140632068241216] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=0.472327882051\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:51 INFO 140632068241216] Epoch[80] Batch [10]#011Speed: 170.88 samples/sec#011loss=0.472328\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:51 INFO 140632068241216] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4726.830005645752, \"sum\": 4726.830005645752, \"min\": 4726.830005645752}}, \"EndTime\": 1587300951.479142, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300946.751759}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:51 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.105910105 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:51 INFO 140632068241216] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:51 INFO 140632068241216] #quality_metric: host=algo-1, epoch=80, train loss <loss>=0.486914665862\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:51 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:52 INFO 140632068241216] Epoch[81] Batch[0] avg_epoch_loss=0.581631\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=0.581631064415\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:54 INFO 140632068241216] Epoch[81] Batch[5] avg_epoch_loss=0.443714\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=0.443714094659\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:54 INFO 140632068241216] Epoch[81] Batch [5]#011Speed: 165.39 samples/sec#011loss=0.443714\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:55 INFO 140632068241216] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4273.96297454834, \"sum\": 4273.96297454834, \"min\": 4273.96297454834}}, \"EndTime\": 1587300955.753709, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300951.479219}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:55 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.721312757 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:55 INFO 140632068241216] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:55 INFO 140632068241216] #quality_metric: host=algo-1, epoch=81, train loss <loss>=0.453717382252\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:55 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:56 INFO 140632068241216] Epoch[82] Batch[0] avg_epoch_loss=0.316357\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:56 INFO 140632068241216] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=0.316356867552\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:58 INFO 140632068241216] Epoch[82] Batch[5] avg_epoch_loss=0.431684\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:58 INFO 140632068241216] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=0.431683778763\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:55:58 INFO 140632068241216] Epoch[82] Batch [5]#011Speed: 160.61 samples/sec#011loss=0.431684\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:00 INFO 140632068241216] Epoch[82] Batch[10] avg_epoch_loss=0.376786\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:00 INFO 140632068241216] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=0.310908044875\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:00 INFO 140632068241216] Epoch[82] Batch [10]#011Speed: 162.92 samples/sec#011loss=0.310908\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:00 INFO 140632068241216] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4794.587850570679, \"sum\": 4794.587850570679, \"min\": 4794.587850570679}}, \"EndTime\": 1587300960.548911, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300955.753774}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:00 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=133.689085068 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:00 INFO 140632068241216] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:00 INFO 140632068241216] #quality_metric: host=algo-1, epoch=82, train loss <loss>=0.376785717905\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:00 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:00 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_5520b02c-26e4-4efb-b114-0c78af199a25-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 65.86599349975586, \"sum\": 65.86599349975586, \"min\": 65.86599349975586}}, \"EndTime\": 1587300960.615408, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300960.548987}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:01 INFO 140632068241216] Epoch[83] Batch[0] avg_epoch_loss=1.011971\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:01 INFO 140632068241216] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=1.01197123528\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:03 INFO 140632068241216] Epoch[83] Batch[5] avg_epoch_loss=1.095500\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=1.09549985329\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:03 INFO 140632068241216] Epoch[83] Batch [5]#011Speed: 164.09 samples/sec#011loss=1.095500\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:05 INFO 140632068241216] Epoch[83] Batch[10] avg_epoch_loss=0.961493\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:05 INFO 140632068241216] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=0.800684976578\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:05 INFO 140632068241216] Epoch[83] Batch [10]#011Speed: 168.68 samples/sec#011loss=0.800685\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:05 INFO 140632068241216] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4707.441806793213, \"sum\": 4707.441806793213, \"min\": 4707.441806793213}}, \"EndTime\": 1587300965.323003, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300960.615487}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:05 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.685666364 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:05 INFO 140632068241216] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:05 INFO 140632068241216] #quality_metric: host=algo-1, epoch=83, train loss <loss>=0.96149309115\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:05 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:06 INFO 140632068241216] Epoch[84] Batch[0] avg_epoch_loss=0.727242\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=0.72724199295\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:08 INFO 140632068241216] Epoch[84] Batch[5] avg_epoch_loss=0.824775\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=0.824774990479\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:08 INFO 140632068241216] Epoch[84] Batch [5]#011Speed: 167.44 samples/sec#011loss=0.824775\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 140632068241216] Epoch[84] Batch[10] avg_epoch_loss=0.769514\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 140632068241216] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=0.703199833632\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 140632068241216] Epoch[84] Batch [10]#011Speed: 169.66 samples/sec#011loss=0.703200\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 140632068241216] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4643.610000610352, \"sum\": 4643.610000610352, \"min\": 4643.610000610352}}, \"EndTime\": 1587300969.96723, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300965.323094}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.850221354 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 140632068241216] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 140632068241216] #quality_metric: host=algo-1, epoch=84, train loss <loss>=0.769513555548\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:09 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:10 INFO 140632068241216] Epoch[85] Batch[0] avg_epoch_loss=0.612660\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=0.612659811974\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:12 INFO 140632068241216] Epoch[85] Batch[5] avg_epoch_loss=0.666219\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:12 INFO 140632068241216] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=0.666218648354\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:12 INFO 140632068241216] Epoch[85] Batch [5]#011Speed: 168.57 samples/sec#011loss=0.666219\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:14 INFO 140632068241216] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4283.806085586548, \"sum\": 4283.806085586548, \"min\": 4283.806085586548}}, \"EndTime\": 1587300974.251663, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300969.967304}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:14 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.959639737 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:14 INFO 140632068241216] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:14 INFO 140632068241216] #quality_metric: host=algo-1, epoch=85, train loss <loss>=0.731045925617\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:14 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:15 INFO 140632068241216] Epoch[86] Batch[0] avg_epoch_loss=0.644687\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:15 INFO 140632068241216] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=0.6446865201\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:17 INFO 140632068241216] Epoch[86] Batch[5] avg_epoch_loss=0.607880\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=0.607880339026\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:17 INFO 140632068241216] Epoch[86] Batch [5]#011Speed: 167.06 samples/sec#011loss=0.607880\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:18 INFO 140632068241216] Epoch[86] Batch[10] avg_epoch_loss=0.619388\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:18 INFO 140632068241216] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=0.633197516203\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:18 INFO 140632068241216] Epoch[86] Batch [10]#011Speed: 166.12 samples/sec#011loss=0.633198\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:18 INFO 140632068241216] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4695.060014724731, \"sum\": 4695.060014724731, \"min\": 4695.060014724731}}, \"EndTime\": 1587300978.947448, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300974.251735}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:18 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.190397652 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:18 INFO 140632068241216] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:18 INFO 140632068241216] #quality_metric: host=algo-1, epoch=86, train loss <loss>=0.619388146834\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:18 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:19 INFO 140632068241216] Epoch[87] Batch[0] avg_epoch_loss=0.605724\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=0.605723798275\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:21 INFO 140632068241216] Epoch[87] Batch[5] avg_epoch_loss=0.932434\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:21 INFO 140632068241216] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=0.932434141636\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:21 INFO 140632068241216] Epoch[87] Batch [5]#011Speed: 170.16 samples/sec#011loss=0.932434\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:23 INFO 140632068241216] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4283.447027206421, \"sum\": 4283.447027206421, \"min\": 4283.447027206421}}, \"EndTime\": 1587300983.231477, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300978.947531}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:23 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=149.408817195 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:23 INFO 140632068241216] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:23 INFO 140632068241216] #quality_metric: host=algo-1, epoch=87, train loss <loss>=0.864246070385\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:23 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:24 INFO 140632068241216] Epoch[88] Batch[0] avg_epoch_loss=0.798168\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=0.798167586327\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:25 INFO 140632068241216] Epoch[88] Batch[5] avg_epoch_loss=0.712985\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:25 INFO 140632068241216] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=0.712985257308\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:25 INFO 140632068241216] Epoch[88] Batch [5]#011Speed: 168.46 samples/sec#011loss=0.712985\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:27 INFO 140632068241216] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4243.813991546631, \"sum\": 4243.813991546631, \"min\": 4243.813991546631}}, \"EndTime\": 1587300987.475899, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300983.231537}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:27 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=148.682947262 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:27 INFO 140632068241216] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:27 INFO 140632068241216] #quality_metric: host=algo-1, epoch=88, train loss <loss>=0.660844197869\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:27 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:28 INFO 140632068241216] Epoch[89] Batch[0] avg_epoch_loss=0.527451\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:28 INFO 140632068241216] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=0.527451455593\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:30 INFO 140632068241216] Epoch[89] Batch[5] avg_epoch_loss=0.527694\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:30 INFO 140632068241216] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=0.527694334586\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:30 INFO 140632068241216] Epoch[89] Batch [5]#011Speed: 168.01 samples/sec#011loss=0.527694\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:31 INFO 140632068241216] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4298.410892486572, \"sum\": 4298.410892486572, \"min\": 4298.410892486572}}, \"EndTime\": 1587300991.774901, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300987.475976}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:31 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.631419768 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:31 INFO 140632068241216] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=89, train loss <loss>=0.525291693211\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:31 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:32 INFO 140632068241216] Epoch[90] Batch[0] avg_epoch_loss=0.417782\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:32 INFO 140632068241216] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=0.417781502008\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:34 INFO 140632068241216] Epoch[90] Batch[5] avg_epoch_loss=0.407343\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:34 INFO 140632068241216] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=0.407342751821\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:34 INFO 140632068241216] Epoch[90] Batch [5]#011Speed: 164.87 samples/sec#011loss=0.407343\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:36 INFO 140632068241216] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4299.007892608643, \"sum\": 4299.007892608643, \"min\": 4299.007892608643}}, \"EndTime\": 1587300996.074491, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300991.77497}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:36 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.581011938 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:36 INFO 140632068241216] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=90, train loss <loss>=0.426773265004\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:36 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:36 INFO 140632068241216] Epoch[91] Batch[0] avg_epoch_loss=0.207121\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=0.207121476531\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:38 INFO 140632068241216] Epoch[91] Batch[5] avg_epoch_loss=0.616176\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:38 INFO 140632068241216] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=0.61617560933\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:38 INFO 140632068241216] Epoch[91] Batch [5]#011Speed: 167.04 samples/sec#011loss=0.616176\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:40 INFO 140632068241216] Epoch[91] Batch[10] avg_epoch_loss=0.639986\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=0.668557476997\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:40 INFO 140632068241216] Epoch[91] Batch [10]#011Speed: 170.03 samples/sec#011loss=0.668557\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:40 INFO 140632068241216] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4704.44917678833, \"sum\": 4704.44917678833, \"min\": 4704.44917678833}}, \"EndTime\": 1587301000.77988, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587300996.07475}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:40 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.114450791 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:40 INFO 140632068241216] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=91, train loss <loss>=0.639985549179\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:40 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:41 INFO 140632068241216] Epoch[92] Batch[0] avg_epoch_loss=0.801219\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=0.801218509674\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:43 INFO 140632068241216] Epoch[92] Batch[5] avg_epoch_loss=0.537728\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=0.537727649013\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:43 INFO 140632068241216] Epoch[92] Batch [5]#011Speed: 168.28 samples/sec#011loss=0.537728\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:45 INFO 140632068241216] Epoch[92] Batch[10] avg_epoch_loss=0.461446\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:45 INFO 140632068241216] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=0.369908973575\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:45 INFO 140632068241216] Epoch[92] Batch [10]#011Speed: 170.46 samples/sec#011loss=0.369909\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:45 INFO 140632068241216] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4621.868848800659, \"sum\": 4621.868848800659, \"min\": 4621.868848800659}}, \"EndTime\": 1587301005.402379, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301000.779987}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:45 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.198014507 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:45 INFO 140632068241216] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:45 INFO 140632068241216] #quality_metric: host=algo-1, epoch=92, train loss <loss>=0.461446432905\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:45 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:46 INFO 140632068241216] Epoch[93] Batch[0] avg_epoch_loss=0.333198\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=0.333198130131\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:48 INFO 140632068241216] Epoch[93] Batch[5] avg_epoch_loss=0.406091\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=0.406091451645\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:48 INFO 140632068241216] Epoch[93] Batch [5]#011Speed: 161.82 samples/sec#011loss=0.406091\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:49 INFO 140632068241216] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4336.032152175903, \"sum\": 4336.032152175903, \"min\": 4336.032152175903}}, \"EndTime\": 1587301009.73907, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301005.4025}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:49 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.364829363 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:49 INFO 140632068241216] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:49 INFO 140632068241216] #quality_metric: host=algo-1, epoch=93, train loss <loss>=0.371067112684\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:49 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:49 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_7c26df4b-529f-4348-bb6e-9c8136f16fc3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 70.90091705322266, \"sum\": 70.90091705322266, \"min\": 70.90091705322266}}, \"EndTime\": 1587301009.810719, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301009.739154}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:50 INFO 140632068241216] Epoch[94] Batch[0] avg_epoch_loss=0.432907\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:50 INFO 140632068241216] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=0.432907402515\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:52 INFO 140632068241216] Epoch[94] Batch[5] avg_epoch_loss=0.428690\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=0.428689690928\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:52 INFO 140632068241216] Epoch[94] Batch [5]#011Speed: 168.83 samples/sec#011loss=0.428690\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:54 INFO 140632068241216] Epoch[94] Batch[10] avg_epoch_loss=0.340508\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=0.234688919783\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:54 INFO 140632068241216] Epoch[94] Batch [10]#011Speed: 163.35 samples/sec#011loss=0.234689\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:54 INFO 140632068241216] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4706.001043319702, \"sum\": 4706.001043319702, \"min\": 4706.001043319702}}, \"EndTime\": 1587301014.516848, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301009.81079}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:54 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=139.393256833 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:54 INFO 140632068241216] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=94, train loss <loss>=0.340507522225\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:54 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:54 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_a3962fd3-bbd2-4c03-9743-f7c0545d0494-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 65.68312644958496, \"sum\": 65.68312644958496, \"min\": 65.68312644958496}}, \"EndTime\": 1587301014.58318, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301014.516922}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:55 INFO 140632068241216] Epoch[95] Batch[0] avg_epoch_loss=0.381616\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:55 INFO 140632068241216] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=0.381616353989\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:57 INFO 140632068241216] Epoch[95] Batch[5] avg_epoch_loss=0.333556\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=0.333556368947\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:57 INFO 140632068241216] Epoch[95] Batch [5]#011Speed: 169.73 samples/sec#011loss=0.333556\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:58 INFO 140632068241216] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4258.881092071533, \"sum\": 4258.881092071533, \"min\": 4258.881092071533}}, \"EndTime\": 1587301018.842208, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301014.583259}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:58 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=150.03504094 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:58 INFO 140632068241216] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:58 INFO 140632068241216] #quality_metric: host=algo-1, epoch=95, train loss <loss>=0.348007389903\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:58 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:59 INFO 140632068241216] Epoch[96] Batch[0] avg_epoch_loss=0.284235\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:56:59 INFO 140632068241216] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=0.284234553576\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:01 INFO 140632068241216] Epoch[96] Batch[5] avg_epoch_loss=0.368136\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:01 INFO 140632068241216] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=0.368136391044\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:01 INFO 140632068241216] Epoch[96] Batch [5]#011Speed: 166.31 samples/sec#011loss=0.368136\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:03 INFO 140632068241216] Epoch[96] Batch[10] avg_epoch_loss=0.342246\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=0.311176586151\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:03 INFO 140632068241216] Epoch[96] Batch [10]#011Speed: 167.40 samples/sec#011loss=0.311177\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:03 INFO 140632068241216] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4716.689109802246, \"sum\": 4716.689109802246, \"min\": 4716.689109802246}}, \"EndTime\": 1587301023.559449, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301018.84229}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:03 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.440848049 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:03 INFO 140632068241216] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=96, train loss <loss>=0.342245570638\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:03 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:04 INFO 140632068241216] Epoch[97] Batch[0] avg_epoch_loss=0.298470\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:04 INFO 140632068241216] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=0.298470258713\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:06 INFO 140632068241216] Epoch[97] Batch[5] avg_epoch_loss=0.328220\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=0.328219632308\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:06 INFO 140632068241216] Epoch[97] Batch [5]#011Speed: 168.74 samples/sec#011loss=0.328220\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:07 INFO 140632068241216] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4272.579908370972, \"sum\": 4272.579908370972, \"min\": 4272.579908370972}}, \"EndTime\": 1587301027.832678, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301023.559536}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:07 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.830563541 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:07 INFO 140632068241216] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:07 INFO 140632068241216] #quality_metric: host=algo-1, epoch=97, train loss <loss>=0.346708443761\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:07 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:08 INFO 140632068241216] Epoch[98] Batch[0] avg_epoch_loss=0.476743\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=0.47674331069\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:10 INFO 140632068241216] Epoch[98] Batch[5] avg_epoch_loss=0.392169\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=0.392169083158\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:10 INFO 140632068241216] Epoch[98] Batch [5]#011Speed: 168.37 samples/sec#011loss=0.392169\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:12 INFO 140632068241216] Epoch[98] Batch[10] avg_epoch_loss=0.311335\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:12 INFO 140632068241216] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=0.214333094191\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:12 INFO 140632068241216] Epoch[98] Batch [10]#011Speed: 168.54 samples/sec#011loss=0.214333\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:12 INFO 140632068241216] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4688.731908798218, \"sum\": 4688.731908798218, \"min\": 4688.731908798218}}, \"EndTime\": 1587301032.522008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301027.832762}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:12 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.62682894 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:12 INFO 140632068241216] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:12 INFO 140632068241216] #quality_metric: host=algo-1, epoch=98, train loss <loss>=0.311334542718\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:12 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:12 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_75c03323-8bf9-4883-b136-0b4521911443-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 70.27006149291992, \"sum\": 70.27006149291992, \"min\": 70.27006149291992}}, \"EndTime\": 1587301032.592828, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301032.522086}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:13 INFO 140632068241216] Epoch[99] Batch[0] avg_epoch_loss=0.827012\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:13 INFO 140632068241216] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=0.82701164484\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:15 INFO 140632068241216] Epoch[99] Batch[5] avg_epoch_loss=0.587569\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:15 INFO 140632068241216] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=0.587569410602\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:15 INFO 140632068241216] Epoch[99] Batch [5]#011Speed: 167.36 samples/sec#011loss=0.587569\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:17 INFO 140632068241216] Epoch[99] Batch[10] avg_epoch_loss=0.486263\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=0.364695441164\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:17 INFO 140632068241216] Epoch[99] Batch [10]#011Speed: 163.98 samples/sec#011loss=0.364695\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:17 INFO 140632068241216] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4738.485097885132, \"sum\": 4738.485097885132, \"min\": 4738.485097885132}}, \"EndTime\": 1587301037.331454, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301032.592903}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:17 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=136.116069818 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:17 INFO 140632068241216] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=99, train loss <loss>=0.486263060858\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:17 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:18 INFO 140632068241216] Epoch[100] Batch[0] avg_epoch_loss=0.403065\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:18 INFO 140632068241216] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=0.403064936399\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:20 INFO 140632068241216] Epoch[100] Batch[5] avg_epoch_loss=0.400603\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:20 INFO 140632068241216] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=0.400603423516\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:20 INFO 140632068241216] Epoch[100] Batch [5]#011Speed: 163.64 samples/sec#011loss=0.400603\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:21 INFO 140632068241216] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4297.706127166748, \"sum\": 4297.706127166748, \"min\": 4297.706127166748}}, \"EndTime\": 1587301041.62975, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301037.331532}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:21 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.818347782 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:21 INFO 140632068241216] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:21 INFO 140632068241216] #quality_metric: host=algo-1, epoch=100, train loss <loss>=0.413514283299\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:21 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:22 INFO 140632068241216] Epoch[101] Batch[0] avg_epoch_loss=0.558193\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:22 INFO 140632068241216] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=0.558193087578\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:24 INFO 140632068241216] Epoch[101] Batch[5] avg_epoch_loss=0.486089\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=0.486089065671\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:24 INFO 140632068241216] Epoch[101] Batch [5]#011Speed: 164.27 samples/sec#011loss=0.486089\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:26 INFO 140632068241216] Epoch[101] Batch[10] avg_epoch_loss=0.500215\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:26 INFO 140632068241216] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=0.51716504097\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:26 INFO 140632068241216] Epoch[101] Batch [10]#011Speed: 166.97 samples/sec#011loss=0.517165\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:26 INFO 140632068241216] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4783.995151519775, \"sum\": 4783.995151519775, \"min\": 4783.995151519775}}, \"EndTime\": 1587301046.414279, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301041.629831}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:26 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.882428374 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:26 INFO 140632068241216] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:26 INFO 140632068241216] #quality_metric: host=algo-1, epoch=101, train loss <loss>=0.500214508989\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:26 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:27 INFO 140632068241216] Epoch[102] Batch[0] avg_epoch_loss=0.444848\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:27 INFO 140632068241216] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=0.444847762585\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:29 INFO 140632068241216] Epoch[102] Batch[5] avg_epoch_loss=0.430729\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:29 INFO 140632068241216] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=0.430729498466\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:29 INFO 140632068241216] Epoch[102] Batch [5]#011Speed: 166.58 samples/sec#011loss=0.430729\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:31 INFO 140632068241216] Epoch[102] Batch[10] avg_epoch_loss=0.318697\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=0.184257248044\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:31 INFO 140632068241216] Epoch[102] Batch [10]#011Speed: 172.38 samples/sec#011loss=0.184257\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:31 INFO 140632068241216] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4678.264856338501, \"sum\": 4678.264856338501, \"min\": 4678.264856338501}}, \"EndTime\": 1587301051.093384, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301046.41436}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:31 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.079684246 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:31 INFO 140632068241216] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=102, train loss <loss>=0.318696657365\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:31 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:31 INFO 140632068241216] Epoch[103] Batch[0] avg_epoch_loss=0.466038\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=0.466038107872\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:33 INFO 140632068241216] Epoch[103] Batch[5] avg_epoch_loss=0.363579\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:33 INFO 140632068241216] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=0.363578503331\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:33 INFO 140632068241216] Epoch[103] Batch [5]#011Speed: 165.07 samples/sec#011loss=0.363579\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:35 INFO 140632068241216] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4283.4038734436035, \"sum\": 4283.4038734436035, \"min\": 4283.4038734436035}}, \"EndTime\": 1587301055.377493, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301051.093463}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:35 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.907291674 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:35 INFO 140632068241216] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:35 INFO 140632068241216] #quality_metric: host=algo-1, epoch=103, train loss <loss>=0.332142077386\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:35 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:36 INFO 140632068241216] Epoch[104] Batch[0] avg_epoch_loss=0.339884\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=0.339884281158\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:38 INFO 140632068241216] Epoch[104] Batch[5] avg_epoch_loss=0.227683\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:38 INFO 140632068241216] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=0.227682884783\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:38 INFO 140632068241216] Epoch[104] Batch [5]#011Speed: 169.26 samples/sec#011loss=0.227683\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:39 INFO 140632068241216] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4267.587900161743, \"sum\": 4267.587900161743, \"min\": 4267.587900161743}}, \"EndTime\": 1587301059.645745, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301055.377561}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:39 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.809254993 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:39 INFO 140632068241216] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:39 INFO 140632068241216] #quality_metric: host=algo-1, epoch=104, train loss <loss>=0.267175652832\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:39 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:39 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_c1b67193-7138-4f04-a719-811ea6d07f72-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 66.41507148742676, \"sum\": 66.41507148742676, \"min\": 66.41507148742676}}, \"EndTime\": 1587301059.712812, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301059.645801}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:40 INFO 140632068241216] Epoch[105] Batch[0] avg_epoch_loss=1.229377\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=1.22937679291\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:42 INFO 140632068241216] Epoch[105] Batch[5] avg_epoch_loss=0.836766\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:42 INFO 140632068241216] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=0.836765537659\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:42 INFO 140632068241216] Epoch[105] Batch [5]#011Speed: 169.12 samples/sec#011loss=0.836766\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:43 INFO 140632068241216] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4262.115955352783, \"sum\": 4262.115955352783, \"min\": 4262.115955352783}}, \"EndTime\": 1587301063.975311, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301059.713124}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:43 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.105609637 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:43 INFO 140632068241216] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=105, train loss <loss>=0.834170371294\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:43 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:44 INFO 140632068241216] Epoch[106] Batch[0] avg_epoch_loss=0.752035\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:44 INFO 140632068241216] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=0.752035498619\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:46 INFO 140632068241216] Epoch[106] Batch[5] avg_epoch_loss=0.618230\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=0.618229637543\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:46 INFO 140632068241216] Epoch[106] Batch [5]#011Speed: 169.29 samples/sec#011loss=0.618230\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:48 INFO 140632068241216] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4342.189073562622, \"sum\": 4342.189073562622, \"min\": 4342.189073562622}}, \"EndTime\": 1587301068.318243, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301063.975398}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:48 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.708418023 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:48 INFO 140632068241216] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=106, train loss <loss>=0.57782292068\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:48 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:49 INFO 140632068241216] Epoch[107] Batch[0] avg_epoch_loss=0.348044\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:49 INFO 140632068241216] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=0.34804391861\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:51 INFO 140632068241216] Epoch[107] Batch[5] avg_epoch_loss=0.250065\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:51 INFO 140632068241216] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=0.250064676628\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:51 INFO 140632068241216] Epoch[107] Batch [5]#011Speed: 170.18 samples/sec#011loss=0.250065\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:52 INFO 140632068241216] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4266.680002212524, \"sum\": 4266.680002212524, \"min\": 4266.680002212524}}, \"EndTime\": 1587301072.585539, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301068.318323}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:52 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.651910685 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:52 INFO 140632068241216] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=107, train loss <loss>=0.291009375826\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:52 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:53 INFO 140632068241216] Epoch[108] Batch[0] avg_epoch_loss=0.210921\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:53 INFO 140632068241216] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=0.210920840502\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:55 INFO 140632068241216] Epoch[108] Batch[5] avg_epoch_loss=0.232370\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:55 INFO 140632068241216] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=0.232370453576\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:55 INFO 140632068241216] Epoch[108] Batch [5]#011Speed: 159.12 samples/sec#011loss=0.232370\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:57 INFO 140632068241216] Epoch[108] Batch[10] avg_epoch_loss=0.271242\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=0.317887048423\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:57 INFO 140632068241216] Epoch[108] Batch [10]#011Speed: 166.37 samples/sec#011loss=0.317887\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:57 INFO 140632068241216] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4835.792779922485, \"sum\": 4835.792779922485, \"min\": 4835.792779922485}}, \"EndTime\": 1587301077.422066, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301072.58561}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:57 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=137.512638343 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:57 INFO 140632068241216] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=108, train loss <loss>=0.271241633052\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:57 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:58 INFO 140632068241216] Epoch[109] Batch[0] avg_epoch_loss=2.251588\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:57:58 INFO 140632068241216] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.25158762932\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:00 INFO 140632068241216] Epoch[109] Batch[5] avg_epoch_loss=1.414182\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:00 INFO 140632068241216] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=1.41418200731\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:00 INFO 140632068241216] Epoch[109] Batch [5]#011Speed: 164.52 samples/sec#011loss=1.414182\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:01 INFO 140632068241216] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4304.734945297241, \"sum\": 4304.734945297241, \"min\": 4304.734945297241}}, \"EndTime\": 1587301081.727376, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301077.422149}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:01 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.740172254 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:01 INFO 140632068241216] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:01 INFO 140632068241216] #quality_metric: host=algo-1, epoch=109, train loss <loss>=1.35506558418\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:01 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:02 INFO 140632068241216] Epoch[110] Batch[0] avg_epoch_loss=1.363127\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:02 INFO 140632068241216] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=1.3631272316\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:04 INFO 140632068241216] Epoch[110] Batch[5] avg_epoch_loss=1.232087\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:04 INFO 140632068241216] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=1.23208691676\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:04 INFO 140632068241216] Epoch[110] Batch [5]#011Speed: 157.52 samples/sec#011loss=1.232087\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:06 INFO 140632068241216] Epoch[110] Batch[10] avg_epoch_loss=1.079858\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=0.897183203697\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:06 INFO 140632068241216] Epoch[110] Batch [10]#011Speed: 168.43 samples/sec#011loss=0.897183\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:06 INFO 140632068241216] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4850.2678871154785, \"sum\": 4850.2678871154785, \"min\": 4850.2678871154785}}, \"EndTime\": 1587301086.578216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301081.727459}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:06 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.493405636 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:06 INFO 140632068241216] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=110, train loss <loss>=1.07985795628\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:06 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:07 INFO 140632068241216] Epoch[111] Batch[0] avg_epoch_loss=0.731965\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:07 INFO 140632068241216] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=0.73196542263\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:09 INFO 140632068241216] Epoch[111] Batch[5] avg_epoch_loss=0.646040\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:09 INFO 140632068241216] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=0.646039694548\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:09 INFO 140632068241216] Epoch[111] Batch [5]#011Speed: 165.19 samples/sec#011loss=0.646040\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:10 INFO 140632068241216] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4281.862020492554, \"sum\": 4281.862020492554, \"min\": 4281.862020492554}}, \"EndTime\": 1587301090.860767, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301086.578303}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:10 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.828395316 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:10 INFO 140632068241216] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=111, train loss <loss>=0.548985257745\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:10 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:11 INFO 140632068241216] Epoch[112] Batch[0] avg_epoch_loss=0.368089\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:11 INFO 140632068241216] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=0.368089437485\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:13 INFO 140632068241216] Epoch[112] Batch[5] avg_epoch_loss=0.270515\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:13 INFO 140632068241216] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=0.270515076816\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:13 INFO 140632068241216] Epoch[112] Batch [5]#011Speed: 168.52 samples/sec#011loss=0.270515\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:15 INFO 140632068241216] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4311.681032180786, \"sum\": 4311.681032180786, \"min\": 4311.681032180786}}, \"EndTime\": 1587301095.173069, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301090.860854}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:15 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.023512989 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:15 INFO 140632068241216] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:15 INFO 140632068241216] #quality_metric: host=algo-1, epoch=112, train loss <loss>=0.277274259925\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:15 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:16 INFO 140632068241216] Epoch[113] Batch[0] avg_epoch_loss=0.356701\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:16 INFO 140632068241216] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=0.356701374054\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:17 INFO 140632068241216] Epoch[113] Batch[5] avg_epoch_loss=0.540051\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=0.540050605933\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:17 INFO 140632068241216] Epoch[113] Batch [5]#011Speed: 165.33 samples/sec#011loss=0.540051\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:19 INFO 140632068241216] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4336.166143417358, \"sum\": 4336.166143417358, \"min\": 4336.166143417358}}, \"EndTime\": 1587301099.509747, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301095.173145}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:19 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.900548516 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:19 INFO 140632068241216] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=113, train loss <loss>=0.503646989167\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:19 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:20 INFO 140632068241216] Epoch[114] Batch[0] avg_epoch_loss=0.346124\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:20 INFO 140632068241216] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=0.346123635769\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:22 INFO 140632068241216] Epoch[114] Batch[5] avg_epoch_loss=0.401654\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:22 INFO 140632068241216] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=0.401653699577\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:22 INFO 140632068241216] Epoch[114] Batch [5]#011Speed: 169.98 samples/sec#011loss=0.401654\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:24 INFO 140632068241216] Epoch[114] Batch[10] avg_epoch_loss=0.363121\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=0.316880974174\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:24 INFO 140632068241216] Epoch[114] Batch [10]#011Speed: 168.95 samples/sec#011loss=0.316881\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:24 INFO 140632068241216] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4639.18399810791, \"sum\": 4639.18399810791, \"min\": 4639.18399810791}}, \"EndTime\": 1587301104.149519, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301099.509815}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:24 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=148.298078773 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:24 INFO 140632068241216] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=114, train loss <loss>=0.363120642575\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:24 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:24 INFO 140632068241216] Epoch[115] Batch[0] avg_epoch_loss=0.440213\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=0.440213143826\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:26 INFO 140632068241216] Epoch[115] Batch[5] avg_epoch_loss=0.317167\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:26 INFO 140632068241216] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=0.317167388896\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:26 INFO 140632068241216] Epoch[115] Batch [5]#011Speed: 168.52 samples/sec#011loss=0.317167\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:28 INFO 140632068241216] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4253.921031951904, \"sum\": 4253.921031951904, \"min\": 4253.921031951904}}, \"EndTime\": 1587301108.404006, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301104.1496}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:28 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.33349168 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:28 INFO 140632068241216] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:28 INFO 140632068241216] #quality_metric: host=algo-1, epoch=115, train loss <loss>=0.275346821547\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:28 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:29 INFO 140632068241216] Epoch[116] Batch[0] avg_epoch_loss=0.297763\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:29 INFO 140632068241216] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=0.297763377428\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:31 INFO 140632068241216] Epoch[116] Batch[5] avg_epoch_loss=0.185058\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=0.185057681054\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:31 INFO 140632068241216] Epoch[116] Batch [5]#011Speed: 168.02 samples/sec#011loss=0.185058\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:32 INFO 140632068241216] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4281.576871871948, \"sum\": 4281.576871871948, \"min\": 4281.576871871948}}, \"EndTime\": 1587301112.686148, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301108.404081}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:32 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.999866249 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:32 INFO 140632068241216] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:32 INFO 140632068241216] #quality_metric: host=algo-1, epoch=116, train loss <loss>=0.191557078063\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:32 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:32 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_f5c2983e-5c19-4e4a-8b5b-0655985a9f2d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 76.13682746887207, \"sum\": 76.13682746887207, \"min\": 76.13682746887207}}, \"EndTime\": 1587301112.76297, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301112.686225}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:33 INFO 140632068241216] Epoch[117] Batch[0] avg_epoch_loss=0.367548\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:33 INFO 140632068241216] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=0.367548495531\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:35 INFO 140632068241216] Epoch[117] Batch[5] avg_epoch_loss=0.476080\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:35 INFO 140632068241216] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=0.476080194116\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:35 INFO 140632068241216] Epoch[117] Batch [5]#011Speed: 166.42 samples/sec#011loss=0.476080\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:37 INFO 140632068241216] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4280.020952224731, \"sum\": 4280.020952224731, \"min\": 4280.020952224731}}, \"EndTime\": 1587301117.043139, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301112.763046}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:37 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=149.526630802 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:37 INFO 140632068241216] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:37 INFO 140632068241216] #quality_metric: host=algo-1, epoch=117, train loss <loss>=0.450397661328\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:37 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:37 INFO 140632068241216] Epoch[118] Batch[0] avg_epoch_loss=0.400893\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:37 INFO 140632068241216] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=0.400892615318\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:39 INFO 140632068241216] Epoch[118] Batch[5] avg_epoch_loss=0.296881\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:39 INFO 140632068241216] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=0.296880799035\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:39 INFO 140632068241216] Epoch[118] Batch [5]#011Speed: 167.10 samples/sec#011loss=0.296881\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:41 INFO 140632068241216] Epoch[118] Batch[10] avg_epoch_loss=0.279991\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=0.259724339843\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:41 INFO 140632068241216] Epoch[118] Batch [10]#011Speed: 165.48 samples/sec#011loss=0.259724\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:41 INFO 140632068241216] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4749.641895294189, \"sum\": 4749.641895294189, \"min\": 4749.641895294189}}, \"EndTime\": 1587301121.793355, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301117.043252}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:41 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.691457628 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:41 INFO 140632068241216] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=118, train loss <loss>=0.279991499402\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:41 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:42 INFO 140632068241216] Epoch[119] Batch[0] avg_epoch_loss=0.316988\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:42 INFO 140632068241216] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=0.316987663507\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:44 INFO 140632068241216] Epoch[119] Batch[5] avg_epoch_loss=0.423435\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:44 INFO 140632068241216] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=0.423435151577\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:44 INFO 140632068241216] Epoch[119] Batch [5]#011Speed: 167.45 samples/sec#011loss=0.423435\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:46 INFO 140632068241216] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4265.541076660156, \"sum\": 4265.541076660156, \"min\": 4265.541076660156}}, \"EndTime\": 1587301126.059389, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301121.793434}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:46 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.471918023 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:46 INFO 140632068241216] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=119, train loss <loss>=0.362036782503\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:46 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:46 INFO 140632068241216] Epoch[120] Batch[0] avg_epoch_loss=0.417182\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=0.417182058096\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:48 INFO 140632068241216] Epoch[120] Batch[5] avg_epoch_loss=0.296830\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=0.296830457946\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:48 INFO 140632068241216] Epoch[120] Batch [5]#011Speed: 164.15 samples/sec#011loss=0.296830\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:50 INFO 140632068241216] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4300.235986709595, \"sum\": 4300.235986709595, \"min\": 4300.235986709595}}, \"EndTime\": 1587301130.360341, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301126.059451}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:50 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.098669808 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:50 INFO 140632068241216] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:50 INFO 140632068241216] #quality_metric: host=algo-1, epoch=120, train loss <loss>=0.281028832495\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:50 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:51 INFO 140632068241216] Epoch[121] Batch[0] avg_epoch_loss=0.484603\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:51 INFO 140632068241216] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=0.484603375196\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:53 INFO 140632068241216] Epoch[121] Batch[5] avg_epoch_loss=0.276469\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:53 INFO 140632068241216] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=0.276468892892\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:53 INFO 140632068241216] Epoch[121] Batch [5]#011Speed: 169.36 samples/sec#011loss=0.276469\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:54 INFO 140632068241216] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4270.545959472656, \"sum\": 4270.545959472656, \"min\": 4270.545959472656}}, \"EndTime\": 1587301134.631669, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301130.360413}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:54 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.112833738 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:54 INFO 140632068241216] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=121, train loss <loss>=0.221205078531\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:54 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:55 INFO 140632068241216] Epoch[122] Batch[0] avg_epoch_loss=0.101917\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:55 INFO 140632068241216] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=0.101916648448\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:57 INFO 140632068241216] Epoch[122] Batch[5] avg_epoch_loss=0.047109\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=0.0471086635565\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:57 INFO 140632068241216] Epoch[122] Batch [5]#011Speed: 168.29 samples/sec#011loss=0.047109\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:59 INFO 140632068241216] Epoch[122] Batch[10] avg_epoch_loss=0.263471\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:59 INFO 140632068241216] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=0.523105952889\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:59 INFO 140632068241216] Epoch[122] Batch [10]#011Speed: 169.13 samples/sec#011loss=0.523106\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:59 INFO 140632068241216] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4652.390956878662, \"sum\": 4652.390956878662, \"min\": 4652.390956878662}}, \"EndTime\": 1587301139.284667, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301134.631752}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:59 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.223324062 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:59 INFO 140632068241216] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:59 INFO 140632068241216] #quality_metric: host=algo-1, epoch=122, train loss <loss>=0.263471067798\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:58:59 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:00 INFO 140632068241216] Epoch[123] Batch[0] avg_epoch_loss=0.778547\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:00 INFO 140632068241216] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=0.778546988964\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:02 INFO 140632068241216] Epoch[123] Batch[5] avg_epoch_loss=0.572997\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:02 INFO 140632068241216] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=0.572997187575\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:02 INFO 140632068241216] Epoch[123] Batch [5]#011Speed: 168.74 samples/sec#011loss=0.572997\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:03 INFO 140632068241216] Epoch[123] Batch[10] avg_epoch_loss=0.593649\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=0.618430173397\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:03 INFO 140632068241216] Epoch[123] Batch [10]#011Speed: 168.28 samples/sec#011loss=0.618430\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:03 INFO 140632068241216] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4649.907112121582, \"sum\": 4649.907112121582, \"min\": 4649.907112121582}}, \"EndTime\": 1587301143.935221, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301139.284747}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:03 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.149988087 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:03 INFO 140632068241216] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=123, train loss <loss>=0.593648544767\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:03 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:04 INFO 140632068241216] Epoch[124] Batch[0] avg_epoch_loss=0.449380\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:04 INFO 140632068241216] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=0.449379891157\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:06 INFO 140632068241216] Epoch[124] Batch[5] avg_epoch_loss=0.326284\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=0.326284326613\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:06 INFO 140632068241216] Epoch[124] Batch [5]#011Speed: 168.60 samples/sec#011loss=0.326284\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:08 INFO 140632068241216] Epoch[124] Batch[10] avg_epoch_loss=0.226348\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=0.106424932182\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:08 INFO 140632068241216] Epoch[124] Batch [10]#011Speed: 169.22 samples/sec#011loss=0.106425\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:08 INFO 140632068241216] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4635.628938674927, \"sum\": 4635.628938674927, \"min\": 4635.628938674927}}, \"EndTime\": 1587301148.571317, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301143.935295}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:08 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.862177498 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:08 INFO 140632068241216] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=124, train loss <loss>=0.226348238235\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:08 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:09 INFO 140632068241216] Epoch[125] Batch[0] avg_epoch_loss=0.792343\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:09 INFO 140632068241216] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=0.792342722416\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:11 INFO 140632068241216] Epoch[125] Batch[5] avg_epoch_loss=0.455392\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:11 INFO 140632068241216] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=0.455391774575\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:11 INFO 140632068241216] Epoch[125] Batch [5]#011Speed: 167.98 samples/sec#011loss=0.455392\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:12 INFO 140632068241216] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4277.808904647827, \"sum\": 4277.808904647827, \"min\": 4277.808904647827}}, \"EndTime\": 1587301152.849619, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301148.571389}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:12 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.333139514 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:12 INFO 140632068241216] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:12 INFO 140632068241216] #quality_metric: host=algo-1, epoch=125, train loss <loss>=0.473830267787\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:12 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:13 INFO 140632068241216] Epoch[126] Batch[0] avg_epoch_loss=0.471456\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:13 INFO 140632068241216] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=0.471456199884\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:15 INFO 140632068241216] Epoch[126] Batch[5] avg_epoch_loss=0.305654\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:15 INFO 140632068241216] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=0.305653703709\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:15 INFO 140632068241216] Epoch[126] Batch [5]#011Speed: 167.91 samples/sec#011loss=0.305654\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:17 INFO 140632068241216] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4244.728088378906, \"sum\": 4244.728088378906, \"min\": 4244.728088378906}}, \"EndTime\": 1587301157.095119, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301152.849687}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:17 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.761495601 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:17 INFO 140632068241216] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=126, train loss <loss>=0.320800964534\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:17 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:18 INFO 140632068241216] Epoch[127] Batch[0] avg_epoch_loss=0.113974\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:18 INFO 140632068241216] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=0.113973706961\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:19 INFO 140632068241216] Epoch[127] Batch[5] avg_epoch_loss=0.250037\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=0.25003704646\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:19 INFO 140632068241216] Epoch[127] Batch [5]#011Speed: 169.91 samples/sec#011loss=0.250037\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:21 INFO 140632068241216] Epoch[127] Batch[10] avg_epoch_loss=0.234002\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:21 INFO 140632068241216] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=0.214759975672\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:21 INFO 140632068241216] Epoch[127] Batch [10]#011Speed: 168.33 samples/sec#011loss=0.214760\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:22 INFO 140632068241216] processed a total of 710 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 5138.081073760986, \"sum\": 5138.081073760986, \"min\": 5138.081073760986}}, \"EndTime\": 1587301162.233701, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301157.095193}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:22 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.180793643 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:22 INFO 140632068241216] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:22 INFO 140632068241216] #quality_metric: host=algo-1, epoch=127, train loss <loss>=0.186615088178\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:22 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:22 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_583aa90e-ef71-460e-9138-563d39f6a1ed-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 71.1829662322998, \"sum\": 71.1829662322998, \"min\": 71.1829662322998}}, \"EndTime\": 1587301162.305464, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301162.233778}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:23 INFO 140632068241216] Epoch[128] Batch[0] avg_epoch_loss=0.217943\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:23 INFO 140632068241216] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=0.21794347465\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:25 INFO 140632068241216] Epoch[128] Batch[5] avg_epoch_loss=0.199609\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:25 INFO 140632068241216] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=0.199608530849\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:25 INFO 140632068241216] Epoch[128] Batch [5]#011Speed: 163.55 samples/sec#011loss=0.199609\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:26 INFO 140632068241216] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4313.326120376587, \"sum\": 4313.326120376587, \"min\": 4313.326120376587}}, \"EndTime\": 1587301166.618933, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301162.305541}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:26 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.982484458 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:26 INFO 140632068241216] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:26 INFO 140632068241216] #quality_metric: host=algo-1, epoch=128, train loss <loss>=0.262022493035\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:26 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:27 INFO 140632068241216] Epoch[129] Batch[0] avg_epoch_loss=0.347919\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:27 INFO 140632068241216] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=0.347918868065\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:29 INFO 140632068241216] Epoch[129] Batch[5] avg_epoch_loss=0.312535\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:29 INFO 140632068241216] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=0.312534650167\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:29 INFO 140632068241216] Epoch[129] Batch [5]#011Speed: 165.91 samples/sec#011loss=0.312535\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:30 INFO 140632068241216] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4273.531913757324, \"sum\": 4273.531913757324, \"min\": 4273.531913757324}}, \"EndTime\": 1587301170.893145, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301166.619006}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:30 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.542560281 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:30 INFO 140632068241216] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:30 INFO 140632068241216] #quality_metric: host=algo-1, epoch=129, train loss <loss>=0.381935417652\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:30 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:31 INFO 140632068241216] Epoch[130] Batch[0] avg_epoch_loss=0.399596\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=0.39959576726\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:33 INFO 140632068241216] Epoch[130] Batch[5] avg_epoch_loss=0.403105\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:33 INFO 140632068241216] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=0.403105097512\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:33 INFO 140632068241216] Epoch[130] Batch [5]#011Speed: 168.01 samples/sec#011loss=0.403105\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:35 INFO 140632068241216] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4234.967947006226, \"sum\": 4234.967947006226, \"min\": 4234.967947006226}}, \"EndTime\": 1587301175.128885, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301170.893233}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:35 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.438072164 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:35 INFO 140632068241216] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:35 INFO 140632068241216] #quality_metric: host=algo-1, epoch=130, train loss <loss>=0.31336536631\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:35 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:35 INFO 140632068241216] Epoch[131] Batch[0] avg_epoch_loss=0.165682\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:35 INFO 140632068241216] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=0.165682464838\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:37 INFO 140632068241216] Epoch[131] Batch[5] avg_epoch_loss=0.198281\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:37 INFO 140632068241216] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=0.198281275729\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:37 INFO 140632068241216] Epoch[131] Batch [5]#011Speed: 168.01 samples/sec#011loss=0.198281\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:39 INFO 140632068241216] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4257.217168807983, \"sum\": 4257.217168807983, \"min\": 4257.217168807983}}, \"EndTime\": 1587301179.386775, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301175.128948}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:39 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.51748033 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:39 INFO 140632068241216] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:39 INFO 140632068241216] #quality_metric: host=algo-1, epoch=131, train loss <loss>=0.183116050065\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:39 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:39 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_df21f131-fc63-44d0-b03c-d58921a4acef-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 66.87402725219727, \"sum\": 66.87402725219727, \"min\": 66.87402725219727}}, \"EndTime\": 1587301179.454199, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301179.386845}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:40 INFO 140632068241216] Epoch[132] Batch[0] avg_epoch_loss=0.741701\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=0.741701364517\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:42 INFO 140632068241216] Epoch[132] Batch[5] avg_epoch_loss=0.477768\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:42 INFO 140632068241216] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=0.477768239876\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:42 INFO 140632068241216] Epoch[132] Batch [5]#011Speed: 168.92 samples/sec#011loss=0.477768\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:43 INFO 140632068241216] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4242.897033691406, \"sum\": 4242.897033691406, \"min\": 4242.897033691406}}, \"EndTime\": 1587301183.697239, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301179.454273}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:43 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.64914797 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:43 INFO 140632068241216] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=132, train loss <loss>=0.474044446647\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:43 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:44 INFO 140632068241216] Epoch[133] Batch[0] avg_epoch_loss=0.496238\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:44 INFO 140632068241216] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=0.496237874031\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:46 INFO 140632068241216] Epoch[133] Batch[5] avg_epoch_loss=0.373514\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=0.373514329394\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:46 INFO 140632068241216] Epoch[133] Batch [5]#011Speed: 167.60 samples/sec#011loss=0.373514\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:48 INFO 140632068241216] Epoch[133] Batch[10] avg_epoch_loss=0.311353\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=0.236759254336\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:48 INFO 140632068241216] Epoch[133] Batch [10]#011Speed: 161.54 samples/sec#011loss=0.236759\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:48 INFO 140632068241216] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4797.44815826416, \"sum\": 4797.44815826416, \"min\": 4797.44815826416}}, \"EndTime\": 1587301188.495291, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301183.697373}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:48 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=135.90287023 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:48 INFO 140632068241216] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=133, train loss <loss>=0.31135293164\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:48 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:49 INFO 140632068241216] Epoch[134] Batch[0] avg_epoch_loss=0.863771\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:49 INFO 140632068241216] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=0.863771319389\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:51 INFO 140632068241216] Epoch[134] Batch[5] avg_epoch_loss=0.449898\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:51 INFO 140632068241216] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=0.449897790949\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:51 INFO 140632068241216] Epoch[134] Batch [5]#011Speed: 164.99 samples/sec#011loss=0.449898\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:52 INFO 140632068241216] processed a total of 593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4228.615999221802, \"sum\": 4228.615999221802, \"min\": 4228.615999221802}}, \"EndTime\": 1587301192.724482, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301188.495352}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:52 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.230794186 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:52 INFO 140632068241216] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=134, train loss <loss>=0.398366272449\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:52 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:53 INFO 140632068241216] Epoch[135] Batch[0] avg_epoch_loss=0.247249\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:53 INFO 140632068241216] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=0.247249081731\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:55 INFO 140632068241216] Epoch[135] Batch[5] avg_epoch_loss=0.133342\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:55 INFO 140632068241216] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=0.133342013073\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:55 INFO 140632068241216] Epoch[135] Batch [5]#011Speed: 165.07 samples/sec#011loss=0.133342\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:57 INFO 140632068241216] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4360.252141952515, \"sum\": 4360.252141952515, \"min\": 4360.252141952515}}, \"EndTime\": 1587301197.085333, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301192.724568}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:57 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.400936963 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:57 INFO 140632068241216] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=135, train loss <loss>=0.211089409702\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:57 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:57 INFO 140632068241216] Epoch[136] Batch[0] avg_epoch_loss=0.627578\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=0.627578496933\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:59 INFO 140632068241216] Epoch[136] Batch[5] avg_epoch_loss=0.326077\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:59 INFO 140632068241216] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=0.326077176879\u001b[0m\n",
      "\u001b[34m[04/19/2020 12:59:59 INFO 140632068241216] Epoch[136] Batch [5]#011Speed: 167.18 samples/sec#011loss=0.326077\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:01 INFO 140632068241216] Epoch[136] Batch[10] avg_epoch_loss=0.248994\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:01 INFO 140632068241216] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=0.156493890285\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:01 INFO 140632068241216] Epoch[136] Batch [10]#011Speed: 168.92 samples/sec#011loss=0.156494\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:01 INFO 140632068241216] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4640.4900550842285, \"sum\": 4640.4900550842285, \"min\": 4640.4900550842285}}, \"EndTime\": 1587301201.726556, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301197.085396}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:01 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.128513852 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:01 INFO 140632068241216] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:01 INFO 140632068241216] #quality_metric: host=algo-1, epoch=136, train loss <loss>=0.248993864791\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:01 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:02 INFO 140632068241216] Epoch[137] Batch[0] avg_epoch_loss=0.261801\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:02 INFO 140632068241216] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=0.261800706387\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:04 INFO 140632068241216] Epoch[137] Batch[5] avg_epoch_loss=0.164310\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:04 INFO 140632068241216] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=0.164310031881\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:04 INFO 140632068241216] Epoch[137] Batch [5]#011Speed: 168.78 samples/sec#011loss=0.164310\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:06 INFO 140632068241216] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4314.103126525879, \"sum\": 4314.103126525879, \"min\": 4314.103126525879}}, \"EndTime\": 1587301206.041268, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301201.726636}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:06 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=137.684438584 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:06 INFO 140632068241216] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=137, train loss <loss>=0.160672697704\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:06 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:06 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_05645a85-b0bd-4e5f-a26d-3c73fac45742-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 70.45197486877441, \"sum\": 70.45197486877441, \"min\": 70.45197486877441}}, \"EndTime\": 1587301206.112351, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301206.041334}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:06 INFO 140632068241216] Epoch[138] Batch[0] avg_epoch_loss=0.179022\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=0.179021656513\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:08 INFO 140632068241216] Epoch[138] Batch[5] avg_epoch_loss=0.059332\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=0.0593316896508\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:08 INFO 140632068241216] Epoch[138] Batch [5]#011Speed: 167.71 samples/sec#011loss=0.059332\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:10 INFO 140632068241216] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4303.941011428833, \"sum\": 4303.941011428833, \"min\": 4303.941011428833}}, \"EndTime\": 1587301210.416422, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301206.112423}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:10 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.302812481 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:10 INFO 140632068241216] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=138, train loss <loss>=0.0448986327276\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:10 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:10 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_7aacbbb7-ca0c-47d1-b743-563842af1da2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 74.33581352233887, \"sum\": 74.33581352233887, \"min\": 74.33581352233887}}, \"EndTime\": 1587301210.49151, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301210.416502}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:11 INFO 140632068241216] Epoch[139] Batch[0] avg_epoch_loss=0.215345\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:11 INFO 140632068241216] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=0.215345293283\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:13 INFO 140632068241216] Epoch[139] Batch[5] avg_epoch_loss=0.291840\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:13 INFO 140632068241216] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=0.291840483745\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:13 INFO 140632068241216] Epoch[139] Batch [5]#011Speed: 168.26 samples/sec#011loss=0.291840\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:15 INFO 140632068241216] Epoch[139] Batch[10] avg_epoch_loss=0.211590\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:15 INFO 140632068241216] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=0.115290374309\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:15 INFO 140632068241216] Epoch[139] Batch [10]#011Speed: 167.99 samples/sec#011loss=0.115290\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:15 INFO 140632068241216] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4665.255069732666, \"sum\": 4665.255069732666, \"min\": 4665.255069732666}}, \"EndTime\": 1587301215.156915, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301210.491591}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:15 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=137.823862131 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:15 INFO 140632068241216] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:15 INFO 140632068241216] #quality_metric: host=algo-1, epoch=139, train loss <loss>=0.211590434001\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:15 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:16 INFO 140632068241216] Epoch[140] Batch[0] avg_epoch_loss=0.207057\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:16 INFO 140632068241216] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=0.207056686282\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:17 INFO 140632068241216] Epoch[140] Batch[5] avg_epoch_loss=0.143368\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=0.143367794653\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:17 INFO 140632068241216] Epoch[140] Batch [5]#011Speed: 163.63 samples/sec#011loss=0.143368\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:19 INFO 140632068241216] Epoch[140] Batch[10] avg_epoch_loss=0.072367\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=-0.0128346750513\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:19 INFO 140632068241216] Epoch[140] Batch [10]#011Speed: 167.86 samples/sec#011loss=-0.012835\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:19 INFO 140632068241216] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4748.625040054321, \"sum\": 4748.625040054321, \"min\": 4748.625040054321}}, \"EndTime\": 1587301219.906203, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301215.156997}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:19 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=137.299517594 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:19 INFO 140632068241216] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=140, train loss <loss>=0.07236667206\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:19 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:20 INFO 140632068241216] Epoch[141] Batch[0] avg_epoch_loss=0.142994\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:20 INFO 140632068241216] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=0.142993867397\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:22 INFO 140632068241216] Epoch[141] Batch[5] avg_epoch_loss=0.135816\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:22 INFO 140632068241216] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=0.135815565785\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:22 INFO 140632068241216] Epoch[141] Batch [5]#011Speed: 167.99 samples/sec#011loss=0.135816\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:24 INFO 140632068241216] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4269.985914230347, \"sum\": 4269.985914230347, \"min\": 4269.985914230347}}, \"EndTime\": 1587301224.176743, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301219.90628}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:24 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.898365166 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:24 INFO 140632068241216] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=141, train loss <loss>=0.0899218000472\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:24 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:25 INFO 140632068241216] Epoch[142] Batch[0] avg_epoch_loss=-0.010073\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:25 INFO 140632068241216] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=-0.0100725190714\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:27 INFO 140632068241216] Epoch[142] Batch[5] avg_epoch_loss=0.056794\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:27 INFO 140632068241216] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=0.0567941527503\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:27 INFO 140632068241216] Epoch[142] Batch [5]#011Speed: 165.41 samples/sec#011loss=0.056794\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:28 INFO 140632068241216] Epoch[142] Batch[10] avg_epoch_loss=0.034079\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:28 INFO 140632068241216] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=0.00681972950697\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:28 INFO 140632068241216] Epoch[142] Batch [10]#011Speed: 167.26 samples/sec#011loss=0.006820\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:28 INFO 140632068241216] processed a total of 702 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4763.73815536499, \"sum\": 4763.73815536499, \"min\": 4763.73815536499}}, \"EndTime\": 1587301228.941015, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301224.176817}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:28 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.35976746 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:28 INFO 140632068241216] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:28 INFO 140632068241216] #quality_metric: host=algo-1, epoch=142, train loss <loss>=0.0340785058215\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:28 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:29 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_96b0ea7f-e00f-4da5-9c7d-52b101329e91-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 73.11010360717773, \"sum\": 73.11010360717773, \"min\": 73.11010360717773}}, \"EndTime\": 1587301229.014746, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301228.941089}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:29 INFO 140632068241216] Epoch[143] Batch[0] avg_epoch_loss=-0.106502\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:29 INFO 140632068241216] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=-0.106501713395\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:31 INFO 140632068241216] Epoch[143] Batch[5] avg_epoch_loss=0.099093\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=0.0990927542249\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:31 INFO 140632068241216] Epoch[143] Batch [5]#011Speed: 167.34 samples/sec#011loss=0.099093\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:33 INFO 140632068241216] Epoch[143] Batch[10] avg_epoch_loss=0.038648\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:33 INFO 140632068241216] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=-0.0338865570724\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:33 INFO 140632068241216] Epoch[143] Batch [10]#011Speed: 168.42 samples/sec#011loss=-0.033887\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:33 INFO 140632068241216] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4672.956943511963, \"sum\": 4672.956943511963, \"min\": 4672.956943511963}}, \"EndTime\": 1587301233.687843, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301229.014821}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:33 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.732599355 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:33 INFO 140632068241216] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:33 INFO 140632068241216] #quality_metric: host=algo-1, epoch=143, train loss <loss>=0.0386476127261\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:33 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:34 INFO 140632068241216] Epoch[144] Batch[0] avg_epoch_loss=0.010612\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:34 INFO 140632068241216] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=0.0106115220115\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:36 INFO 140632068241216] Epoch[144] Batch[5] avg_epoch_loss=0.215197\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=0.215197062586\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:36 INFO 140632068241216] Epoch[144] Batch [5]#011Speed: 166.40 samples/sec#011loss=0.215197\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:38 INFO 140632068241216] Epoch[144] Batch[10] avg_epoch_loss=0.241835\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:38 INFO 140632068241216] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=0.273801524937\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:38 INFO 140632068241216] Epoch[144] Batch [10]#011Speed: 167.39 samples/sec#011loss=0.273802\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:38 INFO 140632068241216] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4678.169012069702, \"sum\": 4678.169012069702, \"min\": 4678.169012069702}}, \"EndTime\": 1587301238.36668, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301233.687922}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:38 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.084377864 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:38 INFO 140632068241216] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:38 INFO 140632068241216] #quality_metric: host=algo-1, epoch=144, train loss <loss>=0.241835454564\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:38 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:39 INFO 140632068241216] Epoch[145] Batch[0] avg_epoch_loss=0.379686\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:39 INFO 140632068241216] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=0.379685819149\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:41 INFO 140632068241216] Epoch[145] Batch[5] avg_epoch_loss=0.366314\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=0.366314321756\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:41 INFO 140632068241216] Epoch[145] Batch [5]#011Speed: 165.91 samples/sec#011loss=0.366314\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:43 INFO 140632068241216] Epoch[145] Batch[10] avg_epoch_loss=0.269821\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=0.154029546678\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:43 INFO 140632068241216] Epoch[145] Batch [10]#011Speed: 169.47 samples/sec#011loss=0.154030\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:43 INFO 140632068241216] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4662.842035293579, \"sum\": 4662.842035293579, \"min\": 4662.842035293579}}, \"EndTime\": 1587301243.030158, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301238.366768}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:43 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.755058486 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:43 INFO 140632068241216] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=145, train loss <loss>=0.269821242175\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:43 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:43 INFO 140632068241216] Epoch[146] Batch[0] avg_epoch_loss=0.242536\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=0.242535546422\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:45 INFO 140632068241216] Epoch[146] Batch[5] avg_epoch_loss=0.138895\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:45 INFO 140632068241216] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=0.138895186285\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:45 INFO 140632068241216] Epoch[146] Batch [5]#011Speed: 167.02 samples/sec#011loss=0.138895\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:47 INFO 140632068241216] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4317.368984222412, \"sum\": 4317.368984222412, \"min\": 4317.368984222412}}, \"EndTime\": 1587301247.347994, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301243.030235}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:47 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.518062562 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:47 INFO 140632068241216] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:47 INFO 140632068241216] #quality_metric: host=algo-1, epoch=146, train loss <loss>=0.0976311992854\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:47 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:48 INFO 140632068241216] Epoch[147] Batch[0] avg_epoch_loss=0.298118\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=0.298118054867\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:50 INFO 140632068241216] Epoch[147] Batch[5] avg_epoch_loss=0.249677\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:50 INFO 140632068241216] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=0.249676900605\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:50 INFO 140632068241216] Epoch[147] Batch [5]#011Speed: 165.18 samples/sec#011loss=0.249677\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:52 INFO 140632068241216] Epoch[147] Batch[10] avg_epoch_loss=0.198822\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=0.137796556205\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:52 INFO 140632068241216] Epoch[147] Batch [10]#011Speed: 167.02 samples/sec#011loss=0.137797\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:52 INFO 140632068241216] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4778.0420780181885, \"sum\": 4778.0420780181885, \"min\": 4778.0420780181885}}, \"EndTime\": 1587301252.126658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301247.348061}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:52 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=135.617027842 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:52 INFO 140632068241216] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=147, train loss <loss>=0.198822198605\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:52 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:52 INFO 140632068241216] Epoch[148] Batch[0] avg_epoch_loss=0.119147\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=0.119146816432\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:54 INFO 140632068241216] Epoch[148] Batch[5] avg_epoch_loss=0.069782\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=0.069782066159\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:54 INFO 140632068241216] Epoch[148] Batch [5]#011Speed: 165.88 samples/sec#011loss=0.069782\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:56 INFO 140632068241216] Epoch[148] Batch[10] avg_epoch_loss=0.080258\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:56 INFO 140632068241216] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=0.0928302153945\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:56 INFO 140632068241216] Epoch[148] Batch [10]#011Speed: 165.43 samples/sec#011loss=0.092830\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:56 INFO 140632068241216] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4702.491998672485, \"sum\": 4702.491998672485, \"min\": 4702.491998672485}}, \"EndTime\": 1587301256.829731, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301252.126734}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:56 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=139.709706792 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:56 INFO 140632068241216] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:56 INFO 140632068241216] #quality_metric: host=algo-1, epoch=148, train loss <loss>=0.0802584976297\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:56 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:57 INFO 140632068241216] Epoch[149] Batch[0] avg_epoch_loss=1.060964\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=1.06096410751\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:59 INFO 140632068241216] Epoch[149] Batch[5] avg_epoch_loss=0.671847\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:59 INFO 140632068241216] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=0.671846747398\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:00:59 INFO 140632068241216] Epoch[149] Batch [5]#011Speed: 167.79 samples/sec#011loss=0.671847\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:01 INFO 140632068241216] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4324.047088623047, \"sum\": 4324.047088623047, \"min\": 4324.047088623047}}, \"EndTime\": 1587301261.154301, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301256.82981}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:01 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.773343581 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:01 INFO 140632068241216] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:01 INFO 140632068241216] #quality_metric: host=algo-1, epoch=149, train loss <loss>=0.599723079801\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:01 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:02 INFO 140632068241216] Epoch[150] Batch[0] avg_epoch_loss=0.478588\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:02 INFO 140632068241216] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=0.478588402271\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:03 INFO 140632068241216] Epoch[150] Batch[5] avg_epoch_loss=0.423883\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=0.423882871866\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:03 INFO 140632068241216] Epoch[150] Batch [5]#011Speed: 166.58 samples/sec#011loss=0.423883\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:05 INFO 140632068241216] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4325.36506652832, \"sum\": 4325.36506652832, \"min\": 4325.36506652832}}, \"EndTime\": 1587301265.480279, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301261.154374}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:05 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.9550113 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:05 INFO 140632068241216] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:05 INFO 140632068241216] #quality_metric: host=algo-1, epoch=150, train loss <loss>=0.32061258927\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:05 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:06 INFO 140632068241216] Epoch[151] Batch[0] avg_epoch_loss=0.102184\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=0.102184280753\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:08 INFO 140632068241216] Epoch[151] Batch[5] avg_epoch_loss=0.007334\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=0.00733438630899\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:08 INFO 140632068241216] Epoch[151] Batch [5]#011Speed: 167.36 samples/sec#011loss=0.007334\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:10 INFO 140632068241216] Epoch[151] Batch[10] avg_epoch_loss=0.044772\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=0.0896966427565\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:10 INFO 140632068241216] Epoch[151] Batch [10]#011Speed: 168.40 samples/sec#011loss=0.089697\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:10 INFO 140632068241216] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4685.831069946289, \"sum\": 4685.831069946289, \"min\": 4685.831069946289}}, \"EndTime\": 1587301270.166881, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301265.480352}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:10 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=139.779111618 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:10 INFO 140632068241216] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=151, train loss <loss>=0.0447717756033\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:10 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:11 INFO 140632068241216] Epoch[152] Batch[0] avg_epoch_loss=0.125300\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:11 INFO 140632068241216] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=0.125299811363\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:12 INFO 140632068241216] Epoch[152] Batch[5] avg_epoch_loss=0.055106\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:12 INFO 140632068241216] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=0.0551055621666\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:12 INFO 140632068241216] Epoch[152] Batch [5]#011Speed: 167.55 samples/sec#011loss=0.055106\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:14 INFO 140632068241216] Epoch[152] Batch[10] avg_epoch_loss=0.021190\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:14 INFO 140632068241216] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=-0.0195088816807\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:14 INFO 140632068241216] Epoch[152] Batch [10]#011Speed: 169.63 samples/sec#011loss=-0.019509\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:14 INFO 140632068241216] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4715.049028396606, \"sum\": 4715.049028396606, \"min\": 4715.049028396606}}, \"EndTime\": 1587301274.882493, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301270.166976}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:14 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.913691119 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:14 INFO 140632068241216] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:14 INFO 140632068241216] #quality_metric: host=algo-1, epoch=152, train loss <loss>=0.0211899058724\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:14 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:14 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_5ee4fa25-6815-4a5f-a733-0f02718da572-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 75.28996467590332, \"sum\": 75.28996467590332, \"min\": 75.28996467590332}}, \"EndTime\": 1587301274.958309, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301274.882564}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:15 INFO 140632068241216] Epoch[153] Batch[0] avg_epoch_loss=0.625565\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:15 INFO 140632068241216] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=0.625564754009\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:17 INFO 140632068241216] Epoch[153] Batch[5] avg_epoch_loss=0.321524\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=0.32152446111\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:17 INFO 140632068241216] Epoch[153] Batch [5]#011Speed: 162.02 samples/sec#011loss=0.321524\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:19 INFO 140632068241216] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4390.59591293335, \"sum\": 4390.59591293335, \"min\": 4390.59591293335}}, \"EndTime\": 1587301279.349042, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301274.958382}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:19 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=144.62373507 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:19 INFO 140632068241216] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=153, train loss <loss>=0.250438325107\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:19 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:20 INFO 140632068241216] Epoch[154] Batch[0] avg_epoch_loss=0.089201\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:20 INFO 140632068241216] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=0.0892014205456\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:22 INFO 140632068241216] Epoch[154] Batch[5] avg_epoch_loss=0.123051\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:22 INFO 140632068241216] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=0.123051162499\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:22 INFO 140632068241216] Epoch[154] Batch [5]#011Speed: 165.54 samples/sec#011loss=0.123051\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:24 INFO 140632068241216] Epoch[154] Batch[10] avg_epoch_loss=0.054274\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=-0.0282596830279\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:24 INFO 140632068241216] Epoch[154] Batch [10]#011Speed: 168.51 samples/sec#011loss=-0.028260\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:24 INFO 140632068241216] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4696.058034896851, \"sum\": 4696.058034896851, \"min\": 4696.058034896851}}, \"EndTime\": 1587301284.045843, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301279.349108}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:24 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.177704509 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:24 INFO 140632068241216] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=154, train loss <loss>=0.0542735054412\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:24 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:24 INFO 140632068241216] Epoch[155] Batch[0] avg_epoch_loss=0.411262\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=0.411261588335\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:26 INFO 140632068241216] Epoch[155] Batch[5] avg_epoch_loss=0.197643\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:26 INFO 140632068241216] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=0.197642753522\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:26 INFO 140632068241216] Epoch[155] Batch [5]#011Speed: 166.35 samples/sec#011loss=0.197643\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:28 INFO 140632068241216] Epoch[155] Batch[10] avg_epoch_loss=0.152987\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:28 INFO 140632068241216] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=0.0993998527527\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:28 INFO 140632068241216] Epoch[155] Batch [10]#011Speed: 167.75 samples/sec#011loss=0.099400\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:28 INFO 140632068241216] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4709.7320556640625, \"sum\": 4709.7320556640625, \"min\": 4709.7320556640625}}, \"EndTime\": 1587301288.756269, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301284.04593}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:28 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.25391403 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:28 INFO 140632068241216] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:28 INFO 140632068241216] #quality_metric: host=algo-1, epoch=155, train loss <loss>=0.152986889536\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:28 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:29 INFO 140632068241216] Epoch[156] Batch[0] avg_epoch_loss=0.236812\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:29 INFO 140632068241216] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=0.236811846495\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:31 INFO 140632068241216] Epoch[156] Batch[5] avg_epoch_loss=0.168733\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=0.168733085195\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:31 INFO 140632068241216] Epoch[156] Batch [5]#011Speed: 163.56 samples/sec#011loss=0.168733\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:33 INFO 140632068241216] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4301.836967468262, \"sum\": 4301.836967468262, \"min\": 4301.836967468262}}, \"EndTime\": 1587301293.058651, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301288.75633}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:33 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.168574364 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:33 INFO 140632068241216] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:33 INFO 140632068241216] #quality_metric: host=algo-1, epoch=156, train loss <loss>=0.106277251802\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:33 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:33 INFO 140632068241216] Epoch[157] Batch[0] avg_epoch_loss=0.128584\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:33 INFO 140632068241216] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=0.128584310412\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:35 INFO 140632068241216] Epoch[157] Batch[5] avg_epoch_loss=0.042501\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:35 INFO 140632068241216] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=0.0425006349881\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:35 INFO 140632068241216] Epoch[157] Batch [5]#011Speed: 167.61 samples/sec#011loss=0.042501\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:37 INFO 140632068241216] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4366.927862167358, \"sum\": 4366.927862167358, \"min\": 4366.927862167358}}, \"EndTime\": 1587301297.426394, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301293.058733}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:37 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.056221552 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:37 INFO 140632068241216] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:37 INFO 140632068241216] #quality_metric: host=algo-1, epoch=157, train loss <loss>=0.0197241905145\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:37 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:37 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_f5f31135-bc0d-432c-bc97-1244121b699c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 71.56896591186523, \"sum\": 71.56896591186523, \"min\": 71.56896591186523}}, \"EndTime\": 1587301297.498675, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301297.426477}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:38 INFO 140632068241216] Epoch[158] Batch[0] avg_epoch_loss=0.094808\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:38 INFO 140632068241216] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=0.0948077887297\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:40 INFO 140632068241216] Epoch[158] Batch[5] avg_epoch_loss=0.072433\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=0.0724331991126\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:40 INFO 140632068241216] Epoch[158] Batch [5]#011Speed: 169.02 samples/sec#011loss=0.072433\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:41 INFO 140632068241216] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4260.711193084717, \"sum\": 4260.711193084717, \"min\": 4260.711193084717}}, \"EndTime\": 1587301301.759535, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301297.498757}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:41 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.348409382 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:41 INFO 140632068241216] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=158, train loss <loss>=-0.00469475239515\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:41 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:41 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_9b974aaa-303a-488c-a716-dfbd00a85c9a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 74.58209991455078, \"sum\": 74.58209991455078, \"min\": 74.58209991455078}}, \"EndTime\": 1587301301.834901, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301301.75961}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:42 INFO 140632068241216] Epoch[159] Batch[0] avg_epoch_loss=0.098742\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:42 INFO 140632068241216] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=0.0987421274185\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:44 INFO 140632068241216] Epoch[159] Batch[5] avg_epoch_loss=0.120277\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:44 INFO 140632068241216] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=0.120277356667\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:44 INFO 140632068241216] Epoch[159] Batch [5]#011Speed: 167.79 samples/sec#011loss=0.120277\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:46 INFO 140632068241216] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4257.110118865967, \"sum\": 4257.110118865967, \"min\": 4257.110118865967}}, \"EndTime\": 1587301306.092154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301301.834977}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:46 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.104840362 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:46 INFO 140632068241216] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=159, train loss <loss>=0.0860975043848\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:46 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:46 INFO 140632068241216] Epoch[160] Batch[0] avg_epoch_loss=-0.035752\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=-0.0357522666454\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:48 INFO 140632068241216] Epoch[160] Batch[5] avg_epoch_loss=-0.061433\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=-0.061433223697\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:48 INFO 140632068241216] Epoch[160] Batch [5]#011Speed: 164.23 samples/sec#011loss=-0.061433\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:50 INFO 140632068241216] processed a total of 590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4353.493928909302, \"sum\": 4353.493928909302, \"min\": 4353.493928909302}}, \"EndTime\": 1587301310.446278, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301306.092226}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:50 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=135.519063822 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:50 INFO 140632068241216] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:50 INFO 140632068241216] #quality_metric: host=algo-1, epoch=160, train loss <loss>=-0.0252749683335\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:50 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:50 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_9b0805c9-e72b-480d-975a-dc53a86fd886-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 69.25392150878906, \"sum\": 69.25392150878906, \"min\": 69.25392150878906}}, \"EndTime\": 1587301310.516222, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301310.446342}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:51 INFO 140632068241216] Epoch[161] Batch[0] avg_epoch_loss=0.566621\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:51 INFO 140632068241216] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=0.566621184349\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:53 INFO 140632068241216] Epoch[161] Batch[5] avg_epoch_loss=0.627127\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:53 INFO 140632068241216] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=0.627126614253\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:53 INFO 140632068241216] Epoch[161] Batch [5]#011Speed: 167.29 samples/sec#011loss=0.627127\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:54 INFO 140632068241216] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4312.052011489868, \"sum\": 4312.052011489868, \"min\": 4312.052011489868}}, \"EndTime\": 1587301314.828406, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301310.516294}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:54 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.170728687 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:54 INFO 140632068241216] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=161, train loss <loss>=0.622975325584\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:54 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:55 INFO 140632068241216] Epoch[162] Batch[0] avg_epoch_loss=0.545923\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:55 INFO 140632068241216] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=0.545923173428\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:57 INFO 140632068241216] Epoch[162] Batch[5] avg_epoch_loss=0.412105\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=0.412104591727\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:57 INFO 140632068241216] Epoch[162] Batch [5]#011Speed: 163.54 samples/sec#011loss=0.412105\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:59 INFO 140632068241216] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4389.775037765503, \"sum\": 4389.775037765503, \"min\": 4389.775037765503}}, \"EndTime\": 1587301319.218737, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301314.82848}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:59 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.966802695 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:59 INFO 140632068241216] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:59 INFO 140632068241216] #quality_metric: host=algo-1, epoch=162, train loss <loss>=0.305901958747\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:01:59 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:00 INFO 140632068241216] Epoch[163] Batch[0] avg_epoch_loss=0.029130\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:00 INFO 140632068241216] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=0.0291302502155\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:02 INFO 140632068241216] Epoch[163] Batch[5] avg_epoch_loss=-0.000561\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:02 INFO 140632068241216] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=-0.000561185181141\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:02 INFO 140632068241216] Epoch[163] Batch [5]#011Speed: 164.12 samples/sec#011loss=-0.000561\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:03 INFO 140632068241216] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4320.164203643799, \"sum\": 4320.164203643799, \"min\": 4320.164203643799}}, \"EndTime\": 1587301323.539494, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301319.218821}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:03 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.74980994 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:03 INFO 140632068241216] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=163, train loss <loss>=0.0727607734501\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:03 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:04 INFO 140632068241216] Epoch[164] Batch[0] avg_epoch_loss=-0.030849\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:04 INFO 140632068241216] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=-0.0308487582952\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:06 INFO 140632068241216] Epoch[164] Batch[5] avg_epoch_loss=0.237821\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=0.237820513236\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:06 INFO 140632068241216] Epoch[164] Batch [5]#011Speed: 165.83 samples/sec#011loss=0.237821\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:08 INFO 140632068241216] Epoch[164] Batch[10] avg_epoch_loss=0.262535\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=0.29219302088\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:08 INFO 140632068241216] Epoch[164] Batch [10]#011Speed: 167.76 samples/sec#011loss=0.292193\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:08 INFO 140632068241216] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4767.102003097534, \"sum\": 4767.102003097534, \"min\": 4767.102003097534}}, \"EndTime\": 1587301328.307279, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301323.539569}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:08 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=137.187159592 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:08 INFO 140632068241216] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=164, train loss <loss>=0.262535289438\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:08 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:09 INFO 140632068241216] Epoch[165] Batch[0] avg_epoch_loss=0.233402\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:09 INFO 140632068241216] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=0.233401864767\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:11 INFO 140632068241216] Epoch[165] Batch[5] avg_epoch_loss=0.165370\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:11 INFO 140632068241216] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=0.165369759624\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:11 INFO 140632068241216] Epoch[165] Batch [5]#011Speed: 166.88 samples/sec#011loss=0.165370\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:13 INFO 140632068241216] Epoch[165] Batch[10] avg_epoch_loss=0.089179\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:13 INFO 140632068241216] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=-0.00225015040487\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:13 INFO 140632068241216] Epoch[165] Batch [10]#011Speed: 165.99 samples/sec#011loss=-0.002250\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:13 INFO 140632068241216] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4749.0599155426025, \"sum\": 4749.0599155426025, \"min\": 4749.0599155426025}}, \"EndTime\": 1587301333.056836, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301328.307351}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:13 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=136.233987648 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:13 INFO 140632068241216] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:13 INFO 140632068241216] #quality_metric: host=algo-1, epoch=165, train loss <loss>=0.0891788914292\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:13 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:13 INFO 140632068241216] Epoch[166] Batch[0] avg_epoch_loss=0.416570\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:13 INFO 140632068241216] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=0.416570186615\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:15 INFO 140632068241216] Epoch[166] Batch[5] avg_epoch_loss=0.170157\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:15 INFO 140632068241216] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=0.170156556492\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:15 INFO 140632068241216] Epoch[166] Batch [5]#011Speed: 168.43 samples/sec#011loss=0.170157\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:17 INFO 140632068241216] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4358.406066894531, \"sum\": 4358.406066894531, \"min\": 4358.406066894531}}, \"EndTime\": 1587301337.415789, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301333.05692}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:17 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.935448656 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:17 INFO 140632068241216] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=166, train loss <loss>=0.105881961249\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:17 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:18 INFO 140632068241216] Epoch[167] Batch[0] avg_epoch_loss=0.093678\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:18 INFO 140632068241216] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=0.0936779007316\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:20 INFO 140632068241216] Epoch[167] Batch[5] avg_epoch_loss=0.040935\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:20 INFO 140632068241216] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=0.0409345601996\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:20 INFO 140632068241216] Epoch[167] Batch [5]#011Speed: 161.82 samples/sec#011loss=0.040935\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:21 INFO 140632068241216] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4413.1920337677, \"sum\": 4413.1920337677, \"min\": 4413.1920337677}}, \"EndTime\": 1587301341.829567, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301337.415926}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:21 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.429403251 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:21 INFO 140632068241216] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:21 INFO 140632068241216] #quality_metric: host=algo-1, epoch=167, train loss <loss>=0.0421795815229\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:21 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:22 INFO 140632068241216] Epoch[168] Batch[0] avg_epoch_loss=0.350439\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:22 INFO 140632068241216] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=0.350438594818\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:24 INFO 140632068241216] Epoch[168] Batch[5] avg_epoch_loss=0.066813\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=0.066813495631\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:24 INFO 140632068241216] Epoch[168] Batch [5]#011Speed: 162.98 samples/sec#011loss=0.066813\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:26 INFO 140632068241216] Epoch[168] Batch[10] avg_epoch_loss=0.023463\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:26 INFO 140632068241216] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=-0.0285581327975\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:26 INFO 140632068241216] Epoch[168] Batch [10]#011Speed: 169.27 samples/sec#011loss=-0.028558\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:26 INFO 140632068241216] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4739.280939102173, \"sum\": 4739.280939102173, \"min\": 4739.280939102173}}, \"EndTime\": 1587301346.569434, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301341.829653}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:26 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.634206218 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:26 INFO 140632068241216] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:26 INFO 140632068241216] #quality_metric: host=algo-1, epoch=168, train loss <loss>=0.0234627554362\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:26 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:27 INFO 140632068241216] Epoch[169] Batch[0] avg_epoch_loss=0.082927\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:27 INFO 140632068241216] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=0.0829266086221\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:29 INFO 140632068241216] Epoch[169] Batch[5] avg_epoch_loss=-0.107093\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:29 INFO 140632068241216] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=-0.107093491902\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:29 INFO 140632068241216] Epoch[169] Batch [5]#011Speed: 168.44 samples/sec#011loss=-0.107093\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:30 INFO 140632068241216] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4330.760955810547, \"sum\": 4330.760955810547, \"min\": 4330.760955810547}}, \"EndTime\": 1587301350.90069, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301346.569512}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:30 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.77655173 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:30 INFO 140632068241216] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:30 INFO 140632068241216] #quality_metric: host=algo-1, epoch=169, train loss <loss>=0.0428908780217\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:30 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:31 INFO 140632068241216] Epoch[170] Batch[0] avg_epoch_loss=0.139676\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:31 INFO 140632068241216] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=0.139675751328\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:33 INFO 140632068241216] Epoch[170] Batch[5] avg_epoch_loss=0.369943\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:33 INFO 140632068241216] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=0.369942886134\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:33 INFO 140632068241216] Epoch[170] Batch [5]#011Speed: 167.23 samples/sec#011loss=0.369943\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:35 INFO 140632068241216] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4273.245096206665, \"sum\": 4273.245096206665, \"min\": 4273.245096206665}}, \"EndTime\": 1587301355.174517, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301350.900759}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:35 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=139.936270983 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:35 INFO 140632068241216] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:35 INFO 140632068241216] #quality_metric: host=algo-1, epoch=170, train loss <loss>=0.338742606342\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:35 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:36 INFO 140632068241216] Epoch[171] Batch[0] avg_epoch_loss=0.211813\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=0.211813464761\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:37 INFO 140632068241216] Epoch[171] Batch[5] avg_epoch_loss=0.150183\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:37 INFO 140632068241216] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=0.150183192454\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:37 INFO 140632068241216] Epoch[171] Batch [5]#011Speed: 166.62 samples/sec#011loss=0.150183\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:39 INFO 140632068241216] Epoch[171] Batch[10] avg_epoch_loss=0.095786\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:39 INFO 140632068241216] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=0.0305087486282\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:39 INFO 140632068241216] Epoch[171] Batch [10]#011Speed: 167.26 samples/sec#011loss=0.030509\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:40 INFO 140632068241216] processed a total of 712 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 5062.111139297485, \"sum\": 5062.111139297485, \"min\": 5062.111139297485}}, \"EndTime\": 1587301360.237284, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301355.174602}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:40 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.648175213 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:40 INFO 140632068241216] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:40 INFO 140632068241216] #quality_metric: host=algo-1, epoch=171, train loss <loss>=0.0581031738936\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:40 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:41 INFO 140632068241216] Epoch[172] Batch[0] avg_epoch_loss=0.600967\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=0.600966632366\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:43 INFO 140632068241216] Epoch[172] Batch[5] avg_epoch_loss=0.329657\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=0.329657062888\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:43 INFO 140632068241216] Epoch[172] Batch [5]#011Speed: 163.33 samples/sec#011loss=0.329657\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:45 INFO 140632068241216] Epoch[172] Batch[10] avg_epoch_loss=0.283429\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:45 INFO 140632068241216] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=0.227956110239\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:45 INFO 140632068241216] Epoch[172] Batch [10]#011Speed: 167.35 samples/sec#011loss=0.227956\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:45 INFO 140632068241216] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4773.025989532471, \"sum\": 4773.025989532471, \"min\": 4773.025989532471}}, \"EndTime\": 1587301365.010858, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301360.23737}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:45 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=136.387348611 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:45 INFO 140632068241216] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:45 INFO 140632068241216] #quality_metric: host=algo-1, epoch=172, train loss <loss>=0.283429357139\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:45 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:45 INFO 140632068241216] Epoch[173] Batch[0] avg_epoch_loss=0.226905\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:45 INFO 140632068241216] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=0.226905345917\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:47 INFO 140632068241216] Epoch[173] Batch[5] avg_epoch_loss=0.174023\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:47 INFO 140632068241216] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=0.174023402234\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:47 INFO 140632068241216] Epoch[173] Batch [5]#011Speed: 165.00 samples/sec#011loss=0.174023\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:49 INFO 140632068241216] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4457.941055297852, \"sum\": 4457.941055297852, \"min\": 4457.941055297852}}, \"EndTime\": 1587301369.469447, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301365.01094}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:49 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.887325159 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:49 INFO 140632068241216] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:49 INFO 140632068241216] #quality_metric: host=algo-1, epoch=173, train loss <loss>=0.104286913574\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:49 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:50 INFO 140632068241216] Epoch[174] Batch[0] avg_epoch_loss=0.185960\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:50 INFO 140632068241216] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=0.185960441828\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:52 INFO 140632068241216] Epoch[174] Batch[5] avg_epoch_loss=0.033334\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=0.0333342552185\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:52 INFO 140632068241216] Epoch[174] Batch [5]#011Speed: 165.66 samples/sec#011loss=0.033334\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:53 INFO 140632068241216] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4316.490888595581, \"sum\": 4316.490888595581, \"min\": 4316.490888595581}}, \"EndTime\": 1587301373.786698, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301369.469524}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:53 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=148.032517265 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:53 INFO 140632068241216] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:53 INFO 140632068241216] #quality_metric: host=algo-1, epoch=174, train loss <loss>=0.00374468937516\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:53 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:54 INFO 140632068241216] Epoch[175] Batch[0] avg_epoch_loss=-0.067721\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=-0.0677207484841\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:56 INFO 140632068241216] Epoch[175] Batch[5] avg_epoch_loss=-0.026583\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:56 INFO 140632068241216] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=-0.0265831913178\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:56 INFO 140632068241216] Epoch[175] Batch [5]#011Speed: 166.09 samples/sec#011loss=-0.026583\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:58 INFO 140632068241216] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4321.805953979492, \"sum\": 4321.805953979492, \"min\": 4321.805953979492}}, \"EndTime\": 1587301378.109411, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301373.786776}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:58 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.303732745 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:58 INFO 140632068241216] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:58 INFO 140632068241216] #quality_metric: host=algo-1, epoch=175, train loss <loss>=-0.0476971546421\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:58 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:58 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_0d45725c-63c6-4c5b-b11d-c4ce6f35e57c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 65.27996063232422, \"sum\": 65.27996063232422, \"min\": 65.27996063232422}}, \"EndTime\": 1587301378.175451, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301378.109475}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:59 INFO 140632068241216] Epoch[176] Batch[0] avg_epoch_loss=-0.219503\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:02:59 INFO 140632068241216] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=-0.219503372908\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:00 INFO 140632068241216] Epoch[176] Batch[5] avg_epoch_loss=-0.060086\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:00 INFO 140632068241216] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=-0.0600860230625\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:00 INFO 140632068241216] Epoch[176] Batch [5]#011Speed: 166.99 samples/sec#011loss=-0.060086\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:02 INFO 140632068241216] Epoch[176] Batch[10] avg_epoch_loss=-0.128845\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:02 INFO 140632068241216] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=-0.211356735229\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:02 INFO 140632068241216] Epoch[176] Batch [10]#011Speed: 161.85 samples/sec#011loss=-0.211357\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:02 INFO 140632068241216] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4773.637056350708, \"sum\": 4773.637056350708, \"min\": 4773.637056350708}}, \"EndTime\": 1587301382.949233, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301378.175526}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:02 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.236036315 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:02 INFO 140632068241216] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:02 INFO 140632068241216] #quality_metric: host=algo-1, epoch=176, train loss <loss>=-0.128845437684\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:02 INFO 140632068241216] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:03 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/state_7fd9f004-3efc-4126-83f6-0cdfddf82845-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 66.61701202392578, \"sum\": 66.61701202392578, \"min\": 66.61701202392578}}, \"EndTime\": 1587301383.01651, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301382.94931}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:03 INFO 140632068241216] Epoch[177] Batch[0] avg_epoch_loss=0.237900\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=0.237900421023\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:05 INFO 140632068241216] Epoch[177] Batch[5] avg_epoch_loss=0.194867\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:05 INFO 140632068241216] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=0.194866570334\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:05 INFO 140632068241216] Epoch[177] Batch [5]#011Speed: 167.98 samples/sec#011loss=0.194867\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:07 INFO 140632068241216] Epoch[177] Batch[10] avg_epoch_loss=0.101214\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:07 INFO 140632068241216] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=-0.011169718951\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:07 INFO 140632068241216] Epoch[177] Batch [10]#011Speed: 162.64 samples/sec#011loss=-0.011170\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:07 INFO 140632068241216] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4724.123001098633, \"sum\": 4724.123001098633, \"min\": 4724.123001098633}}, \"EndTime\": 1587301387.740782, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301383.016586}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:07 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.551975409 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:07 INFO 140632068241216] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:07 INFO 140632068241216] #quality_metric: host=algo-1, epoch=177, train loss <loss>=0.101213711568\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:07 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:08 INFO 140632068241216] Epoch[178] Batch[0] avg_epoch_loss=0.088735\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=0.088735088706\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:10 INFO 140632068241216] Epoch[178] Batch[5] avg_epoch_loss=0.081472\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=0.0814720272707\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:10 INFO 140632068241216] Epoch[178] Batch [5]#011Speed: 165.93 samples/sec#011loss=0.081472\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:12 INFO 140632068241216] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4261.263132095337, \"sum\": 4261.263132095337, \"min\": 4261.263132095337}}, \"EndTime\": 1587301392.002575, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301387.740847}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:12 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.207590609 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:12 INFO 140632068241216] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:12 INFO 140632068241216] #quality_metric: host=algo-1, epoch=178, train loss <loss>=0.0351571719162\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:12 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:12 INFO 140632068241216] Epoch[179] Batch[0] avg_epoch_loss=-0.000044\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:12 INFO 140632068241216] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=-4.36478294432e-05\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:14 INFO 140632068241216] Epoch[179] Batch[5] avg_epoch_loss=0.031398\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:14 INFO 140632068241216] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=0.0313978166475\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:14 INFO 140632068241216] Epoch[179] Batch [5]#011Speed: 166.02 samples/sec#011loss=0.031398\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:16 INFO 140632068241216] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4331.769943237305, \"sum\": 4331.769943237305, \"min\": 4331.769943237305}}, \"EndTime\": 1587301396.334924, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301392.002652}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:16 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.202917359 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:16 INFO 140632068241216] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:16 INFO 140632068241216] #quality_metric: host=algo-1, epoch=179, train loss <loss>=0.107209613686\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:16 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:17 INFO 140632068241216] Epoch[180] Batch[0] avg_epoch_loss=0.151791\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:17 INFO 140632068241216] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=0.151791363955\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:19 INFO 140632068241216] Epoch[180] Batch[5] avg_epoch_loss=0.097381\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=0.0973808874066\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:19 INFO 140632068241216] Epoch[180] Batch [5]#011Speed: 159.59 samples/sec#011loss=0.097381\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:20 INFO 140632068241216] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4362.356185913086, \"sum\": 4362.356185913086, \"min\": 4362.356185913086}}, \"EndTime\": 1587301400.697875, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301396.334988}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:20 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.43347791 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:20 INFO 140632068241216] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:20 INFO 140632068241216] #quality_metric: host=algo-1, epoch=180, train loss <loss>=0.149014306068\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:20 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:21 INFO 140632068241216] Epoch[181] Batch[0] avg_epoch_loss=0.137153\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:21 INFO 140632068241216] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=0.137153208256\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:23 INFO 140632068241216] Epoch[181] Batch[5] avg_epoch_loss=0.168552\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:23 INFO 140632068241216] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=0.168552067441\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:23 INFO 140632068241216] Epoch[181] Batch [5]#011Speed: 166.35 samples/sec#011loss=0.168552\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:25 INFO 140632068241216] Epoch[181] Batch[10] avg_epoch_loss=0.080795\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:25 INFO 140632068241216] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=-0.0245139982551\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:25 INFO 140632068241216] Epoch[181] Batch [10]#011Speed: 165.08 samples/sec#011loss=-0.024514\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:25 INFO 140632068241216] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4755.664110183716, \"sum\": 4755.664110183716, \"min\": 4755.664110183716}}, \"EndTime\": 1587301405.454147, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301400.697954}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:25 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.778525268 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:25 INFO 140632068241216] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:25 INFO 140632068241216] #quality_metric: host=algo-1, epoch=181, train loss <loss>=0.080794764852\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:25 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:26 INFO 140632068241216] Epoch[182] Batch[0] avg_epoch_loss=0.250329\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:26 INFO 140632068241216] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=0.250329047441\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:28 INFO 140632068241216] Epoch[182] Batch[5] avg_epoch_loss=0.147726\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:28 INFO 140632068241216] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=0.147725857794\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:28 INFO 140632068241216] Epoch[182] Batch [5]#011Speed: 164.19 samples/sec#011loss=0.147726\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:29 INFO 140632068241216] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4366.067886352539, \"sum\": 4366.067886352539, \"min\": 4366.067886352539}}, \"EndTime\": 1587301409.820697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301405.454224}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:29 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.828317879 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:29 INFO 140632068241216] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:29 INFO 140632068241216] #quality_metric: host=algo-1, epoch=182, train loss <loss>=0.0413616705686\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:29 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:30 INFO 140632068241216] Epoch[183] Batch[0] avg_epoch_loss=-0.102137\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:30 INFO 140632068241216] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=-0.102136835456\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:32 INFO 140632068241216] Epoch[183] Batch[5] avg_epoch_loss=-0.075077\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:32 INFO 140632068241216] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=-0.075077001083\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:32 INFO 140632068241216] Epoch[183] Batch [5]#011Speed: 168.19 samples/sec#011loss=-0.075077\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:34 INFO 140632068241216] processed a total of 595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4252.712965011597, \"sum\": 4252.712965011597, \"min\": 4252.712965011597}}, \"EndTime\": 1587301414.074192, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301409.820769}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:34 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=139.906602267 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:34 INFO 140632068241216] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:34 INFO 140632068241216] #quality_metric: host=algo-1, epoch=183, train loss <loss>=-0.0863976896275\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:34 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:34 INFO 140632068241216] Epoch[184] Batch[0] avg_epoch_loss=0.010714\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:34 INFO 140632068241216] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=0.0107142617926\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:36 INFO 140632068241216] Epoch[184] Batch[5] avg_epoch_loss=0.271207\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=0.271207401374\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:36 INFO 140632068241216] Epoch[184] Batch [5]#011Speed: 167.56 samples/sec#011loss=0.271207\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:38 INFO 140632068241216] Epoch[184] Batch[10] avg_epoch_loss=0.256991\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:38 INFO 140632068241216] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=0.239932392538\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:38 INFO 140632068241216] Epoch[184] Batch [10]#011Speed: 167.90 samples/sec#011loss=0.239932\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:38 INFO 140632068241216] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4653.321981430054, \"sum\": 4653.321981430054, \"min\": 4653.321981430054}}, \"EndTime\": 1587301418.728083, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301414.074251}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:38 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.32641851 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:38 INFO 140632068241216] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:38 INFO 140632068241216] #quality_metric: host=algo-1, epoch=184, train loss <loss>=0.256991488266\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:38 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:39 INFO 140632068241216] Epoch[185] Batch[0] avg_epoch_loss=0.268016\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:39 INFO 140632068241216] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=0.268016070127\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:41 INFO 140632068241216] Epoch[185] Batch[5] avg_epoch_loss=0.299522\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=0.299521769087\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:41 INFO 140632068241216] Epoch[185] Batch [5]#011Speed: 167.43 samples/sec#011loss=0.299522\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:43 INFO 140632068241216] Epoch[185] Batch[10] avg_epoch_loss=0.238672\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=0.165653096139\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:43 INFO 140632068241216] Epoch[185] Batch [10]#011Speed: 167.51 samples/sec#011loss=0.165653\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:43 INFO 140632068241216] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4683.645009994507, \"sum\": 4683.645009994507, \"min\": 4683.645009994507}}, \"EndTime\": 1587301423.412281, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301418.728157}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:43 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=140.698863362 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:43 INFO 140632068241216] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=185, train loss <loss>=0.238672372292\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:43 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:44 INFO 140632068241216] Epoch[186] Batch[0] avg_epoch_loss=0.037096\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:44 INFO 140632068241216] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=0.037096016109\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:46 INFO 140632068241216] Epoch[186] Batch[5] avg_epoch_loss=-0.031350\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=-0.0313502770538\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:46 INFO 140632068241216] Epoch[186] Batch [5]#011Speed: 167.37 samples/sec#011loss=-0.031350\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:47 INFO 140632068241216] processed a total of 585 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4259.758949279785, \"sum\": 4259.758949279785, \"min\": 4259.758949279785}}, \"EndTime\": 1587301427.67274, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301423.412363}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:47 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=137.325911507 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:47 INFO 140632068241216] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:47 INFO 140632068241216] #quality_metric: host=algo-1, epoch=186, train loss <loss>=-0.0655837714672\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:47 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:48 INFO 140632068241216] Epoch[187] Batch[0] avg_epoch_loss=0.436547\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=0.436546504498\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:50 INFO 140632068241216] Epoch[187] Batch[5] avg_epoch_loss=0.305903\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:50 INFO 140632068241216] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=0.305902525783\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:50 INFO 140632068241216] Epoch[187] Batch [5]#011Speed: 162.06 samples/sec#011loss=0.305903\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:52 INFO 140632068241216] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4335.952043533325, \"sum\": 4335.952043533325, \"min\": 4335.952043533325}}, \"EndTime\": 1587301432.009536, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301427.672805}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:52 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=142.063929919 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:52 INFO 140632068241216] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=187, train loss <loss>=0.288874340057\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:52 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:52 INFO 140632068241216] Epoch[188] Batch[0] avg_epoch_loss=0.134620\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:52 INFO 140632068241216] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=0.134620293975\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:54 INFO 140632068241216] Epoch[188] Batch[5] avg_epoch_loss=0.154248\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=0.154248035202\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:54 INFO 140632068241216] Epoch[188] Batch [5]#011Speed: 165.62 samples/sec#011loss=0.154248\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:56 INFO 140632068241216] processed a total of 595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4305.285930633545, \"sum\": 4305.285930633545, \"min\": 4305.285930633545}}, \"EndTime\": 1587301436.315445, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301432.009618}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:56 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.198544746 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:56 INFO 140632068241216] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:56 INFO 140632068241216] #quality_metric: host=algo-1, epoch=188, train loss <loss>=0.0827197469771\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:56 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:57 INFO 140632068241216] Epoch[189] Batch[0] avg_epoch_loss=0.075243\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:57 INFO 140632068241216] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=0.0752430334687\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:59 INFO 140632068241216] Epoch[189] Batch[5] avg_epoch_loss=0.060110\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:59 INFO 140632068241216] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=0.0601098376016\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:03:59 INFO 140632068241216] Epoch[189] Batch [5]#011Speed: 167.59 samples/sec#011loss=0.060110\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:00 INFO 140632068241216] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4255.311012268066, \"sum\": 4255.311012268066, \"min\": 4255.311012268066}}, \"EndTime\": 1587301440.571332, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301436.31552}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:00 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.231590518 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:00 INFO 140632068241216] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:00 INFO 140632068241216] #quality_metric: host=algo-1, epoch=189, train loss <loss>=-0.0274911291897\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:00 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:01 INFO 140632068241216] Epoch[190] Batch[0] avg_epoch_loss=0.024270\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:01 INFO 140632068241216] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=0.0242698341608\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:03 INFO 140632068241216] Epoch[190] Batch[5] avg_epoch_loss=-0.022204\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:03 INFO 140632068241216] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=-0.0222043430743\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:03 INFO 140632068241216] Epoch[190] Batch [5]#011Speed: 168.14 samples/sec#011loss=-0.022204\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:05 INFO 140632068241216] Epoch[190] Batch[10] avg_epoch_loss=-0.075988\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:05 INFO 140632068241216] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=-0.140527355019\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:05 INFO 140632068241216] Epoch[190] Batch [10]#011Speed: 169.61 samples/sec#011loss=-0.140527\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:05 INFO 140632068241216] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4673.8831996917725, \"sum\": 4673.8831996917725, \"min\": 4673.8831996917725}}, \"EndTime\": 1587301445.245854, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301440.571401}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:05 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.424412962 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:05 INFO 140632068241216] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:05 INFO 140632068241216] #quality_metric: host=algo-1, epoch=190, train loss <loss>=-0.0759875303219\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:05 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:06 INFO 140632068241216] Epoch[191] Batch[0] avg_epoch_loss=-0.071678\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:06 INFO 140632068241216] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=-0.0716776549816\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:08 INFO 140632068241216] Epoch[191] Batch[5] avg_epoch_loss=0.074333\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:08 INFO 140632068241216] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=0.0743330704281\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:08 INFO 140632068241216] Epoch[191] Batch [5]#011Speed: 166.54 samples/sec#011loss=0.074333\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:09 INFO 140632068241216] Epoch[191] Batch[10] avg_epoch_loss=-0.018234\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:09 INFO 140632068241216] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=-0.129315229505\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:09 INFO 140632068241216] Epoch[191] Batch [10]#011Speed: 169.58 samples/sec#011loss=-0.129315\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:09 INFO 140632068241216] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4725.269079208374, \"sum\": 4725.269079208374, \"min\": 4725.269079208374}}, \"EndTime\": 1587301449.971645, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301445.245964}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:09 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=139.670801128 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:09 INFO 140632068241216] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:09 INFO 140632068241216] #quality_metric: host=algo-1, epoch=191, train loss <loss>=-0.0182343386325\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:09 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:10 INFO 140632068241216] Epoch[192] Batch[0] avg_epoch_loss=0.242911\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:10 INFO 140632068241216] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=0.242911145091\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:12 INFO 140632068241216] Epoch[192] Batch[5] avg_epoch_loss=-0.000806\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:12 INFO 140632068241216] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=-0.000805702370902\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:12 INFO 140632068241216] Epoch[192] Batch [5]#011Speed: 170.18 samples/sec#011loss=-0.000806\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:14 INFO 140632068241216] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4228.090047836304, \"sum\": 4228.090047836304, \"min\": 4228.090047836304}}, \"EndTime\": 1587301454.200389, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301449.971732}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:14 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=149.945892265 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:14 INFO 140632068241216] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:14 INFO 140632068241216] #quality_metric: host=algo-1, epoch=192, train loss <loss>=-0.0478615188971\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:14 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:15 INFO 140632068241216] Epoch[193] Batch[0] avg_epoch_loss=-0.174246\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:15 INFO 140632068241216] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=-0.174246102571\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:16 INFO 140632068241216] Epoch[193] Batch[5] avg_epoch_loss=-0.085708\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:16 INFO 140632068241216] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=-0.0857081338763\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:16 INFO 140632068241216] Epoch[193] Batch [5]#011Speed: 170.50 samples/sec#011loss=-0.085708\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:18 INFO 140632068241216] Epoch[193] Batch[10] avg_epoch_loss=-0.021806\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:18 INFO 140632068241216] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=0.0548767687753\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:18 INFO 140632068241216] Epoch[193] Batch [10]#011Speed: 168.95 samples/sec#011loss=0.054877\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:18 INFO 140632068241216] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4636.270999908447, \"sum\": 4636.270999908447, \"min\": 4636.270999908447}}, \"EndTime\": 1587301458.83726, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301454.200455}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:18 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=138.685550965 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:18 INFO 140632068241216] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:18 INFO 140632068241216] #quality_metric: host=algo-1, epoch=193, train loss <loss>=-0.0218059053983\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:18 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:19 INFO 140632068241216] Epoch[194] Batch[0] avg_epoch_loss=0.121243\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:19 INFO 140632068241216] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=0.121242634952\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:21 INFO 140632068241216] Epoch[194] Batch[5] avg_epoch_loss=0.153678\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:21 INFO 140632068241216] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=0.15367794844\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:21 INFO 140632068241216] Epoch[194] Batch [5]#011Speed: 169.32 samples/sec#011loss=0.153678\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:23 INFO 140632068241216] Epoch[194] Batch[10] avg_epoch_loss=0.146073\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:23 INFO 140632068241216] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=0.136946363002\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:23 INFO 140632068241216] Epoch[194] Batch [10]#011Speed: 170.53 samples/sec#011loss=0.136946\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:23 INFO 140632068241216] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4729.247093200684, \"sum\": 4729.247093200684, \"min\": 4729.247093200684}}, \"EndTime\": 1587301463.567035, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301458.837338}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:23 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.033793555 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:23 INFO 140632068241216] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:23 INFO 140632068241216] #quality_metric: host=algo-1, epoch=194, train loss <loss>=0.146072682332\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:23 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:24 INFO 140632068241216] Epoch[195] Batch[0] avg_epoch_loss=0.248129\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:24 INFO 140632068241216] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=0.248128861189\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:26 INFO 140632068241216] Epoch[195] Batch[5] avg_epoch_loss=0.108593\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:26 INFO 140632068241216] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=0.108592632848\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:26 INFO 140632068241216] Epoch[195] Batch [5]#011Speed: 168.41 samples/sec#011loss=0.108593\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:27 INFO 140632068241216] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4310.064792633057, \"sum\": 4310.064792633057, \"min\": 4310.064792633057}}, \"EndTime\": 1587301467.877652, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301463.567115}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:27 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=146.397389435 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:27 INFO 140632068241216] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:27 INFO 140632068241216] #quality_metric: host=algo-1, epoch=195, train loss <loss>=0.0522446935996\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:27 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:28 INFO 140632068241216] Epoch[196] Batch[0] avg_epoch_loss=0.110093\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:28 INFO 140632068241216] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=0.110093280673\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:30 INFO 140632068241216] Epoch[196] Batch[5] avg_epoch_loss=-0.007564\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:30 INFO 140632068241216] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=-0.00756367389113\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:30 INFO 140632068241216] Epoch[196] Batch [5]#011Speed: 169.74 samples/sec#011loss=-0.007564\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:32 INFO 140632068241216] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4263.848066329956, \"sum\": 4263.848066329956, \"min\": 4263.848066329956}}, \"EndTime\": 1587301472.142192, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301467.87773}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:32 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.873719223 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:32 INFO 140632068241216] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:32 INFO 140632068241216] #quality_metric: host=algo-1, epoch=196, train loss <loss>=-0.0472907483112\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:32 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:32 INFO 140632068241216] Epoch[197] Batch[0] avg_epoch_loss=-0.033968\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:32 INFO 140632068241216] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=-0.033967744559\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:34 INFO 140632068241216] Epoch[197] Batch[5] avg_epoch_loss=-0.013359\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:34 INFO 140632068241216] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=-0.0133592862015\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:34 INFO 140632068241216] Epoch[197] Batch [5]#011Speed: 167.13 samples/sec#011loss=-0.013359\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:36 INFO 140632068241216] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4267.712116241455, \"sum\": 4267.712116241455, \"min\": 4267.712116241455}}, \"EndTime\": 1587301476.410495, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301472.142264}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:36 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=148.085041076 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:36 INFO 140632068241216] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:36 INFO 140632068241216] #quality_metric: host=algo-1, epoch=197, train loss <loss>=-0.0447001596913\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:36 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:37 INFO 140632068241216] Epoch[198] Batch[0] avg_epoch_loss=0.108987\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:37 INFO 140632068241216] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=0.10898655653\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:39 INFO 140632068241216] Epoch[198] Batch[5] avg_epoch_loss=-0.013586\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:39 INFO 140632068241216] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=-0.0135858282447\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:39 INFO 140632068241216] Epoch[198] Batch [5]#011Speed: 169.23 samples/sec#011loss=-0.013586\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:41 INFO 140632068241216] Epoch[198] Batch[10] avg_epoch_loss=-0.057779\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=-0.110811141133\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:41 INFO 140632068241216] Epoch[198] Batch [10]#011Speed: 166.72 samples/sec#011loss=-0.110811\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:41 INFO 140632068241216] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4653.78999710083, \"sum\": 4653.78999710083, \"min\": 4653.78999710083}}, \"EndTime\": 1587301481.065018, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301476.410567}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:41 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=141.385970942 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:41 INFO 140632068241216] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=198, train loss <loss>=-0.057779152285\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:41 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:41 INFO 140632068241216] Epoch[199] Batch[0] avg_epoch_loss=0.365518\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:41 INFO 140632068241216] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=0.365518480539\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:43 INFO 140632068241216] Epoch[199] Batch[5] avg_epoch_loss=0.223083\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:43 INFO 140632068241216] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=0.223082980762\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:43 INFO 140632068241216] Epoch[199] Batch [5]#011Speed: 167.49 samples/sec#011loss=0.223083\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:45 INFO 140632068241216] Epoch[199] Batch[10] avg_epoch_loss=0.141178\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:45 INFO 140632068241216] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=0.0428917517886\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:45 INFO 140632068241216] Epoch[199] Batch [10]#011Speed: 166.89 samples/sec#011loss=0.042892\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:45 INFO 140632068241216] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4721.199035644531, \"sum\": 4721.199035644531, \"min\": 4721.199035644531}}, \"EndTime\": 1587301485.786727, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301481.065097}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:45 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=145.2980726 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:45 INFO 140632068241216] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:45 INFO 140632068241216] #quality_metric: host=algo-1, epoch=199, train loss <loss>=0.141177876683\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:45 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:46 INFO 140632068241216] Epoch[200] Batch[0] avg_epoch_loss=-0.048714\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:46 INFO 140632068241216] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=-0.0487137250602\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:48 INFO 140632068241216] Epoch[200] Batch[5] avg_epoch_loss=-0.114045\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:48 INFO 140632068241216] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=-0.114044683054\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:48 INFO 140632068241216] Epoch[200] Batch [5]#011Speed: 169.11 samples/sec#011loss=-0.114045\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:50 INFO 140632068241216] Epoch[200] Batch[10] avg_epoch_loss=-0.007169\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:50 INFO 140632068241216] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=0.121081569791\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:50 INFO 140632068241216] Epoch[200] Batch [10]#011Speed: 161.06 samples/sec#011loss=0.121082\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:50 INFO 140632068241216] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4733.361005783081, \"sum\": 4733.361005783081, \"min\": 4733.361005783081}}, \"EndTime\": 1587301490.520689, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301485.78682}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:50 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=143.657579066 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:50 INFO 140632068241216] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:50 INFO 140632068241216] #quality_metric: host=algo-1, epoch=200, train loss <loss>=-0.00716911357912\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:50 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:51 INFO 140632068241216] Epoch[201] Batch[0] avg_epoch_loss=0.158437\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:51 INFO 140632068241216] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=0.158437311649\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:53 INFO 140632068241216] Epoch[201] Batch[5] avg_epoch_loss=0.017221\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:53 INFO 140632068241216] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=0.017221139123\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:53 INFO 140632068241216] Epoch[201] Batch [5]#011Speed: 166.40 samples/sec#011loss=0.017221\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:54 INFO 140632068241216] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4296.565055847168, \"sum\": 4296.565055847168, \"min\": 4296.565055847168}}, \"EndTime\": 1587301494.817812, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301490.520764}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:54 INFO 140632068241216] #throughput_metric: host=algo-1, train throughput=147.32246992 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:54 INFO 140632068241216] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:54 INFO 140632068241216] #quality_metric: host=algo-1, epoch=201, train loss <loss>=-0.0420384671539\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:54 INFO 140632068241216] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:54 INFO 140632068241216] Loading parameters from best epoch (176)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 28.56898307800293, \"sum\": 28.56898307800293, \"min\": 28.56898307800293}}, \"EndTime\": 1587301494.847048, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301494.817902}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:54 INFO 140632068241216] stopping training now\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:54 INFO 140632068241216] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:54 INFO 140632068241216] Final loss: -0.128845437684 (occurred at epoch 176)\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:54 INFO 140632068241216] #quality_metric: host=algo-1, train final_loss <loss>=-0.128845437684\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:54 INFO 140632068241216] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:54 WARNING 140632068241216] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:54 INFO 140632068241216] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 672.0681190490723, \"sum\": 672.0681190490723, \"min\": 672.0681190490723}}, \"EndTime\": 1587301495.519914, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301494.847116}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:55 INFO 140632068241216] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 990.6899929046631, \"sum\": 990.6899929046631, \"min\": 990.6899929046631}}, \"EndTime\": 1587301495.838477, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301495.519981}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:55 INFO 140632068241216] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:55 INFO 140632068241216] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 48.40207099914551, \"sum\": 48.40207099914551, \"min\": 48.40207099914551}}, \"EndTime\": 1587301495.887005, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301495.838556}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:55 INFO 140632068241216] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:04:55 INFO 140632068241216] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.04601478576660156, \"sum\": 0.04601478576660156, \"min\": 0.04601478576660156}}, \"EndTime\": 1587301495.887755, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301495.887061}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 13627.252101898193, \"sum\": 13627.252101898193, \"min\": 13627.252101898193}}, \"EndTime\": 1587301509.514953, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301495.887836}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #test_score (algo-1, RMSE): 12.9885853872\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #test_score (algo-1, mean_absolute_QuantileLoss): 1198.5416644480492\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #test_score (algo-1, mean_wQuantileLoss): 0.7722562270928152\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #test_score (algo-1, wQuantileLoss[0.1]): 0.31769662994853\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #test_score (algo-1, wQuantileLoss[0.2]): 0.4443013366503815\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #test_score (algo-1, wQuantileLoss[0.3]): 0.5630255001414681\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #test_score (algo-1, wQuantileLoss[0.4]): 0.6766121851721989\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #test_score (algo-1, wQuantileLoss[0.5]): 0.7871304396347901\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #test_score (algo-1, wQuantileLoss[0.6]): 0.8946108339066356\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #test_score (algo-1, wQuantileLoss[0.7]): 0.9972152995387302\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #test_score (algo-1, wQuantileLoss[0.8]): 1.0938479724004098\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #test_score (algo-1, wQuantileLoss[0.9]): 1.1758658464421932\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.772256227093\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:05:09 INFO 140632068241216] #quality_metric: host=algo-1, test RMSE <loss>=12.9885853872\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 923582.3509693146, \"sum\": 923582.3509693146, \"min\": 923582.3509693146}, \"setuptime\": {\"count\": 1, \"max\": 9.248971939086914, \"sum\": 9.248971939086914, \"min\": 9.248971939086914}}, \"EndTime\": 1587301509.584665, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587301509.51502}\n",
      "\u001b[0m\n",
      "Training seconds: 961\n",
      "Billable seconds: 286\n",
      "Managed Spot Training savings: 70.2%\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.estimator import Estimator\n",
    "import csv\n",
    "\n",
    "image_name = get_image_uri(boto3.Session().region_name, 'forecasting-deepar') \n",
    "s3_output_path_model = f's3://{bucket}/{model_prefix}'\n",
    "\n",
    "def fit_model(train_path, test_path, base_job_name, hyperparameters=None):\n",
    "    image_name = get_image_uri(boto3.Session().region_name, 'forecasting-deepar')    \n",
    "    estimator = Estimator(sagemaker_session=sagemaker_session,\n",
    "                            image_name=image_name,\n",
    "                            role=role,\n",
    "                            train_instance_count=1,\n",
    "                            train_instance_type='ml.c4.xlarge',\n",
    "                            output_path=s3_output_path_model,\n",
    "                            base_job_name=base_job_name,\n",
    "                            train_use_spot_instances=True,\n",
    "                            train_max_wait=60*60,\n",
    "                            train_max_run=60*60\n",
    "                         )\n",
    "    \n",
    "    hyperparameters_base = {\n",
    "        \"epochs\": \"250\",\n",
    "        \"time_freq\": 'W',\n",
    "        \"num_cells\": \"128\",\n",
    "        \"num_layers\": \"2\",\n",
    "        \"mini_batch_size\": \"64\",\n",
    "        \"learning_rate\": \"0.005\",\n",
    "        \"dropout_rate\": \"0.01\",\n",
    "        \"early_stopping_patience\": \"25\",\n",
    "        'prediction_length': hyperparameters['prediction_length'],\n",
    "        'context_length': 52,\n",
    "        'num_dynamic_feat': 'auto',\n",
    "        'cardinality': 'auto'}\n",
    "    dict_update(hyperparameters_base, hyperparameters)\n",
    "    \n",
    "    dict_update(current_model_info, hyperparameters_base)\n",
    "    \n",
    "    data_channels = {'train': train_path}\n",
    "    if test_path:\n",
    "        data_channels['test'] = test_path\n",
    "    \n",
    "    estimator.set_hyperparameters(**hyperparameters_base)\n",
    "    estimator.fit(inputs=data_channels, wait=False)\n",
    "    return estimator.latest_training_job.name\n",
    "\n",
    "estimator_sj_training_job = fit_model(train_path_sj,\n",
    "                                      train_test_path_sj,\n",
    "                                      f'{prefix}-{tag}-sj',\n",
    "                                      {'prediction_length': str(PREDICTION_LENGTH['sj'])})\n",
    "estimator_iq_training_job = fit_model(train_path_iq,\n",
    "                                      train_test_path_iq,\n",
    "                                      f'{prefix}-{tag}-iq',\n",
    "                                      {'prediction_length': str(PREDICTION_LENGTH['iq']),\n",
    "                                      'num_cells': '64',\n",
    "                                      'context_length': '32'})\n",
    "\n",
    "print(estimator_sj_training_job)\n",
    "print(estimator_iq_training_job)\n",
    "\n",
    "estimator_sj = Estimator.attach(estimator_sj_training_job)\n",
    "estimator_iq = Estimator.attach(estimator_iq_training_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer created from dengai-only-target-optim-sj-2020-04-19-12-47-00-833\n",
      "> Transform job dengai-only-target-optim-sj-2020-04-19--2020-04-19-13-50-33-619 created with data: s3://sagemaker-eu-central-1-964501460451/dengai/2020-04-19--12-42-only-target-optim/pprocess_data/validation_pp_sj.json\n",
      "Transformer created from dengai-only-target-optim-iq-2020-04-19-12-47-01-020\n",
      "> Transform job dengai-only-target-optim-iq-2020-04-19--2020-04-19-13-50-34-166 created with data: s3://sagemaker-eu-central-1-964501460451/dengai/2020-04-19--12-42-only-target-optim/pprocess_data/validation_pp_iq.json\n",
      "......................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34mNo handlers could be found for logger \"root\"\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 INFO 140506417739584] Estimated memory required per model 102MB.\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 INFO 140506417739584] Estimated available memory 15083MB.\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 INFO 140506417739584] Estimated maximum number of workers for the available memory is 146.\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 INFO 140506417739584] Using 4 workers\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 INFO 140506417739584] loading entry points\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 INFO 140506417739584] Prediction endpoint operating in batch mode\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 INFO 140506417739584] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 INFO 140506417739584] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 INFO 140506417739584] loaded model class model\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 WARNING 140506417739584] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 INFO 140506417739584] nvidia-smi took: 0.0252320766449 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 INFO 140506417739584] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 INFO 140506417739584] Loading Config from /opt/ml/model/model_algo-1-config.json\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase1.time\": {\"count\": 1, \"max\": 1.497030258178711, \"sum\": 1.497030258178711, \"min\": 1.497030258178711}}, \"EndTime\": 1587304435.952427, \"Dimensions\": {}, \"StartTime\": 1587304435.861651}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:53:55 INFO 140506417739584] Deserializing model parameters from /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[13:53:56] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202184.0/RHEL5_64/generic-flavor/src/src/engine/engine.cc:55: MXNet start using engine: NaiveEngine\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 472.1260070800781, \"sum\": 472.1260070800781, \"min\": 472.1260070800781}}, \"EndTime\": 1587304436.872592, \"Dimensions\": {}, \"StartTime\": 1587304435.952552}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase2.time\": {\"count\": 1, \"max\": 920.1149940490723, \"sum\": 920.1149940490723, \"min\": 920.1149940490723}}, \"EndTime\": 1587304436.872692, \"Dimensions\": {}, \"StartTime\": 1587304436.872668}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:53:56 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:53:56 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:53:56 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:53:56 +0000] [33] [INFO] Booting worker with pid: 33\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:53:56 +0000] [34] [INFO] Booting worker with pid: 34\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:53:56 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:53:57 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.04100799560546875, \"sum\": 0.04100799560546875, \"min\": 0.04100799560546875}}, \"EndTime\": 1587304452.263625, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587304436.924162}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.04100799560546875, \"sum\": 0.04100799560546875, \"min\": 0.04100799560546875}}, \"EndTime\": 1587304452.263625, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587304436.924162}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.25200843811035156, \"sum\": 0.25200843811035156, \"min\": 0.25200843811035156}}, \"EndTime\": 1587304453.664036, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587304452.263792}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1587304453.664333, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587304453.664114}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.25200843811035156, \"sum\": 0.25200843811035156, \"min\": 0.25200843811035156}}, \"EndTime\": 1587304453.664036, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587304452.263792}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1587304453.664333, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587304453.664114}\n",
      "\u001b[0m\n",
      "\u001b[32m2020-04-19T13:54:12.127:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[34mNo handlers could be found for logger \"root\"\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 INFO 140571394627392] Estimated memory required per model 55MB.\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 INFO 140571394627392] Estimated available memory 15194MB.\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 INFO 140571394627392] Estimated maximum number of workers for the available memory is 275.\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 INFO 140571394627392] Using 4 workers\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 INFO 140571394627392] loading entry points\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 INFO 140571394627392] Prediction endpoint operating in batch mode\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 INFO 140571394627392] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 INFO 140571394627392] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 INFO 140571394627392] loaded model class model\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 WARNING 140571394627392] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 INFO 140571394627392] nvidia-smi took: 0.0251879692078 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 INFO 140571394627392] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 INFO 140571394627392] Loading Config from /opt/ml/model/model_algo-1-config.json\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase1.time\": {\"count\": 1, \"max\": 1.5478134155273438, \"sum\": 1.5478134155273438, \"min\": 1.5478134155273438}}, \"EndTime\": 1587304446.447293, \"Dimensions\": {}, \"StartTime\": 1587304446.335688}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 13:54:06 INFO 140571394627392] Deserializing model parameters from /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[13:54:06] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202184.0/RHEL5_64/generic-flavor/src/src/engine/engine.cc:55: MXNet start using engine: NaiveEngine\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 209.97881889343262, \"sum\": 209.97881889343262, \"min\": 209.97881889343262}}, \"EndTime\": 1587304446.885201, \"Dimensions\": {}, \"StartTime\": 1587304446.447404}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase2.time\": {\"count\": 1, \"max\": 437.9620552062988, \"sum\": 437.9620552062988, \"min\": 437.9620552062988}}, \"EndTime\": 1587304446.885395, \"Dimensions\": {}, \"StartTime\": 1587304446.885362}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:54:06 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:54:06 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:54:06 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:54:06 +0000] [34] [INFO] Booting worker with pid: 34\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:54:07 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:54:07 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-04-19 13:54:07 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35mNo handlers could be found for logger \"root\"\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 INFO 140571394627392] Estimated memory required per model 55MB.\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 INFO 140571394627392] Estimated available memory 15194MB.\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 INFO 140571394627392] Estimated maximum number of workers for the available memory is 275.\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 INFO 140571394627392] Using 4 workers\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 INFO 140571394627392] loading entry points\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 INFO 140571394627392] Prediction endpoint operating in batch mode\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 INFO 140571394627392] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 INFO 140571394627392] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 INFO 140571394627392] loaded model class model\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 WARNING 140571394627392] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 INFO 140571394627392] nvidia-smi took: 0.0251879692078 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 INFO 140571394627392] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 INFO 140571394627392] Loading Config from /opt/ml/model/model_algo-1-config.json\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.deserialize_phase1.time\": {\"count\": 1, \"max\": 1.5478134155273438, \"sum\": 1.5478134155273438, \"min\": 1.5478134155273438}}, \"EndTime\": 1587304446.447293, \"Dimensions\": {}, \"StartTime\": 1587304446.335688}\n",
      "\u001b[0m\n",
      "\u001b[35m[04/19/2020 13:54:06 INFO 140571394627392] Deserializing model parameters from /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[35m[13:54:06] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202184.0/RHEL5_64/generic-flavor/src/src/engine/engine.cc:55: MXNet start using engine: NaiveEngine\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 209.97881889343262, \"sum\": 209.97881889343262, \"min\": 209.97881889343262}}, \"EndTime\": 1587304446.885201, \"Dimensions\": {}, \"StartTime\": 1587304446.447404}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.deserialize_phase2.time\": {\"count\": 1, \"max\": 437.9620552062988, \"sum\": 437.9620552062988, \"min\": 437.9620552062988}}, \"EndTime\": 1587304446.885395, \"Dimensions\": {}, \"StartTime\": 1587304446.885362}\n",
      "\u001b[0m\n",
      "\u001b[35m[2020-04-19 13:54:06 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-04-19 13:54:06 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-04-19 13:54:06 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2020-04-19 13:54:06 +0000] [34] [INFO] Booting worker with pid: 34\u001b[0m\n",
      "\u001b[35m[2020-04-19 13:54:07 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[35m[2020-04-19 13:54:07 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2020-04-19 13:54:07 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.04100799560546875, \"sum\": 0.04100799560546875, \"min\": 0.04100799560546875}}, \"EndTime\": 1587304451.331871, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587304447.082891}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.04100799560546875, \"sum\": 0.04100799560546875, \"min\": 0.04100799560546875}}, \"EndTime\": 1587304451.331871, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587304447.082891}\n",
      "\u001b[0m\n",
      "\u001b[32m2020-04-19T13:54:11.174:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.16498565673828125, \"sum\": 0.16498565673828125, \"min\": 0.16498565673828125}}, \"EndTime\": 1587304451.793952, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587304451.332036}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1587304451.794375, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587304451.794032}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.16498565673828125, \"sum\": 0.16498565673828125, \"min\": 0.16498565673828125}}, \"EndTime\": 1587304451.793952, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587304451.332036}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1587304451.794375, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587304451.794032}\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "s3_batch_output_path = f's3://{bucket}/{batch_transform_prefix}'\n",
    "\n",
    "def batch_transform(estimator, data_path):\n",
    "    transformer = estimator.transformer(instance_count=1,\n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    strategy='SingleRecord',\n",
    "                                    assemble_with='Line',\n",
    "                                    output_path=s3_batch_output_path)\n",
    "    print(f'Transformer created from {estimator.latest_training_job.job_name}')\n",
    "    transformer.transform(data=data_path,\n",
    "                          data_type='S3Prefix',\n",
    "                          content_type=None,\n",
    "                          split_type='Line',\n",
    "                          wait=False,\n",
    "                          logs=True)\n",
    "    print(f'> Transform job {transformer.latest_transform_job.name} created with data: {data_path}')\n",
    "    return transformer.latest_transform_job.name\n",
    "    \n",
    "\n",
    "\n",
    "transformer_sj_job = batch_transform(estimator_sj, validation_path_sj)\n",
    "transformer_iq_job = batch_transform(estimator_iq, validation_path_iq)\n",
    "\n",
    "transformer_sj = Transformer.attach(transformer_sj_job).wait()\n",
    "transformer_iq = Transformer.attach(transformer_iq_job).wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to decode JSON prediction\n",
    "import json\n",
    "\n",
    "def unjson_prediction(predictions):\n",
    "    '''Accepts a JSON prediction and returns a list of quantiles for prediction.\n",
    "    '''\n",
    "    prediction_data = json.loads(predictions)\n",
    "    predictions_quantiles = pd.DataFrame(prediction_data['quantiles'])\n",
    "    return predictions_quantiles\n",
    "\n",
    "def groundtruth(validation_path, prediction_length):\n",
    "    data = []\n",
    "    f = sagemaker.s3.S3Downloader.read_file(validation_path)\n",
    "    for line in f.split('\\n'):\n",
    "        if (len(line)>0):\n",
    "            data.append(json.loads(line))\n",
    "    return data[0]['target'][-prediction_length:]\n",
    "\n",
    "def predictions_path(s3_batch_output_path, data_path):\n",
    "    file_name = os.path.basename(data_path)\n",
    "    return f'{s3_batch_output_path}/{file_name}.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_sj = unjson_prediction(sagemaker.s3.S3Downloader.read_file(predictions_path(s3_batch_output_path, validation_path_sj)))\n",
    "predictions_iq = unjson_prediction(sagemaker.s3.S3Downloader.read_file(predictions_path(s3_batch_output_path, validation_path_iq)))\n",
    "\n",
    "target_sj = groundtruth(train_test_path_sj, PREDICTION_LENGTH['sj'])\n",
    "target_iq = groundtruth(train_test_path_iq,  PREDICTION_LENGTH['iq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE_sj': 13.721162476446157,\n",
       " 'MAE_iq': 7.822390629507051,\n",
       " 'MAE_total': 21.543553105953208}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "quantile = '0.5'\n",
    "\n",
    "scores = {'MAE_sj': mean_absolute_error(predictions_sj[quantile], target_sj),\n",
    "       'MAE_iq': mean_absolute_error(predictions_iq[quantile], target_iq),\n",
    "      'MAE_total': mean_absolute_error(predictions_sj[quantile], target_sj) + mean_absolute_error(predictions_iq[quantile], target_iq)}\n",
    "   \n",
    "dict_update(current_model_info, scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# display the prediction median against the actual data\n",
    "def display_quantiles(prediction, target=None, other_predictions_path=None, scores=''):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    \n",
    "    # get the quantile values at 10, 50 and 90%\n",
    "    p10 = prediction['0.1']\n",
    "    p50 = prediction['0.5']\n",
    "    p90 = prediction['0.9']\n",
    "\n",
    "    if len(p50)==PREDICTION_LENGTH['sj']:\n",
    "        city='sj'\n",
    "    else:\n",
    "        city='iq'\n",
    "        \n",
    "    # fill the 80% confidence interval\n",
    "    plt.fill_between(p10.index, p10, p90, color='y', alpha=0.5, label='80% confidence interval')\n",
    "    \n",
    "    # plot the median prediction line\n",
    "    p50.plot(label='prediction median')\n",
    "\n",
    "    # plot target\n",
    "    if target is not None:\n",
    "        plt.plot(target, label='target')\n",
    "        \n",
    "    # plot previous submission\n",
    "    if other_predictions_path is not None:\n",
    "        try:\n",
    "            prev = pd.read_csv(other_predictions_path)\n",
    "            pd.Series(prev[prev.city==city].total_cases.tolist()).plot(label='prv')\n",
    "        except FileNotFoundError as err:\n",
    "            print(err)\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.title(f'{model_version} / {city} / Score (MAE): {scores[\"MAE_\"+city]:.2f}')\n",
    "    plt.savefig(f'./data/figures/{model_version}_{city}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_quantiles(predictions_sj, target=target_sj, other_predictions_path= './data/submissions/submission_features-scaled-2020-04-14-14-45-36-63.csv', scores=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_quantiles(predictions_iq, target=target_iq, other_predictions_path= './data/submissions/submission_features-scaled-2020-04-14-14-45-36-63.csv', scores=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving our model info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/models.infos.csv', 'a+', newline='') as f:\n",
    "    w = csv.DictWriter(f, fieldnames=model_info_keys)\n",
    "    if (f.tell()==0):\n",
    "        w.writeheader()\n",
    "    w.writerow(current_model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our model on full data and generate a submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we want to skip training and reuse a previously trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "def get_model(model_file):\n",
    "    model_s3_path = f's3://{bucket}/{model_file}'\n",
    "    model = Model(model_data=model_s3_path,\n",
    "              image=image_name,\n",
    "             role=role)\n",
    "    return model\n",
    "\n",
    "# estimator_sj = get_model('dengai/all-feat-stdscale-2020-04-09-18-03-41-96/models/dengai-deepar-all-feat-stdscale-SJ-2020-04-09-18-07-55-834/output/model.tar.gz')\n",
    "# estimator_iq = get_model('dengai/all-feat-stdscale-2020-04-09-18-03-41-96/models/dengai-deepar-all-feat-stdscale-IQ-2020-04-09-18-38-28-653/output/model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-19 14:19:14 Starting - Launching requested ML instances......\n",
      "2020-04-19 14:20:12 Starting - Preparing the instances for training.........\n",
      "2020-04-19 14:21:35 Downloading - Downloading input data...\n",
      "2020-04-19 14:22:07 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.01', u'mini_batch_size': u'64', u'learning_rate': u'0.005', u'num_cells': u'128', u'prediction_length': u'260', u'epochs': u'500', u'time_freq': u'W', u'context_length': u'52', u'num_layers': u'2', u'cardinality': u'auto', u'early_stopping_patience': u'25'}\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] Final configuration: {u'dropout_rate': u'0.01', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'0.005', u'num_layers': u'2', u'epochs': u'500', u'embedding_dimension': u'10', u'num_cells': u'128', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'260', u'time_freq': u'W', u'context_length': u'52', u'_kvstore': u'auto', u'early_stopping_patience': u'25'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] Using early stopping with patience 25\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/submission_train_pp_sj.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/submission_train_pp_sj.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] Training set statistics:\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] Integer time series\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] number of time series: 1\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] number of observations: 936\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] mean target length: 936\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] min/mean/max target: 0.0/34.1805555556/461.0\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] mean abs(target): 34.1805555556\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] contains missing values: no\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] Small number of time series. Doing 640 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] No test channel found not running evaluations\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] nvidia-smi took: 0.0251820087433 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 700.7260322570801, \"sum\": 700.7260322570801, \"min\": 700.7260322570801}}, \"EndTime\": 1587306130.953176, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306130.251576}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140480903202624] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 1974.8971462249756, \"sum\": 1974.8971462249756, \"min\": 1974.8971462249756}}, \"EndTime\": 1587306132.226596, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306130.953265}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:14 INFO 140480903202624] Epoch[0] Batch[0] avg_epoch_loss=6.050739\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:14 INFO 140480903202624] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=6.05073881149\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:20 INFO 140480903202624] Epoch[0] Batch[5] avg_epoch_loss=5.397346\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:20 INFO 140480903202624] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=5.39734562238\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:20 INFO 140480903202624] Epoch[0] Batch [5]#011Speed: 53.13 samples/sec#011loss=5.397346\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:25 INFO 140480903202624] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 500, \"sum\": 500.0, \"min\": 500}, \"update.time\": {\"count\": 1, \"max\": 12978.657960891724, \"sum\": 12978.657960891724, \"min\": 12978.657960891724}}, \"EndTime\": 1587306145.205528, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306132.226745}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:25 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=46.9997336371 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:25 INFO 140480903202624] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:25 INFO 140480903202624] #quality_metric: host=algo-1, epoch=0, train loss <loss>=5.03963356018\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:25 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:25 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_df63d8c7-ba66-48fe-bf0c-7bf8eb867dc7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 116.75500869750977, \"sum\": 116.75500869750977, \"min\": 116.75500869750977}}, \"EndTime\": 1587306145.322985, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306145.205625}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:27 INFO 140480903202624] Epoch[1] Batch[0] avg_epoch_loss=4.431969\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:27 INFO 140480903202624] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=4.4319691658\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:33 INFO 140480903202624] Epoch[1] Batch[5] avg_epoch_loss=4.150063\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=4.15006323655\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:33 INFO 140480903202624] Epoch[1] Batch [5]#011Speed: 56.81 samples/sec#011loss=4.150063\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:37 INFO 140480903202624] processed a total of 589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12194.644212722778, \"sum\": 12194.644212722778, \"min\": 12194.644212722778}}, \"EndTime\": 1587306157.517772, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306145.323059}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:37 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.2994568013 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:37 INFO 140480903202624] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:37 INFO 140480903202624] #quality_metric: host=algo-1, epoch=1, train loss <loss>=4.05397796631\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:37 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:37 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_7ea4ee1c-e985-4f46-a78d-37775fa80717-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 101.53985023498535, \"sum\": 101.53985023498535, \"min\": 101.53985023498535}}, \"EndTime\": 1587306157.620017, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306157.517841}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:39 INFO 140480903202624] Epoch[2] Batch[0] avg_epoch_loss=3.711143\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:39 INFO 140480903202624] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.71114253998\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:45 INFO 140480903202624] Epoch[2] Batch[5] avg_epoch_loss=3.778180\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:45 INFO 140480903202624] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.77818044027\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:45 INFO 140480903202624] Epoch[2] Batch [5]#011Speed: 56.17 samples/sec#011loss=3.778180\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:51 INFO 140480903202624] Epoch[2] Batch[10] avg_epoch_loss=3.718525\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.64693932533\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:51 INFO 140480903202624] Epoch[2] Batch [10]#011Speed: 57.15 samples/sec#011loss=3.646939\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:51 INFO 140480903202624] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13406.954050064087, \"sum\": 13406.954050064087, \"min\": 13406.954050064087}}, \"EndTime\": 1587306171.027097, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306157.620088}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:51 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.3022285077 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:51 INFO 140480903202624] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.71852538802\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:51 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:51 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_6dd4ec33-4a67-4967-858d-ce48e5757310-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 105.91983795166016, \"sum\": 105.91983795166016, \"min\": 105.91983795166016}}, \"EndTime\": 1587306171.133615, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306171.027211}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:53 INFO 140480903202624] Epoch[3] Batch[0] avg_epoch_loss=3.561118\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.56111836433\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:58 INFO 140480903202624] Epoch[3] Batch[5] avg_epoch_loss=3.558848\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.55884766579\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:58 INFO 140480903202624] Epoch[3] Batch [5]#011Speed: 56.63 samples/sec#011loss=3.558848\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:03 INFO 140480903202624] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12156.412124633789, \"sum\": 12156.412124633789, \"min\": 12156.412124633789}}, \"EndTime\": 1587306183.290162, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306171.133686}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:03 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.0836777188 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:03 INFO 140480903202624] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:03 INFO 140480903202624] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.54301650524\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:03 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:03 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_f25d4da4-9eda-4968-a068-7f3b1b091002-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 105.61490058898926, \"sum\": 105.61490058898926, \"min\": 105.61490058898926}}, \"EndTime\": 1587306183.39635, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306183.290237}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:05 INFO 140480903202624] Epoch[4] Batch[0] avg_epoch_loss=3.536608\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:05 INFO 140480903202624] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.53660821915\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:11 INFO 140480903202624] Epoch[4] Batch[5] avg_epoch_loss=3.475894\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.47589445114\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:11 INFO 140480903202624] Epoch[4] Batch [5]#011Speed: 57.19 samples/sec#011loss=3.475894\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:16 INFO 140480903202624] Epoch[4] Batch[10] avg_epoch_loss=3.458081\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.43670535088\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:16 INFO 140480903202624] Epoch[4] Batch [10]#011Speed: 56.88 samples/sec#011loss=3.436705\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:16 INFO 140480903202624] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13268.29218864441, \"sum\": 13268.29218864441, \"min\": 13268.29218864441}}, \"EndTime\": 1587306196.664809, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306183.396453}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:16 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.515990755 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:16 INFO 140480903202624] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.45808122375\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:16 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:16 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_4af67dff-cadb-44ed-beee-be59c8efc790-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.48705673217773, \"sum\": 109.48705673217773, \"min\": 109.48705673217773}}, \"EndTime\": 1587306196.774959, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306196.664922}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:18 INFO 140480903202624] Epoch[5] Batch[0] avg_epoch_loss=3.453990\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.45399045944\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:24 INFO 140480903202624] Epoch[5] Batch[5] avg_epoch_loss=3.440799\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:24 INFO 140480903202624] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.44079875946\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:24 INFO 140480903202624] Epoch[5] Batch [5]#011Speed: 56.88 samples/sec#011loss=3.440799\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140480903202624] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12106.085062026978, \"sum\": 12106.085062026978, \"min\": 12106.085062026978}}, \"EndTime\": 1587306208.881194, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306196.775039}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.6260561281 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140480903202624] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140480903202624] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.42972257137\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_208ef799-1234-4b4d-8615-296eac4b0936-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 115.03005027770996, \"sum\": 115.03005027770996, \"min\": 115.03005027770996}}, \"EndTime\": 1587306208.996878, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306208.881361}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:31 INFO 140480903202624] Epoch[6] Batch[0] avg_epoch_loss=3.349882\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:31 INFO 140480903202624] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.34988164902\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:36 INFO 140480903202624] Epoch[6] Batch[5] avg_epoch_loss=3.388487\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:36 INFO 140480903202624] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.38848694166\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:36 INFO 140480903202624] Epoch[6] Batch [5]#011Speed: 57.25 samples/sec#011loss=3.388487\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:41 INFO 140480903202624] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12070.458173751831, \"sum\": 12070.458173751831, \"min\": 12070.458173751831}}, \"EndTime\": 1587306221.067475, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306208.99695}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:41 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.0390580292 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:41 INFO 140480903202624] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:41 INFO 140480903202624] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.36594927311\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:41 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:41 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_fb59e706-22d4-4808-bb5e-dbd8d5082c4f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 162.977933883667, \"sum\": 162.977933883667, \"min\": 162.977933883667}}, \"EndTime\": 1587306221.231058, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306221.067549}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:43 INFO 140480903202624] Epoch[7] Batch[0] avg_epoch_loss=3.346093\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:43 INFO 140480903202624] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.3460931778\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:49 INFO 140480903202624] Epoch[7] Batch[5] avg_epoch_loss=3.300568\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:49 INFO 140480903202624] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.30056798458\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:49 INFO 140480903202624] Epoch[7] Batch [5]#011Speed: 56.06 samples/sec#011loss=3.300568\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:53 INFO 140480903202624] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12297.327041625977, \"sum\": 12297.327041625977, \"min\": 12297.327041625977}}, \"EndTime\": 1587306233.528518, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306221.231127}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:53 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.8807204408 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:53 INFO 140480903202624] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.27612166405\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:53 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:53 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_1f2ff9a8-9e57-424f-8221-f0b19241703f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 146.15893363952637, \"sum\": 146.15893363952637, \"min\": 146.15893363952637}}, \"EndTime\": 1587306233.675297, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306233.528592}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:55 INFO 140480903202624] Epoch[8] Batch[0] avg_epoch_loss=3.240924\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:55 INFO 140480903202624] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.24092435837\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:01 INFO 140480903202624] Epoch[8] Batch[5] avg_epoch_loss=3.338812\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:01 INFO 140480903202624] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.33881231149\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:01 INFO 140480903202624] Epoch[8] Batch [5]#011Speed: 57.18 samples/sec#011loss=3.338812\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:06 INFO 140480903202624] Epoch[8] Batch[10] avg_epoch_loss=3.280210\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:06 INFO 140480903202624] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.20988745689\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:06 INFO 140480903202624] Epoch[8] Batch [10]#011Speed: 57.16 samples/sec#011loss=3.209887\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:06 INFO 140480903202624] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13278.403043746948, \"sum\": 13278.403043746948, \"min\": 13278.403043746948}}, \"EndTime\": 1587306246.953836, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306233.675368}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:06 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.7043341177 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:06 INFO 140480903202624] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:06 INFO 140480903202624] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.28021010486\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:06 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:08 INFO 140480903202624] Epoch[9] Batch[0] avg_epoch_loss=3.268190\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:08 INFO 140480903202624] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.26818990707\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:14 INFO 140480903202624] Epoch[9] Batch[5] avg_epoch_loss=3.221918\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:14 INFO 140480903202624] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.22191806634\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:14 INFO 140480903202624] Epoch[9] Batch [5]#011Speed: 56.15 samples/sec#011loss=3.221918\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:20 INFO 140480903202624] Epoch[9] Batch[10] avg_epoch_loss=3.248583\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:20 INFO 140480903202624] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.28058075905\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:20 INFO 140480903202624] Epoch[9] Batch [10]#011Speed: 57.13 samples/sec#011loss=3.280581\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:20 INFO 140480903202624] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13342.273950576782, \"sum\": 13342.273950576782, \"min\": 13342.273950576782}}, \"EndTime\": 1587306260.296577, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306246.953916}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:20 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.7918683719 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:20 INFO 140480903202624] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:20 INFO 140480903202624] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.24858292666\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:20 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:20 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_b07a8f6d-bc3c-4352-ba08-44073cb167ed-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 100.04496574401855, \"sum\": 100.04496574401855, \"min\": 100.04496574401855}}, \"EndTime\": 1587306260.397309, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306260.296656}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:22 INFO 140480903202624] Epoch[10] Batch[0] avg_epoch_loss=3.243581\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:22 INFO 140480903202624] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.24358105659\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:28 INFO 140480903202624] Epoch[10] Batch[5] avg_epoch_loss=3.355030\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:28 INFO 140480903202624] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.35503017902\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:28 INFO 140480903202624] Epoch[10] Batch [5]#011Speed: 57.21 samples/sec#011loss=3.355030\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:32 INFO 140480903202624] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12143.544912338257, \"sum\": 12143.544912338257, \"min\": 12143.544912338257}}, \"EndTime\": 1587306272.540993, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306260.397381}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:32 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.5377159142 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:32 INFO 140480903202624] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:32 INFO 140480903202624] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.3402307272\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:32 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:34 INFO 140480903202624] Epoch[11] Batch[0] avg_epoch_loss=3.177681\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:34 INFO 140480903202624] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=3.17768073082\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:40 INFO 140480903202624] Epoch[11] Batch[5] avg_epoch_loss=3.210149\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:40 INFO 140480903202624] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.21014889081\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:40 INFO 140480903202624] Epoch[11] Batch [5]#011Speed: 56.97 samples/sec#011loss=3.210149\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:44 INFO 140480903202624] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12135.502099990845, \"sum\": 12135.502099990845, \"min\": 12135.502099990845}}, \"EndTime\": 1587306284.677188, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306272.541065}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:44 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.4076968378 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:44 INFO 140480903202624] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:44 INFO 140480903202624] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.18687484264\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:44 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:44 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_bfc831fc-1b7c-426e-87e5-5ecec0099606-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 100.36611557006836, \"sum\": 100.36611557006836, \"min\": 100.36611557006836}}, \"EndTime\": 1587306284.77828, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306284.677265}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:46 INFO 140480903202624] Epoch[12] Batch[0] avg_epoch_loss=3.172338\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:46 INFO 140480903202624] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.17233753204\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:52 INFO 140480903202624] Epoch[12] Batch[5] avg_epoch_loss=3.219348\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:52 INFO 140480903202624] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=3.21934843063\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:52 INFO 140480903202624] Epoch[12] Batch [5]#011Speed: 57.00 samples/sec#011loss=3.219348\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:56 INFO 140480903202624] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12167.083024978638, \"sum\": 12167.083024978638, \"min\": 12167.083024978638}}, \"EndTime\": 1587306296.945494, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306284.778349}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:56 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.4361055084 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:56 INFO 140480903202624] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:56 INFO 140480903202624] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.19231247902\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:56 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:58 INFO 140480903202624] Epoch[13] Batch[0] avg_epoch_loss=3.157176\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.1571764946\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:04 INFO 140480903202624] Epoch[13] Batch[5] avg_epoch_loss=3.170614\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=3.17061372598\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:04 INFO 140480903202624] Epoch[13] Batch [5]#011Speed: 56.83 samples/sec#011loss=3.170614\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:09 INFO 140480903202624] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12135.861873626709, \"sum\": 12135.861873626709, \"min\": 12135.861873626709}}, \"EndTime\": 1587306309.081919, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306296.945566}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:09 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.9109909552 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:09 INFO 140480903202624] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:09 INFO 140480903202624] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.17522068024\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:09 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:09 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_709a9f40-c406-42ab-b1ac-3ea414f598b2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 101.14312171936035, \"sum\": 101.14312171936035, \"min\": 101.14312171936035}}, \"EndTime\": 1587306309.183866, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306309.081998}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:11 INFO 140480903202624] Epoch[14] Batch[0] avg_epoch_loss=3.064487\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=3.06448674202\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:16 INFO 140480903202624] Epoch[14] Batch[5] avg_epoch_loss=3.061749\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=3.06174874306\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:16 INFO 140480903202624] Epoch[14] Batch [5]#011Speed: 56.82 samples/sec#011loss=3.061749\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:21 INFO 140480903202624] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12127.97999382019, \"sum\": 12127.97999382019, \"min\": 12127.97999382019}}, \"EndTime\": 1587306321.311969, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306309.183926}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:21 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.4718879329 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:21 INFO 140480903202624] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:21 INFO 140480903202624] #quality_metric: host=algo-1, epoch=14, train loss <loss>=3.08086633682\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:21 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:21 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_b767bcff-8f39-445f-abcc-5e21477ad167-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 102.86808013916016, \"sum\": 102.86808013916016, \"min\": 102.86808013916016}}, \"EndTime\": 1587306321.415673, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306321.312053}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:23 INFO 140480903202624] Epoch[15] Batch[0] avg_epoch_loss=2.980438\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:23 INFO 140480903202624] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=2.980437994\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:29 INFO 140480903202624] Epoch[15] Batch[5] avg_epoch_loss=2.989737\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:29 INFO 140480903202624] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=2.98973695437\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:29 INFO 140480903202624] Epoch[15] Batch [5]#011Speed: 57.15 samples/sec#011loss=2.989737\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:33 INFO 140480903202624] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12162.353992462158, \"sum\": 12162.353992462158, \"min\": 12162.353992462158}}, \"EndTime\": 1587306333.5782, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306321.415756}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:33 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.6474982968 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:33 INFO 140480903202624] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=15, train loss <loss>=2.9642288208\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:33 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:33 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_cf33ae87-392b-479b-ac5c-6169bd5bbf06-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 133.87298583984375, \"sum\": 133.87298583984375, \"min\": 133.87298583984375}}, \"EndTime\": 1587306333.712792, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306333.578283}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:35 INFO 140480903202624] Epoch[16] Batch[0] avg_epoch_loss=2.902596\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:35 INFO 140480903202624] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=2.90259599686\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:41 INFO 140480903202624] Epoch[16] Batch[5] avg_epoch_loss=2.924783\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:41 INFO 140480903202624] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=2.92478326956\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:41 INFO 140480903202624] Epoch[16] Batch [5]#011Speed: 56.99 samples/sec#011loss=2.924783\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:47 INFO 140480903202624] Epoch[16] Batch[10] avg_epoch_loss=2.915985\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:47 INFO 140480903202624] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=2.90542683601\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:47 INFO 140480903202624] Epoch[16] Batch [10]#011Speed: 56.17 samples/sec#011loss=2.905427\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:47 INFO 140480903202624] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13347.933053970337, \"sum\": 13347.933053970337, \"min\": 13347.933053970337}}, \"EndTime\": 1587306347.060868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306333.712868}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:47 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.3965645574 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:47 INFO 140480903202624] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:47 INFO 140480903202624] #quality_metric: host=algo-1, epoch=16, train loss <loss>=2.91598489068\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:47 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:47 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_99243825-ca6a-45f9-98ba-4115aa0cf1f7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 100.91495513916016, \"sum\": 100.91495513916016, \"min\": 100.91495513916016}}, \"EndTime\": 1587306347.162635, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306347.060952}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:49 INFO 140480903202624] Epoch[17] Batch[0] avg_epoch_loss=3.441592\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:49 INFO 140480903202624] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=3.44159150124\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:54 INFO 140480903202624] Epoch[17] Batch[5] avg_epoch_loss=3.345646\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:54 INFO 140480903202624] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=3.34564606349\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:54 INFO 140480903202624] Epoch[17] Batch [5]#011Speed: 56.93 samples/sec#011loss=3.345646\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:59 INFO 140480903202624] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12093.628883361816, \"sum\": 12093.628883361816, \"min\": 12093.628883361816}}, \"EndTime\": 1587306359.256409, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306347.162709}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:59 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.5969114311 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:59 INFO 140480903202624] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:59 INFO 140480903202624] #quality_metric: host=algo-1, epoch=17, train loss <loss>=3.2703448534\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:59 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:01 INFO 140480903202624] Epoch[18] Batch[0] avg_epoch_loss=3.085684\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:01 INFO 140480903202624] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.08568429947\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:06 INFO 140480903202624] Epoch[18] Batch[5] avg_epoch_loss=3.019557\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:06 INFO 140480903202624] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=3.01955743631\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:06 INFO 140480903202624] Epoch[18] Batch [5]#011Speed: 56.93 samples/sec#011loss=3.019557\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:12 INFO 140480903202624] Epoch[18] Batch[10] avg_epoch_loss=2.950759\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:12 INFO 140480903202624] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=2.86820163727\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:12 INFO 140480903202624] Epoch[18] Batch [10]#011Speed: 57.01 samples/sec#011loss=2.868202\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:12 INFO 140480903202624] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13352.606058120728, \"sum\": 13352.606058120728, \"min\": 13352.606058120728}}, \"EndTime\": 1587306372.609571, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306359.256487}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:12 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.9259881323 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:12 INFO 140480903202624] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:12 INFO 140480903202624] #quality_metric: host=algo-1, epoch=18, train loss <loss>=2.95075934583\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:12 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:14 INFO 140480903202624] Epoch[19] Batch[0] avg_epoch_loss=2.836216\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:14 INFO 140480903202624] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=2.8362159729\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:20 INFO 140480903202624] Epoch[19] Batch[5] avg_epoch_loss=2.787948\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:20 INFO 140480903202624] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=2.78794781367\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:20 INFO 140480903202624] Epoch[19] Batch [5]#011Speed: 57.36 samples/sec#011loss=2.787948\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:25 INFO 140480903202624] Epoch[19] Batch[10] avg_epoch_loss=2.869258\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:25 INFO 140480903202624] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=2.96683058739\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:25 INFO 140480903202624] Epoch[19] Batch [10]#011Speed: 57.47 samples/sec#011loss=2.966831\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:26 INFO 140480903202624] processed a total of 713 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14388.7939453125, \"sum\": 14388.7939453125, \"min\": 14388.7939453125}}, \"EndTime\": 1587306386.999001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306372.609643}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:26 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.5520440918 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:26 INFO 140480903202624] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:26 INFO 140480903202624] #quality_metric: host=algo-1, epoch=19, train loss <loss>=2.91432271401\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:26 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:27 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_e4c45865-9d7f-4477-86f7-095a8e76959c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 125.49304962158203, \"sum\": 125.49304962158203, \"min\": 125.49304962158203}}, \"EndTime\": 1587306387.125073, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306386.999083}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:29 INFO 140480903202624] Epoch[20] Batch[0] avg_epoch_loss=2.994012\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:29 INFO 140480903202624] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=2.9940123558\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:34 INFO 140480903202624] Epoch[20] Batch[5] avg_epoch_loss=3.012662\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:34 INFO 140480903202624] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=3.01266177495\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:34 INFO 140480903202624] Epoch[20] Batch [5]#011Speed: 57.53 samples/sec#011loss=3.012662\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:40 INFO 140480903202624] Epoch[20] Batch[10] avg_epoch_loss=2.944975\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:40 INFO 140480903202624] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=2.86374988556\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:40 INFO 140480903202624] Epoch[20] Batch [10]#011Speed: 57.51 samples/sec#011loss=2.863750\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:40 INFO 140480903202624] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13193.352937698364, \"sum\": 13193.352937698364, \"min\": 13193.352937698364}}, \"EndTime\": 1587306400.318566, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306387.125146}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:40 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.2228003802 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:40 INFO 140480903202624] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:40 INFO 140480903202624] #quality_metric: host=algo-1, epoch=20, train loss <loss>=2.9449745525\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:40 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:42 INFO 140480903202624] Epoch[21] Batch[0] avg_epoch_loss=2.724001\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:42 INFO 140480903202624] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=2.72400093079\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:48 INFO 140480903202624] Epoch[21] Batch[5] avg_epoch_loss=2.752842\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:48 INFO 140480903202624] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=2.75284202894\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:48 INFO 140480903202624] Epoch[21] Batch [5]#011Speed: 56.94 samples/sec#011loss=2.752842\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:53 INFO 140480903202624] Epoch[21] Batch[10] avg_epoch_loss=2.669104\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=2.56861829758\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:53 INFO 140480903202624] Epoch[21] Batch [10]#011Speed: 57.46 samples/sec#011loss=2.568618\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:53 INFO 140480903202624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13288.72299194336, \"sum\": 13288.72299194336, \"min\": 13288.72299194336}}, \"EndTime\": 1587306413.607799, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306400.318645}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:53 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.8379545855 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:53 INFO 140480903202624] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=21, train loss <loss>=2.66910396923\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:53 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:53 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_5cca6962-3333-4889-8ff9-33fb03ef12e1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 108.47616195678711, \"sum\": 108.47616195678711, \"min\": 108.47616195678711}}, \"EndTime\": 1587306413.716888, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306413.607883}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:55 INFO 140480903202624] Epoch[22] Batch[0] avg_epoch_loss=2.705843\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:55 INFO 140480903202624] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=2.70584321022\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:01 INFO 140480903202624] Epoch[22] Batch[5] avg_epoch_loss=2.710466\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:01 INFO 140480903202624] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=2.7104656299\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:01 INFO 140480903202624] Epoch[22] Batch [5]#011Speed: 57.45 samples/sec#011loss=2.710466\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:05 INFO 140480903202624] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12105.910062789917, \"sum\": 12105.910062789917, \"min\": 12105.910062789917}}, \"EndTime\": 1587306425.822929, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306413.71696}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:05 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.1228919039 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:05 INFO 140480903202624] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:05 INFO 140480903202624] #quality_metric: host=algo-1, epoch=22, train loss <loss>=2.70104827881\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:05 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:07 INFO 140480903202624] Epoch[23] Batch[0] avg_epoch_loss=2.665755\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:07 INFO 140480903202624] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=2.66575503349\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:13 INFO 140480903202624] Epoch[23] Batch[5] avg_epoch_loss=2.594226\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=2.5942261219\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:13 INFO 140480903202624] Epoch[23] Batch [5]#011Speed: 56.74 samples/sec#011loss=2.594226\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:19 INFO 140480903202624] Epoch[23] Batch[10] avg_epoch_loss=2.618847\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:19 INFO 140480903202624] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=2.64839196205\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:19 INFO 140480903202624] Epoch[23] Batch [10]#011Speed: 56.68 samples/sec#011loss=2.648392\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:19 INFO 140480903202624] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13370.801210403442, \"sum\": 13370.801210403442, \"min\": 13370.801210403442}}, \"EndTime\": 1587306439.194275, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306425.822993}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:19 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.8566462449 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:19 INFO 140480903202624] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:19 INFO 140480903202624] #quality_metric: host=algo-1, epoch=23, train loss <loss>=2.61884695833\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:19 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:19 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_42a50588-568c-40dc-8db2-0865dc01e67f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 108.2308292388916, \"sum\": 108.2308292388916, \"min\": 108.2308292388916}}, \"EndTime\": 1587306439.303035, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306439.194354}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:21 INFO 140480903202624] Epoch[24] Batch[0] avg_epoch_loss=2.451327\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:21 INFO 140480903202624] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.45132660866\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:26 INFO 140480903202624] Epoch[24] Batch[5] avg_epoch_loss=2.520224\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:26 INFO 140480903202624] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.52022373676\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:26 INFO 140480903202624] Epoch[24] Batch [5]#011Speed: 56.94 samples/sec#011loss=2.520224\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:31 INFO 140480903202624] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12143.716096878052, \"sum\": 12143.716096878052, \"min\": 12143.716096878052}}, \"EndTime\": 1587306451.446888, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306439.303107}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:31 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.231294109 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:31 INFO 140480903202624] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:31 INFO 140480903202624] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.69770965576\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:31 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:33 INFO 140480903202624] Epoch[25] Batch[0] avg_epoch_loss=2.625566\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=2.62556576729\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:39 INFO 140480903202624] Epoch[25] Batch[5] avg_epoch_loss=2.928556\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:39 INFO 140480903202624] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=2.92855552832\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:39 INFO 140480903202624] Epoch[25] Batch [5]#011Speed: 57.09 samples/sec#011loss=2.928556\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:43 INFO 140480903202624] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12121.359825134277, \"sum\": 12121.359825134277, \"min\": 12121.359825134277}}, \"EndTime\": 1587306463.568922, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306451.446957}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:43 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.3963470052 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:43 INFO 140480903202624] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:43 INFO 140480903202624] #quality_metric: host=algo-1, epoch=25, train loss <loss>=2.89677517414\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:43 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:45 INFO 140480903202624] Epoch[26] Batch[0] avg_epoch_loss=2.704473\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:45 INFO 140480903202624] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=2.70447278023\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:51 INFO 140480903202624] Epoch[26] Batch[5] avg_epoch_loss=2.560067\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.56006741524\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:51 INFO 140480903202624] Epoch[26] Batch [5]#011Speed: 57.10 samples/sec#011loss=2.560067\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:56 INFO 140480903202624] Epoch[26] Batch[10] avg_epoch_loss=2.577780\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:56 INFO 140480903202624] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=2.59903607368\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:56 INFO 140480903202624] Epoch[26] Batch [10]#011Speed: 57.08 samples/sec#011loss=2.599036\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:56 INFO 140480903202624] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13360.973119735718, \"sum\": 13360.973119735718, \"min\": 13360.973119735718}}, \"EndTime\": 1587306476.930423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306463.569005}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:56 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.2683218875 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:56 INFO 140480903202624] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:56 INFO 140480903202624] #quality_metric: host=algo-1, epoch=26, train loss <loss>=2.5777804418\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:56 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:57 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_b29bfe99-0a93-4e56-a9f1-1baf2ec10623-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.67318916320801, \"sum\": 110.67318916320801, \"min\": 110.67318916320801}}, \"EndTime\": 1587306477.041688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306476.930495}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:59 INFO 140480903202624] Epoch[27] Batch[0] avg_epoch_loss=3.170892\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:59 INFO 140480903202624] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=3.17089152336\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:04 INFO 140480903202624] Epoch[27] Batch[5] avg_epoch_loss=2.771929\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=2.77192910512\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:04 INFO 140480903202624] Epoch[27] Batch [5]#011Speed: 57.06 samples/sec#011loss=2.771929\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:09 INFO 140480903202624] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12128.71503829956, \"sum\": 12128.71503829956, \"min\": 12128.71503829956}}, \"EndTime\": 1587306489.170547, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306477.041769}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:09 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.2721864694 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:09 INFO 140480903202624] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:09 INFO 140480903202624] #quality_metric: host=algo-1, epoch=27, train loss <loss>=2.70967082977\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:09 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:11 INFO 140480903202624] Epoch[28] Batch[0] avg_epoch_loss=2.530167\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=2.5301668644\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:16 INFO 140480903202624] Epoch[28] Batch[5] avg_epoch_loss=2.451352\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=2.45135168235\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:16 INFO 140480903202624] Epoch[28] Batch [5]#011Speed: 56.28 samples/sec#011loss=2.451352\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:22 INFO 140480903202624] Epoch[28] Batch[10] avg_epoch_loss=2.501144\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:22 INFO 140480903202624] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=2.56089553833\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:22 INFO 140480903202624] Epoch[28] Batch [10]#011Speed: 57.19 samples/sec#011loss=2.560896\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:22 INFO 140480903202624] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13330.78908920288, \"sum\": 13330.78908920288, \"min\": 13330.78908920288}}, \"EndTime\": 1587306502.50192, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306489.170619}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:22 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.9591105639 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:22 INFO 140480903202624] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:22 INFO 140480903202624] #quality_metric: host=algo-1, epoch=28, train loss <loss>=2.50114434416\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:22 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:22 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_0323d603-d8f3-494b-8ba8-20a65e210469-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 107.38992691040039, \"sum\": 107.38992691040039, \"min\": 107.38992691040039}}, \"EndTime\": 1587306502.609825, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306502.501998}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:24 INFO 140480903202624] Epoch[29] Batch[0] avg_epoch_loss=2.734596\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:24 INFO 140480903202624] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.73459649086\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:30 INFO 140480903202624] Epoch[29] Batch[5] avg_epoch_loss=2.873918\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:30 INFO 140480903202624] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.87391813596\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:30 INFO 140480903202624] Epoch[29] Batch [5]#011Speed: 57.16 samples/sec#011loss=2.873918\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:35 INFO 140480903202624] Epoch[29] Batch[10] avg_epoch_loss=2.853598\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:35 INFO 140480903202624] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=2.82921299934\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:35 INFO 140480903202624] Epoch[29] Batch [10]#011Speed: 57.31 samples/sec#011loss=2.829213\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:35 INFO 140480903202624] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13220.4270362854, \"sum\": 13220.4270362854, \"min\": 13220.4270362854}}, \"EndTime\": 1587306515.830388, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306502.609898}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:35 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.4351077561 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:35 INFO 140480903202624] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:35 INFO 140480903202624] #quality_metric: host=algo-1, epoch=29, train loss <loss>=2.85359761932\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:35 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:37 INFO 140480903202624] Epoch[30] Batch[0] avg_epoch_loss=2.634500\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:37 INFO 140480903202624] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=2.63449978828\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:43 INFO 140480903202624] Epoch[30] Batch[5] avg_epoch_loss=2.495751\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:43 INFO 140480903202624] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.49575050672\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:43 INFO 140480903202624] Epoch[30] Batch [5]#011Speed: 56.88 samples/sec#011loss=2.495751\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:48 INFO 140480903202624] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12265.854835510254, \"sum\": 12265.854835510254, \"min\": 12265.854835510254}}, \"EndTime\": 1587306528.096715, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306515.830468}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:48 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.280091306 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:48 INFO 140480903202624] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:48 INFO 140480903202624] #quality_metric: host=algo-1, epoch=30, train loss <loss>=2.38819298744\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:48 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:48 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_d3530c47-107a-49d9-ad2e-7bc0f0241ff9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.73286628723145, \"sum\": 109.73286628723145, \"min\": 109.73286628723145}}, \"EndTime\": 1587306528.207052, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306528.096793}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:50 INFO 140480903202624] Epoch[31] Batch[0] avg_epoch_loss=2.729009\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:50 INFO 140480903202624] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.72900915146\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:55 INFO 140480903202624] Epoch[31] Batch[5] avg_epoch_loss=2.603520\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:55 INFO 140480903202624] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.6035198768\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:55 INFO 140480903202624] Epoch[31] Batch [5]#011Speed: 56.83 samples/sec#011loss=2.603520\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:00 INFO 140480903202624] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12179.455041885376, \"sum\": 12179.455041885376, \"min\": 12179.455041885376}}, \"EndTime\": 1587306540.386658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306528.207137}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:00 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.9049052154 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:00 INFO 140480903202624] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:00 INFO 140480903202624] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.49824233055\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:00 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:02 INFO 140480903202624] Epoch[32] Batch[0] avg_epoch_loss=2.342788\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:02 INFO 140480903202624] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=2.3427875042\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:08 INFO 140480903202624] Epoch[32] Batch[5] avg_epoch_loss=2.248118\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:08 INFO 140480903202624] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.24811808268\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:08 INFO 140480903202624] Epoch[32] Batch [5]#011Speed: 56.79 samples/sec#011loss=2.248118\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140480903202624] Epoch[32] Batch[10] avg_epoch_loss=2.284040\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=2.32714619637\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140480903202624] Epoch[32] Batch [10]#011Speed: 56.67 samples/sec#011loss=2.327146\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140480903202624] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13332.491874694824, \"sum\": 13332.491874694824, \"min\": 13332.491874694824}}, \"EndTime\": 1587306553.720052, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306540.386742}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.8023655596 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140480903202624] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.28403995254\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_3df60277-8d88-4829-90d8-026680c7a13c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.7630729675293, \"sum\": 110.7630729675293, \"min\": 110.7630729675293}}, \"EndTime\": 1587306553.831745, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306553.720129}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:15 INFO 140480903202624] Epoch[33] Batch[0] avg_epoch_loss=2.558241\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:15 INFO 140480903202624] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=2.55824112892\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:21 INFO 140480903202624] Epoch[33] Batch[5] avg_epoch_loss=2.449262\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:21 INFO 140480903202624] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.44926218192\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:21 INFO 140480903202624] Epoch[33] Batch [5]#011Speed: 57.00 samples/sec#011loss=2.449262\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140480903202624] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12174.957990646362, \"sum\": 12174.957990646362, \"min\": 12174.957990646362}}, \"EndTime\": 1587306566.006823, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306553.831806}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.5807696422 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140480903202624] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140480903202624] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.37152750492\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:28 INFO 140480903202624] Epoch[34] Batch[0] avg_epoch_loss=2.237469\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:28 INFO 140480903202624] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=2.23746871948\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:33 INFO 140480903202624] Epoch[34] Batch[5] avg_epoch_loss=2.196954\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.19695444902\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:33 INFO 140480903202624] Epoch[34] Batch [5]#011Speed: 56.76 samples/sec#011loss=2.196954\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:38 INFO 140480903202624] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12127.714157104492, \"sum\": 12127.714157104492, \"min\": 12127.714157104492}}, \"EndTime\": 1587306578.135131, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306566.006895}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:38 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.9677059872 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:38 INFO 140480903202624] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.19375275373\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:38 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:38 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_d123d3d8-9e7c-46fa-81dc-06c8d3ea7006-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 101.93991661071777, \"sum\": 101.93991661071777, \"min\": 101.93991661071777}}, \"EndTime\": 1587306578.237865, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306578.135215}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:40 INFO 140480903202624] Epoch[35] Batch[0] avg_epoch_loss=3.228451\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:40 INFO 140480903202624] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=3.22845125198\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:45 INFO 140480903202624] Epoch[35] Batch[5] avg_epoch_loss=2.386286\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:45 INFO 140480903202624] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.38628578186\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:45 INFO 140480903202624] Epoch[35] Batch [5]#011Speed: 56.72 samples/sec#011loss=2.386286\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:51 INFO 140480903202624] Epoch[35] Batch[10] avg_epoch_loss=2.279949\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=2.15234379768\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:51 INFO 140480903202624] Epoch[35] Batch [10]#011Speed: 57.11 samples/sec#011loss=2.152344\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:51 INFO 140480903202624] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13274.631977081299, \"sum\": 13274.631977081299, \"min\": 13274.631977081299}}, \"EndTime\": 1587306591.512641, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306578.237943}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:51 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.115817575 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:51 INFO 140480903202624] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.27994851633\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:51 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:53 INFO 140480903202624] Epoch[36] Batch[0] avg_epoch_loss=2.008991\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.00899147987\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:59 INFO 140480903202624] Epoch[36] Batch[5] avg_epoch_loss=2.074900\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:59 INFO 140480903202624] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.07490005096\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:59 INFO 140480903202624] Epoch[36] Batch [5]#011Speed: 57.13 samples/sec#011loss=2.074900\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:04 INFO 140480903202624] Epoch[36] Batch[10] avg_epoch_loss=2.221052\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=2.39643468857\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:04 INFO 140480903202624] Epoch[36] Batch [10]#011Speed: 56.19 samples/sec#011loss=2.396435\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:04 INFO 140480903202624] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13344.64406967163, \"sum\": 13344.64406967163, \"min\": 13344.64406967163}}, \"EndTime\": 1587306604.857759, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306591.512717}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:04 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.0827554957 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:04 INFO 140480903202624] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.22105215896\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:04 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:06 INFO 140480903202624] Epoch[37] Batch[0] avg_epoch_loss=2.669056\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:06 INFO 140480903202624] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.66905617714\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:12 INFO 140480903202624] Epoch[37] Batch[5] avg_epoch_loss=2.269279\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:12 INFO 140480903202624] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.26927894354\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:12 INFO 140480903202624] Epoch[37] Batch [5]#011Speed: 56.30 samples/sec#011loss=2.269279\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:18 INFO 140480903202624] Epoch[37] Batch[10] avg_epoch_loss=2.218452\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=2.15746035576\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:18 INFO 140480903202624] Epoch[37] Batch [10]#011Speed: 56.28 samples/sec#011loss=2.157460\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:18 INFO 140480903202624] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13449.542045593262, \"sum\": 13449.542045593262, \"min\": 13449.542045593262}}, \"EndTime\": 1587306618.307937, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306604.857883}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:18 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.4436402216 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:18 INFO 140480903202624] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.21845231273\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:18 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:20 INFO 140480903202624] Epoch[38] Batch[0] avg_epoch_loss=2.055517\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:20 INFO 140480903202624] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.05551743507\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:25 INFO 140480903202624] Epoch[38] Batch[5] avg_epoch_loss=1.921837\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:25 INFO 140480903202624] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=1.92183740934\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:25 INFO 140480903202624] Epoch[38] Batch [5]#011Speed: 56.98 samples/sec#011loss=1.921837\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:30 INFO 140480903202624] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12119.96603012085, \"sum\": 12119.96603012085, \"min\": 12119.96603012085}}, \"EndTime\": 1587306630.428534, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306618.308012}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:30 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.2273688156 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:30 INFO 140480903202624] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:30 INFO 140480903202624] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.1159889698\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:30 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:30 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_c59c2897-c883-408c-b7e7-dfba385cc848-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 99.67899322509766, \"sum\": 99.67899322509766, \"min\": 99.67899322509766}}, \"EndTime\": 1587306630.528868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306630.428608}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:32 INFO 140480903202624] Epoch[39] Batch[0] avg_epoch_loss=2.164880\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:32 INFO 140480903202624] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.16487979889\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:38 INFO 140480903202624] Epoch[39] Batch[5] avg_epoch_loss=2.324257\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.32425713539\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:38 INFO 140480903202624] Epoch[39] Batch [5]#011Speed: 56.84 samples/sec#011loss=2.324257\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:42 INFO 140480903202624] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12140.291929244995, \"sum\": 12140.291929244995, \"min\": 12140.291929244995}}, \"EndTime\": 1587306642.669306, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306630.528945}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:42 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.2222718289 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:42 INFO 140480903202624] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:42 INFO 140480903202624] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.32721502781\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:42 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:44 INFO 140480903202624] Epoch[40] Batch[0] avg_epoch_loss=2.227769\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:44 INFO 140480903202624] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.22776865959\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:50 INFO 140480903202624] Epoch[40] Batch[5] avg_epoch_loss=2.091585\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:50 INFO 140480903202624] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.09158470233\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:50 INFO 140480903202624] Epoch[40] Batch [5]#011Speed: 56.56 samples/sec#011loss=2.091585\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:54 INFO 140480903202624] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12184.014797210693, \"sum\": 12184.014797210693, \"min\": 12184.014797210693}}, \"EndTime\": 1587306654.853943, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306642.669386}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:54 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.8859313791 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:54 INFO 140480903202624] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:54 INFO 140480903202624] #quality_metric: host=algo-1, epoch=40, train loss <loss>=1.99860010147\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:54 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:54 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_14c85a87-f223-475a-a779-ef9c8d54cc06-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 107.4068546295166, \"sum\": 107.4068546295166, \"min\": 107.4068546295166}}, \"EndTime\": 1587306654.96196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306654.85401}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:56 INFO 140480903202624] Epoch[41] Batch[0] avg_epoch_loss=1.855889\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:56 INFO 140480903202624] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=1.85588932037\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:02 INFO 140480903202624] Epoch[41] Batch[5] avg_epoch_loss=2.171689\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:02 INFO 140480903202624] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.17168921232\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:02 INFO 140480903202624] Epoch[41] Batch [5]#011Speed: 57.01 samples/sec#011loss=2.171689\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:07 INFO 140480903202624] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12112.113952636719, \"sum\": 12112.113952636719, \"min\": 12112.113952636719}}, \"EndTime\": 1587306667.074201, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306654.962027}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:07 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.1146369262 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:07 INFO 140480903202624] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:07 INFO 140480903202624] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.10089843273\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:07 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:09 INFO 140480903202624] Epoch[42] Batch[0] avg_epoch_loss=2.240942\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:09 INFO 140480903202624] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.24094176292\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:14 INFO 140480903202624] Epoch[42] Batch[5] avg_epoch_loss=2.005869\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:14 INFO 140480903202624] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.00586911043\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:14 INFO 140480903202624] Epoch[42] Batch [5]#011Speed: 57.28 samples/sec#011loss=2.005869\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:20 INFO 140480903202624] Epoch[42] Batch[10] avg_epoch_loss=1.907928\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:20 INFO 140480903202624] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=1.79039778709\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:20 INFO 140480903202624] Epoch[42] Batch [10]#011Speed: 56.93 samples/sec#011loss=1.790398\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:20 INFO 140480903202624] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13280.643939971924, \"sum\": 13280.643939971924, \"min\": 13280.643939971924}}, \"EndTime\": 1587306680.355658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306667.074275}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:20 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.4159106809 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:20 INFO 140480903202624] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:20 INFO 140480903202624] #quality_metric: host=algo-1, epoch=42, train loss <loss>=1.90792759982\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:20 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:20 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_322db988-5a03-4d0c-a549-f26cad959faa-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.72897911071777, \"sum\": 110.72897911071777, \"min\": 110.72897911071777}}, \"EndTime\": 1587306680.46694, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306680.355735}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:22 INFO 140480903202624] Epoch[43] Batch[0] avg_epoch_loss=2.888169\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:22 INFO 140480903202624] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=2.88816928864\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:28 INFO 140480903202624] Epoch[43] Batch[5] avg_epoch_loss=2.422314\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:28 INFO 140480903202624] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.42231353124\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:28 INFO 140480903202624] Epoch[43] Batch [5]#011Speed: 57.35 samples/sec#011loss=2.422314\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:33 INFO 140480903202624] Epoch[43] Batch[10] avg_epoch_loss=2.384114\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.33827409744\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:33 INFO 140480903202624] Epoch[43] Batch [10]#011Speed: 57.32 samples/sec#011loss=2.338274\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:33 INFO 140480903202624] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13204.44107055664, \"sum\": 13204.44107055664, \"min\": 13204.44107055664}}, \"EndTime\": 1587306693.671517, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306680.467016}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:33 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.7555127867 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:33 INFO 140480903202624] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.3841137886\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:33 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:35 INFO 140480903202624] Epoch[44] Batch[0] avg_epoch_loss=2.127662\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:35 INFO 140480903202624] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.12766194344\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:41 INFO 140480903202624] Epoch[44] Batch[5] avg_epoch_loss=2.116248\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:41 INFO 140480903202624] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.11624821027\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:41 INFO 140480903202624] Epoch[44] Batch [5]#011Speed: 57.35 samples/sec#011loss=2.116248\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:46 INFO 140480903202624] Epoch[44] Batch[10] avg_epoch_loss=1.950960\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:46 INFO 140480903202624] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=1.75261414051\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:46 INFO 140480903202624] Epoch[44] Batch [10]#011Speed: 57.21 samples/sec#011loss=1.752614\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:46 INFO 140480903202624] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13201.036930084229, \"sum\": 13201.036930084229, \"min\": 13201.036930084229}}, \"EndTime\": 1587306706.873165, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306693.671603}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:46 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.7836280379 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:46 INFO 140480903202624] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:46 INFO 140480903202624] #quality_metric: host=algo-1, epoch=44, train loss <loss>=1.95095999674\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:46 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:48 INFO 140480903202624] Epoch[45] Batch[0] avg_epoch_loss=1.788713\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:48 INFO 140480903202624] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=1.78871273994\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:54 INFO 140480903202624] Epoch[45] Batch[5] avg_epoch_loss=2.192260\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:54 INFO 140480903202624] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.1922601064\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:54 INFO 140480903202624] Epoch[45] Batch [5]#011Speed: 57.15 samples/sec#011loss=2.192260\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:00 INFO 140480903202624] Epoch[45] Batch[10] avg_epoch_loss=2.042240\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:00 INFO 140480903202624] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=1.86221494675\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:00 INFO 140480903202624] Epoch[45] Batch [10]#011Speed: 57.55 samples/sec#011loss=1.862215\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:00 INFO 140480903202624] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13254.623889923096, \"sum\": 13254.623889923096, \"min\": 13254.623889923096}}, \"EndTime\": 1587306720.128242, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306706.873243}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:00 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.4355213695 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:00 INFO 140480903202624] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:00 INFO 140480903202624] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.04223957929\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:00 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:02 INFO 140480903202624] Epoch[46] Batch[0] avg_epoch_loss=2.122785\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:02 INFO 140480903202624] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.1227850914\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:07 INFO 140480903202624] Epoch[46] Batch[5] avg_epoch_loss=2.072754\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:07 INFO 140480903202624] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.07275398572\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:07 INFO 140480903202624] Epoch[46] Batch [5]#011Speed: 57.36 samples/sec#011loss=2.072754\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:13 INFO 140480903202624] Epoch[46] Batch[10] avg_epoch_loss=1.998233\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=1.90880794525\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:13 INFO 140480903202624] Epoch[46] Batch [10]#011Speed: 57.49 samples/sec#011loss=1.908808\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:13 INFO 140480903202624] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13191.731929779053, \"sum\": 13191.731929779053, \"min\": 13191.731929779053}}, \"EndTime\": 1587306733.320475, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306720.128319}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:13 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.2727522958 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:13 INFO 140480903202624] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=46, train loss <loss>=1.99823305824\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:13 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:15 INFO 140480903202624] Epoch[47] Batch[0] avg_epoch_loss=1.836238\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:15 INFO 140480903202624] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=1.83623826504\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:21 INFO 140480903202624] Epoch[47] Batch[5] avg_epoch_loss=1.867921\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:21 INFO 140480903202624] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=1.86792097489\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:21 INFO 140480903202624] Epoch[47] Batch [5]#011Speed: 56.49 samples/sec#011loss=1.867921\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140480903202624] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12247.45798110962, \"sum\": 12247.45798110962, \"min\": 12247.45798110962}}, \"EndTime\": 1587306745.568458, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306733.320583}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.9889214301 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140480903202624] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140480903202624] #quality_metric: host=algo-1, epoch=47, train loss <loss>=1.74234725237\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_11636fa5-0a64-4fee-b9cd-a106fc8c17e2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.84208297729492, \"sum\": 112.84208297729492, \"min\": 112.84208297729492}}, \"EndTime\": 1587306745.682222, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306745.568626}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:27 INFO 140480903202624] Epoch[48] Batch[0] avg_epoch_loss=1.772971\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:27 INFO 140480903202624] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=1.77297055721\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:33 INFO 140480903202624] Epoch[48] Batch[5] avg_epoch_loss=1.979354\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=1.97935368617\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:33 INFO 140480903202624] Epoch[48] Batch [5]#011Speed: 57.05 samples/sec#011loss=1.979354\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:38 INFO 140480903202624] Epoch[48] Batch[10] avg_epoch_loss=1.863803\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=1.72514200211\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:38 INFO 140480903202624] Epoch[48] Batch [10]#011Speed: 57.25 samples/sec#011loss=1.725142\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:38 INFO 140480903202624] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13226.819038391113, \"sum\": 13226.819038391113, \"min\": 13226.819038391113}}, \"EndTime\": 1587306758.909176, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306745.682296}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:38 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.7640063132 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:38 INFO 140480903202624] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=48, train loss <loss>=1.86380292069\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:38 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:41 INFO 140480903202624] Epoch[49] Batch[0] avg_epoch_loss=1.838041\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:41 INFO 140480903202624] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=1.83804130554\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:46 INFO 140480903202624] Epoch[49] Batch[5] avg_epoch_loss=1.761290\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:46 INFO 140480903202624] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=1.76129039129\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:46 INFO 140480903202624] Epoch[49] Batch [5]#011Speed: 56.68 samples/sec#011loss=1.761290\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:51 INFO 140480903202624] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12236.875057220459, \"sum\": 12236.875057220459, \"min\": 12236.875057220459}}, \"EndTime\": 1587306771.146655, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306758.909291}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:51 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.0747063634 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:51 INFO 140480903202624] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=49, train loss <loss>=1.75977776051\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:51 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:53 INFO 140480903202624] Epoch[50] Batch[0] avg_epoch_loss=2.023427\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.023427248\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:58 INFO 140480903202624] Epoch[50] Batch[5] avg_epoch_loss=1.766743\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=1.76674284538\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:58 INFO 140480903202624] Epoch[50] Batch [5]#011Speed: 56.93 samples/sec#011loss=1.766743\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:04 INFO 140480903202624] Epoch[50] Batch[10] avg_epoch_loss=1.805864\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=1.85280971527\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:04 INFO 140480903202624] Epoch[50] Batch [10]#011Speed: 56.64 samples/sec#011loss=1.852810\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:04 INFO 140480903202624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13317.466020584106, \"sum\": 13317.466020584106, \"min\": 13317.466020584106}}, \"EndTime\": 1587306784.464701, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306771.146727}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:04 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.7325741067 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:04 INFO 140480903202624] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=50, train loss <loss>=1.80586414987\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:04 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:06 INFO 140480903202624] Epoch[51] Batch[0] avg_epoch_loss=2.257150\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:06 INFO 140480903202624] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.25715017319\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:12 INFO 140480903202624] Epoch[51] Batch[5] avg_epoch_loss=2.127725\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:12 INFO 140480903202624] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.12772468726\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:12 INFO 140480903202624] Epoch[51] Batch [5]#011Speed: 57.07 samples/sec#011loss=2.127725\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:17 INFO 140480903202624] Epoch[51] Batch[10] avg_epoch_loss=2.027104\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:17 INFO 140480903202624] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=1.90635993481\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:17 INFO 140480903202624] Epoch[51] Batch [10]#011Speed: 56.75 samples/sec#011loss=1.906360\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:17 INFO 140480903202624] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13318.268060684204, \"sum\": 13318.268060684204, \"min\": 13318.268060684204}}, \"EndTime\": 1587306797.783804, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306784.464775}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:17 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.1562345287 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:17 INFO 140480903202624] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:17 INFO 140480903202624] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.02710434523\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:17 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:19 INFO 140480903202624] Epoch[52] Batch[0] avg_epoch_loss=1.790045\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:19 INFO 140480903202624] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=1.79004526138\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:25 INFO 140480903202624] Epoch[52] Batch[5] avg_epoch_loss=1.721426\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:25 INFO 140480903202624] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=1.72142648697\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:25 INFO 140480903202624] Epoch[52] Batch [5]#011Speed: 57.14 samples/sec#011loss=1.721426\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140480903202624] Epoch[52] Batch[10] avg_epoch_loss=1.684696\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140480903202624] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=1.64061970711\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140480903202624] Epoch[52] Batch [10]#011Speed: 57.08 samples/sec#011loss=1.640620\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140480903202624] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13332.18002319336, \"sum\": 13332.18002319336, \"min\": 13332.18002319336}}, \"EndTime\": 1587306811.116486, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306797.783884}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.3787893395 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140480903202624] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140480903202624] #quality_metric: host=algo-1, epoch=52, train loss <loss>=1.68469613249\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_98643870-16e9-41aa-b2a4-47db504d110b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 101.98092460632324, \"sum\": 101.98092460632324, \"min\": 101.98092460632324}}, \"EndTime\": 1587306811.219097, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306811.11656}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:33 INFO 140480903202624] Epoch[53] Batch[0] avg_epoch_loss=3.976314\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=3.97631406784\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:38 INFO 140480903202624] Epoch[53] Batch[5] avg_epoch_loss=2.996386\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.9963862896\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:38 INFO 140480903202624] Epoch[53] Batch [5]#011Speed: 56.74 samples/sec#011loss=2.996386\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:43 INFO 140480903202624] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12107.447862625122, \"sum\": 12107.447862625122, \"min\": 12107.447862625122}}, \"EndTime\": 1587306823.326685, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306811.219173}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:43 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.051335742 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:43 INFO 140480903202624] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:43 INFO 140480903202624] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.79380819798\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:43 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:45 INFO 140480903202624] Epoch[54] Batch[0] avg_epoch_loss=2.639447\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:45 INFO 140480903202624] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.63944673538\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:51 INFO 140480903202624] Epoch[54] Batch[5] avg_epoch_loss=2.615503\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.61550315221\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:51 INFO 140480903202624] Epoch[54] Batch [5]#011Speed: 56.56 samples/sec#011loss=2.615503\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:56 INFO 140480903202624] Epoch[54] Batch[10] avg_epoch_loss=2.533755\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:56 INFO 140480903202624] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=2.43565788269\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:56 INFO 140480903202624] Epoch[54] Batch [10]#011Speed: 57.30 samples/sec#011loss=2.435658\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:56 INFO 140480903202624] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13317.620992660522, \"sum\": 13317.620992660522, \"min\": 13317.620992660522}}, \"EndTime\": 1587306836.645032, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306823.326769}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:56 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.1312965682 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:56 INFO 140480903202624] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:56 INFO 140480903202624] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.53375530243\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:56 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:58 INFO 140480903202624] Epoch[55] Batch[0] avg_epoch_loss=2.354310\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.35431027412\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:04 INFO 140480903202624] Epoch[55] Batch[5] avg_epoch_loss=2.164587\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=2.16458745797\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:04 INFO 140480903202624] Epoch[55] Batch [5]#011Speed: 56.88 samples/sec#011loss=2.164587\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:09 INFO 140480903202624] Epoch[55] Batch[10] avg_epoch_loss=1.991541\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:09 INFO 140480903202624] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=1.7838861227\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:09 INFO 140480903202624] Epoch[55] Batch [10]#011Speed: 57.04 samples/sec#011loss=1.783886\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:09 INFO 140480903202624] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13303.378105163574, \"sum\": 13303.378105163574, \"min\": 13303.378105163574}}, \"EndTime\": 1587306849.949012, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306836.645112}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:09 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.2351930298 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:09 INFO 140480903202624] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:09 INFO 140480903202624] #quality_metric: host=algo-1, epoch=55, train loss <loss>=1.99154139649\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:09 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:11 INFO 140480903202624] Epoch[56] Batch[0] avg_epoch_loss=1.743984\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=1.74398362637\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:17 INFO 140480903202624] Epoch[56] Batch[5] avg_epoch_loss=1.764802\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:17 INFO 140480903202624] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=1.76480247577\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:17 INFO 140480903202624] Epoch[56] Batch [5]#011Speed: 56.61 samples/sec#011loss=1.764802\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:23 INFO 140480903202624] Epoch[56] Batch[10] avg_epoch_loss=1.855447\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:23 INFO 140480903202624] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=1.96422023773\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:23 INFO 140480903202624] Epoch[56] Batch [10]#011Speed: 57.21 samples/sec#011loss=1.964220\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:23 INFO 140480903202624] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13287.397861480713, \"sum\": 13287.397861480713, \"min\": 13287.397861480713}}, \"EndTime\": 1587306863.237039, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306849.94909}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:23 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.5417462889 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:23 INFO 140480903202624] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:23 INFO 140480903202624] #quality_metric: host=algo-1, epoch=56, train loss <loss>=1.85544691303\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:23 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:25 INFO 140480903202624] Epoch[57] Batch[0] avg_epoch_loss=1.859018\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:25 INFO 140480903202624] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=1.85901832581\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:31 INFO 140480903202624] Epoch[57] Batch[5] avg_epoch_loss=1.742805\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:31 INFO 140480903202624] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=1.74280528227\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:31 INFO 140480903202624] Epoch[57] Batch [5]#011Speed: 56.48 samples/sec#011loss=1.742805\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:36 INFO 140480903202624] Epoch[57] Batch[10] avg_epoch_loss=1.680350\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:36 INFO 140480903202624] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=1.60540332794\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:36 INFO 140480903202624] Epoch[57] Batch [10]#011Speed: 56.79 samples/sec#011loss=1.605403\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:36 INFO 140480903202624] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13418.462991714478, \"sum\": 13418.462991714478, \"min\": 13418.462991714478}}, \"EndTime\": 1587306876.655993, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306863.237118}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:36 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.7938217189 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:36 INFO 140480903202624] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:36 INFO 140480903202624] #quality_metric: host=algo-1, epoch=57, train loss <loss>=1.68034984849\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:36 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:36 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_03a7dfc9-8e23-40ca-a695-4c68017cda84-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 101.13096237182617, \"sum\": 101.13096237182617, \"min\": 101.13096237182617}}, \"EndTime\": 1587306876.757828, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306876.65608}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:38 INFO 140480903202624] Epoch[58] Batch[0] avg_epoch_loss=1.539761\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=1.53976130486\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:44 INFO 140480903202624] Epoch[58] Batch[5] avg_epoch_loss=1.684643\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:44 INFO 140480903202624] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=1.68464318911\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:44 INFO 140480903202624] Epoch[58] Batch [5]#011Speed: 57.03 samples/sec#011loss=1.684643\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:50 INFO 140480903202624] Epoch[58] Batch[10] avg_epoch_loss=1.595323\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:50 INFO 140480903202624] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=1.48813824654\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:50 INFO 140480903202624] Epoch[58] Batch [10]#011Speed: 56.63 samples/sec#011loss=1.488138\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:50 INFO 140480903202624] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13306.466817855835, \"sum\": 13306.466817855835, \"min\": 13306.466817855835}}, \"EndTime\": 1587306890.064667, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306876.758137}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:50 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.472255872 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:50 INFO 140480903202624] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:50 INFO 140480903202624] #quality_metric: host=algo-1, epoch=58, train loss <loss>=1.59532276067\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:50 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:50 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_4370b7be-0913-4a27-8291-c74b966f220e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 105.41391372680664, \"sum\": 105.41391372680664, \"min\": 105.41391372680664}}, \"EndTime\": 1587306890.1706, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306890.064745}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:52 INFO 140480903202624] Epoch[59] Batch[0] avg_epoch_loss=2.496254\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:52 INFO 140480903202624] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.4962542057\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:57 INFO 140480903202624] Epoch[59] Batch[5] avg_epoch_loss=2.071495\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:57 INFO 140480903202624] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.07149501642\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:57 INFO 140480903202624] Epoch[59] Batch [5]#011Speed: 57.12 samples/sec#011loss=2.071495\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:02 INFO 140480903202624] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12108.57605934143, \"sum\": 12108.57605934143, \"min\": 12108.57605934143}}, \"EndTime\": 1587306902.279322, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306890.170676}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:02 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.551178292 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:02 INFO 140480903202624] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:02 INFO 140480903202624] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.02916733027\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:02 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:04 INFO 140480903202624] Epoch[60] Batch[0] avg_epoch_loss=1.832998\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=1.83299803734\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:09 INFO 140480903202624] Epoch[60] Batch[5] avg_epoch_loss=1.808544\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:09 INFO 140480903202624] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=1.80854441722\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:09 INFO 140480903202624] Epoch[60] Batch [5]#011Speed: 56.85 samples/sec#011loss=1.808544\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:14 INFO 140480903202624] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12223.251819610596, \"sum\": 12223.251819610596, \"min\": 12223.251819610596}}, \"EndTime\": 1587306914.503341, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306902.279399}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:14 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.7405512506 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:14 INFO 140480903202624] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:14 INFO 140480903202624] #quality_metric: host=algo-1, epoch=60, train loss <loss>=1.70826832056\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:14 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:16 INFO 140480903202624] Epoch[61] Batch[0] avg_epoch_loss=1.480385\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=1.48038494587\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:22 INFO 140480903202624] Epoch[61] Batch[5] avg_epoch_loss=1.494981\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:22 INFO 140480903202624] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=1.49498126904\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:22 INFO 140480903202624] Epoch[61] Batch [5]#011Speed: 56.02 samples/sec#011loss=1.494981\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:27 INFO 140480903202624] Epoch[61] Batch[10] avg_epoch_loss=1.665546\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:27 INFO 140480903202624] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=1.87022445202\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:27 INFO 140480903202624] Epoch[61] Batch [10]#011Speed: 56.89 samples/sec#011loss=1.870224\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:27 INFO 140480903202624] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13373.876810073853, \"sum\": 13373.876810073853, \"min\": 13373.876810073853}}, \"EndTime\": 1587306927.877853, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306914.503406}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:27 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.6485715868 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:27 INFO 140480903202624] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:27 INFO 140480903202624] #quality_metric: host=algo-1, epoch=61, train loss <loss>=1.66554635221\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:27 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:29 INFO 140480903202624] Epoch[62] Batch[0] avg_epoch_loss=1.913419\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:29 INFO 140480903202624] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=1.91341876984\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:35 INFO 140480903202624] Epoch[62] Batch[5] avg_epoch_loss=1.614387\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:35 INFO 140480903202624] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=1.61438665787\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:35 INFO 140480903202624] Epoch[62] Batch [5]#011Speed: 57.06 samples/sec#011loss=1.614387\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:39 INFO 140480903202624] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12091.974973678589, \"sum\": 12091.974973678589, \"min\": 12091.974973678589}}, \"EndTime\": 1587306939.97045, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306927.877939}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:39 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.7846686422 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:39 INFO 140480903202624] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:39 INFO 140480903202624] #quality_metric: host=algo-1, epoch=62, train loss <loss>=1.60113120079\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:39 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:41 INFO 140480903202624] Epoch[63] Batch[0] avg_epoch_loss=1.984683\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:41 INFO 140480903202624] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=1.98468339443\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:47 INFO 140480903202624] Epoch[63] Batch[5] avg_epoch_loss=1.669037\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:47 INFO 140480903202624] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=1.66903736194\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:47 INFO 140480903202624] Epoch[63] Batch [5]#011Speed: 56.46 samples/sec#011loss=1.669037\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:53 INFO 140480903202624] Epoch[63] Batch[10] avg_epoch_loss=1.636903\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=1.59834158421\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:53 INFO 140480903202624] Epoch[63] Batch [10]#011Speed: 57.06 samples/sec#011loss=1.598342\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:53 INFO 140480903202624] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13299.77011680603, \"sum\": 13299.77011680603, \"min\": 13299.77011680603}}, \"EndTime\": 1587306953.270859, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306939.970521}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:53 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.4214746597 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:53 INFO 140480903202624] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=63, train loss <loss>=1.63690291752\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:53 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:55 INFO 140480903202624] Epoch[64] Batch[0] avg_epoch_loss=1.512761\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:55 INFO 140480903202624] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=1.51276051998\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:00 INFO 140480903202624] Epoch[64] Batch[5] avg_epoch_loss=1.625532\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:00 INFO 140480903202624] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=1.62553171317\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:00 INFO 140480903202624] Epoch[64] Batch [5]#011Speed: 56.77 samples/sec#011loss=1.625532\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:05 INFO 140480903202624] processed a total of 595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12080.445051193237, \"sum\": 12080.445051193237, \"min\": 12080.445051193237}}, \"EndTime\": 1587306965.351862, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306953.270932}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:05 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.2527003017 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:05 INFO 140480903202624] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:05 INFO 140480903202624] #quality_metric: host=algo-1, epoch=64, train loss <loss>=1.5372754097\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:05 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:05 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_bc33cd9d-5846-4500-9b15-69838a7a6301-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 102.66900062561035, \"sum\": 102.66900062561035, \"min\": 102.66900062561035}}, \"EndTime\": 1587306965.455296, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306965.351937}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:07 INFO 140480903202624] Epoch[65] Batch[0] avg_epoch_loss=1.290413\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:07 INFO 140480903202624] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=1.2904125452\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:13 INFO 140480903202624] Epoch[65] Batch[5] avg_epoch_loss=1.606899\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=1.60689944029\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:13 INFO 140480903202624] Epoch[65] Batch [5]#011Speed: 56.98 samples/sec#011loss=1.606899\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:18 INFO 140480903202624] Epoch[65] Batch[10] avg_epoch_loss=1.467703\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=1.30066742897\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:18 INFO 140480903202624] Epoch[65] Batch [10]#011Speed: 57.03 samples/sec#011loss=1.300667\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:18 INFO 140480903202624] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13290.499925613403, \"sum\": 13290.499925613403, \"min\": 13290.499925613403}}, \"EndTime\": 1587306978.745924, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306965.455367}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:18 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.0352993803 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:18 INFO 140480903202624] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=65, train loss <loss>=1.46770307151\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:18 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:18 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_412665f1-4eb0-4ad9-8037-2351fee9f107-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 101.82714462280273, \"sum\": 101.82714462280273, \"min\": 101.82714462280273}}, \"EndTime\": 1587306978.848495, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306978.746006}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:20 INFO 140480903202624] Epoch[66] Batch[0] avg_epoch_loss=1.591906\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:20 INFO 140480903202624] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=1.59190571308\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:26 INFO 140480903202624] Epoch[66] Batch[5] avg_epoch_loss=1.505493\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:26 INFO 140480903202624] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=1.50549346209\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:26 INFO 140480903202624] Epoch[66] Batch [5]#011Speed: 56.45 samples/sec#011loss=1.505493\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:30 INFO 140480903202624] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12122.997999191284, \"sum\": 12122.997999191284, \"min\": 12122.997999191284}}, \"EndTime\": 1587306990.971619, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306978.848566}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:30 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.6469362313 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:30 INFO 140480903202624] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:30 INFO 140480903202624] #quality_metric: host=algo-1, epoch=66, train loss <loss>=1.49834228754\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:30 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:33 INFO 140480903202624] Epoch[67] Batch[0] avg_epoch_loss=1.382732\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=1.38273155689\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:38 INFO 140480903202624] Epoch[67] Batch[5] avg_epoch_loss=1.377762\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=1.37776156267\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:38 INFO 140480903202624] Epoch[67] Batch [5]#011Speed: 57.17 samples/sec#011loss=1.377762\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:44 INFO 140480903202624] Epoch[67] Batch[10] avg_epoch_loss=1.413575\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:44 INFO 140480903202624] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=1.45655217171\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:44 INFO 140480903202624] Epoch[67] Batch [10]#011Speed: 56.86 samples/sec#011loss=1.456552\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:44 INFO 140480903202624] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13330.981016159058, \"sum\": 13330.981016159058, \"min\": 13330.981016159058}}, \"EndTime\": 1587307004.303195, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306990.971729}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:44 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.1083815546 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:44 INFO 140480903202624] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:44 INFO 140480903202624] #quality_metric: host=algo-1, epoch=67, train loss <loss>=1.41357547587\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:44 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:44 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_ef6d8f16-e334-4d27-b964-f607ee219dd3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 115.40794372558594, \"sum\": 115.40794372558594, \"min\": 115.40794372558594}}, \"EndTime\": 1587307004.419232, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307004.30328}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:46 INFO 140480903202624] Epoch[68] Batch[0] avg_epoch_loss=1.709028\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:46 INFO 140480903202624] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=1.70902824402\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:52 INFO 140480903202624] Epoch[68] Batch[5] avg_epoch_loss=1.451105\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:52 INFO 140480903202624] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=1.45110537608\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:52 INFO 140480903202624] Epoch[68] Batch [5]#011Speed: 56.76 samples/sec#011loss=1.451105\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:56 INFO 140480903202624] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12087.84008026123, \"sum\": 12087.84008026123, \"min\": 12087.84008026123}}, \"EndTime\": 1587307016.507214, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307004.419304}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:56 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.7938321642 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:56 INFO 140480903202624] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:56 INFO 140480903202624] #quality_metric: host=algo-1, epoch=68, train loss <loss>=1.40712724924\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:56 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:56 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_885c81dd-143d-499d-abc6-e19efa7a367f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 133.33415985107422, \"sum\": 133.33415985107422, \"min\": 133.33415985107422}}, \"EndTime\": 1587307016.641317, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307016.507416}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:58 INFO 140480903202624] Epoch[69] Batch[0] avg_epoch_loss=1.870736\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=1.87073552608\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:04 INFO 140480903202624] Epoch[69] Batch[5] avg_epoch_loss=1.683941\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=1.68394098679\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:04 INFO 140480903202624] Epoch[69] Batch [5]#011Speed: 57.09 samples/sec#011loss=1.683941\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:08 INFO 140480903202624] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12070.92308998108, \"sum\": 12070.92308998108, \"min\": 12070.92308998108}}, \"EndTime\": 1587307028.712405, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307016.64139}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:08 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.7766861005 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:08 INFO 140480903202624] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:08 INFO 140480903202624] #quality_metric: host=algo-1, epoch=69, train loss <loss>=1.57958289385\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:08 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:10 INFO 140480903202624] Epoch[70] Batch[0] avg_epoch_loss=1.370437\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:10 INFO 140480903202624] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=1.37043714523\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:16 INFO 140480903202624] Epoch[70] Batch[5] avg_epoch_loss=1.320190\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=1.32019040982\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:16 INFO 140480903202624] Epoch[70] Batch [5]#011Speed: 57.23 samples/sec#011loss=1.320190\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:22 INFO 140480903202624] Epoch[70] Batch[10] avg_epoch_loss=1.465972\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:22 INFO 140480903202624] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=1.64091057777\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:22 INFO 140480903202624] Epoch[70] Batch [10]#011Speed: 56.60 samples/sec#011loss=1.640911\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:22 INFO 140480903202624] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13318.73106956482, \"sum\": 13318.73106956482, \"min\": 13318.73106956482}}, \"EndTime\": 1587307042.031735, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307028.712487}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:22 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.2774265326 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:22 INFO 140480903202624] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:22 INFO 140480903202624] #quality_metric: host=algo-1, epoch=70, train loss <loss>=1.46597230434\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:22 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:24 INFO 140480903202624] Epoch[71] Batch[0] avg_epoch_loss=1.277535\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:24 INFO 140480903202624] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=1.2775349617\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:29 INFO 140480903202624] Epoch[71] Batch[5] avg_epoch_loss=1.415356\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:29 INFO 140480903202624] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=1.41535627842\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:29 INFO 140480903202624] Epoch[71] Batch [5]#011Speed: 57.01 samples/sec#011loss=1.415356\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:34 INFO 140480903202624] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12212.552070617676, \"sum\": 12212.552070617676, \"min\": 12212.552070617676}}, \"EndTime\": 1587307054.244834, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307042.031808}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:34 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.3226889318 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:34 INFO 140480903202624] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:34 INFO 140480903202624] #quality_metric: host=algo-1, epoch=71, train loss <loss>=1.38711639643\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:34 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:34 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_dcca7a5b-63c6-4f64-904b-1b3ccf0c9f2d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 111.93990707397461, \"sum\": 111.93990707397461, \"min\": 111.93990707397461}}, \"EndTime\": 1587307054.357349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307054.244918}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:36 INFO 140480903202624] Epoch[72] Batch[0] avg_epoch_loss=1.294506\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:36 INFO 140480903202624] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=1.29450631142\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:42 INFO 140480903202624] Epoch[72] Batch[5] avg_epoch_loss=1.393058\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:42 INFO 140480903202624] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=1.39305841923\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:42 INFO 140480903202624] Epoch[72] Batch [5]#011Speed: 56.22 samples/sec#011loss=1.393058\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:46 INFO 140480903202624] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12195.52993774414, \"sum\": 12195.52993774414, \"min\": 12195.52993774414}}, \"EndTime\": 1587307066.553017, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307054.357421}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:46 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.4278328184 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:46 INFO 140480903202624] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:46 INFO 140480903202624] #quality_metric: host=algo-1, epoch=72, train loss <loss>=1.41477662325\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:46 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:48 INFO 140480903202624] Epoch[73] Batch[0] avg_epoch_loss=1.293936\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:48 INFO 140480903202624] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=1.29393649101\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:54 INFO 140480903202624] Epoch[73] Batch[5] avg_epoch_loss=1.338943\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:54 INFO 140480903202624] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=1.33894340197\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:54 INFO 140480903202624] Epoch[73] Batch [5]#011Speed: 56.93 samples/sec#011loss=1.338943\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:59 INFO 140480903202624] Epoch[73] Batch[10] avg_epoch_loss=1.336150\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:59 INFO 140480903202624] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=1.33279840946\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:59 INFO 140480903202624] Epoch[73] Batch [10]#011Speed: 57.14 samples/sec#011loss=1.332798\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:59 INFO 140480903202624] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13356.513023376465, \"sum\": 13356.513023376465, \"min\": 13356.513023376465}}, \"EndTime\": 1587307079.910151, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307066.553094}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:59 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.0875370669 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:59 INFO 140480903202624] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:59 INFO 140480903202624] #quality_metric: host=algo-1, epoch=73, train loss <loss>=1.33615022356\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:59 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:00 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_3320c94b-b3f7-4271-acd3-018e82c9b206-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 105.23486137390137, \"sum\": 105.23486137390137, \"min\": 105.23486137390137}}, \"EndTime\": 1587307080.015964, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307079.910215}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:02 INFO 140480903202624] Epoch[74] Batch[0] avg_epoch_loss=2.027227\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:02 INFO 140480903202624] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.02722740173\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:07 INFO 140480903202624] Epoch[74] Batch[5] avg_epoch_loss=1.895202\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:07 INFO 140480903202624] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=1.89520206054\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:07 INFO 140480903202624] Epoch[74] Batch [5]#011Speed: 56.77 samples/sec#011loss=1.895202\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:13 INFO 140480903202624] Epoch[74] Batch[10] avg_epoch_loss=1.798473\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=1.68239712715\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:13 INFO 140480903202624] Epoch[74] Batch [10]#011Speed: 57.10 samples/sec#011loss=1.682397\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:13 INFO 140480903202624] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13291.6579246521, \"sum\": 13291.6579246521, \"min\": 13291.6579246521}}, \"EndTime\": 1587307093.307764, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307080.016041}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:13 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.5043094108 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:13 INFO 140480903202624] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=74, train loss <loss>=1.79847254536\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:13 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:15 INFO 140480903202624] Epoch[75] Batch[0] avg_epoch_loss=1.640003\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:15 INFO 140480903202624] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=1.64000320435\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:21 INFO 140480903202624] Epoch[75] Batch[5] avg_epoch_loss=1.633866\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:21 INFO 140480903202624] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=1.63386555513\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:21 INFO 140480903202624] Epoch[75] Batch [5]#011Speed: 56.50 samples/sec#011loss=1.633866\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:26 INFO 140480903202624] Epoch[75] Batch[10] avg_epoch_loss=1.525993\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:26 INFO 140480903202624] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=1.39654681683\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:26 INFO 140480903202624] Epoch[75] Batch [10]#011Speed: 57.20 samples/sec#011loss=1.396547\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:26 INFO 140480903202624] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13389.820098876953, \"sum\": 13389.820098876953, \"min\": 13389.820098876953}}, \"EndTime\": 1587307106.698067, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307093.307841}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:26 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.5312433662 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:26 INFO 140480903202624] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:26 INFO 140480903202624] #quality_metric: host=algo-1, epoch=75, train loss <loss>=1.52599340135\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:26 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 INFO 140480903202624] Epoch[76] Batch[0] avg_epoch_loss=1.080279\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 INFO 140480903202624] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=1.08027851582\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:34 INFO 140480903202624] Epoch[76] Batch[5] avg_epoch_loss=1.612850\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:34 INFO 140480903202624] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=1.61284991105\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:34 INFO 140480903202624] Epoch[76] Batch [5]#011Speed: 57.05 samples/sec#011loss=1.612850\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:38 INFO 140480903202624] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12127.1231174469, \"sum\": 12127.1231174469, \"min\": 12127.1231174469}}, \"EndTime\": 1587307118.825764, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307106.698143}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:38 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.6088771768 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:38 INFO 140480903202624] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=76, train loss <loss>=1.59713766575\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:38 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:40 INFO 140480903202624] Epoch[77] Batch[0] avg_epoch_loss=1.306257\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:40 INFO 140480903202624] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=1.30625712872\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:46 INFO 140480903202624] Epoch[77] Batch[5] avg_epoch_loss=1.306593\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:46 INFO 140480903202624] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=1.3065927426\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:46 INFO 140480903202624] Epoch[77] Batch [5]#011Speed: 57.29 samples/sec#011loss=1.306593\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:51 INFO 140480903202624] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12240.592002868652, \"sum\": 12240.592002868652, \"min\": 12240.592002868652}}, \"EndTime\": 1587307131.066964, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307118.825836}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:51 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.0394912993 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:51 INFO 140480903202624] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=77, train loss <loss>=1.29258617163\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:51 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:51 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_9d743893-8b4d-48d7-9925-e3bdc43acb22-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 113.33799362182617, \"sum\": 113.33799362182617, \"min\": 113.33799362182617}}, \"EndTime\": 1587307131.180956, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307131.06704}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:53 INFO 140480903202624] Epoch[78] Batch[0] avg_epoch_loss=1.196305\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=1.19630479813\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:58 INFO 140480903202624] Epoch[78] Batch[5] avg_epoch_loss=1.658457\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=1.65845737855\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:58 INFO 140480903202624] Epoch[78] Batch [5]#011Speed: 56.88 samples/sec#011loss=1.658457\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:03 INFO 140480903202624] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12136.718034744263, \"sum\": 12136.718034744263, \"min\": 12136.718034744263}}, \"EndTime\": 1587307143.317814, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307131.181028}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:03 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.7545577156 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:03 INFO 140480903202624] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:03 INFO 140480903202624] #quality_metric: host=algo-1, epoch=78, train loss <loss>=1.44487508535\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:03 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:05 INFO 140480903202624] Epoch[79] Batch[0] avg_epoch_loss=1.200096\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:05 INFO 140480903202624] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=1.20009636879\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:10 INFO 140480903202624] Epoch[79] Batch[5] avg_epoch_loss=1.356205\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:10 INFO 140480903202624] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=1.35620516539\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:10 INFO 140480903202624] Epoch[79] Batch [5]#011Speed: 56.81 samples/sec#011loss=1.356205\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:15 INFO 140480903202624] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12131.968021392822, \"sum\": 12131.968021392822, \"min\": 12131.968021392822}}, \"EndTime\": 1587307155.450396, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307143.317897}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:15 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.702973144 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:15 INFO 140480903202624] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:15 INFO 140480903202624] #quality_metric: host=algo-1, epoch=79, train loss <loss>=1.30614299774\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:15 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:17 INFO 140480903202624] Epoch[80] Batch[0] avg_epoch_loss=2.256437\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:17 INFO 140480903202624] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.25643658638\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:23 INFO 140480903202624] Epoch[80] Batch[5] avg_epoch_loss=1.610438\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:23 INFO 140480903202624] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=1.61043753227\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:23 INFO 140480903202624] Epoch[80] Batch [5]#011Speed: 56.27 samples/sec#011loss=1.610438\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:27 INFO 140480903202624] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12156.877994537354, \"sum\": 12156.877994537354, \"min\": 12156.877994537354}}, \"EndTime\": 1587307167.607902, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307155.450468}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:27 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.6575529402 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:27 INFO 140480903202624] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:27 INFO 140480903202624] #quality_metric: host=algo-1, epoch=80, train loss <loss>=1.51594444513\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:27 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:29 INFO 140480903202624] Epoch[81] Batch[0] avg_epoch_loss=1.323331\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:29 INFO 140480903202624] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=1.32333123684\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:35 INFO 140480903202624] Epoch[81] Batch[5] avg_epoch_loss=1.214827\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:35 INFO 140480903202624] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=1.21482652426\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:35 INFO 140480903202624] Epoch[81] Batch [5]#011Speed: 56.86 samples/sec#011loss=1.214827\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:40 INFO 140480903202624] Epoch[81] Batch[10] avg_epoch_loss=1.458509\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:40 INFO 140480903202624] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=1.75092823505\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:40 INFO 140480903202624] Epoch[81] Batch [10]#011Speed: 57.16 samples/sec#011loss=1.750928\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:40 INFO 140480903202624] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13307.54804611206, \"sum\": 13307.54804611206, \"min\": 13307.54804611206}}, \"EndTime\": 1587307180.916117, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307167.607974}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:40 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.7978153433 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:40 INFO 140480903202624] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:40 INFO 140480903202624] #quality_metric: host=algo-1, epoch=81, train loss <loss>=1.45850912007\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:40 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:42 INFO 140480903202624] Epoch[82] Batch[0] avg_epoch_loss=1.744500\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:42 INFO 140480903202624] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=1.74449968338\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:48 INFO 140480903202624] Epoch[82] Batch[5] avg_epoch_loss=1.728942\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:48 INFO 140480903202624] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=1.72894177834\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:48 INFO 140480903202624] Epoch[82] Batch [5]#011Speed: 56.68 samples/sec#011loss=1.728942\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:54 INFO 140480903202624] Epoch[82] Batch[10] avg_epoch_loss=1.664539\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:54 INFO 140480903202624] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=1.58725628853\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:54 INFO 140480903202624] Epoch[82] Batch [10]#011Speed: 56.07 samples/sec#011loss=1.587256\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:54 INFO 140480903202624] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13397.922039031982, \"sum\": 13397.922039031982, \"min\": 13397.922039031982}}, \"EndTime\": 1587307194.314558, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307180.916194}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:54 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.1863319454 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:54 INFO 140480903202624] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:54 INFO 140480903202624] #quality_metric: host=algo-1, epoch=82, train loss <loss>=1.66453928297\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:54 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:56 INFO 140480903202624] Epoch[83] Batch[0] avg_epoch_loss=1.481461\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:39:56 INFO 140480903202624] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=1.48146092892\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:02 INFO 140480903202624] Epoch[83] Batch[5] avg_epoch_loss=1.489325\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:02 INFO 140480903202624] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=1.48932528496\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:02 INFO 140480903202624] Epoch[83] Batch [5]#011Speed: 56.56 samples/sec#011loss=1.489325\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:06 INFO 140480903202624] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12235.062837600708, \"sum\": 12235.062837600708, \"min\": 12235.062837600708}}, \"EndTime\": 1587307206.550139, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307194.314631}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:06 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.0004333558 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:06 INFO 140480903202624] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:06 INFO 140480903202624] #quality_metric: host=algo-1, epoch=83, train loss <loss>=1.42233895063\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:06 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:08 INFO 140480903202624] Epoch[84] Batch[0] avg_epoch_loss=1.250055\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:08 INFO 140480903202624] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=1.25005495548\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:14 INFO 140480903202624] Epoch[84] Batch[5] avg_epoch_loss=1.467262\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:14 INFO 140480903202624] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=1.46726185083\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:14 INFO 140480903202624] Epoch[84] Batch [5]#011Speed: 57.03 samples/sec#011loss=1.467262\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:19 INFO 140480903202624] Epoch[84] Batch[10] avg_epoch_loss=1.428792\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:19 INFO 140480903202624] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=1.3826277256\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:19 INFO 140480903202624] Epoch[84] Batch [10]#011Speed: 56.74 samples/sec#011loss=1.382628\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:19 INFO 140480903202624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13395.863056182861, \"sum\": 13395.863056182861, \"min\": 13395.863056182861}}, \"EndTime\": 1587307219.946535, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307206.550223}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:19 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.4474023647 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:19 INFO 140480903202624] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:19 INFO 140480903202624] #quality_metric: host=algo-1, epoch=84, train loss <loss>=1.42879179391\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:19 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:22 INFO 140480903202624] Epoch[85] Batch[0] avg_epoch_loss=1.729013\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:22 INFO 140480903202624] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=1.72901320457\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:27 INFO 140480903202624] Epoch[85] Batch[5] avg_epoch_loss=1.747987\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:27 INFO 140480903202624] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=1.74798653523\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:27 INFO 140480903202624] Epoch[85] Batch [5]#011Speed: 56.82 samples/sec#011loss=1.747987\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:33 INFO 140480903202624] Epoch[85] Batch[10] avg_epoch_loss=1.725411\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=1.69831986427\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:33 INFO 140480903202624] Epoch[85] Batch [10]#011Speed: 57.00 samples/sec#011loss=1.698320\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:33 INFO 140480903202624] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13367.403984069824, \"sum\": 13367.403984069824, \"min\": 13367.403984069824}}, \"EndTime\": 1587307233.31443, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307219.946609}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:33 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.4207586865 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:33 INFO 140480903202624] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=85, train loss <loss>=1.7254107757\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:33 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:35 INFO 140480903202624] Epoch[86] Batch[0] avg_epoch_loss=1.596143\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:35 INFO 140480903202624] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=1.59614312649\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:40 INFO 140480903202624] Epoch[86] Batch[5] avg_epoch_loss=1.542818\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:40 INFO 140480903202624] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=1.54281812906\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:40 INFO 140480903202624] Epoch[86] Batch [5]#011Speed: 56.84 samples/sec#011loss=1.542818\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:45 INFO 140480903202624] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12153.894901275635, \"sum\": 12153.894901275635, \"min\": 12153.894901275635}}, \"EndTime\": 1587307245.468926, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307233.314504}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:45 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.2587440882 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:45 INFO 140480903202624] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:45 INFO 140480903202624] #quality_metric: host=algo-1, epoch=86, train loss <loss>=1.45154739618\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:45 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:47 INFO 140480903202624] Epoch[87] Batch[0] avg_epoch_loss=1.176575\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:47 INFO 140480903202624] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=1.17657506466\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:53 INFO 140480903202624] Epoch[87] Batch[5] avg_epoch_loss=1.139801\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=1.13980100552\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:53 INFO 140480903202624] Epoch[87] Batch [5]#011Speed: 56.00 samples/sec#011loss=1.139801\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:58 INFO 140480903202624] Epoch[87] Batch[10] avg_epoch_loss=1.376402\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=1.66032416821\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:58 INFO 140480903202624] Epoch[87] Batch [10]#011Speed: 56.78 samples/sec#011loss=1.660324\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:58 INFO 140480903202624] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13416.964054107666, \"sum\": 13416.964054107666, \"min\": 13416.964054107666}}, \"EndTime\": 1587307258.886507, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307245.468991}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:58 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.2033917822 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:58 INFO 140480903202624] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=87, train loss <loss>=1.37640244311\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:40:58 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:00 INFO 140480903202624] Epoch[88] Batch[0] avg_epoch_loss=1.977399\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:00 INFO 140480903202624] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=1.97739863396\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:06 INFO 140480903202624] Epoch[88] Batch[5] avg_epoch_loss=1.713503\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:06 INFO 140480903202624] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=1.71350336075\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:06 INFO 140480903202624] Epoch[88] Batch [5]#011Speed: 56.46 samples/sec#011loss=1.713503\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:11 INFO 140480903202624] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12232.717990875244, \"sum\": 12232.717990875244, \"min\": 12232.717990875244}}, \"EndTime\": 1587307271.119818, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307258.88659}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:11 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.6015614702 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:11 INFO 140480903202624] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=88, train loss <loss>=1.65114048719\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:11 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:13 INFO 140480903202624] Epoch[89] Batch[0] avg_epoch_loss=1.625412\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=1.62541222572\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:18 INFO 140480903202624] Epoch[89] Batch[5] avg_epoch_loss=1.529749\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=1.52974869808\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:18 INFO 140480903202624] Epoch[89] Batch [5]#011Speed: 56.97 samples/sec#011loss=1.529749\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:24 INFO 140480903202624] Epoch[89] Batch[10] avg_epoch_loss=1.459158\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:24 INFO 140480903202624] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=1.3744489193\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:24 INFO 140480903202624] Epoch[89] Batch [10]#011Speed: 56.72 samples/sec#011loss=1.374449\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:24 INFO 140480903202624] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13277.4658203125, \"sum\": 13277.4658203125, \"min\": 13277.4658203125}}, \"EndTime\": 1587307284.398293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307271.119888}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:24 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.3312972594 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:24 INFO 140480903202624] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:24 INFO 140480903202624] #quality_metric: host=algo-1, epoch=89, train loss <loss>=1.45915788954\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:24 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:26 INFO 140480903202624] Epoch[90] Batch[0] avg_epoch_loss=1.231209\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:26 INFO 140480903202624] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=1.23120939732\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:32 INFO 140480903202624] Epoch[90] Batch[5] avg_epoch_loss=1.401358\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:32 INFO 140480903202624] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=1.40135836601\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:32 INFO 140480903202624] Epoch[90] Batch [5]#011Speed: 57.19 samples/sec#011loss=1.401358\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:37 INFO 140480903202624] Epoch[90] Batch[10] avg_epoch_loss=1.313517\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:37 INFO 140480903202624] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=1.20810703039\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:37 INFO 140480903202624] Epoch[90] Batch [10]#011Speed: 57.48 samples/sec#011loss=1.208107\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:37 INFO 140480903202624] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13231.726169586182, \"sum\": 13231.726169586182, \"min\": 13231.726169586182}}, \"EndTime\": 1587307297.630502, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307284.398367}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:37 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.5193400085 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:37 INFO 140480903202624] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:37 INFO 140480903202624] #quality_metric: host=algo-1, epoch=90, train loss <loss>=1.31351684982\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:37 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:39 INFO 140480903202624] Epoch[91] Batch[0] avg_epoch_loss=1.780337\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:39 INFO 140480903202624] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=1.78033685684\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:45 INFO 140480903202624] Epoch[91] Batch[5] avg_epoch_loss=1.519308\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:45 INFO 140480903202624] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=1.51930779219\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:45 INFO 140480903202624] Epoch[91] Batch [5]#011Speed: 57.52 samples/sec#011loss=1.519308\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:51 INFO 140480903202624] Epoch[91] Batch[10] avg_epoch_loss=1.421444\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=1.30400800705\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:51 INFO 140480903202624] Epoch[91] Batch [10]#011Speed: 56.59 samples/sec#011loss=1.304008\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:52 INFO 140480903202624] processed a total of 719 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14509.600162506104, \"sum\": 14509.600162506104, \"min\": 14509.600162506104}}, \"EndTime\": 1587307312.140576, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307297.630579}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:52 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.5529890092 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:52 INFO 140480903202624] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:52 INFO 140480903202624] #quality_metric: host=algo-1, epoch=91, train loss <loss>=1.38148166736\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:52 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:54 INFO 140480903202624] Epoch[92] Batch[0] avg_epoch_loss=1.203504\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:54 INFO 140480903202624] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=1.20350432396\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:59 INFO 140480903202624] Epoch[92] Batch[5] avg_epoch_loss=1.144372\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:59 INFO 140480903202624] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=1.1443721354\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:41:59 INFO 140480903202624] Epoch[92] Batch [5]#011Speed: 57.17 samples/sec#011loss=1.144372\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:05 INFO 140480903202624] Epoch[92] Batch[10] avg_epoch_loss=1.218895\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:05 INFO 140480903202624] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=1.30832281113\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:05 INFO 140480903202624] Epoch[92] Batch [10]#011Speed: 57.36 samples/sec#011loss=1.308323\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:05 INFO 140480903202624] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13263.11182975769, \"sum\": 13263.11182975769, \"min\": 13263.11182975769}}, \"EndTime\": 1587307325.404197, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307312.140659}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:05 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.6108714033 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:05 INFO 140480903202624] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:05 INFO 140480903202624] #quality_metric: host=algo-1, epoch=92, train loss <loss>=1.21889516982\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:05 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:05 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_a0b88c2d-0437-48e2-a805-d92c206eb988-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 101.12500190734863, \"sum\": 101.12500190734863, \"min\": 101.12500190734863}}, \"EndTime\": 1587307325.505994, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307325.40427}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:07 INFO 140480903202624] Epoch[93] Batch[0] avg_epoch_loss=1.122157\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:07 INFO 140480903202624] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=1.12215673923\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:13 INFO 140480903202624] Epoch[93] Batch[5] avg_epoch_loss=1.174249\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=1.17424867551\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:13 INFO 140480903202624] Epoch[93] Batch [5]#011Speed: 56.98 samples/sec#011loss=1.174249\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:18 INFO 140480903202624] Epoch[93] Batch[10] avg_epoch_loss=1.220095\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=1.27511100769\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:18 INFO 140480903202624] Epoch[93] Batch [10]#011Speed: 57.38 samples/sec#011loss=1.275111\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:18 INFO 140480903202624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13236.953973770142, \"sum\": 13236.953973770142, \"min\": 13236.953973770142}}, \"EndTime\": 1587307338.743079, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307325.506065}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:18 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.028969582 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:18 INFO 140480903202624] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=93, train loss <loss>=1.22009519013\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:18 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:20 INFO 140480903202624] Epoch[94] Batch[0] avg_epoch_loss=2.006188\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:20 INFO 140480903202624] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.00618839264\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:26 INFO 140480903202624] Epoch[94] Batch[5] avg_epoch_loss=1.686556\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:26 INFO 140480903202624] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=1.68655568361\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:26 INFO 140480903202624] Epoch[94] Batch [5]#011Speed: 57.03 samples/sec#011loss=1.686556\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:30 INFO 140480903202624] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12215.380907058716, \"sum\": 12215.380907058716, \"min\": 12215.380907058716}}, \"EndTime\": 1587307350.959081, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307338.743159}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:30 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.8187144529 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:30 INFO 140480903202624] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:30 INFO 140480903202624] #quality_metric: host=algo-1, epoch=94, train loss <loss>=1.60668792725\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:30 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:33 INFO 140480903202624] Epoch[95] Batch[0] avg_epoch_loss=1.301546\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=1.30154597759\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:38 INFO 140480903202624] Epoch[95] Batch[5] avg_epoch_loss=1.394398\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=1.39439841112\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:38 INFO 140480903202624] Epoch[95] Batch [5]#011Speed: 56.90 samples/sec#011loss=1.394398\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:44 INFO 140480903202624] Epoch[95] Batch[10] avg_epoch_loss=1.292357\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:44 INFO 140480903202624] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=1.16990805864\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:44 INFO 140480903202624] Epoch[95] Batch [10]#011Speed: 57.13 samples/sec#011loss=1.169908\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:44 INFO 140480903202624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13322.043180465698, \"sum\": 13322.043180465698, \"min\": 13322.043180465698}}, \"EndTime\": 1587307364.281906, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307350.959326}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:44 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.7158491233 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:44 INFO 140480903202624] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:44 INFO 140480903202624] #quality_metric: host=algo-1, epoch=95, train loss <loss>=1.29235734181\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:44 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:46 INFO 140480903202624] Epoch[96] Batch[0] avg_epoch_loss=1.330915\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:46 INFO 140480903202624] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=1.33091545105\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:51 INFO 140480903202624] Epoch[96] Batch[5] avg_epoch_loss=1.199459\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=1.19945861896\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:51 INFO 140480903202624] Epoch[96] Batch [5]#011Speed: 56.58 samples/sec#011loss=1.199459\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:57 INFO 140480903202624] Epoch[96] Batch[10] avg_epoch_loss=1.240749\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:57 INFO 140480903202624] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=1.29029803276\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:57 INFO 140480903202624] Epoch[96] Batch [10]#011Speed: 57.09 samples/sec#011loss=1.290298\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:57 INFO 140480903202624] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13314.987897872925, \"sum\": 13314.987897872925, \"min\": 13314.987897872925}}, \"EndTime\": 1587307377.597603, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307364.281979}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:57 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.4926814103 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:57 INFO 140480903202624] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:57 INFO 140480903202624] #quality_metric: host=algo-1, epoch=96, train loss <loss>=1.2407492616\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:57 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:59 INFO 140480903202624] Epoch[97] Batch[0] avg_epoch_loss=1.499275\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:42:59 INFO 140480903202624] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=1.49927520752\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:05 INFO 140480903202624] Epoch[97] Batch[5] avg_epoch_loss=1.363770\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:05 INFO 140480903202624] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=1.36377008756\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:05 INFO 140480903202624] Epoch[97] Batch [5]#011Speed: 56.69 samples/sec#011loss=1.363770\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:11 INFO 140480903202624] Epoch[97] Batch[10] avg_epoch_loss=1.308836\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=1.24291417599\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:11 INFO 140480903202624] Epoch[97] Batch [10]#011Speed: 56.57 samples/sec#011loss=1.242914\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:11 INFO 140480903202624] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13441.879034042358, \"sum\": 13441.879034042358, \"min\": 13441.879034042358}}, \"EndTime\": 1587307391.040011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307377.59768}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:11 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.1084853722 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:11 INFO 140480903202624] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=97, train loss <loss>=1.3088355823\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:11 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:13 INFO 140480903202624] Epoch[98] Batch[0] avg_epoch_loss=1.071150\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=1.07114958763\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:18 INFO 140480903202624] Epoch[98] Batch[5] avg_epoch_loss=1.080988\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=1.080988427\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:18 INFO 140480903202624] Epoch[98] Batch [5]#011Speed: 57.06 samples/sec#011loss=1.080988\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:23 INFO 140480903202624] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12159.6200466156, \"sum\": 12159.6200466156, \"min\": 12159.6200466156}}, \"EndTime\": 1587307403.200147, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307391.040091}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:23 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.2343619303 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:23 INFO 140480903202624] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:23 INFO 140480903202624] #quality_metric: host=algo-1, epoch=98, train loss <loss>=1.16188502312\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:23 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:23 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_7474da45-1d1b-4941-a3f7-a8ac8dc863ac-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 105.93104362487793, \"sum\": 105.93104362487793, \"min\": 105.93104362487793}}, \"EndTime\": 1587307403.306754, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307403.200296}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:25 INFO 140480903202624] Epoch[99] Batch[0] avg_epoch_loss=0.977148\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:25 INFO 140480903202624] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=0.977147519588\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:31 INFO 140480903202624] Epoch[99] Batch[5] avg_epoch_loss=1.187310\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:31 INFO 140480903202624] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=1.18731046716\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:31 INFO 140480903202624] Epoch[99] Batch [5]#011Speed: 57.08 samples/sec#011loss=1.187310\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:36 INFO 140480903202624] Epoch[99] Batch[10] avg_epoch_loss=1.144199\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:36 INFO 140480903202624] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=1.09246566296\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:36 INFO 140480903202624] Epoch[99] Batch [10]#011Speed: 56.62 samples/sec#011loss=1.092466\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:36 INFO 140480903202624] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13359.028100967407, \"sum\": 13359.028100967407, \"min\": 13359.028100967407}}, \"EndTime\": 1587307416.66592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307403.306827}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:36 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.0781108338 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:36 INFO 140480903202624] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:36 INFO 140480903202624] #quality_metric: host=algo-1, epoch=99, train loss <loss>=1.14419919252\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:36 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:36 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_658cfe24-e891-41c1-88fb-3abd11857c14-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 101.32098197937012, \"sum\": 101.32098197937012, \"min\": 101.32098197937012}}, \"EndTime\": 1587307416.767834, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307416.665985}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:38 INFO 140480903202624] Epoch[100] Batch[0] avg_epoch_loss=1.269575\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=1.26957511902\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:44 INFO 140480903202624] Epoch[100] Batch[5] avg_epoch_loss=1.256318\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:44 INFO 140480903202624] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=1.2563183705\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:44 INFO 140480903202624] Epoch[100] Batch [5]#011Speed: 56.89 samples/sec#011loss=1.256318\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:50 INFO 140480903202624] Epoch[100] Batch[10] avg_epoch_loss=1.193702\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:50 INFO 140480903202624] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=1.11856323481\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:50 INFO 140480903202624] Epoch[100] Batch [10]#011Speed: 56.46 samples/sec#011loss=1.118563\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:50 INFO 140480903202624] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13320.33085823059, \"sum\": 13320.33085823059, \"min\": 13320.33085823059}}, \"EndTime\": 1587307430.088299, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307416.767909}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:50 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.1484179925 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:50 INFO 140480903202624] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:50 INFO 140480903202624] #quality_metric: host=algo-1, epoch=100, train loss <loss>=1.19370239973\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:50 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:52 INFO 140480903202624] Epoch[101] Batch[0] avg_epoch_loss=1.090212\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:52 INFO 140480903202624] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=1.09021246433\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:57 INFO 140480903202624] Epoch[101] Batch[5] avg_epoch_loss=1.054655\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:57 INFO 140480903202624] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=1.05465505521\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:43:57 INFO 140480903202624] Epoch[101] Batch [5]#011Speed: 56.90 samples/sec#011loss=1.054655\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:02 INFO 140480903202624] processed a total of 586 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12190.088987350464, \"sum\": 12190.088987350464, \"min\": 12190.088987350464}}, \"EndTime\": 1587307442.27892, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307430.088396}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:02 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.0713815172 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:02 INFO 140480903202624] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:02 INFO 140480903202624] #quality_metric: host=algo-1, epoch=101, train loss <loss>=1.13534851074\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:02 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:02 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_63b2e57f-b202-46da-9dc3-83ed96bc8f9d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 103.93905639648438, \"sum\": 103.93905639648438, \"min\": 103.93905639648438}}, \"EndTime\": 1587307442.383427, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307442.278998}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:04 INFO 140480903202624] Epoch[102] Batch[0] avg_epoch_loss=1.708670\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=1.70866966248\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:10 INFO 140480903202624] Epoch[102] Batch[5] avg_epoch_loss=1.997430\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:10 INFO 140480903202624] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=1.99742988745\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:10 INFO 140480903202624] Epoch[102] Batch [5]#011Speed: 56.63 samples/sec#011loss=1.997430\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:14 INFO 140480903202624] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12141.576051712036, \"sum\": 12141.576051712036, \"min\": 12141.576051712036}}, \"EndTime\": 1587307454.525142, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307442.383499}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:14 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.6635570292 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:14 INFO 140480903202624] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:14 INFO 140480903202624] #quality_metric: host=algo-1, epoch=102, train loss <loss>=1.92116066217\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:14 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:16 INFO 140480903202624] Epoch[103] Batch[0] avg_epoch_loss=1.818544\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=1.81854367256\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:22 INFO 140480903202624] Epoch[103] Batch[5] avg_epoch_loss=1.740401\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:22 INFO 140480903202624] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=1.74040089051\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:22 INFO 140480903202624] Epoch[103] Batch [5]#011Speed: 56.53 samples/sec#011loss=1.740401\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:27 INFO 140480903202624] Epoch[103] Batch[10] avg_epoch_loss=1.595643\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:27 INFO 140480903202624] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=1.42193359137\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:27 INFO 140480903202624] Epoch[103] Batch [10]#011Speed: 57.12 samples/sec#011loss=1.421934\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:27 INFO 140480903202624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13414.402961730957, \"sum\": 13414.402961730957, \"min\": 13414.402961730957}}, \"EndTime\": 1587307467.940096, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307454.525226}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:27 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.3804399581 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:27 INFO 140480903202624] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:27 INFO 140480903202624] #quality_metric: host=algo-1, epoch=103, train loss <loss>=1.59564302726\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:27 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:30 INFO 140480903202624] Epoch[104] Batch[0] avg_epoch_loss=1.258870\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:30 INFO 140480903202624] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=1.25886952877\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:35 INFO 140480903202624] Epoch[104] Batch[5] avg_epoch_loss=1.214121\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:35 INFO 140480903202624] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=1.21412140131\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:35 INFO 140480903202624] Epoch[104] Batch [5]#011Speed: 56.81 samples/sec#011loss=1.214121\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:40 INFO 140480903202624] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12238.876819610596, \"sum\": 12238.876819610596, \"min\": 12238.876819610596}}, \"EndTime\": 1587307480.179491, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307467.94017}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:40 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.3112813494 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:40 INFO 140480903202624] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:40 INFO 140480903202624] #quality_metric: host=algo-1, epoch=104, train loss <loss>=1.20716645718\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:40 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:42 INFO 140480903202624] Epoch[105] Batch[0] avg_epoch_loss=1.399958\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:42 INFO 140480903202624] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=1.39995837212\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:47 INFO 140480903202624] Epoch[105] Batch[5] avg_epoch_loss=1.228099\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:47 INFO 140480903202624] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=1.22809874018\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:47 INFO 140480903202624] Epoch[105] Batch [5]#011Speed: 56.82 samples/sec#011loss=1.228099\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:53 INFO 140480903202624] Epoch[105] Batch[10] avg_epoch_loss=1.171570\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=1.10373632908\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:53 INFO 140480903202624] Epoch[105] Batch [10]#011Speed: 56.40 samples/sec#011loss=1.103736\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:53 INFO 140480903202624] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13406.666040420532, \"sum\": 13406.666040420532, \"min\": 13406.666040420532}}, \"EndTime\": 1587307493.586836, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307480.179577}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:53 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.5714461618 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:53 INFO 140480903202624] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=105, train loss <loss>=1.1715703715\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:53 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:55 INFO 140480903202624] Epoch[106] Batch[0] avg_epoch_loss=2.620488\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:44:55 INFO 140480903202624] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.62048768997\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:01 INFO 140480903202624] Epoch[106] Batch[5] avg_epoch_loss=1.866462\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:01 INFO 140480903202624] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=1.86646169424\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:01 INFO 140480903202624] Epoch[106] Batch [5]#011Speed: 56.81 samples/sec#011loss=1.866462\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:05 INFO 140480903202624] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12185.233116149902, \"sum\": 12185.233116149902, \"min\": 12185.233116149902}}, \"EndTime\": 1587307505.77263, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307493.586909}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:05 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.4550490994 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:05 INFO 140480903202624] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:05 INFO 140480903202624] #quality_metric: host=algo-1, epoch=106, train loss <loss>=1.75110640526\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:05 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:07 INFO 140480903202624] Epoch[107] Batch[0] avg_epoch_loss=1.606648\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:07 INFO 140480903202624] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=1.60664784908\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:13 INFO 140480903202624] Epoch[107] Batch[5] avg_epoch_loss=1.462467\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=1.46246653795\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:13 INFO 140480903202624] Epoch[107] Batch [5]#011Speed: 56.57 samples/sec#011loss=1.462467\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:19 INFO 140480903202624] Epoch[107] Batch[10] avg_epoch_loss=1.357159\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:19 INFO 140480903202624] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=1.23078955412\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:19 INFO 140480903202624] Epoch[107] Batch [10]#011Speed: 57.08 samples/sec#011loss=1.230790\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:19 INFO 140480903202624] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13318.806886672974, \"sum\": 13318.806886672974, \"min\": 13318.806886672974}}, \"EndTime\": 1587307519.092145, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307505.772748}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:19 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.5775309272 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:19 INFO 140480903202624] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:19 INFO 140480903202624] #quality_metric: host=algo-1, epoch=107, train loss <loss>=1.35715881803\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:19 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:21 INFO 140480903202624] Epoch[108] Batch[0] avg_epoch_loss=1.339693\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:21 INFO 140480903202624] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=1.33969295025\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:26 INFO 140480903202624] Epoch[108] Batch[5] avg_epoch_loss=1.099399\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:26 INFO 140480903202624] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=1.09939895074\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:26 INFO 140480903202624] Epoch[108] Batch [5]#011Speed: 57.12 samples/sec#011loss=1.099399\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:31 INFO 140480903202624] processed a total of 580 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12267.912149429321, \"sum\": 12267.912149429321, \"min\": 12267.912149429321}}, \"EndTime\": 1587307531.360573, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307519.092217}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:31 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=47.276914407 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:31 INFO 140480903202624] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:31 INFO 140480903202624] #quality_metric: host=algo-1, epoch=108, train loss <loss>=1.1768903017\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:31 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:33 INFO 140480903202624] Epoch[109] Batch[0] avg_epoch_loss=2.031271\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.03127145767\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:39 INFO 140480903202624] Epoch[109] Batch[5] avg_epoch_loss=2.225739\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:39 INFO 140480903202624] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.2257390221\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:39 INFO 140480903202624] Epoch[109] Batch [5]#011Speed: 57.05 samples/sec#011loss=2.225739\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:43 INFO 140480903202624] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12167.428016662598, \"sum\": 12167.428016662598, \"min\": 12167.428016662598}}, \"EndTime\": 1587307543.528687, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307531.360766}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:43 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.4346146536 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:43 INFO 140480903202624] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:43 INFO 140480903202624] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.15495568514\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:43 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:45 INFO 140480903202624] Epoch[110] Batch[0] avg_epoch_loss=1.863178\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:45 INFO 140480903202624] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=1.86317849159\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:51 INFO 140480903202624] Epoch[110] Batch[5] avg_epoch_loss=1.969018\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=1.9690177838\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:51 INFO 140480903202624] Epoch[110] Batch [5]#011Speed: 56.24 samples/sec#011loss=1.969018\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:56 INFO 140480903202624] Epoch[110] Batch[10] avg_epoch_loss=1.858697\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:56 INFO 140480903202624] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=1.72631132603\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:56 INFO 140480903202624] Epoch[110] Batch [10]#011Speed: 56.68 samples/sec#011loss=1.726311\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:56 INFO 140480903202624] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13390.130043029785, \"sum\": 13390.130043029785, \"min\": 13390.130043029785}}, \"EndTime\": 1587307556.919369, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307543.528755}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:56 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.2605000427 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:56 INFO 140480903202624] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:56 INFO 140480903202624] #quality_metric: host=algo-1, epoch=110, train loss <loss>=1.85869666663\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:56 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:58 INFO 140480903202624] Epoch[111] Batch[0] avg_epoch_loss=1.584526\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:45:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=1.58452558517\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:04 INFO 140480903202624] Epoch[111] Batch[5] avg_epoch_loss=1.547527\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=1.54752675692\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:04 INFO 140480903202624] Epoch[111] Batch [5]#011Speed: 56.79 samples/sec#011loss=1.547527\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:10 INFO 140480903202624] Epoch[111] Batch[10] avg_epoch_loss=1.397342\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:10 INFO 140480903202624] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=1.21712042093\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:10 INFO 140480903202624] Epoch[111] Batch [10]#011Speed: 56.80 samples/sec#011loss=1.217120\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:10 INFO 140480903202624] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13317.480087280273, \"sum\": 13317.480087280273, \"min\": 13317.480087280273}}, \"EndTime\": 1587307570.237353, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307556.919443}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:10 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.0841296781 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:10 INFO 140480903202624] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:10 INFO 140480903202624] #quality_metric: host=algo-1, epoch=111, train loss <loss>=1.39734205875\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:10 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:12 INFO 140480903202624] Epoch[112] Batch[0] avg_epoch_loss=1.209366\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:12 INFO 140480903202624] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=1.20936620235\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:17 INFO 140480903202624] Epoch[112] Batch[5] avg_epoch_loss=1.124796\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:17 INFO 140480903202624] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=1.12479612231\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:17 INFO 140480903202624] Epoch[112] Batch [5]#011Speed: 56.86 samples/sec#011loss=1.124796\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:23 INFO 140480903202624] Epoch[112] Batch[10] avg_epoch_loss=1.306474\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:23 INFO 140480903202624] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=1.52448655367\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:23 INFO 140480903202624] Epoch[112] Batch [10]#011Speed: 56.92 samples/sec#011loss=1.524487\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:23 INFO 140480903202624] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13312.99090385437, \"sum\": 13312.99090385437, \"min\": 13312.99090385437}}, \"EndTime\": 1587307583.550875, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307570.237427}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:23 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.2982525101 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:23 INFO 140480903202624] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:23 INFO 140480903202624] #quality_metric: host=algo-1, epoch=112, train loss <loss>=1.30647359111\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:23 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:25 INFO 140480903202624] Epoch[113] Batch[0] avg_epoch_loss=2.045084\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:25 INFO 140480903202624] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=2.04508376122\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:31 INFO 140480903202624] Epoch[113] Batch[5] avg_epoch_loss=1.822392\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:31 INFO 140480903202624] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=1.82239162922\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:31 INFO 140480903202624] Epoch[113] Batch [5]#011Speed: 57.15 samples/sec#011loss=1.822392\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:35 INFO 140480903202624] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12080.960035324097, \"sum\": 12080.960035324097, \"min\": 12080.960035324097}}, \"EndTime\": 1587307595.632531, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307583.550961}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:35 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.0649383017 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:35 INFO 140480903202624] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:35 INFO 140480903202624] #quality_metric: host=algo-1, epoch=113, train loss <loss>=1.71930398941\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:35 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:37 INFO 140480903202624] Epoch[114] Batch[0] avg_epoch_loss=1.475939\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:37 INFO 140480903202624] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=1.47593891621\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:43 INFO 140480903202624] Epoch[114] Batch[5] avg_epoch_loss=1.389756\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:43 INFO 140480903202624] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=1.3897562027\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:43 INFO 140480903202624] Epoch[114] Batch [5]#011Speed: 57.37 samples/sec#011loss=1.389756\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:48 INFO 140480903202624] Epoch[114] Batch[10] avg_epoch_loss=1.324722\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:48 INFO 140480903202624] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=1.24668176174\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:48 INFO 140480903202624] Epoch[114] Batch [10]#011Speed: 57.28 samples/sec#011loss=1.246682\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:48 INFO 140480903202624] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13231.588125228882, \"sum\": 13231.588125228882, \"min\": 13231.588125228882}}, \"EndTime\": 1587307608.864709, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307595.632597}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:48 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.787140633 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:48 INFO 140480903202624] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:48 INFO 140480903202624] #quality_metric: host=algo-1, epoch=114, train loss <loss>=1.3247223659\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:48 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:50 INFO 140480903202624] Epoch[115] Batch[0] avg_epoch_loss=1.137770\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:50 INFO 140480903202624] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=1.1377696991\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:56 INFO 140480903202624] Epoch[115] Batch[5] avg_epoch_loss=1.054470\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:56 INFO 140480903202624] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=1.05446995298\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:46:56 INFO 140480903202624] Epoch[115] Batch [5]#011Speed: 56.69 samples/sec#011loss=1.054470\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:02 INFO 140480903202624] Epoch[115] Batch[10] avg_epoch_loss=1.249069\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:02 INFO 140480903202624] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=1.48258769512\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:02 INFO 140480903202624] Epoch[115] Batch [10]#011Speed: 56.25 samples/sec#011loss=1.482588\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:02 INFO 140480903202624] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13417.017936706543, \"sum\": 13417.017936706543, \"min\": 13417.017936706543}}, \"EndTime\": 1587307622.282175, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307608.864783}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:02 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.1163162556 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:02 INFO 140480903202624] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:02 INFO 140480903202624] #quality_metric: host=algo-1, epoch=115, train loss <loss>=1.24906892668\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:02 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:04 INFO 140480903202624] Epoch[116] Batch[0] avg_epoch_loss=2.107017\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.10701727867\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:09 INFO 140480903202624] Epoch[116] Batch[5] avg_epoch_loss=2.145166\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:09 INFO 140480903202624] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.14516639709\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:09 INFO 140480903202624] Epoch[116] Batch [5]#011Speed: 57.15 samples/sec#011loss=2.145166\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:14 INFO 140480903202624] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12168.915033340454, \"sum\": 12168.915033340454, \"min\": 12168.915033340454}}, \"EndTime\": 1587307634.451586, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307622.282252}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:14 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.6064354272 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:14 INFO 140480903202624] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:14 INFO 140480903202624] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.04891706705\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:14 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:16 INFO 140480903202624] Epoch[117] Batch[0] avg_epoch_loss=1.847844\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=1.84784424305\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:22 INFO 140480903202624] Epoch[117] Batch[5] avg_epoch_loss=1.807710\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:22 INFO 140480903202624] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=1.80771025022\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:22 INFO 140480903202624] Epoch[117] Batch [5]#011Speed: 56.99 samples/sec#011loss=1.807710\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:26 INFO 140480903202624] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12111.593961715698, \"sum\": 12111.593961715698, \"min\": 12111.593961715698}}, \"EndTime\": 1587307646.563773, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307634.451657}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:26 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.8691139497 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:26 INFO 140480903202624] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:26 INFO 140480903202624] #quality_metric: host=algo-1, epoch=117, train loss <loss>=1.730747509\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:26 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:28 INFO 140480903202624] Epoch[118] Batch[0] avg_epoch_loss=1.504962\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:28 INFO 140480903202624] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=1.50496184826\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:34 INFO 140480903202624] Epoch[118] Batch[5] avg_epoch_loss=1.389311\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:34 INFO 140480903202624] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=1.38931119442\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:34 INFO 140480903202624] Epoch[118] Batch [5]#011Speed: 56.76 samples/sec#011loss=1.389311\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:38 INFO 140480903202624] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12183.59112739563, \"sum\": 12183.59112739563, \"min\": 12183.59112739563}}, \"EndTime\": 1587307658.748031, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307646.563842}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:38 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.6257133981 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:38 INFO 140480903202624] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=118, train loss <loss>=1.29789742827\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:38 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:40 INFO 140480903202624] Epoch[119] Batch[0] avg_epoch_loss=1.084676\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:40 INFO 140480903202624] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=1.08467590809\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:46 INFO 140480903202624] Epoch[119] Batch[5] avg_epoch_loss=1.024631\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:46 INFO 140480903202624] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=1.0246314009\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:46 INFO 140480903202624] Epoch[119] Batch [5]#011Speed: 56.99 samples/sec#011loss=1.024631\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:52 INFO 140480903202624] Epoch[119] Batch[10] avg_epoch_loss=1.072894\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:52 INFO 140480903202624] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=1.13080962896\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:52 INFO 140480903202624] Epoch[119] Batch [10]#011Speed: 56.56 samples/sec#011loss=1.130810\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:52 INFO 140480903202624] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13394.355773925781, \"sum\": 13394.355773925781, \"min\": 13394.355773925781}}, \"EndTime\": 1587307672.1431, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307658.748144}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:52 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.0500564778 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:52 INFO 140480903202624] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:52 INFO 140480903202624] #quality_metric: host=algo-1, epoch=119, train loss <loss>=1.07289423184\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:52 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:52 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_cdec72c1-8fe9-4cb2-a3c9-8bb20a27111d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 104.04491424560547, \"sum\": 104.04491424560547, \"min\": 104.04491424560547}}, \"EndTime\": 1587307672.247804, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307672.143185}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:54 INFO 140480903202624] Epoch[120] Batch[0] avg_epoch_loss=0.921855\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:54 INFO 140480903202624] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=0.921855449677\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:59 INFO 140480903202624] Epoch[120] Batch[5] avg_epoch_loss=1.157533\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:59 INFO 140480903202624] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=1.15753250321\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:47:59 INFO 140480903202624] Epoch[120] Batch [5]#011Speed: 56.89 samples/sec#011loss=1.157533\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:04 INFO 140480903202624] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12162.935018539429, \"sum\": 12162.935018539429, \"min\": 12162.935018539429}}, \"EndTime\": 1587307684.411111, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307672.248108}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:04 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.329695777 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:04 INFO 140480903202624] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=120, train loss <loss>=1.14111596346\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:04 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:06 INFO 140480903202624] Epoch[121] Batch[0] avg_epoch_loss=1.028001\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:06 INFO 140480903202624] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=1.02800095081\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:12 INFO 140480903202624] Epoch[121] Batch[5] avg_epoch_loss=1.197932\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:12 INFO 140480903202624] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=1.19793216387\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:12 INFO 140480903202624] Epoch[121] Batch [5]#011Speed: 56.54 samples/sec#011loss=1.197932\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:17 INFO 140480903202624] Epoch[121] Batch[10] avg_epoch_loss=1.132381\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:17 INFO 140480903202624] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=1.05371870995\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:17 INFO 140480903202624] Epoch[121] Batch [10]#011Speed: 56.57 samples/sec#011loss=1.053719\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:17 INFO 140480903202624] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13403.563022613525, \"sum\": 13403.563022613525, \"min\": 13403.563022613525}}, \"EndTime\": 1587307697.815222, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307684.411196}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:17 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.4941808088 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:17 INFO 140480903202624] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:17 INFO 140480903202624] #quality_metric: host=algo-1, epoch=121, train loss <loss>=1.13238059391\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:17 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:19 INFO 140480903202624] Epoch[122] Batch[0] avg_epoch_loss=1.854805\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:19 INFO 140480903202624] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=1.85480487347\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:25 INFO 140480903202624] Epoch[122] Batch[5] avg_epoch_loss=1.456758\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:25 INFO 140480903202624] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=1.45675758521\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:25 INFO 140480903202624] Epoch[122] Batch [5]#011Speed: 56.56 samples/sec#011loss=1.456758\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:31 INFO 140480903202624] Epoch[122] Batch[10] avg_epoch_loss=1.282919\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:31 INFO 140480903202624] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=1.0743129611\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:31 INFO 140480903202624] Epoch[122] Batch [10]#011Speed: 56.94 samples/sec#011loss=1.074313\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:31 INFO 140480903202624] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13332.533836364746, \"sum\": 13332.533836364746, \"min\": 13332.533836364746}}, \"EndTime\": 1587307711.148329, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307697.815294}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:31 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.0274880729 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:31 INFO 140480903202624] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:31 INFO 140480903202624] #quality_metric: host=algo-1, epoch=122, train loss <loss>=1.2829191197\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:31 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:33 INFO 140480903202624] Epoch[123] Batch[0] avg_epoch_loss=1.036828\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=1.03682780266\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:38 INFO 140480903202624] Epoch[123] Batch[5] avg_epoch_loss=1.082315\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=1.08231504758\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:38 INFO 140480903202624] Epoch[123] Batch [5]#011Speed: 57.02 samples/sec#011loss=1.082315\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:43 INFO 140480903202624] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12301.793813705444, \"sum\": 12301.793813705444, \"min\": 12301.793813705444}}, \"EndTime\": 1587307723.450687, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307711.148429}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:43 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.9429968224 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:43 INFO 140480903202624] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:43 INFO 140480903202624] #quality_metric: host=algo-1, epoch=123, train loss <loss>=1.02528973222\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:43 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:43 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_73b40836-74ad-4e02-b29a-22a94feee0da-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 100.85797309875488, \"sum\": 100.85797309875488, \"min\": 100.85797309875488}}, \"EndTime\": 1587307723.552271, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307723.450771}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:45 INFO 140480903202624] Epoch[124] Batch[0] avg_epoch_loss=0.719759\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:45 INFO 140480903202624] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=0.719758927822\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:51 INFO 140480903202624] Epoch[124] Batch[5] avg_epoch_loss=1.182531\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=1.18253096938\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:51 INFO 140480903202624] Epoch[124] Batch [5]#011Speed: 56.87 samples/sec#011loss=1.182531\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:55 INFO 140480903202624] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12241.283893585205, \"sum\": 12241.283893585205, \"min\": 12241.283893585205}}, \"EndTime\": 1587307735.793713, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307723.552344}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:55 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.2816017629 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:55 INFO 140480903202624] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:55 INFO 140480903202624] #quality_metric: host=algo-1, epoch=124, train loss <loss>=1.05311989784\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:55 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:57 INFO 140480903202624] Epoch[125] Batch[0] avg_epoch_loss=1.169388\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:48:57 INFO 140480903202624] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=1.16938817501\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:03 INFO 140480903202624] Epoch[125] Batch[5] avg_epoch_loss=1.056366\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:03 INFO 140480903202624] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=1.05636639396\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:03 INFO 140480903202624] Epoch[125] Batch [5]#011Speed: 56.59 samples/sec#011loss=1.056366\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:09 INFO 140480903202624] Epoch[125] Batch[10] avg_epoch_loss=1.023007\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:09 INFO 140480903202624] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=0.98297624588\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:09 INFO 140480903202624] Epoch[125] Batch [10]#011Speed: 56.94 samples/sec#011loss=0.982976\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:09 INFO 140480903202624] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13355.88788986206, \"sum\": 13355.88788986206, \"min\": 13355.88788986206}}, \"EndTime\": 1587307749.150192, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307735.793789}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:09 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.3678431862 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:09 INFO 140480903202624] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:09 INFO 140480903202624] #quality_metric: host=algo-1, epoch=125, train loss <loss>=1.02300723574\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:09 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:09 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_717faa91-399c-4e77-89aa-594118c38ee3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 103.97696495056152, \"sum\": 103.97696495056152, \"min\": 103.97696495056152}}, \"EndTime\": 1587307749.254948, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307749.150252}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:11 INFO 140480903202624] Epoch[126] Batch[0] avg_epoch_loss=1.600006\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=1.60000634193\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:16 INFO 140480903202624] Epoch[126] Batch[5] avg_epoch_loss=1.318561\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=1.31856056054\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:16 INFO 140480903202624] Epoch[126] Batch [5]#011Speed: 56.76 samples/sec#011loss=1.318561\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:21 INFO 140480903202624] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12120.145082473755, \"sum\": 12120.145082473755, \"min\": 12120.145082473755}}, \"EndTime\": 1587307761.37523, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307749.25502}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:21 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.4938669732 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:21 INFO 140480903202624] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:21 INFO 140480903202624] #quality_metric: host=algo-1, epoch=126, train loss <loss>=1.21177604198\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:21 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:23 INFO 140480903202624] Epoch[127] Batch[0] avg_epoch_loss=1.044278\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:23 INFO 140480903202624] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=1.04427790642\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:29 INFO 140480903202624] Epoch[127] Batch[5] avg_epoch_loss=0.968497\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:29 INFO 140480903202624] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=0.968496700128\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:29 INFO 140480903202624] Epoch[127] Batch [5]#011Speed: 56.92 samples/sec#011loss=0.968497\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:33 INFO 140480903202624] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12262.91298866272, \"sum\": 12262.91298866272, \"min\": 12262.91298866272}}, \"EndTime\": 1587307773.638905, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307761.37533}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:33 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.8630876736 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:33 INFO 140480903202624] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:33 INFO 140480903202624] #quality_metric: host=algo-1, epoch=127, train loss <loss>=0.928423953056\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:33 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:33 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_5241210f-41be-498d-881c-8a240c48db79-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.12084579467773, \"sum\": 109.12084579467773, \"min\": 109.12084579467773}}, \"EndTime\": 1587307773.74861, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307773.639014}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:35 INFO 140480903202624] Epoch[128] Batch[0] avg_epoch_loss=0.952230\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:35 INFO 140480903202624] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=0.952229738235\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:41 INFO 140480903202624] Epoch[128] Batch[5] avg_epoch_loss=1.045559\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:41 INFO 140480903202624] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=1.04555855195\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:41 INFO 140480903202624] Epoch[128] Batch [5]#011Speed: 56.79 samples/sec#011loss=1.045559\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:45 INFO 140480903202624] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12122.688055038452, \"sum\": 12122.688055038452, \"min\": 12122.688055038452}}, \"EndTime\": 1587307785.871433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307773.748682}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:45 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.1534294383 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:45 INFO 140480903202624] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:45 INFO 140480903202624] #quality_metric: host=algo-1, epoch=128, train loss <loss>=1.0786830008\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:45 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:47 INFO 140480903202624] Epoch[129] Batch[0] avg_epoch_loss=0.890275\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:47 INFO 140480903202624] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=0.890275120735\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:53 INFO 140480903202624] Epoch[129] Batch[5] avg_epoch_loss=0.976998\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=0.976997802655\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:53 INFO 140480903202624] Epoch[129] Batch [5]#011Speed: 56.12 samples/sec#011loss=0.976998\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:58 INFO 140480903202624] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12246.158838272095, \"sum\": 12246.158838272095, \"min\": 12246.158838272095}}, \"EndTime\": 1587307798.118101, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307785.871508}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:58 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.4844468333 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:58 INFO 140480903202624] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=129, train loss <loss>=0.890179133415\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:58 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:49:58 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_0c75f278-1b0e-4776-8ee2-74fff791023e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 100.91090202331543, \"sum\": 100.91090202331543, \"min\": 100.91090202331543}}, \"EndTime\": 1587307798.219726, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307798.118176}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:00 INFO 140480903202624] Epoch[130] Batch[0] avg_epoch_loss=1.557764\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:00 INFO 140480903202624] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=1.55776381493\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:05 INFO 140480903202624] Epoch[130] Batch[5] avg_epoch_loss=1.122963\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:05 INFO 140480903202624] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=1.12296277285\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:05 INFO 140480903202624] Epoch[130] Batch [5]#011Speed: 56.87 samples/sec#011loss=1.122963\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:11 INFO 140480903202624] Epoch[130] Batch[10] avg_epoch_loss=1.087910\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=1.04584707022\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:11 INFO 140480903202624] Epoch[130] Batch [10]#011Speed: 57.03 samples/sec#011loss=1.045847\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:11 INFO 140480903202624] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13321.595191955566, \"sum\": 13321.595191955566, \"min\": 13321.595191955566}}, \"EndTime\": 1587307811.54146, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307798.2198}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:11 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.6424036151 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:11 INFO 140480903202624] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=130, train loss <loss>=1.08791018074\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:11 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:13 INFO 140480903202624] Epoch[131] Batch[0] avg_epoch_loss=0.925201\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=0.925200998783\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:19 INFO 140480903202624] Epoch[131] Batch[5] avg_epoch_loss=0.961737\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:19 INFO 140480903202624] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=0.961737294992\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:19 INFO 140480903202624] Epoch[131] Batch [5]#011Speed: 56.54 samples/sec#011loss=0.961737\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:24 INFO 140480903202624] Epoch[131] Batch[10] avg_epoch_loss=0.986251\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:24 INFO 140480903202624] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=1.01566745043\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:24 INFO 140480903202624] Epoch[131] Batch [10]#011Speed: 56.49 samples/sec#011loss=1.015667\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:24 INFO 140480903202624] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13357.079982757568, \"sum\": 13357.079982757568, \"min\": 13357.079982757568}}, \"EndTime\": 1587307824.899131, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307811.541536}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:24 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.0105039021 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:24 INFO 140480903202624] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:24 INFO 140480903202624] #quality_metric: host=algo-1, epoch=131, train loss <loss>=0.986251002008\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:24 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:27 INFO 140480903202624] Epoch[132] Batch[0] avg_epoch_loss=1.002733\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:27 INFO 140480903202624] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=1.0027333498\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:32 INFO 140480903202624] Epoch[132] Batch[5] avg_epoch_loss=1.032378\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:32 INFO 140480903202624] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=1.03237757087\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:32 INFO 140480903202624] Epoch[132] Batch [5]#011Speed: 56.71 samples/sec#011loss=1.032378\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:38 INFO 140480903202624] Epoch[132] Batch[10] avg_epoch_loss=1.010188\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=0.983561122417\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:38 INFO 140480903202624] Epoch[132] Batch [10]#011Speed: 56.67 samples/sec#011loss=0.983561\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:38 INFO 140480903202624] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13395.95103263855, \"sum\": 13395.95103263855, \"min\": 13395.95103263855}}, \"EndTime\": 1587307838.295688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307824.89921}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:38 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.2230733648 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:38 INFO 140480903202624] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=132, train loss <loss>=1.01018827612\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:38 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:40 INFO 140480903202624] Epoch[133] Batch[0] avg_epoch_loss=1.190421\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:40 INFO 140480903202624] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=1.19042134285\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:45 INFO 140480903202624] Epoch[133] Batch[5] avg_epoch_loss=1.143219\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:45 INFO 140480903202624] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=1.14321862658\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:45 INFO 140480903202624] Epoch[133] Batch [5]#011Speed: 57.04 samples/sec#011loss=1.143219\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:50 INFO 140480903202624] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12093.272924423218, \"sum\": 12093.272924423218, \"min\": 12093.272924423218}}, \"EndTime\": 1587307850.389582, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307838.295775}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:50 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.4482713358 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:50 INFO 140480903202624] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:50 INFO 140480903202624] #quality_metric: host=algo-1, epoch=133, train loss <loss>=1.11515198946\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:50 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:52 INFO 140480903202624] Epoch[134] Batch[0] avg_epoch_loss=1.207976\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:52 INFO 140480903202624] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=1.20797610283\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:58 INFO 140480903202624] Epoch[134] Batch[5] avg_epoch_loss=1.022484\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=1.02248369654\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:50:58 INFO 140480903202624] Epoch[134] Batch [5]#011Speed: 56.45 samples/sec#011loss=1.022484\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:02 INFO 140480903202624] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12301.392078399658, \"sum\": 12301.392078399658, \"min\": 12301.392078399658}}, \"EndTime\": 1587307862.691565, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307850.389718}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:02 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.8067990375 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:02 INFO 140480903202624] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:02 INFO 140480903202624] #quality_metric: host=algo-1, epoch=134, train loss <loss>=0.971119099855\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:02 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:04 INFO 140480903202624] Epoch[135] Batch[0] avg_epoch_loss=1.338227\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:04 INFO 140480903202624] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=1.33822727203\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:10 INFO 140480903202624] Epoch[135] Batch[5] avg_epoch_loss=1.096294\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:10 INFO 140480903202624] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=1.09629377723\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:10 INFO 140480903202624] Epoch[135] Batch [5]#011Speed: 56.87 samples/sec#011loss=1.096294\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:16 INFO 140480903202624] Epoch[135] Batch[10] avg_epoch_loss=1.062196\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=1.02127834558\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:16 INFO 140480903202624] Epoch[135] Batch [10]#011Speed: 56.31 samples/sec#011loss=1.021278\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:16 INFO 140480903202624] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13449.655055999756, \"sum\": 13449.655055999756, \"min\": 13449.655055999756}}, \"EndTime\": 1587307876.141787, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307862.691641}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:16 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.1458254051 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:16 INFO 140480903202624] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=135, train loss <loss>=1.06219585375\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:16 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:18 INFO 140480903202624] Epoch[136] Batch[0] avg_epoch_loss=0.843071\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=0.843070626259\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:23 INFO 140480903202624] Epoch[136] Batch[5] avg_epoch_loss=1.285503\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:23 INFO 140480903202624] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=1.28550342719\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:23 INFO 140480903202624] Epoch[136] Batch [5]#011Speed: 56.15 samples/sec#011loss=1.285503\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:29 INFO 140480903202624] Epoch[136] Batch[10] avg_epoch_loss=1.285004\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:29 INFO 140480903202624] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=1.28440496922\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:29 INFO 140480903202624] Epoch[136] Batch [10]#011Speed: 57.12 samples/sec#011loss=1.284405\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:29 INFO 140480903202624] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13426.77092552185, \"sum\": 13426.77092552185, \"min\": 13426.77092552185}}, \"EndTime\": 1587307889.569112, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307876.141865}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:29 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.3892905418 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:29 INFO 140480903202624] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:29 INFO 140480903202624] #quality_metric: host=algo-1, epoch=136, train loss <loss>=1.28500412811\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:29 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:31 INFO 140480903202624] Epoch[137] Batch[0] avg_epoch_loss=1.047707\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:31 INFO 140480903202624] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=1.04770720005\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:37 INFO 140480903202624] Epoch[137] Batch[5] avg_epoch_loss=1.105011\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:37 INFO 140480903202624] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=1.10501096646\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:37 INFO 140480903202624] Epoch[137] Batch [5]#011Speed: 57.12 samples/sec#011loss=1.105011\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:41 INFO 140480903202624] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12127.815961837769, \"sum\": 12127.815961837769, \"min\": 12127.815961837769}}, \"EndTime\": 1587307901.697462, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307889.569219}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:41 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.9778189595 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:41 INFO 140480903202624] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:41 INFO 140480903202624] #quality_metric: host=algo-1, epoch=137, train loss <loss>=1.0150367856\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:41 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:43 INFO 140480903202624] Epoch[138] Batch[0] avg_epoch_loss=1.221549\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:43 INFO 140480903202624] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=1.22154903412\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:49 INFO 140480903202624] Epoch[138] Batch[5] avg_epoch_loss=1.078920\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:49 INFO 140480903202624] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=1.07891983787\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:49 INFO 140480903202624] Epoch[138] Batch [5]#011Speed: 57.30 samples/sec#011loss=1.078920\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:53 INFO 140480903202624] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12217.434883117676, \"sum\": 12217.434883117676, \"min\": 12217.434883117676}}, \"EndTime\": 1587307913.915452, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307901.697546}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:53 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.9744258593 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:53 INFO 140480903202624] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=138, train loss <loss>=1.03820666671\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:53 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:56 INFO 140480903202624] Epoch[139] Batch[0] avg_epoch_loss=0.871465\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:51:56 INFO 140480903202624] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=0.871464550495\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:01 INFO 140480903202624] Epoch[139] Batch[5] avg_epoch_loss=1.079936\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:01 INFO 140480903202624] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=1.07993593812\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:01 INFO 140480903202624] Epoch[139] Batch [5]#011Speed: 57.23 samples/sec#011loss=1.079936\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:07 INFO 140480903202624] Epoch[139] Batch[10] avg_epoch_loss=1.040494\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:07 INFO 140480903202624] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=0.993164277077\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:07 INFO 140480903202624] Epoch[139] Batch [10]#011Speed: 56.60 samples/sec#011loss=0.993164\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:07 INFO 140480903202624] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13344.079971313477, \"sum\": 13344.079971313477, \"min\": 13344.079971313477}}, \"EndTime\": 1587307927.260035, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307913.915526}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:07 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.0334537612 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:07 INFO 140480903202624] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:07 INFO 140480903202624] #quality_metric: host=algo-1, epoch=139, train loss <loss>=1.04049427401\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:07 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:09 INFO 140480903202624] Epoch[140] Batch[0] avg_epoch_loss=0.914661\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:09 INFO 140480903202624] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=0.914661109447\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:14 INFO 140480903202624] Epoch[140] Batch[5] avg_epoch_loss=0.974490\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:14 INFO 140480903202624] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=0.974490493536\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:14 INFO 140480903202624] Epoch[140] Batch [5]#011Speed: 57.24 samples/sec#011loss=0.974490\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:19 INFO 140480903202624] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12141.398906707764, \"sum\": 12141.398906707764, \"min\": 12141.398906707764}}, \"EndTime\": 1587307939.40226, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307927.260107}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:19 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.6409643768 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:19 INFO 140480903202624] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:19 INFO 140480903202624] #quality_metric: host=algo-1, epoch=140, train loss <loss>=0.938296186924\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:19 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:21 INFO 140480903202624] Epoch[141] Batch[0] avg_epoch_loss=0.929367\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:21 INFO 140480903202624] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=0.929366588593\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:27 INFO 140480903202624] Epoch[141] Batch[5] avg_epoch_loss=0.937979\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:27 INFO 140480903202624] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=0.937978615363\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:27 INFO 140480903202624] Epoch[141] Batch [5]#011Speed: 56.11 samples/sec#011loss=0.937979\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:32 INFO 140480903202624] Epoch[141] Batch[10] avg_epoch_loss=0.935693\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:32 INFO 140480903202624] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=0.932950687408\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:32 INFO 140480903202624] Epoch[141] Batch [10]#011Speed: 57.00 samples/sec#011loss=0.932951\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:32 INFO 140480903202624] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13410.857915878296, \"sum\": 13410.857915878296, \"min\": 13410.857915878296}}, \"EndTime\": 1587307952.813625, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307939.402345}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:32 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.2880048457 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:32 INFO 140480903202624] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:32 INFO 140480903202624] #quality_metric: host=algo-1, epoch=141, train loss <loss>=0.935693193566\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:32 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:34 INFO 140480903202624] Epoch[142] Batch[0] avg_epoch_loss=1.451143\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:34 INFO 140480903202624] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=1.45114266872\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:40 INFO 140480903202624] Epoch[142] Batch[5] avg_epoch_loss=1.200284\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:40 INFO 140480903202624] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=1.20028447111\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:40 INFO 140480903202624] Epoch[142] Batch [5]#011Speed: 56.77 samples/sec#011loss=1.200284\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:46 INFO 140480903202624] Epoch[142] Batch[10] avg_epoch_loss=1.240509\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:46 INFO 140480903202624] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=1.28877774477\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:46 INFO 140480903202624] Epoch[142] Batch [10]#011Speed: 55.06 samples/sec#011loss=1.288778\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:46 INFO 140480903202624] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13551.514148712158, \"sum\": 13551.514148712158, \"min\": 13551.514148712158}}, \"EndTime\": 1587307966.365692, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307952.813703}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:46 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.259838097 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:46 INFO 140480903202624] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:46 INFO 140480903202624] #quality_metric: host=algo-1, epoch=142, train loss <loss>=1.24050868641\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:46 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:48 INFO 140480903202624] Epoch[143] Batch[0] avg_epoch_loss=1.314701\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:48 INFO 140480903202624] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=1.3147008419\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:54 INFO 140480903202624] Epoch[143] Batch[5] avg_epoch_loss=1.257569\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:54 INFO 140480903202624] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=1.25756890575\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:54 INFO 140480903202624] Epoch[143] Batch [5]#011Speed: 56.40 samples/sec#011loss=1.257569\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:58 INFO 140480903202624] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12224.714040756226, \"sum\": 12224.714040756226, \"min\": 12224.714040756226}}, \"EndTime\": 1587307978.590997, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307966.365778}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:58 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.7798655628 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:58 INFO 140480903202624] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=143, train loss <loss>=1.18297641873\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:52:58 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:00 INFO 140480903202624] Epoch[144] Batch[0] avg_epoch_loss=1.413558\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:00 INFO 140480903202624] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=1.41355752945\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:06 INFO 140480903202624] Epoch[144] Batch[5] avg_epoch_loss=1.079359\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:06 INFO 140480903202624] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=1.07935850819\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:06 INFO 140480903202624] Epoch[144] Batch [5]#011Speed: 56.76 samples/sec#011loss=1.079359\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:11 INFO 140480903202624] Epoch[144] Batch[10] avg_epoch_loss=1.048183\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=1.01077337265\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:11 INFO 140480903202624] Epoch[144] Batch [10]#011Speed: 56.46 samples/sec#011loss=1.010773\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:11 INFO 140480903202624] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13382.79414176941, \"sum\": 13382.79414176941, \"min\": 13382.79414176941}}, \"EndTime\": 1587307991.974385, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307978.591075}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:11 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.7935880255 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:11 INFO 140480903202624] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=144, train loss <loss>=1.04818344658\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:11 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:13 INFO 140480903202624] Epoch[145] Batch[0] avg_epoch_loss=0.994888\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=0.994887769222\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:19 INFO 140480903202624] Epoch[145] Batch[5] avg_epoch_loss=0.992973\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:19 INFO 140480903202624] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=0.992972999811\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:19 INFO 140480903202624] Epoch[145] Batch [5]#011Speed: 56.97 samples/sec#011loss=0.992973\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:24 INFO 140480903202624] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12245.157957077026, \"sum\": 12245.157957077026, \"min\": 12245.157957077026}}, \"EndTime\": 1587308004.220108, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307991.974463}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:24 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.2650572505 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:24 INFO 140480903202624] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:24 INFO 140480903202624] #quality_metric: host=algo-1, epoch=145, train loss <loss>=1.04854402542\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:24 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:26 INFO 140480903202624] Epoch[146] Batch[0] avg_epoch_loss=0.815194\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:26 INFO 140480903202624] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=0.815193831921\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:31 INFO 140480903202624] Epoch[146] Batch[5] avg_epoch_loss=0.842255\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:31 INFO 140480903202624] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=0.842254946629\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:31 INFO 140480903202624] Epoch[146] Batch [5]#011Speed: 56.85 samples/sec#011loss=0.842255\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:36 INFO 140480903202624] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12189.769983291626, \"sum\": 12189.769983291626, \"min\": 12189.769983291626}}, \"EndTime\": 1587308016.410513, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308004.220178}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:36 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.2564613488 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:36 INFO 140480903202624] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:36 INFO 140480903202624] #quality_metric: host=algo-1, epoch=146, train loss <loss>=0.873288208246\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:36 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:36 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_e1233656-6a66-4930-9149-306553cb9118-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 104.5830249786377, \"sum\": 104.5830249786377, \"min\": 104.5830249786377}}, \"EndTime\": 1587308016.515777, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308016.410588}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:38 INFO 140480903202624] Epoch[147] Batch[0] avg_epoch_loss=0.985845\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=0.985844910145\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:44 INFO 140480903202624] Epoch[147] Batch[5] avg_epoch_loss=0.918080\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:44 INFO 140480903202624] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=0.918080012004\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:44 INFO 140480903202624] Epoch[147] Batch [5]#011Speed: 56.73 samples/sec#011loss=0.918080\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:49 INFO 140480903202624] Epoch[147] Batch[10] avg_epoch_loss=0.958746\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:49 INFO 140480903202624] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=1.00754497051\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:49 INFO 140480903202624] Epoch[147] Batch [10]#011Speed: 56.83 samples/sec#011loss=1.007545\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:49 INFO 140480903202624] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13327.089071273804, \"sum\": 13327.089071273804, \"min\": 13327.089071273804}}, \"EndTime\": 1587308029.842999, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308016.515849}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:49 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.8474333688 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:49 INFO 140480903202624] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:49 INFO 140480903202624] #quality_metric: host=algo-1, epoch=147, train loss <loss>=0.958745902235\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:49 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:51 INFO 140480903202624] Epoch[148] Batch[0] avg_epoch_loss=0.859625\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=0.859625399113\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:57 INFO 140480903202624] Epoch[148] Batch[5] avg_epoch_loss=0.995841\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:57 INFO 140480903202624] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=0.995841304461\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:53:57 INFO 140480903202624] Epoch[148] Batch [5]#011Speed: 56.35 samples/sec#011loss=0.995841\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:03 INFO 140480903202624] Epoch[148] Batch[10] avg_epoch_loss=0.986432\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:03 INFO 140480903202624] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=0.97514128685\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:03 INFO 140480903202624] Epoch[148] Batch [10]#011Speed: 56.71 samples/sec#011loss=0.975141\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:03 INFO 140480903202624] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13390.451192855835, \"sum\": 13390.451192855835, \"min\": 13390.451192855835}}, \"EndTime\": 1587308043.234021, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308029.843079}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:03 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.2429089734 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:03 INFO 140480903202624] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:03 INFO 140480903202624] #quality_metric: host=algo-1, epoch=148, train loss <loss>=0.986432205547\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:03 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:05 INFO 140480903202624] Epoch[149] Batch[0] avg_epoch_loss=1.218116\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:05 INFO 140480903202624] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=1.218116045\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:11 INFO 140480903202624] Epoch[149] Batch[5] avg_epoch_loss=1.134669\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=1.13466911515\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:11 INFO 140480903202624] Epoch[149] Batch [5]#011Speed: 56.27 samples/sec#011loss=1.134669\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:16 INFO 140480903202624] Epoch[149] Batch[10] avg_epoch_loss=1.027631\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=0.89918448925\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:16 INFO 140480903202624] Epoch[149] Batch [10]#011Speed: 56.79 samples/sec#011loss=0.899184\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:16 INFO 140480903202624] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13433.374881744385, \"sum\": 13433.374881744385, \"min\": 13433.374881744385}}, \"EndTime\": 1587308056.667892, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308043.234102}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:16 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.354259471 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:16 INFO 140480903202624] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=149, train loss <loss>=1.02763064883\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:16 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:18 INFO 140480903202624] Epoch[150] Batch[0] avg_epoch_loss=1.003140\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=1.0031400919\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:24 INFO 140480903202624] Epoch[150] Batch[5] avg_epoch_loss=0.958585\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:24 INFO 140480903202624] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=0.95858541131\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:24 INFO 140480903202624] Epoch[150] Batch [5]#011Speed: 56.21 samples/sec#011loss=0.958585\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:30 INFO 140480903202624] Epoch[150] Batch[10] avg_epoch_loss=0.944741\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:30 INFO 140480903202624] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=0.928127652407\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:30 INFO 140480903202624] Epoch[150] Batch [10]#011Speed: 56.85 samples/sec#011loss=0.928128\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:30 INFO 140480903202624] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13407.885074615479, \"sum\": 13407.885074615479, \"min\": 13407.885074615479}}, \"EndTime\": 1587308070.076399, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308056.667972}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:30 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.1191891771 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:30 INFO 140480903202624] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:30 INFO 140480903202624] #quality_metric: host=algo-1, epoch=150, train loss <loss>=0.944740975445\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:30 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:32 INFO 140480903202624] Epoch[151] Batch[0] avg_epoch_loss=0.755850\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:32 INFO 140480903202624] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=0.755850493908\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:37 INFO 140480903202624] Epoch[151] Batch[5] avg_epoch_loss=0.957250\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:37 INFO 140480903202624] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=0.957249641418\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:37 INFO 140480903202624] Epoch[151] Batch [5]#011Speed: 56.90 samples/sec#011loss=0.957250\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:43 INFO 140480903202624] Epoch[151] Batch[10] avg_epoch_loss=0.844111\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:43 INFO 140480903202624] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=0.708343547583\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:43 INFO 140480903202624] Epoch[151] Batch [10]#011Speed: 56.91 samples/sec#011loss=0.708344\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:43 INFO 140480903202624] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13408.663034439087, \"sum\": 13408.663034439087, \"min\": 13408.663034439087}}, \"EndTime\": 1587308083.485562, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308070.076481}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:43 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.9231905122 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:43 INFO 140480903202624] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:43 INFO 140480903202624] #quality_metric: host=algo-1, epoch=151, train loss <loss>=0.844110507857\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:43 INFO 140480903202624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:43 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/state_b2e9453a-9bab-4681-9f0a-843db4d9186a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.27009582519531, \"sum\": 109.27009582519531, \"min\": 109.27009582519531}}, \"EndTime\": 1587308083.595639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308083.485636}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:45 INFO 140480903202624] Epoch[152] Batch[0] avg_epoch_loss=0.961470\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:45 INFO 140480903202624] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=0.961469590664\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:51 INFO 140480903202624] Epoch[152] Batch[5] avg_epoch_loss=1.035516\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=1.03551627199\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:51 INFO 140480903202624] Epoch[152] Batch [5]#011Speed: 56.83 samples/sec#011loss=1.035516\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:55 INFO 140480903202624] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12182.564973831177, \"sum\": 12182.564973831177, \"min\": 12182.564973831177}}, \"EndTime\": 1587308095.778337, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308083.595709}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:55 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.49649003 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:55 INFO 140480903202624] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:55 INFO 140480903202624] #quality_metric: host=algo-1, epoch=152, train loss <loss>=0.998387897015\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:55 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:57 INFO 140480903202624] Epoch[153] Batch[0] avg_epoch_loss=0.947627\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:54:57 INFO 140480903202624] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=0.947626650333\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:03 INFO 140480903202624] Epoch[153] Batch[5] avg_epoch_loss=0.926058\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:03 INFO 140480903202624] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=0.926058044036\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:03 INFO 140480903202624] Epoch[153] Batch [5]#011Speed: 56.41 samples/sec#011loss=0.926058\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:09 INFO 140480903202624] Epoch[153] Batch[10] avg_epoch_loss=0.906334\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:09 INFO 140480903202624] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=0.882664597034\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:09 INFO 140480903202624] Epoch[153] Batch [10]#011Speed: 56.99 samples/sec#011loss=0.882665\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:10 INFO 140480903202624] processed a total of 708 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14568.173885345459, \"sum\": 14568.173885345459, \"min\": 14568.173885345459}}, \"EndTime\": 1587308110.347136, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308095.778411}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:10 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.5986068529 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:10 INFO 140480903202624] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:10 INFO 140480903202624] #quality_metric: host=algo-1, epoch=153, train loss <loss>=0.868302536507\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:10 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:12 INFO 140480903202624] Epoch[154] Batch[0] avg_epoch_loss=1.011789\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:12 INFO 140480903202624] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=1.01178860664\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:18 INFO 140480903202624] Epoch[154] Batch[5] avg_epoch_loss=1.093813\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=1.09381298224\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:18 INFO 140480903202624] Epoch[154] Batch [5]#011Speed: 57.03 samples/sec#011loss=1.093813\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:23 INFO 140480903202624] Epoch[154] Batch[10] avg_epoch_loss=1.003078\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:23 INFO 140480903202624] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=0.894194972515\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:23 INFO 140480903202624] Epoch[154] Batch [10]#011Speed: 56.78 samples/sec#011loss=0.894195\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:23 INFO 140480903202624] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13374.11093711853, \"sum\": 13374.11093711853, \"min\": 13374.11093711853}}, \"EndTime\": 1587308123.721871, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308110.347214}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:23 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.3018353008 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:23 INFO 140480903202624] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:23 INFO 140480903202624] #quality_metric: host=algo-1, epoch=154, train loss <loss>=1.00307752327\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:23 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:25 INFO 140480903202624] Epoch[155] Batch[0] avg_epoch_loss=0.860207\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:25 INFO 140480903202624] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=0.860206604004\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:31 INFO 140480903202624] Epoch[155] Batch[5] avg_epoch_loss=0.862130\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:31 INFO 140480903202624] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=0.862130264441\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:31 INFO 140480903202624] Epoch[155] Batch [5]#011Speed: 56.50 samples/sec#011loss=0.862130\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:37 INFO 140480903202624] Epoch[155] Batch[10] avg_epoch_loss=0.974012\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:37 INFO 140480903202624] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=1.10826901197\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:37 INFO 140480903202624] Epoch[155] Batch [10]#011Speed: 56.60 samples/sec#011loss=1.108269\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:37 INFO 140480903202624] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13428.008079528809, \"sum\": 13428.008079528809, \"min\": 13428.008079528809}}, \"EndTime\": 1587308137.150417, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308123.721954}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:37 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.9697307196 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:37 INFO 140480903202624] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:37 INFO 140480903202624] #quality_metric: host=algo-1, epoch=155, train loss <loss>=0.97401151332\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:37 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:39 INFO 140480903202624] Epoch[156] Batch[0] avg_epoch_loss=1.370897\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:39 INFO 140480903202624] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=1.37089729309\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:44 INFO 140480903202624] Epoch[156] Batch[5] avg_epoch_loss=1.104687\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:44 INFO 140480903202624] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=1.10468663772\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:44 INFO 140480903202624] Epoch[156] Batch [5]#011Speed: 56.74 samples/sec#011loss=1.104687\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:50 INFO 140480903202624] Epoch[156] Batch[10] avg_epoch_loss=1.059770\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:50 INFO 140480903202624] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=1.00587084293\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:50 INFO 140480903202624] Epoch[156] Batch [10]#011Speed: 53.14 samples/sec#011loss=1.005871\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:52 INFO 140480903202624] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14966.39609336853, \"sum\": 14966.39609336853, \"min\": 14966.39609336853}}, \"EndTime\": 1587308152.117353, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308137.150504}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:52 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=47.3724589962 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:52 INFO 140480903202624] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:52 INFO 140480903202624] #quality_metric: host=algo-1, epoch=156, train loss <loss>=1.10162205497\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:52 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:54 INFO 140480903202624] Epoch[157] Batch[0] avg_epoch_loss=1.154725\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:54 INFO 140480903202624] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=1.15472483635\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:59 INFO 140480903202624] Epoch[157] Batch[5] avg_epoch_loss=1.033540\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:59 INFO 140480903202624] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=1.03353987137\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:55:59 INFO 140480903202624] Epoch[157] Batch [5]#011Speed: 56.94 samples/sec#011loss=1.033540\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:05 INFO 140480903202624] Epoch[157] Batch[10] avg_epoch_loss=1.018592\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:05 INFO 140480903202624] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=1.00065492392\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:05 INFO 140480903202624] Epoch[157] Batch [10]#011Speed: 56.42 samples/sec#011loss=1.000655\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:05 INFO 140480903202624] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13389.350891113281, \"sum\": 13389.350891113281, \"min\": 13389.350891113281}}, \"EndTime\": 1587308165.507277, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308152.117424}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:05 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.2177918623 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:05 INFO 140480903202624] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:05 INFO 140480903202624] #quality_metric: host=algo-1, epoch=157, train loss <loss>=1.01859216798\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:05 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:07 INFO 140480903202624] Epoch[158] Batch[0] avg_epoch_loss=1.855165\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:07 INFO 140480903202624] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=1.85516452789\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:13 INFO 140480903202624] Epoch[158] Batch[5] avg_epoch_loss=1.768641\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:13 INFO 140480903202624] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=1.76864129305\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:13 INFO 140480903202624] Epoch[158] Batch [5]#011Speed: 56.77 samples/sec#011loss=1.768641\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:18 INFO 140480903202624] Epoch[158] Batch[10] avg_epoch_loss=1.640829\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=1.48745384216\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:18 INFO 140480903202624] Epoch[158] Batch [10]#011Speed: 56.93 samples/sec#011loss=1.487454\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:18 INFO 140480903202624] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13350.750923156738, \"sum\": 13350.750923156738, \"min\": 13350.750923156738}}, \"EndTime\": 1587308178.858641, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308165.507356}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:18 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.3115122279 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:18 INFO 140480903202624] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=158, train loss <loss>=1.64082881537\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:18 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:20 INFO 140480903202624] Epoch[159] Batch[0] avg_epoch_loss=1.617541\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:20 INFO 140480903202624] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=1.61754095554\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:26 INFO 140480903202624] Epoch[159] Batch[5] avg_epoch_loss=1.421328\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:26 INFO 140480903202624] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=1.42132761081\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:26 INFO 140480903202624] Epoch[159] Batch [5]#011Speed: 56.25 samples/sec#011loss=1.421328\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:32 INFO 140480903202624] Epoch[159] Batch[10] avg_epoch_loss=1.283317\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:32 INFO 140480903202624] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=1.11770533323\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:32 INFO 140480903202624] Epoch[159] Batch [10]#011Speed: 57.29 samples/sec#011loss=1.117705\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:32 INFO 140480903202624] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13360.677003860474, \"sum\": 13360.677003860474, \"min\": 13360.677003860474}}, \"EndTime\": 1587308192.219771, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308178.85871}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:32 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.6228212508 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:32 INFO 140480903202624] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:32 INFO 140480903202624] #quality_metric: host=algo-1, epoch=159, train loss <loss>=1.28331748464\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:32 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:34 INFO 140480903202624] Epoch[160] Batch[0] avg_epoch_loss=1.031707\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:34 INFO 140480903202624] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=1.03170704842\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:39 INFO 140480903202624] Epoch[160] Batch[5] avg_epoch_loss=0.969099\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:39 INFO 140480903202624] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=0.96909853816\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:39 INFO 140480903202624] Epoch[160] Batch [5]#011Speed: 57.06 samples/sec#011loss=0.969099\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:44 INFO 140480903202624] processed a total of 591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12100.67105293274, \"sum\": 12100.67105293274, \"min\": 12100.67105293274}}, \"EndTime\": 1587308204.320956, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308192.219849}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:44 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.8398585681 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:44 INFO 140480903202624] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:44 INFO 140480903202624] #quality_metric: host=algo-1, epoch=160, train loss <loss>=1.00199333429\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:44 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:46 INFO 140480903202624] Epoch[161] Batch[0] avg_epoch_loss=1.207404\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:46 INFO 140480903202624] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=1.20740401745\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:51 INFO 140480903202624] Epoch[161] Batch[5] avg_epoch_loss=1.035242\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:51 INFO 140480903202624] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=1.03524215023\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:51 INFO 140480903202624] Epoch[161] Batch [5]#011Speed: 57.21 samples/sec#011loss=1.035242\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:57 INFO 140480903202624] Epoch[161] Batch[10] avg_epoch_loss=1.000148\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:57 INFO 140480903202624] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=0.958035492897\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:57 INFO 140480903202624] Epoch[161] Batch [10]#011Speed: 56.48 samples/sec#011loss=0.958035\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:57 INFO 140480903202624] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13308.386087417603, \"sum\": 13308.386087417603, \"min\": 13308.386087417603}}, \"EndTime\": 1587308217.629951, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308204.321021}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:57 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.7194157415 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:57 INFO 140480903202624] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:57 INFO 140480903202624] #quality_metric: host=algo-1, epoch=161, train loss <loss>=1.00014821508\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:57 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:59 INFO 140480903202624] Epoch[162] Batch[0] avg_epoch_loss=0.941982\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:56:59 INFO 140480903202624] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=0.941981732845\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:05 INFO 140480903202624] Epoch[162] Batch[5] avg_epoch_loss=0.958647\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:05 INFO 140480903202624] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=0.958647429943\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:05 INFO 140480903202624] Epoch[162] Batch [5]#011Speed: 57.18 samples/sec#011loss=0.958647\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:09 INFO 140480903202624] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12136.950016021729, \"sum\": 12136.950016021729, \"min\": 12136.950016021729}}, \"EndTime\": 1587308229.767506, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308217.630038}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:09 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.412809958 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:09 INFO 140480903202624] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:09 INFO 140480903202624] #quality_metric: host=algo-1, epoch=162, train loss <loss>=0.906151920557\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:09 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:11 INFO 140480903202624] Epoch[163] Batch[0] avg_epoch_loss=0.957319\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:11 INFO 140480903202624] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=0.957318723202\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:17 INFO 140480903202624] Epoch[163] Batch[5] avg_epoch_loss=1.024963\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:17 INFO 140480903202624] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=1.02496330937\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:17 INFO 140480903202624] Epoch[163] Batch [5]#011Speed: 57.01 samples/sec#011loss=1.024963\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:23 INFO 140480903202624] Epoch[163] Batch[10] avg_epoch_loss=0.929961\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:23 INFO 140480903202624] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=0.815959250927\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:23 INFO 140480903202624] Epoch[163] Batch [10]#011Speed: 57.11 samples/sec#011loss=0.815959\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:23 INFO 140480903202624] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13288.614988327026, \"sum\": 13288.614988327026, \"min\": 13288.614988327026}}, \"EndTime\": 1587308243.056665, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308229.767571}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:23 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.3969082981 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:23 INFO 140480903202624] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:23 INFO 140480903202624] #quality_metric: host=algo-1, epoch=163, train loss <loss>=0.929961464622\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:23 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:25 INFO 140480903202624] Epoch[164] Batch[0] avg_epoch_loss=1.454183\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:25 INFO 140480903202624] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=1.45418286324\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:30 INFO 140480903202624] Epoch[164] Batch[5] avg_epoch_loss=1.008303\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:30 INFO 140480903202624] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=1.00830297669\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:30 INFO 140480903202624] Epoch[164] Batch [5]#011Speed: 56.87 samples/sec#011loss=1.008303\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:36 INFO 140480903202624] Epoch[164] Batch[10] avg_epoch_loss=0.940752\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:36 INFO 140480903202624] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=0.859690022469\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:36 INFO 140480903202624] Epoch[164] Batch [10]#011Speed: 56.76 samples/sec#011loss=0.859690\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:36 INFO 140480903202624] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13387.283086776733, \"sum\": 13387.283086776733, \"min\": 13387.283086776733}}, \"EndTime\": 1587308256.444553, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308243.05675}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:36 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.2422277656 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:36 INFO 140480903202624] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:36 INFO 140480903202624] #quality_metric: host=algo-1, epoch=164, train loss <loss>=0.940751633861\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:36 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:38 INFO 140480903202624] Epoch[165] Batch[0] avg_epoch_loss=0.832167\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:38 INFO 140480903202624] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=0.832166850567\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:44 INFO 140480903202624] Epoch[165] Batch[5] avg_epoch_loss=0.856186\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:44 INFO 140480903202624] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=0.856186201175\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:44 INFO 140480903202624] Epoch[165] Batch [5]#011Speed: 56.80 samples/sec#011loss=0.856186\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:48 INFO 140480903202624] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12158.196926116943, \"sum\": 12158.196926116943, \"min\": 12158.196926116943}}, \"EndTime\": 1587308268.603234, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308256.444631}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:48 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.1838849647 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:48 INFO 140480903202624] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:48 INFO 140480903202624] #quality_metric: host=algo-1, epoch=165, train loss <loss>=0.946880686283\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:48 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:50 INFO 140480903202624] Epoch[166] Batch[0] avg_epoch_loss=1.846248\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:50 INFO 140480903202624] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=1.84624814987\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:56 INFO 140480903202624] Epoch[166] Batch[5] avg_epoch_loss=1.536423\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:56 INFO 140480903202624] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=1.53642308712\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:57:56 INFO 140480903202624] Epoch[166] Batch [5]#011Speed: 56.50 samples/sec#011loss=1.536423\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:00 INFO 140480903202624] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12266.615152359009, \"sum\": 12266.615152359009, \"min\": 12266.615152359009}}, \"EndTime\": 1587308280.870533, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308268.603454}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:00 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=51.0323320274 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:00 INFO 140480903202624] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:00 INFO 140480903202624] #quality_metric: host=algo-1, epoch=166, train loss <loss>=1.43000435829\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:00 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:02 INFO 140480903202624] Epoch[167] Batch[0] avg_epoch_loss=1.303868\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:02 INFO 140480903202624] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=1.30386805534\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:08 INFO 140480903202624] Epoch[167] Batch[5] avg_epoch_loss=1.213024\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:08 INFO 140480903202624] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=1.2130240798\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:08 INFO 140480903202624] Epoch[167] Batch [5]#011Speed: 56.60 samples/sec#011loss=1.213024\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:14 INFO 140480903202624] Epoch[167] Batch[10] avg_epoch_loss=1.067373\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:14 INFO 140480903202624] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=0.892591124773\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:14 INFO 140480903202624] Epoch[167] Batch [10]#011Speed: 56.66 samples/sec#011loss=0.892591\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:14 INFO 140480903202624] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13410.210132598877, \"sum\": 13410.210132598877, \"min\": 13410.210132598877}}, \"EndTime\": 1587308294.281247, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308280.870613}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:14 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.9921080196 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:14 INFO 140480903202624] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:14 INFO 140480903202624] #quality_metric: host=algo-1, epoch=167, train loss <loss>=1.06737273661\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:14 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:16 INFO 140480903202624] Epoch[168] Batch[0] avg_epoch_loss=0.841322\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:16 INFO 140480903202624] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=0.8413220644\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:21 INFO 140480903202624] Epoch[168] Batch[5] avg_epoch_loss=0.812332\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:21 INFO 140480903202624] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=0.812332312266\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:21 INFO 140480903202624] Epoch[168] Batch [5]#011Speed: 56.72 samples/sec#011loss=0.812332\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:27 INFO 140480903202624] Epoch[168] Batch[10] avg_epoch_loss=0.974363\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:27 INFO 140480903202624] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=1.16879893541\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:27 INFO 140480903202624] Epoch[168] Batch [10]#011Speed: 56.75 samples/sec#011loss=1.168799\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:27 INFO 140480903202624] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13348.805904388428, \"sum\": 13348.805904388428, \"min\": 13348.805904388428}}, \"EndTime\": 1587308307.630644, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308294.281325}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:27 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.3934285594 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:27 INFO 140480903202624] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:27 INFO 140480903202624] #quality_metric: host=algo-1, epoch=168, train loss <loss>=0.974362595515\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:27 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:29 INFO 140480903202624] Epoch[169] Batch[0] avg_epoch_loss=0.809690\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:29 INFO 140480903202624] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=0.809690415859\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:35 INFO 140480903202624] Epoch[169] Batch[5] avg_epoch_loss=0.871033\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:35 INFO 140480903202624] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=0.871032784383\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:35 INFO 140480903202624] Epoch[169] Batch [5]#011Speed: 56.76 samples/sec#011loss=0.871033\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:41 INFO 140480903202624] Epoch[169] Batch[10] avg_epoch_loss=0.870939\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:41 INFO 140480903202624] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=0.87082631588\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:41 INFO 140480903202624] Epoch[169] Batch [10]#011Speed: 56.94 samples/sec#011loss=0.870826\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:41 INFO 140480903202624] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13376.475095748901, \"sum\": 13376.475095748901, \"min\": 13376.475095748901}}, \"EndTime\": 1587308321.007702, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308307.630724}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:41 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.068907994 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:41 INFO 140480903202624] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:41 INFO 140480903202624] #quality_metric: host=algo-1, epoch=169, train loss <loss>=0.870938935063\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:41 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:43 INFO 140480903202624] Epoch[170] Batch[0] avg_epoch_loss=1.135513\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:43 INFO 140480903202624] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=1.13551282883\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:48 INFO 140480903202624] Epoch[170] Batch[5] avg_epoch_loss=1.297814\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:48 INFO 140480903202624] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=1.29781353474\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:48 INFO 140480903202624] Epoch[170] Batch [5]#011Speed: 56.37 samples/sec#011loss=1.297814\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:53 INFO 140480903202624] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12267.972946166992, \"sum\": 12267.972946166992, \"min\": 12267.972946166992}}, \"EndTime\": 1587308333.27625, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308321.007821}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:53 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.8637216544 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:53 INFO 140480903202624] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=170, train loss <loss>=1.22324631214\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:53 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:55 INFO 140480903202624] Epoch[171] Batch[0] avg_epoch_loss=1.295645\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:58:55 INFO 140480903202624] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=1.29564511776\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:01 INFO 140480903202624] Epoch[171] Batch[5] avg_epoch_loss=1.044578\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:01 INFO 140480903202624] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=1.04457763831\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:01 INFO 140480903202624] Epoch[171] Batch [5]#011Speed: 56.73 samples/sec#011loss=1.044578\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:06 INFO 140480903202624] Epoch[171] Batch[10] avg_epoch_loss=0.941701\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:06 INFO 140480903202624] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=0.818249225616\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:06 INFO 140480903202624] Epoch[171] Batch [10]#011Speed: 56.85 samples/sec#011loss=0.818249\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:06 INFO 140480903202624] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13401.694059371948, \"sum\": 13401.694059371948, \"min\": 13401.694059371948}}, \"EndTime\": 1587308346.678609, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308333.276321}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:06 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.6200001957 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:06 INFO 140480903202624] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:06 INFO 140480903202624] #quality_metric: host=algo-1, epoch=171, train loss <loss>=0.941701087085\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:06 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:08 INFO 140480903202624] Epoch[172] Batch[0] avg_epoch_loss=0.959465\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:08 INFO 140480903202624] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=0.959465324879\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:14 INFO 140480903202624] Epoch[172] Batch[5] avg_epoch_loss=0.926924\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:14 INFO 140480903202624] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=0.926923940579\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:14 INFO 140480903202624] Epoch[172] Batch [5]#011Speed: 56.83 samples/sec#011loss=0.926924\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:18 INFO 140480903202624] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 12187.482833862305, \"sum\": 12187.482833862305, \"min\": 12187.482833862305}}, \"EndTime\": 1587308358.866737, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308346.678729}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:18 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=52.184063103 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:18 INFO 140480903202624] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:18 INFO 140480903202624] #quality_metric: host=algo-1, epoch=172, train loss <loss>=0.906041538715\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:18 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:20 INFO 140480903202624] Epoch[173] Batch[0] avg_epoch_loss=1.676678\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:20 INFO 140480903202624] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=1.67667818069\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:26 INFO 140480903202624] Epoch[173] Batch[5] avg_epoch_loss=0.870834\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:26 INFO 140480903202624] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=0.870834420125\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:26 INFO 140480903202624] Epoch[173] Batch [5]#011Speed: 56.58 samples/sec#011loss=0.870834\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:32 INFO 140480903202624] Epoch[173] Batch[10] avg_epoch_loss=0.845535\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:32 INFO 140480903202624] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=0.815176528692\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:32 INFO 140480903202624] Epoch[173] Batch [10]#011Speed: 56.48 samples/sec#011loss=0.815177\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:32 INFO 140480903202624] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13441.265106201172, \"sum\": 13441.265106201172, \"min\": 13441.265106201172}}, \"EndTime\": 1587308372.308693, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308358.866844}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:32 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.0605089228 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:32 INFO 140480903202624] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:32 INFO 140480903202624] #quality_metric: host=algo-1, epoch=173, train loss <loss>=0.845535378564\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:32 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:34 INFO 140480903202624] Epoch[174] Batch[0] avg_epoch_loss=1.313650\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:34 INFO 140480903202624] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=1.31364953518\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:40 INFO 140480903202624] Epoch[174] Batch[5] avg_epoch_loss=1.195519\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:40 INFO 140480903202624] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=1.19551934799\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:40 INFO 140480903202624] Epoch[174] Batch [5]#011Speed: 56.70 samples/sec#011loss=1.195519\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:45 INFO 140480903202624] Epoch[174] Batch[10] avg_epoch_loss=1.080429\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:45 INFO 140480903202624] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=0.94231967926\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:45 INFO 140480903202624] Epoch[174] Batch [10]#011Speed: 57.03 samples/sec#011loss=0.942320\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:45 INFO 140480903202624] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13329.162120819092, \"sum\": 13329.162120819092, \"min\": 13329.162120819092}}, \"EndTime\": 1587308385.63849, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308372.308777}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:45 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=49.1399424273 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:45 INFO 140480903202624] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:45 INFO 140480903202624] #quality_metric: host=algo-1, epoch=174, train loss <loss>=1.08042858947\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:45 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:47 INFO 140480903202624] Epoch[175] Batch[0] avg_epoch_loss=1.176170\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:47 INFO 140480903202624] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=1.17616975307\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:53 INFO 140480903202624] Epoch[175] Batch[5] avg_epoch_loss=0.998117\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:53 INFO 140480903202624] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=0.998116523027\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:53 INFO 140480903202624] Epoch[175] Batch [5]#011Speed: 56.74 samples/sec#011loss=0.998117\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:58 INFO 140480903202624] Epoch[175] Batch[10] avg_epoch_loss=1.001485\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=1.00552741289\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:58 INFO 140480903202624] Epoch[175] Batch [10]#011Speed: 56.71 samples/sec#011loss=1.005527\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:58 INFO 140480903202624] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13325.54292678833, \"sum\": 13325.54292678833, \"min\": 13325.54292678833}}, \"EndTime\": 1587308398.964663, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308385.638567}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:58 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=48.402880993 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:58 INFO 140480903202624] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:58 INFO 140480903202624] #quality_metric: host=algo-1, epoch=175, train loss <loss>=1.00148510933\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:59:58 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:01 INFO 140480903202624] Epoch[176] Batch[0] avg_epoch_loss=1.461030\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:01 INFO 140480903202624] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=1.46103048325\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:06 INFO 140480903202624] Epoch[176] Batch[5] avg_epoch_loss=1.415970\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:06 INFO 140480903202624] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=1.41597020626\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:06 INFO 140480903202624] Epoch[176] Batch [5]#011Speed: 56.37 samples/sec#011loss=1.415970\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] Epoch[176] Batch[10] avg_epoch_loss=1.338292\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=1.24507713318\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] Epoch[176] Batch [10]#011Speed: 56.45 samples/sec#011loss=1.245077\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 13424.937963485718, \"sum\": 13424.937963485718, \"min\": 13424.937963485718}}, \"EndTime\": 1587308412.390175, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308398.964733}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] #throughput_metric: host=algo-1, train throughput=50.5770891537 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] #quality_metric: host=algo-1, epoch=176, train loss <loss>=1.33829153668\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] Loading parameters from best epoch (151)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 42.060136795043945, \"sum\": 42.060136795043945, \"min\": 42.060136795043945}}, \"EndTime\": 1587308412.432899, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308412.39025}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] stopping training now\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] Final loss: 0.844110507857 (occurred at epoch 151)\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] #quality_metric: host=algo-1, train final_loss <loss>=0.844110507857\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 WARNING 140480903202624] You are using large values for `context_length` and/or `prediction_length`. The following step may take some time. If the step crashes, use an instance with more memory or reduce these two parameters.\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 WARNING 140480903202624] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:12 INFO 140480903202624] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 1064.7518634796143, \"sum\": 1064.7518634796143, \"min\": 1064.7518634796143}}, \"EndTime\": 1587308413.498676, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308412.432969}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:13 INFO 140480903202624] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 1545.2070236206055, \"sum\": 1545.2070236206055, \"min\": 1545.2070236206055}}, \"EndTime\": 1587308413.97909, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308413.498742}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:13 INFO 140480903202624] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:14 INFO 140480903202624] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 77.86202430725098, \"sum\": 77.86202430725098, \"min\": 77.86202430725098}}, \"EndTime\": 1587308414.057067, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308413.979159}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:14 INFO 140480903202624] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:00:14 INFO 140480903202624] No test data passed, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 2284084.7589969635, \"sum\": 2284084.7589969635, \"min\": 2284084.7589969635}, \"setuptime\": {\"count\": 1, \"max\": 8.892059326171875, \"sum\": 8.892059326171875, \"min\": 8.892059326171875}}, \"EndTime\": 1587308414.154971, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587308414.057123}\n",
      "\u001b[0m\n",
      "\n",
      "2020-04-19 15:00:36 Uploading - Uploading generated training model\n",
      "2020-04-19 15:00:36 Completed - Training job completed\n",
      "Training seconds: 2341\n",
      "Billable seconds: 698\n",
      "Managed Spot Training savings: 70.2%\n",
      "2020-04-19 14:38:45 Starting - Preparing the instances for training\n",
      "2020-04-19 14:38:45 Downloading - Downloading input data\n",
      "2020-04-19 14:38:45 Training - Training image download completed. Training in progress.\n",
      "2020-04-19 14:38:45 Uploading - Uploading generated training model\n",
      "2020-04-19 14:38:45 Completed - Training job completed\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.01', u'mini_batch_size': u'64', u'learning_rate': u'0.005', u'num_cells': u'64', u'prediction_length': u'156', u'epochs': u'500', u'time_freq': u'W', u'context_length': u'32', u'num_layers': u'2', u'cardinality': u'auto', u'early_stopping_patience': u'25'}\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] Final configuration: {u'dropout_rate': u'0.01', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'0.005', u'num_layers': u'2', u'epochs': u'500', u'embedding_dimension': u'10', u'num_cells': u'64', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'156', u'time_freq': u'W', u'context_length': u'32', u'_kvstore': u'auto', u'early_stopping_patience': u'25'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] Using early stopping with patience 25\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/submission_train_pp_iq.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/submission_train_pp_iq.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] Training set statistics:\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] Integer time series\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] number of time series: 1\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] number of observations: 520\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] mean target length: 520\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] min/mean/max target: 0.0/7.56538461538/116.0\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] mean abs(target): 7.56538461538\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] contains missing values: no\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] Small number of time series. Doing 640 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] No test channel found not running evaluations\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] nvidia-smi took: 0.0251948833466 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:01 INFO 140144812640064] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 409.4560146331787, \"sum\": 409.4560146331787, \"min\": 409.4560146331787}}, \"EndTime\": 1587306122.162453, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306121.752123}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:02 INFO 140144812640064] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 1125.4189014434814, \"sum\": 1125.4189014434814, \"min\": 1125.4189014434814}}, \"EndTime\": 1587306122.877675, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306122.162531}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:04 INFO 140144812640064] Epoch[0] Batch[0] avg_epoch_loss=4.788274\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=4.78827428818\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:05 INFO 140144812640064] Epoch[0] Batch[5] avg_epoch_loss=3.976898\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.976897796\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:05 INFO 140144812640064] Epoch[0] Batch [5]#011Speed: 172.95 samples/sec#011loss=3.976898\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:07 INFO 140144812640064] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 500, \"sum\": 500.0, \"min\": 500}, \"update.time\": {\"count\": 1, \"max\": 4971.7700481414795, \"sum\": 4971.7700481414795, \"min\": 4971.7700481414795}}, \"EndTime\": 1587306127.84966, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306122.877785}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:07 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=127.315977532 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:07 INFO 140144812640064] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.73134770393\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:07 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:07 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_f98900ed-d387-4556-a022-23f111897c91-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 87.37707138061523, \"sum\": 87.37707138061523, \"min\": 87.37707138061523}}, \"EndTime\": 1587306127.93779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306127.849732}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:08 INFO 140144812640064] Epoch[1] Batch[0] avg_epoch_loss=3.096551\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:08 INFO 140144812640064] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.09655070305\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140144812640064] Epoch[1] Batch[5] avg_epoch_loss=3.049154\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.04915380478\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:10 INFO 140144812640064] Epoch[1] Batch [5]#011Speed: 171.42 samples/sec#011loss=3.049154\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:12 INFO 140144812640064] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4309.71097946167, \"sum\": 4309.71097946167, \"min\": 4309.71097946167}}, \"EndTime\": 1587306132.247949, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306127.938045}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:12 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=140.607940312 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:12 INFO 140144812640064] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=1, train loss <loss>=2.99725177288\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:12 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:12 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_c6a028e1-955c-4ead-8d79-4c511262ca81-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 83.12678337097168, \"sum\": 83.12678337097168, \"min\": 83.12678337097168}}, \"EndTime\": 1587306132.331688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306132.248052}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:13 INFO 140144812640064] Epoch[2] Batch[0] avg_epoch_loss=2.894375\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:13 INFO 140144812640064] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=2.89437460899\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:15 INFO 140144812640064] Epoch[2] Batch[5] avg_epoch_loss=2.814029\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:15 INFO 140144812640064] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=2.81402917703\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:15 INFO 140144812640064] Epoch[2] Batch [5]#011Speed: 169.52 samples/sec#011loss=2.814029\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:16 INFO 140144812640064] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4334.0208530426025, \"sum\": 4334.0208530426025, \"min\": 4334.0208530426025}}, \"EndTime\": 1587306136.665869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306132.331756}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:16 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.664746919 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:16 INFO 140144812640064] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:16 INFO 140144812640064] #quality_metric: host=algo-1, epoch=2, train loss <loss>=2.78325746059\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:16 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:16 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_90a38019-b1c4-4d98-b6ec-14baa504152f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 67.04306602478027, \"sum\": 67.04306602478027, \"min\": 67.04306602478027}}, \"EndTime\": 1587306136.73347, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306136.665943}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:17 INFO 140144812640064] Epoch[3] Batch[0] avg_epoch_loss=2.661233\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=2.66123342514\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:19 INFO 140144812640064] Epoch[3] Batch[5] avg_epoch_loss=2.693848\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=2.69384841124\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:19 INFO 140144812640064] Epoch[3] Batch [5]#011Speed: 165.74 samples/sec#011loss=2.693848\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:21 INFO 140144812640064] Epoch[3] Batch[10] avg_epoch_loss=2.680311\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=2.66406593323\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:21 INFO 140144812640064] Epoch[3] Batch [10]#011Speed: 175.10 samples/sec#011loss=2.664066\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:21 INFO 140144812640064] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4751.929998397827, \"sum\": 4751.929998397827, \"min\": 4751.929998397827}}, \"EndTime\": 1587306141.485593, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306136.733547}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:21 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.939691534 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:21 INFO 140144812640064] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=3, train loss <loss>=2.68031092124\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:21 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:21 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_de838315-c545-490c-9ace-4ae81d4a16f6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 74.55301284790039, \"sum\": 74.55301284790039, \"min\": 74.55301284790039}}, \"EndTime\": 1587306141.560873, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306141.485671}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:22 INFO 140144812640064] Epoch[4] Batch[0] avg_epoch_loss=2.552414\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:22 INFO 140144812640064] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=2.55241394043\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:24 INFO 140144812640064] Epoch[4] Batch[5] avg_epoch_loss=2.565775\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:24 INFO 140144812640064] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=2.56577519576\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:24 INFO 140144812640064] Epoch[4] Batch [5]#011Speed: 175.21 samples/sec#011loss=2.565775\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:25 INFO 140144812640064] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4246.981143951416, \"sum\": 4246.981143951416, \"min\": 4246.981143951416}}, \"EndTime\": 1587306145.807989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306141.560952}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:25 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.450842311 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:25 INFO 140144812640064] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=4, train loss <loss>=2.54187557697\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:25 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:25 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_49fddf39-d177-4cbe-9c31-40690e958228-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.82503700256348, \"sum\": 61.82503700256348, \"min\": 61.82503700256348}}, \"EndTime\": 1587306145.870446, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306145.808057}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:26 INFO 140144812640064] Epoch[5] Batch[0] avg_epoch_loss=2.567456\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=2.56745553017\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:28 INFO 140144812640064] Epoch[5] Batch[5] avg_epoch_loss=2.489326\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=2.48932560285\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:28 INFO 140144812640064] Epoch[5] Batch [5]#011Speed: 174.04 samples/sec#011loss=2.489326\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:30 INFO 140144812640064] Epoch[5] Batch[10] avg_epoch_loss=2.494340\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=2.5003575325\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:30 INFO 140144812640064] Epoch[5] Batch [10]#011Speed: 172.57 samples/sec#011loss=2.500358\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:30 INFO 140144812640064] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4674.178123474121, \"sum\": 4674.178123474121, \"min\": 4674.178123474121}}, \"EndTime\": 1587306150.544749, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306145.870516}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:30 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.9144773 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:30 INFO 140144812640064] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=5, train loss <loss>=2.49434011633\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:30 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:30 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_aadb0735-b7d9-410e-bb43-a8e97b937f69-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 63.13490867614746, \"sum\": 63.13490867614746, \"min\": 63.13490867614746}}, \"EndTime\": 1587306150.608765, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306150.544822}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:31 INFO 140144812640064] Epoch[6] Batch[0] avg_epoch_loss=2.822397\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:31 INFO 140144812640064] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=2.82239723206\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:33 INFO 140144812640064] Epoch[6] Batch[5] avg_epoch_loss=2.602527\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:33 INFO 140144812640064] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=2.60252682368\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:33 INFO 140144812640064] Epoch[6] Batch [5]#011Speed: 176.36 samples/sec#011loss=2.602527\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:35 INFO 140144812640064] Epoch[6] Batch[10] avg_epoch_loss=2.531285\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:35 INFO 140144812640064] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=2.44579515457\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:35 INFO 140144812640064] Epoch[6] Batch [10]#011Speed: 169.50 samples/sec#011loss=2.445795\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:35 INFO 140144812640064] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4671.683073043823, \"sum\": 4671.683073043823, \"min\": 4671.683073043823}}, \"EndTime\": 1587306155.280593, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306150.608835}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:35 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.697483483 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:35 INFO 140144812640064] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:35 INFO 140144812640064] #quality_metric: host=algo-1, epoch=6, train loss <loss>=2.5312851559\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:35 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:36 INFO 140144812640064] Epoch[7] Batch[0] avg_epoch_loss=2.483432\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:36 INFO 140144812640064] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=2.48343229294\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:38 INFO 140144812640064] Epoch[7] Batch[5] avg_epoch_loss=2.413559\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:38 INFO 140144812640064] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=2.41355876128\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:38 INFO 140144812640064] Epoch[7] Batch [5]#011Speed: 173.34 samples/sec#011loss=2.413559\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:39 INFO 140144812640064] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4286.45396232605, \"sum\": 4286.45396232605, \"min\": 4286.45396232605}}, \"EndTime\": 1587306159.567947, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306155.28067}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:39 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.736655586 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:39 INFO 140144812640064] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=7, train loss <loss>=2.39215476513\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:39 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:39 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_715f3b2e-de3b-4fa4-a12b-bb2ea9bd52a1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 65.24801254272461, \"sum\": 65.24801254272461, \"min\": 65.24801254272461}}, \"EndTime\": 1587306159.63377, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306159.568028}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:40 INFO 140144812640064] Epoch[8] Batch[0] avg_epoch_loss=2.309145\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=2.30914545059\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:42 INFO 140144812640064] Epoch[8] Batch[5] avg_epoch_loss=2.285545\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=2.28554507097\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:42 INFO 140144812640064] Epoch[8] Batch [5]#011Speed: 176.16 samples/sec#011loss=2.285545\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:43 INFO 140144812640064] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4216.686010360718, \"sum\": 4216.686010360718, \"min\": 4216.686010360718}}, \"EndTime\": 1587306163.85083, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306159.633841}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:43 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=145.835783343 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:43 INFO 140144812640064] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=8, train loss <loss>=2.279408741\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:43 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:43 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_9162c698-a966-482e-bdb0-2cafe2dc1525-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 63.58599662780762, \"sum\": 63.58599662780762, \"min\": 63.58599662780762}}, \"EndTime\": 1587306163.915044, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306163.850933}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:44 INFO 140144812640064] Epoch[9] Batch[0] avg_epoch_loss=2.281406\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:44 INFO 140144812640064] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=2.28140616417\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:46 INFO 140144812640064] Epoch[9] Batch[5] avg_epoch_loss=2.186279\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=2.18627854188\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:46 INFO 140144812640064] Epoch[9] Batch [5]#011Speed: 172.06 samples/sec#011loss=2.186279\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:48 INFO 140144812640064] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4256.637096405029, \"sum\": 4256.637096405029, \"min\": 4256.637096405029}}, \"EndTime\": 1587306168.171819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306163.915114}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:48 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.831969165 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:48 INFO 140144812640064] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=9, train loss <loss>=2.16685957909\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:48 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:48 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_9a9cfa18-9c1c-400b-bd13-bae8e2504e53-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 68.09496879577637, \"sum\": 68.09496879577637, \"min\": 68.09496879577637}}, \"EndTime\": 1587306168.24047, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306168.171893}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:49 INFO 140144812640064] Epoch[10] Batch[0] avg_epoch_loss=2.237005\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:49 INFO 140144812640064] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=2.23700547218\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:51 INFO 140144812640064] Epoch[10] Batch[5] avg_epoch_loss=2.326460\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:51 INFO 140144812640064] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=2.32646036148\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:51 INFO 140144812640064] Epoch[10] Batch [5]#011Speed: 175.14 samples/sec#011loss=2.326460\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:52 INFO 140144812640064] Epoch[10] Batch[10] avg_epoch_loss=2.331274\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:52 INFO 140144812640064] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=2.33704977036\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:52 INFO 140144812640064] Epoch[10] Batch [10]#011Speed: 177.82 samples/sec#011loss=2.337050\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:52 INFO 140144812640064] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4573.076009750366, \"sum\": 4573.076009750366, \"min\": 4573.076009750366}}, \"EndTime\": 1587306172.813684, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306168.240547}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:52 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.788888861 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:52 INFO 140144812640064] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:52 INFO 140144812640064] #quality_metric: host=algo-1, epoch=10, train loss <loss>=2.33127372915\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:52 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:53 INFO 140144812640064] Epoch[11] Batch[0] avg_epoch_loss=2.154531\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=2.15453052521\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:55 INFO 140144812640064] Epoch[11] Batch[5] avg_epoch_loss=2.166284\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=2.16628356775\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:55 INFO 140144812640064] Epoch[11] Batch [5]#011Speed: 173.89 samples/sec#011loss=2.166284\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:57 INFO 140144812640064] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4309.1700077056885, \"sum\": 4309.1700077056885, \"min\": 4309.1700077056885}}, \"EndTime\": 1587306177.123359, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306172.81376}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:57 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.123729744 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:57 INFO 140144812640064] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:57 INFO 140144812640064] #quality_metric: host=algo-1, epoch=11, train loss <loss>=2.12539829016\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:57 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:57 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_d93350b9-d6dd-4731-b1db-8c25fad5c689-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.24997138977051, \"sum\": 61.24997138977051, \"min\": 61.24997138977051}}, \"EndTime\": 1587306177.185367, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306177.123419}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:58 INFO 140144812640064] Epoch[12] Batch[0] avg_epoch_loss=2.005799\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:58 INFO 140144812640064] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=2.00579929352\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:59 INFO 140144812640064] Epoch[12] Batch[5] avg_epoch_loss=2.035416\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:59 INFO 140144812640064] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.03541604678\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:22:59 INFO 140144812640064] Epoch[12] Batch [5]#011Speed: 172.93 samples/sec#011loss=2.035416\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:01 INFO 140144812640064] processed a total of 585 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4257.83896446228, \"sum\": 4257.83896446228, \"min\": 4257.83896446228}}, \"EndTime\": 1587306181.443342, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306177.185437}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:01 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=137.389925637 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:01 INFO 140144812640064] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:01 INFO 140144812640064] #quality_metric: host=algo-1, epoch=12, train loss <loss>=2.0419182539\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:01 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:01 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_244408c9-467f-4e23-a2d3-e36c9126d6a5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 86.25984191894531, \"sum\": 86.25984191894531, \"min\": 86.25984191894531}}, \"EndTime\": 1587306181.530313, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306181.443417}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:02 INFO 140144812640064] Epoch[13] Batch[0] avg_epoch_loss=2.161271\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=2.16127085686\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:04 INFO 140144812640064] Epoch[13] Batch[5] avg_epoch_loss=2.046329\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=2.04632890224\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:04 INFO 140144812640064] Epoch[13] Batch [5]#011Speed: 176.67 samples/sec#011loss=2.046329\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:05 INFO 140144812640064] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4249.032974243164, \"sum\": 4249.032974243164, \"min\": 4249.032974243164}}, \"EndTime\": 1587306185.779485, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306181.530385}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:05 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.322579885 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:05 INFO 140144812640064] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=13, train loss <loss>=2.02211647034\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:05 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:05 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_66956274-ed23-4dd4-86c9-583c2735fd04-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 68.92204284667969, \"sum\": 68.92204284667969, \"min\": 68.92204284667969}}, \"EndTime\": 1587306185.849123, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306185.779567}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:06 INFO 140144812640064] Epoch[14] Batch[0] avg_epoch_loss=2.055476\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:06 INFO 140144812640064] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=2.05547642708\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:08 INFO 140144812640064] Epoch[14] Batch[5] avg_epoch_loss=2.125758\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:08 INFO 140144812640064] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=2.12575821082\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:08 INFO 140144812640064] Epoch[14] Batch [5]#011Speed: 175.41 samples/sec#011loss=2.125758\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:10 INFO 140144812640064] Epoch[14] Batch[10] avg_epoch_loss=2.085758\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=2.03775687218\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:10 INFO 140144812640064] Epoch[14] Batch [10]#011Speed: 174.98 samples/sec#011loss=2.037757\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:10 INFO 140144812640064] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4637.049913406372, \"sum\": 4637.049913406372, \"min\": 4637.049913406372}}, \"EndTime\": 1587306190.486313, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306185.849201}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:10 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=140.17096935 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:10 INFO 140144812640064] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=14, train loss <loss>=2.08575760234\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:10 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:11 INFO 140144812640064] Epoch[15] Batch[0] avg_epoch_loss=1.896865\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:11 INFO 140144812640064] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=1.89686477184\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:13 INFO 140144812640064] Epoch[15] Batch[5] avg_epoch_loss=1.894962\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:13 INFO 140144812640064] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=1.89496233066\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:13 INFO 140144812640064] Epoch[15] Batch [5]#011Speed: 172.96 samples/sec#011loss=1.894962\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:14 INFO 140144812640064] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4256.6258907318115, \"sum\": 4256.6258907318115, \"min\": 4256.6258907318115}}, \"EndTime\": 1587306194.743569, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306190.48642}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:14 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.879565644 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:14 INFO 140144812640064] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:14 INFO 140144812640064] #quality_metric: host=algo-1, epoch=15, train loss <loss>=1.86650923491\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:14 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:14 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_079deedc-0ff8-45aa-afa8-4c7d046d18c1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 66.26009941101074, \"sum\": 66.26009941101074, \"min\": 66.26009941101074}}, \"EndTime\": 1587306194.810415, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306194.743654}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:15 INFO 140144812640064] Epoch[16] Batch[0] avg_epoch_loss=1.689828\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:15 INFO 140144812640064] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=1.68982768059\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:17 INFO 140144812640064] Epoch[16] Batch[5] avg_epoch_loss=1.803864\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=1.80386435986\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:17 INFO 140144812640064] Epoch[16] Batch [5]#011Speed: 177.22 samples/sec#011loss=1.803864\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:19 INFO 140144812640064] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4246.336936950684, \"sum\": 4246.336936950684, \"min\": 4246.336936950684}}, \"EndTime\": 1587306199.05689, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306194.810493}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:19 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.711055592 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:19 INFO 140144812640064] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=16, train loss <loss>=1.80761190653\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:19 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:19 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_87bd6115-0c11-4f5d-99e8-f7a2d6737668-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.68103218078613, \"sum\": 61.68103218078613, \"min\": 61.68103218078613}}, \"EndTime\": 1587306199.119254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306199.056963}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:20 INFO 140144812640064] Epoch[17] Batch[0] avg_epoch_loss=1.826139\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:20 INFO 140144812640064] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=1.82613909245\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:21 INFO 140144812640064] Epoch[17] Batch[5] avg_epoch_loss=1.779645\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=1.77964480718\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:21 INFO 140144812640064] Epoch[17] Batch [5]#011Speed: 175.42 samples/sec#011loss=1.779645\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:23 INFO 140144812640064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4224.023103713989, \"sum\": 4224.023103713989, \"min\": 4224.023103713989}}, \"EndTime\": 1587306203.343416, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306199.119325}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:23 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=151.509952844 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:23 INFO 140144812640064] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:23 INFO 140144812640064] #quality_metric: host=algo-1, epoch=17, train loss <loss>=1.79177513123\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:23 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:23 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_e29fd9b7-fc5e-4f54-83be-74a31479095b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 81.62212371826172, \"sum\": 81.62212371826172, \"min\": 81.62212371826172}}, \"EndTime\": 1587306203.426056, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306203.343498}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:24 INFO 140144812640064] Epoch[18] Batch[0] avg_epoch_loss=1.870279\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:24 INFO 140144812640064] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=1.87027943134\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:26 INFO 140144812640064] Epoch[18] Batch[5] avg_epoch_loss=1.775051\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=1.77505113681\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:26 INFO 140144812640064] Epoch[18] Batch [5]#011Speed: 175.51 samples/sec#011loss=1.775051\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140144812640064] Epoch[18] Batch[10] avg_epoch_loss=1.740454\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=1.69893696308\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140144812640064] Epoch[18] Batch [10]#011Speed: 175.40 samples/sec#011loss=1.698937\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140144812640064] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4622.556924819946, \"sum\": 4622.556924819946, \"min\": 4622.556924819946}}, \"EndTime\": 1587306208.048746, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306203.426128}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=140.611655826 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140144812640064] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=18, train loss <loss>=1.74045378512\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:28 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_a035ffcb-ca69-471e-b306-b9089d0b9dbc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.30719184875488, \"sum\": 61.30719184875488, \"min\": 61.30719184875488}}, \"EndTime\": 1587306208.110697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306208.048812}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:29 INFO 140144812640064] Epoch[19] Batch[0] avg_epoch_loss=1.708436\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:29 INFO 140144812640064] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=1.70843553543\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:30 INFO 140144812640064] Epoch[19] Batch[5] avg_epoch_loss=1.666667\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=1.66666732232\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:30 INFO 140144812640064] Epoch[19] Batch [5]#011Speed: 173.28 samples/sec#011loss=1.666667\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:32 INFO 140144812640064] Epoch[19] Batch[10] avg_epoch_loss=1.599465\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:32 INFO 140144812640064] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=1.51882312298\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:32 INFO 140144812640064] Epoch[19] Batch [10]#011Speed: 173.70 samples/sec#011loss=1.518823\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:32 INFO 140144812640064] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4705.168962478638, \"sum\": 4705.168962478638, \"min\": 4705.168962478638}}, \"EndTime\": 1587306212.816, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306208.110767}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:32 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.455831276 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:32 INFO 140144812640064] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:32 INFO 140144812640064] #quality_metric: host=algo-1, epoch=19, train loss <loss>=1.59946541353\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:32 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:32 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_14bf6aac-4da9-4c4f-a226-cc3697f33afa-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 67.55805015563965, \"sum\": 67.55805015563965, \"min\": 67.55805015563965}}, \"EndTime\": 1587306212.884063, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306212.816075}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:33 INFO 140144812640064] Epoch[20] Batch[0] avg_epoch_loss=1.691175\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:33 INFO 140144812640064] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=1.69117534161\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:35 INFO 140144812640064] Epoch[20] Batch[5] avg_epoch_loss=1.731040\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:35 INFO 140144812640064] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=1.73104031881\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:35 INFO 140144812640064] Epoch[20] Batch [5]#011Speed: 172.84 samples/sec#011loss=1.731040\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:37 INFO 140144812640064] Epoch[20] Batch[10] avg_epoch_loss=1.681399\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:37 INFO 140144812640064] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=1.62182948589\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:37 INFO 140144812640064] Epoch[20] Batch [10]#011Speed: 178.00 samples/sec#011loss=1.621829\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:37 INFO 140144812640064] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4610.111951828003, \"sum\": 4610.111951828003, \"min\": 4610.111951828003}}, \"EndTime\": 1587306217.494314, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306212.884141}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:37 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.038825751 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:37 INFO 140144812640064] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:37 INFO 140144812640064] #quality_metric: host=algo-1, epoch=20, train loss <loss>=1.68139903112\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:37 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:38 INFO 140144812640064] Epoch[21] Batch[0] avg_epoch_loss=1.709053\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:38 INFO 140144812640064] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=1.70905339718\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:40 INFO 140144812640064] Epoch[21] Batch[5] avg_epoch_loss=1.687472\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=1.68747186661\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:40 INFO 140144812640064] Epoch[21] Batch [5]#011Speed: 177.84 samples/sec#011loss=1.687472\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:42 INFO 140144812640064] Epoch[21] Batch[10] avg_epoch_loss=1.666171\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=1.64061071873\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:42 INFO 140144812640064] Epoch[21] Batch [10]#011Speed: 174.78 samples/sec#011loss=1.640611\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:42 INFO 140144812640064] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4654.858112335205, \"sum\": 4654.858112335205, \"min\": 4654.858112335205}}, \"EndTime\": 1587306222.151688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306217.494391}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:42 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=138.346460719 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:42 INFO 140144812640064] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=21, train loss <loss>=1.66617134484\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:42 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:43 INFO 140144812640064] Epoch[22] Batch[0] avg_epoch_loss=1.863167\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=1.86316668987\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:44 INFO 140144812640064] Epoch[22] Batch[5] avg_epoch_loss=1.685203\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:44 INFO 140144812640064] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=1.68520265818\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:44 INFO 140144812640064] Epoch[22] Batch [5]#011Speed: 176.45 samples/sec#011loss=1.685203\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:46 INFO 140144812640064] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4229.538917541504, \"sum\": 4229.538917541504, \"min\": 4229.538917541504}}, \"EndTime\": 1587306226.381836, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306222.151771}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:46 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.894730861 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:46 INFO 140144812640064] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=22, train loss <loss>=1.63526240587\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:46 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:47 INFO 140144812640064] Epoch[23] Batch[0] avg_epoch_loss=1.515554\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:47 INFO 140144812640064] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=1.51555359364\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:49 INFO 140144812640064] Epoch[23] Batch[5] avg_epoch_loss=1.557105\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:49 INFO 140144812640064] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=1.55710502466\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:49 INFO 140144812640064] Epoch[23] Batch [5]#011Speed: 172.34 samples/sec#011loss=1.557105\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:50 INFO 140144812640064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4246.646165847778, \"sum\": 4246.646165847778, \"min\": 4246.646165847778}}, \"EndTime\": 1587306230.629109, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306226.381892}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:50 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=150.703618834 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:50 INFO 140144812640064] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:50 INFO 140144812640064] #quality_metric: host=algo-1, epoch=23, train loss <loss>=1.53434385061\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:50 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:50 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_f867541d-53bb-4962-b557-5fcc5dca011c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 63.77887725830078, \"sum\": 63.77887725830078, \"min\": 63.77887725830078}}, \"EndTime\": 1587306230.693602, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306230.629174}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:51 INFO 140144812640064] Epoch[24] Batch[0] avg_epoch_loss=1.361982\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:51 INFO 140144812640064] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=1.36198222637\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:53 INFO 140144812640064] Epoch[24] Batch[5] avg_epoch_loss=1.473794\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=1.47379436096\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:53 INFO 140144812640064] Epoch[24] Batch [5]#011Speed: 175.45 samples/sec#011loss=1.473794\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:55 INFO 140144812640064] Epoch[24] Batch[10] avg_epoch_loss=1.463097\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=1.45025999546\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:55 INFO 140144812640064] Epoch[24] Batch [10]#011Speed: 176.07 samples/sec#011loss=1.450260\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:55 INFO 140144812640064] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4618.005037307739, \"sum\": 4618.005037307739, \"min\": 4618.005037307739}}, \"EndTime\": 1587306235.31175, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306230.693681}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:55 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.915263366 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:55 INFO 140144812640064] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=24, train loss <loss>=1.46309692209\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:55 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:55 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_9a7d4d22-3dab-425d-8918-a8faf660022c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 69.64397430419922, \"sum\": 69.64397430419922, \"min\": 69.64397430419922}}, \"EndTime\": 1587306235.381933, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306235.311829}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:56 INFO 140144812640064] Epoch[25] Batch[0] avg_epoch_loss=1.471857\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:56 INFO 140144812640064] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=1.4718568325\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:58 INFO 140144812640064] Epoch[25] Batch[5] avg_epoch_loss=1.524301\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:58 INFO 140144812640064] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=1.52430105209\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:58 INFO 140144812640064] Epoch[25] Batch [5]#011Speed: 176.65 samples/sec#011loss=1.524301\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:59 INFO 140144812640064] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4299.407005310059, \"sum\": 4299.407005310059, \"min\": 4299.407005310059}}, \"EndTime\": 1587306239.681475, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306235.382006}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:59 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.993494534 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:59 INFO 140144812640064] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:59 INFO 140144812640064] #quality_metric: host=algo-1, epoch=25, train loss <loss>=1.49242122173\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:23:59 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:00 INFO 140144812640064] Epoch[26] Batch[0] avg_epoch_loss=1.502297\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:00 INFO 140144812640064] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=1.50229728222\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:02 INFO 140144812640064] Epoch[26] Batch[5] avg_epoch_loss=1.409277\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=1.40927698215\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:02 INFO 140144812640064] Epoch[26] Batch [5]#011Speed: 173.11 samples/sec#011loss=1.409277\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:04 INFO 140144812640064] Epoch[26] Batch[10] avg_epoch_loss=1.354915\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=1.28968145847\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:04 INFO 140144812640064] Epoch[26] Batch [10]#011Speed: 175.33 samples/sec#011loss=1.289681\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:04 INFO 140144812640064] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4637.640953063965, \"sum\": 4637.640953063965, \"min\": 4637.640953063965}}, \"EndTime\": 1587306244.319735, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306239.681543}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:04 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.231852945 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:04 INFO 140144812640064] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=26, train loss <loss>=1.35491538048\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:04 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:04 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_5370dfaa-6de4-4daf-8a5c-78295beddc20-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 70.43814659118652, \"sum\": 70.43814659118652, \"min\": 70.43814659118652}}, \"EndTime\": 1587306244.390753, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306244.319812}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:05 INFO 140144812640064] Epoch[27] Batch[0] avg_epoch_loss=2.102692\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=2.10269165039\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:07 INFO 140144812640064] Epoch[27] Batch[5] avg_epoch_loss=1.752891\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=1.75289138158\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:07 INFO 140144812640064] Epoch[27] Batch [5]#011Speed: 174.54 samples/sec#011loss=1.752891\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:09 INFO 140144812640064] Epoch[27] Batch[10] avg_epoch_loss=1.681199\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:09 INFO 140144812640064] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=1.5951675415\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:09 INFO 140144812640064] Epoch[27] Batch [10]#011Speed: 175.33 samples/sec#011loss=1.595168\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:09 INFO 140144812640064] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4629.4660568237305, \"sum\": 4629.4660568237305, \"min\": 4629.4660568237305}}, \"EndTime\": 1587306249.02036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306244.390824}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:09 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.777559342 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:09 INFO 140144812640064] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:09 INFO 140144812640064] #quality_metric: host=algo-1, epoch=27, train loss <loss>=1.681198727\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:09 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:09 INFO 140144812640064] Epoch[28] Batch[0] avg_epoch_loss=1.461882\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:09 INFO 140144812640064] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=1.46188223362\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:11 INFO 140144812640064] Epoch[28] Batch[5] avg_epoch_loss=1.374941\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:11 INFO 140144812640064] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=1.37494063377\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:11 INFO 140144812640064] Epoch[28] Batch [5]#011Speed: 171.60 samples/sec#011loss=1.374941\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:13 INFO 140144812640064] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4298.632860183716, \"sum\": 4298.632860183716, \"min\": 4298.632860183716}}, \"EndTime\": 1587306253.319568, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306249.020437}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:13 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.22736787 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:13 INFO 140144812640064] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:13 INFO 140144812640064] #quality_metric: host=algo-1, epoch=28, train loss <loss>=1.32177667618\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:13 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:13 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_57fa9a53-1764-4044-9746-fdb99e09a26a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 63.52710723876953, \"sum\": 63.52710723876953, \"min\": 63.52710723876953}}, \"EndTime\": 1587306253.383877, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306253.319632}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:14 INFO 140144812640064] Epoch[29] Batch[0] avg_epoch_loss=1.243932\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:14 INFO 140144812640064] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=1.24393153191\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:16 INFO 140144812640064] Epoch[29] Batch[5] avg_epoch_loss=1.211320\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:16 INFO 140144812640064] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=1.21132000287\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:16 INFO 140144812640064] Epoch[29] Batch [5]#011Speed: 175.16 samples/sec#011loss=1.211320\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:17 INFO 140144812640064] Epoch[29] Batch[10] avg_epoch_loss=1.287615\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=1.37916884422\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:17 INFO 140144812640064] Epoch[29] Batch [10]#011Speed: 176.35 samples/sec#011loss=1.379169\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:17 INFO 140144812640064] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4603.97481918335, \"sum\": 4603.97481918335, \"min\": 4603.97481918335}}, \"EndTime\": 1587306257.987988, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306253.383951}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:17 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.830541616 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:17 INFO 140144812640064] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=29, train loss <loss>=1.28761493076\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:17 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:18 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_b47cc15e-c489-4fe0-85ba-f40044e30e54-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 75.84404945373535, \"sum\": 75.84404945373535, \"min\": 75.84404945373535}}, \"EndTime\": 1587306258.064362, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306257.988064}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:19 INFO 140144812640064] Epoch[30] Batch[0] avg_epoch_loss=1.342240\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=1.34224045277\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:20 INFO 140144812640064] Epoch[30] Batch[5] avg_epoch_loss=1.412404\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:20 INFO 140144812640064] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=1.41240408023\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:20 INFO 140144812640064] Epoch[30] Batch [5]#011Speed: 174.49 samples/sec#011loss=1.412404\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:22 INFO 140144812640064] Epoch[30] Batch[10] avg_epoch_loss=1.352188\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:22 INFO 140144812640064] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=1.27992935181\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:22 INFO 140144812640064] Epoch[30] Batch [10]#011Speed: 170.85 samples/sec#011loss=1.279929\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:22 INFO 140144812640064] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4687.724828720093, \"sum\": 4687.724828720093, \"min\": 4687.724828720093}}, \"EndTime\": 1587306262.752217, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306258.064433}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:22 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.549646532 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:22 INFO 140144812640064] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:22 INFO 140144812640064] #quality_metric: host=algo-1, epoch=30, train loss <loss>=1.35218829458\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:22 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:23 INFO 140144812640064] Epoch[31] Batch[0] avg_epoch_loss=1.198224\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:23 INFO 140144812640064] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=1.19822430611\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:25 INFO 140144812640064] Epoch[31] Batch[5] avg_epoch_loss=1.184283\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=1.18428349495\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:25 INFO 140144812640064] Epoch[31] Batch [5]#011Speed: 175.75 samples/sec#011loss=1.184283\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:27 INFO 140144812640064] Epoch[31] Batch[10] avg_epoch_loss=1.251742\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:27 INFO 140144812640064] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=1.33269309998\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:27 INFO 140144812640064] Epoch[31] Batch [10]#011Speed: 176.98 samples/sec#011loss=1.332693\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:27 INFO 140144812640064] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4660.382032394409, \"sum\": 4660.382032394409, \"min\": 4660.382032394409}}, \"EndTime\": 1587306267.413102, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306262.752288}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:27 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=137.539276201 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:27 INFO 140144812640064] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:27 INFO 140144812640064] #quality_metric: host=algo-1, epoch=31, train loss <loss>=1.25174240632\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:27 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:27 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_8395f485-81e9-44f2-bc26-6d835217ee89-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 66.34402275085449, \"sum\": 66.34402275085449, \"min\": 66.34402275085449}}, \"EndTime\": 1587306267.479957, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306267.413173}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:28 INFO 140144812640064] Epoch[32] Batch[0] avg_epoch_loss=1.215072\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=1.21507179737\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:30 INFO 140144812640064] Epoch[32] Batch[5] avg_epoch_loss=1.263876\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=1.26387572289\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:30 INFO 140144812640064] Epoch[32] Batch [5]#011Speed: 170.16 samples/sec#011loss=1.263876\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:31 INFO 140144812640064] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4318.943023681641, \"sum\": 4318.943023681641, \"min\": 4318.943023681641}}, \"EndTime\": 1587306271.799037, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306267.480028}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:31 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.254439517 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:31 INFO 140144812640064] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:31 INFO 140144812640064] #quality_metric: host=algo-1, epoch=32, train loss <loss>=1.21906540394\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:31 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:31 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_8b61cd53-8e95-4748-8f7f-f575e326eefa-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 95.53885459899902, \"sum\": 95.53885459899902, \"min\": 95.53885459899902}}, \"EndTime\": 1587306271.895278, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306271.79911}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:32 INFO 140144812640064] Epoch[33] Batch[0] avg_epoch_loss=1.132282\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:32 INFO 140144812640064] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=1.13228166103\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:34 INFO 140144812640064] Epoch[33] Batch[5] avg_epoch_loss=1.118390\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:34 INFO 140144812640064] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=1.11838954687\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:34 INFO 140144812640064] Epoch[33] Batch [5]#011Speed: 174.20 samples/sec#011loss=1.118390\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:36 INFO 140144812640064] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4269.327163696289, \"sum\": 4269.327163696289, \"min\": 4269.327163696289}}, \"EndTime\": 1587306276.164758, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306271.895361}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:36 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.560024877 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:36 INFO 140144812640064] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:36 INFO 140144812640064] #quality_metric: host=algo-1, epoch=33, train loss <loss>=1.13904095292\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:36 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:36 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_502d3790-7fc0-4f01-8852-f75460ec8f34-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 74.78713989257812, \"sum\": 74.78713989257812, \"min\": 74.78713989257812}}, \"EndTime\": 1587306276.240113, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306276.164839}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:37 INFO 140144812640064] Epoch[34] Batch[0] avg_epoch_loss=1.080358\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:37 INFO 140144812640064] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=1.08035755157\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:39 INFO 140144812640064] Epoch[34] Batch[5] avg_epoch_loss=1.074466\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=1.07446577152\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:39 INFO 140144812640064] Epoch[34] Batch [5]#011Speed: 173.98 samples/sec#011loss=1.074466\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:40 INFO 140144812640064] Epoch[34] Batch[10] avg_epoch_loss=1.088910\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=1.10624302626\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:40 INFO 140144812640064] Epoch[34] Batch [10]#011Speed: 177.16 samples/sec#011loss=1.106243\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:40 INFO 140144812640064] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4644.092082977295, \"sum\": 4644.092082977295, \"min\": 4644.092082977295}}, \"EndTime\": 1587306280.884391, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306276.240233}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:40 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.911937901 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:40 INFO 140144812640064] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=34, train loss <loss>=1.08890997822\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:40 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:40 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_bb8b6ebe-3d68-4f44-8f35-ff3f95822f92-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 96.71783447265625, \"sum\": 96.71783447265625, \"min\": 96.71783447265625}}, \"EndTime\": 1587306280.981794, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306280.884462}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:41 INFO 140144812640064] Epoch[35] Batch[0] avg_epoch_loss=1.293514\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:41 INFO 140144812640064] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=1.29351389408\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:43 INFO 140144812640064] Epoch[35] Batch[5] avg_epoch_loss=1.206113\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=1.20611284177\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:43 INFO 140144812640064] Epoch[35] Batch [5]#011Speed: 173.18 samples/sec#011loss=1.206113\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:45 INFO 140144812640064] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4260.385990142822, \"sum\": 4260.385990142822, \"min\": 4260.385990142822}}, \"EndTime\": 1587306285.242334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306280.981878}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:45 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.940131014 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:45 INFO 140144812640064] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:45 INFO 140144812640064] #quality_metric: host=algo-1, epoch=35, train loss <loss>=1.18579005003\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:45 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:46 INFO 140144812640064] Epoch[36] Batch[0] avg_epoch_loss=1.260589\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=1.26058876514\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:48 INFO 140144812640064] Epoch[36] Batch[5] avg_epoch_loss=1.182711\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=1.18271120389\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:48 INFO 140144812640064] Epoch[36] Batch [5]#011Speed: 173.67 samples/sec#011loss=1.182711\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:49 INFO 140144812640064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4283.748149871826, \"sum\": 4283.748149871826, \"min\": 4283.748149871826}}, \"EndTime\": 1587306289.526712, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306285.24243}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:49 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.129787558 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:49 INFO 140144812640064] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:49 INFO 140144812640064] #quality_metric: host=algo-1, epoch=36, train loss <loss>=1.16224489212\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:49 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:50 INFO 140144812640064] Epoch[37] Batch[0] avg_epoch_loss=1.023690\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:50 INFO 140144812640064] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=1.02368950844\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:52 INFO 140144812640064] Epoch[37] Batch[5] avg_epoch_loss=1.103037\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:52 INFO 140144812640064] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=1.10303709904\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:52 INFO 140144812640064] Epoch[37] Batch [5]#011Speed: 174.12 samples/sec#011loss=1.103037\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:54 INFO 140144812640064] Epoch[37] Batch[10] avg_epoch_loss=1.111639\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:54 INFO 140144812640064] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=1.12196130753\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:54 INFO 140144812640064] Epoch[37] Batch [10]#011Speed: 177.20 samples/sec#011loss=1.121961\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:54 INFO 140144812640064] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4619.2638874053955, \"sum\": 4619.2638874053955, \"min\": 4619.2638874053955}}, \"EndTime\": 1587306294.146621, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306289.526785}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:54 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.742389689 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:54 INFO 140144812640064] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:54 INFO 140144812640064] #quality_metric: host=algo-1, epoch=37, train loss <loss>=1.11163901199\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:54 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:55 INFO 140144812640064] Epoch[38] Batch[0] avg_epoch_loss=1.470166\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=1.47016608715\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:57 INFO 140144812640064] Epoch[38] Batch[5] avg_epoch_loss=1.282345\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:57 INFO 140144812640064] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=1.28234491746\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:57 INFO 140144812640064] Epoch[38] Batch [5]#011Speed: 173.97 samples/sec#011loss=1.282345\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:58 INFO 140144812640064] Epoch[38] Batch[10] avg_epoch_loss=1.190984\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:58 INFO 140144812640064] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=1.08134994507\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:58 INFO 140144812640064] Epoch[38] Batch [10]#011Speed: 177.88 samples/sec#011loss=1.081350\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:58 INFO 140144812640064] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4657.454013824463, \"sum\": 4657.454013824463, \"min\": 4657.454013824463}}, \"EndTime\": 1587306298.804613, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306294.146695}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:58 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=137.625649986 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:58 INFO 140144812640064] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:58 INFO 140144812640064] #quality_metric: host=algo-1, epoch=38, train loss <loss>=1.19098356637\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:58 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:59 INFO 140144812640064] Epoch[39] Batch[0] avg_epoch_loss=1.496077\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:24:59 INFO 140144812640064] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=1.49607717991\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:01 INFO 140144812640064] Epoch[39] Batch[5] avg_epoch_loss=1.278828\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:01 INFO 140144812640064] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=1.27882794539\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:01 INFO 140144812640064] Epoch[39] Batch [5]#011Speed: 172.49 samples/sec#011loss=1.278828\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:03 INFO 140144812640064] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4425.54497718811, \"sum\": 4425.54497718811, \"min\": 4425.54497718811}}, \"EndTime\": 1587306303.230742, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306298.804685}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:03 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=137.153231955 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:03 INFO 140144812640064] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:03 INFO 140144812640064] #quality_metric: host=algo-1, epoch=39, train loss <loss>=1.2148907423\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:03 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:04 INFO 140144812640064] Epoch[40] Batch[0] avg_epoch_loss=1.151335\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=1.15133535862\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:06 INFO 140144812640064] Epoch[40] Batch[5] avg_epoch_loss=1.019736\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:06 INFO 140144812640064] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=1.01973561446\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:06 INFO 140144812640064] Epoch[40] Batch [5]#011Speed: 175.90 samples/sec#011loss=1.019736\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:07 INFO 140144812640064] Epoch[40] Batch[10] avg_epoch_loss=1.026852\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=1.03539094925\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:07 INFO 140144812640064] Epoch[40] Batch [10]#011Speed: 175.56 samples/sec#011loss=1.035391\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:07 INFO 140144812640064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4661.066055297852, \"sum\": 4661.066055297852, \"min\": 4661.066055297852}}, \"EndTime\": 1587306307.892391, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306303.230824}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:07 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=138.805967627 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:07 INFO 140144812640064] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=40, train loss <loss>=1.02685167573\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:07 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:07 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_8a8f5eef-91e4-4e64-b585-c413bce54c59-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.1112117767334, \"sum\": 61.1112117767334, \"min\": 61.1112117767334}}, \"EndTime\": 1587306307.954107, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306307.892468}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:08 INFO 140144812640064] Epoch[41] Batch[0] avg_epoch_loss=2.121122\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:08 INFO 140144812640064] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.12112236023\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:10 INFO 140144812640064] Epoch[41] Batch[5] avg_epoch_loss=1.590507\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=1.59050695101\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:10 INFO 140144812640064] Epoch[41] Batch [5]#011Speed: 174.47 samples/sec#011loss=1.590507\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:12 INFO 140144812640064] Epoch[41] Batch[10] avg_epoch_loss=1.544925\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=1.49022650719\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:12 INFO 140144812640064] Epoch[41] Batch [10]#011Speed: 174.41 samples/sec#011loss=1.490227\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:12 INFO 140144812640064] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4664.870023727417, \"sum\": 4664.870023727417, \"min\": 4664.870023727417}}, \"EndTime\": 1587306312.619125, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306307.954188}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:12 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.196302827 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:12 INFO 140144812640064] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=41, train loss <loss>=1.54492493109\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:12 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:13 INFO 140144812640064] Epoch[42] Batch[0] avg_epoch_loss=1.356927\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:13 INFO 140144812640064] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=1.35692739487\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:15 INFO 140144812640064] Epoch[42] Batch[5] avg_epoch_loss=1.208950\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:15 INFO 140144812640064] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=1.20894972483\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:15 INFO 140144812640064] Epoch[42] Batch [5]#011Speed: 175.07 samples/sec#011loss=1.208950\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:16 INFO 140144812640064] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4249.9589920043945, \"sum\": 4249.9589920043945, \"min\": 4249.9589920043945}}, \"EndTime\": 1587306316.869658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306312.619209}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:16 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.821042007 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:16 INFO 140144812640064] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:16 INFO 140144812640064] #quality_metric: host=algo-1, epoch=42, train loss <loss>=1.11567981243\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:16 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:17 INFO 140144812640064] Epoch[43] Batch[0] avg_epoch_loss=0.914120\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=0.914120018482\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:19 INFO 140144812640064] Epoch[43] Batch[5] avg_epoch_loss=0.929963\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=0.929962913195\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:19 INFO 140144812640064] Epoch[43] Batch [5]#011Speed: 177.03 samples/sec#011loss=0.929963\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:21 INFO 140144812640064] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4273.351192474365, \"sum\": 4273.351192474365, \"min\": 4273.351192474365}}, \"EndTime\": 1587306321.143679, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306316.869734}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:21 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.613259154 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:21 INFO 140144812640064] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=43, train loss <loss>=0.941941034794\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:21 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:21 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_6044f9f8-d9f0-4423-8767-5b4d920021b6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 71.81000709533691, \"sum\": 71.81000709533691, \"min\": 71.81000709533691}}, \"EndTime\": 1587306321.216061, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306321.143757}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:22 INFO 140144812640064] Epoch[44] Batch[0] avg_epoch_loss=0.970965\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:22 INFO 140144812640064] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=0.970965027809\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:24 INFO 140144812640064] Epoch[44] Batch[5] avg_epoch_loss=0.940708\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:24 INFO 140144812640064] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=0.940708170334\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:24 INFO 140144812640064] Epoch[44] Batch [5]#011Speed: 174.96 samples/sec#011loss=0.940708\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:25 INFO 140144812640064] Epoch[44] Batch[10] avg_epoch_loss=0.896861\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=0.844244027138\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:25 INFO 140144812640064] Epoch[44] Batch [10]#011Speed: 177.28 samples/sec#011loss=0.844244\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:25 INFO 140144812640064] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4631.641864776611, \"sum\": 4631.641864776611, \"min\": 4631.641864776611}}, \"EndTime\": 1587306325.847825, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306321.216128}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:25 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.869467388 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:25 INFO 140144812640064] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=44, train loss <loss>=0.896860832518\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:25 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:25 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_7f34f4ba-9ab8-4760-931e-b83411312344-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 66.3459300994873, \"sum\": 66.3459300994873, \"min\": 66.3459300994873}}, \"EndTime\": 1587306325.914746, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306325.847904}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:26 INFO 140144812640064] Epoch[45] Batch[0] avg_epoch_loss=0.912889\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=0.912889063358\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:28 INFO 140144812640064] Epoch[45] Batch[5] avg_epoch_loss=0.976712\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=0.976711501678\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:28 INFO 140144812640064] Epoch[45] Batch [5]#011Speed: 172.69 samples/sec#011loss=0.976712\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:30 INFO 140144812640064] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4338.913917541504, \"sum\": 4338.913917541504, \"min\": 4338.913917541504}}, \"EndTime\": 1587306330.253812, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306325.914817}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:30 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.267904467 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:30 INFO 140144812640064] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=45, train loss <loss>=0.96704043746\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:30 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:31 INFO 140144812640064] Epoch[46] Batch[0] avg_epoch_loss=0.711384\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:31 INFO 140144812640064] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=0.71138381958\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:33 INFO 140144812640064] Epoch[46] Batch[5] avg_epoch_loss=0.784032\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:33 INFO 140144812640064] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=0.784031798442\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:33 INFO 140144812640064] Epoch[46] Batch [5]#011Speed: 174.95 samples/sec#011loss=0.784032\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:34 INFO 140144812640064] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4202.5511264801025, \"sum\": 4202.5511264801025, \"min\": 4202.5511264801025}}, \"EndTime\": 1587306334.456985, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306330.253891}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:34 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.052347549 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:34 INFO 140144812640064] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:34 INFO 140144812640064] #quality_metric: host=algo-1, epoch=46, train loss <loss>=0.795579588413\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:34 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:34 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_42a769a2-6757-4e9f-94bc-836c79393244-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 64.9878978729248, \"sum\": 64.9878978729248, \"min\": 64.9878978729248}}, \"EndTime\": 1587306334.522597, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306334.457069}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:35 INFO 140144812640064] Epoch[47] Batch[0] avg_epoch_loss=0.940603\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:35 INFO 140144812640064] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=0.94060254097\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:37 INFO 140144812640064] Epoch[47] Batch[5] avg_epoch_loss=0.821950\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:37 INFO 140144812640064] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=0.821949501832\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:37 INFO 140144812640064] Epoch[47] Batch [5]#011Speed: 175.45 samples/sec#011loss=0.821950\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:39 INFO 140144812640064] Epoch[47] Batch[10] avg_epoch_loss=0.785219\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=0.741142010689\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:39 INFO 140144812640064] Epoch[47] Batch [10]#011Speed: 173.47 samples/sec#011loss=0.741142\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:39 INFO 140144812640064] processed a total of 707 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 5011.734962463379, \"sum\": 5011.734962463379, \"min\": 5011.734962463379}}, \"EndTime\": 1587306339.534465, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306334.522666}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:39 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.065704566 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:39 INFO 140144812640064] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=47, train loss <loss>=0.75922618558\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:39 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:39 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_210d143c-7058-4ca6-a5a1-e91b9756618d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 85.46304702758789, \"sum\": 85.46304702758789, \"min\": 85.46304702758789}}, \"EndTime\": 1587306339.620533, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306339.534539}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:40 INFO 140144812640064] Epoch[48] Batch[0] avg_epoch_loss=2.553076\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.55307602882\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:42 INFO 140144812640064] Epoch[48] Batch[5] avg_epoch_loss=1.650618\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=1.6506182154\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:42 INFO 140144812640064] Epoch[48] Batch [5]#011Speed: 175.26 samples/sec#011loss=1.650618\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:43 INFO 140144812640064] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4261.998176574707, \"sum\": 4261.998176574707, \"min\": 4261.998176574707}}, \"EndTime\": 1587306343.882662, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306339.620603}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:43 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.886038823 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:43 INFO 140144812640064] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=48, train loss <loss>=1.59264184237\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:43 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:44 INFO 140144812640064] Epoch[49] Batch[0] avg_epoch_loss=1.501970\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:44 INFO 140144812640064] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=1.5019698143\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:46 INFO 140144812640064] Epoch[49] Batch[5] avg_epoch_loss=1.396991\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=1.39699085553\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:46 INFO 140144812640064] Epoch[49] Batch [5]#011Speed: 176.48 samples/sec#011loss=1.396991\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:48 INFO 140144812640064] Epoch[49] Batch[10] avg_epoch_loss=1.224266\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=1.0169965744\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:48 INFO 140144812640064] Epoch[49] Batch [10]#011Speed: 173.28 samples/sec#011loss=1.016997\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:48 INFO 140144812640064] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4693.769931793213, \"sum\": 4693.769931793213, \"min\": 4693.769931793213}}, \"EndTime\": 1587306348.577143, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306343.882761}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:48 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.313183624 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:48 INFO 140144812640064] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=49, train loss <loss>=1.22426618229\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:48 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:49 INFO 140144812640064] Epoch[50] Batch[0] avg_epoch_loss=0.908485\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:49 INFO 140144812640064] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=0.908485352993\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:51 INFO 140144812640064] Epoch[50] Batch[5] avg_epoch_loss=0.821353\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:51 INFO 140144812640064] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=0.821352879206\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:51 INFO 140144812640064] Epoch[50] Batch [5]#011Speed: 177.22 samples/sec#011loss=0.821353\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:52 INFO 140144812640064] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4305.552005767822, \"sum\": 4305.552005767822, \"min\": 4305.552005767822}}, \"EndTime\": 1587306352.883228, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306348.577213}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:52 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.228727094 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:52 INFO 140144812640064] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:52 INFO 140144812640064] #quality_metric: host=algo-1, epoch=50, train loss <loss>=0.841827124357\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:52 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:53 INFO 140144812640064] Epoch[51] Batch[0] avg_epoch_loss=0.738381\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=0.738380849361\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:55 INFO 140144812640064] Epoch[51] Batch[5] avg_epoch_loss=1.036762\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=1.03676154216\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:55 INFO 140144812640064] Epoch[51] Batch [5]#011Speed: 174.93 samples/sec#011loss=1.036762\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:57 INFO 140144812640064] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4307.079076766968, \"sum\": 4307.079076766968, \"min\": 4307.079076766968}}, \"EndTime\": 1587306357.190843, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306352.883301}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:57 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.71252029 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:57 INFO 140144812640064] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:57 INFO 140144812640064] #quality_metric: host=algo-1, epoch=51, train loss <loss>=0.986480247974\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:57 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:58 INFO 140144812640064] Epoch[52] Batch[0] avg_epoch_loss=0.967251\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:25:58 INFO 140144812640064] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=0.967250883579\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:00 INFO 140144812640064] Epoch[52] Batch[5] avg_epoch_loss=0.892274\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:00 INFO 140144812640064] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=0.892274032036\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:00 INFO 140144812640064] Epoch[52] Batch [5]#011Speed: 169.69 samples/sec#011loss=0.892274\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:01 INFO 140144812640064] Epoch[52] Batch[10] avg_epoch_loss=0.811182\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:01 INFO 140144812640064] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=0.713872385025\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:01 INFO 140144812640064] Epoch[52] Batch [10]#011Speed: 174.33 samples/sec#011loss=0.713872\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:01 INFO 140144812640064] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4697.764873504639, \"sum\": 4697.764873504639, \"min\": 4697.764873504639}}, \"EndTime\": 1587306361.889465, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306357.190942}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:01 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=137.508511888 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:01 INFO 140144812640064] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:01 INFO 140144812640064] #quality_metric: host=algo-1, epoch=52, train loss <loss>=0.811182374304\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:01 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:02 INFO 140144812640064] Epoch[53] Batch[0] avg_epoch_loss=1.188235\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=1.18823480606\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:04 INFO 140144812640064] Epoch[53] Batch[5] avg_epoch_loss=1.008895\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=1.00889485081\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:04 INFO 140144812640064] Epoch[53] Batch [5]#011Speed: 174.74 samples/sec#011loss=1.008895\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:06 INFO 140144812640064] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4305.269956588745, \"sum\": 4305.269956588745, \"min\": 4305.269956588745}}, \"EndTime\": 1587306366.195223, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306361.889543}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:06 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=148.18648676 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:06 INFO 140144812640064] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:06 INFO 140144812640064] #quality_metric: host=algo-1, epoch=53, train loss <loss>=0.970518916845\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:06 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:07 INFO 140144812640064] Epoch[54] Batch[0] avg_epoch_loss=0.874933\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=0.874933421612\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:09 INFO 140144812640064] Epoch[54] Batch[5] avg_epoch_loss=0.730896\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:09 INFO 140144812640064] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=0.730895668268\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:09 INFO 140144812640064] Epoch[54] Batch [5]#011Speed: 175.46 samples/sec#011loss=0.730896\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:10 INFO 140144812640064] Epoch[54] Batch[10] avg_epoch_loss=0.780647\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=0.840349411964\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:10 INFO 140144812640064] Epoch[54] Batch [10]#011Speed: 175.04 samples/sec#011loss=0.840349\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:10 INFO 140144812640064] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4708.185911178589, \"sum\": 4708.185911178589, \"min\": 4708.185911178589}}, \"EndTime\": 1587306370.903942, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306366.195298}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:10 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.939162938 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:10 INFO 140144812640064] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=54, train loss <loss>=0.780647369948\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:10 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:11 INFO 140144812640064] Epoch[55] Batch[0] avg_epoch_loss=1.357255\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:11 INFO 140144812640064] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=1.3572551012\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:13 INFO 140144812640064] Epoch[55] Batch[5] avg_epoch_loss=1.708471\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:13 INFO 140144812640064] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=1.70847088099\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:13 INFO 140144812640064] Epoch[55] Batch [5]#011Speed: 174.79 samples/sec#011loss=1.708471\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:15 INFO 140144812640064] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4266.0582065582275, \"sum\": 4266.0582065582275, \"min\": 4266.0582065582275}}, \"EndTime\": 1587306375.170463, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306370.904018}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:15 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.548306506 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:15 INFO 140144812640064] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:15 INFO 140144812640064] #quality_metric: host=algo-1, epoch=55, train loss <loss>=1.64559651613\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:15 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:16 INFO 140144812640064] Epoch[56] Batch[0] avg_epoch_loss=1.584352\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:16 INFO 140144812640064] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=1.58435153961\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:18 INFO 140144812640064] Epoch[56] Batch[5] avg_epoch_loss=1.415840\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:18 INFO 140144812640064] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=1.41583963235\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:18 INFO 140144812640064] Epoch[56] Batch [5]#011Speed: 175.29 samples/sec#011loss=1.415840\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:19 INFO 140144812640064] Epoch[56] Batch[10] avg_epoch_loss=1.259200\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=1.07123353481\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:19 INFO 140144812640064] Epoch[56] Batch [10]#011Speed: 176.72 samples/sec#011loss=1.071234\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:19 INFO 140144812640064] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4648.467063903809, \"sum\": 4648.467063903809, \"min\": 4648.467063903809}}, \"EndTime\": 1587306379.819502, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306375.170548}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:19 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.990667078 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:19 INFO 140144812640064] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=56, train loss <loss>=1.25920049711\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:19 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:20 INFO 140144812640064] Epoch[57] Batch[0] avg_epoch_loss=1.007071\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:20 INFO 140144812640064] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=1.00707137585\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:22 INFO 140144812640064] Epoch[57] Batch[5] avg_epoch_loss=0.934046\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:22 INFO 140144812640064] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=0.93404597044\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:22 INFO 140144812640064] Epoch[57] Batch [5]#011Speed: 175.81 samples/sec#011loss=0.934046\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:24 INFO 140144812640064] Epoch[57] Batch[10] avg_epoch_loss=0.934271\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:24 INFO 140144812640064] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=0.934541487694\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:24 INFO 140144812640064] Epoch[57] Batch [10]#011Speed: 176.17 samples/sec#011loss=0.934541\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:24 INFO 140144812640064] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4663.908004760742, \"sum\": 4663.908004760742, \"min\": 4663.908004760742}}, \"EndTime\": 1587306384.483872, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306379.819573}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:24 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.223988593 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:24 INFO 140144812640064] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:24 INFO 140144812640064] #quality_metric: host=algo-1, epoch=57, train loss <loss>=0.934271205555\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:24 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:25 INFO 140144812640064] Epoch[58] Batch[0] avg_epoch_loss=2.152808\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.15280842781\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:27 INFO 140144812640064] Epoch[58] Batch[5] avg_epoch_loss=1.495513\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:27 INFO 140144812640064] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=1.49551345905\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:27 INFO 140144812640064] Epoch[58] Batch [5]#011Speed: 177.97 samples/sec#011loss=1.495513\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:28 INFO 140144812640064] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4207.880020141602, \"sum\": 4207.880020141602, \"min\": 4207.880020141602}}, \"EndTime\": 1587306388.69229, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306384.483951}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:28 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.714754522 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:28 INFO 140144812640064] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=58, train loss <loss>=1.44783773422\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:28 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:29 INFO 140144812640064] Epoch[59] Batch[0] avg_epoch_loss=1.343591\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:29 INFO 140144812640064] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=1.34359121323\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:31 INFO 140144812640064] Epoch[59] Batch[5] avg_epoch_loss=1.235721\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:31 INFO 140144812640064] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=1.23572081327\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:31 INFO 140144812640064] Epoch[59] Batch [5]#011Speed: 170.46 samples/sec#011loss=1.235721\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:32 INFO 140144812640064] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4290.509939193726, \"sum\": 4290.509939193726, \"min\": 4290.509939193726}}, \"EndTime\": 1587306392.983339, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306388.692372}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:32 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.102763215 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:32 INFO 140144812640064] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:32 INFO 140144812640064] #quality_metric: host=algo-1, epoch=59, train loss <loss>=1.13141084313\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:32 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:34 INFO 140144812640064] Epoch[60] Batch[0] avg_epoch_loss=0.888199\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:34 INFO 140144812640064] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=0.888198971748\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:35 INFO 140144812640064] Epoch[60] Batch[5] avg_epoch_loss=0.781675\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:35 INFO 140144812640064] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=0.781674832106\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:35 INFO 140144812640064] Epoch[60] Batch [5]#011Speed: 175.22 samples/sec#011loss=0.781675\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:37 INFO 140144812640064] Epoch[60] Batch[10] avg_epoch_loss=0.814104\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:37 INFO 140144812640064] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=0.853018724918\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:37 INFO 140144812640064] Epoch[60] Batch [10]#011Speed: 177.85 samples/sec#011loss=0.853019\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:37 INFO 140144812640064] processed a total of 692 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4676.17392539978, \"sum\": 4676.17392539978, \"min\": 4676.17392539978}}, \"EndTime\": 1587306397.660023, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306392.983416}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:37 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.980903179 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:37 INFO 140144812640064] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:37 INFO 140144812640064] #quality_metric: host=algo-1, epoch=60, train loss <loss>=0.814103874293\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:37 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:38 INFO 140144812640064] Epoch[61] Batch[0] avg_epoch_loss=1.226732\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:38 INFO 140144812640064] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=1.22673177719\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:40 INFO 140144812640064] Epoch[61] Batch[5] avg_epoch_loss=0.985959\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=0.985959162315\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:40 INFO 140144812640064] Epoch[61] Batch [5]#011Speed: 176.88 samples/sec#011loss=0.985959\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:41 INFO 140144812640064] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4263.745069503784, \"sum\": 4263.745069503784, \"min\": 4263.745069503784}}, \"EndTime\": 1587306401.924251, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306397.660093}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:41 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.111502635 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:41 INFO 140144812640064] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:41 INFO 140144812640064] #quality_metric: host=algo-1, epoch=61, train loss <loss>=0.966473245621\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:41 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:42 INFO 140144812640064] Epoch[62] Batch[0] avg_epoch_loss=0.797301\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=0.797300994396\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:44 INFO 140144812640064] Epoch[62] Batch[5] avg_epoch_loss=0.759891\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:44 INFO 140144812640064] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=0.759891092777\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:44 INFO 140144812640064] Epoch[62] Batch [5]#011Speed: 174.38 samples/sec#011loss=0.759891\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:46 INFO 140144812640064] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4234.389066696167, \"sum\": 4234.389066696167, \"min\": 4234.389066696167}}, \"EndTime\": 1587306406.159192, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306401.924335}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:46 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=148.541316338 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:46 INFO 140144812640064] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=62, train loss <loss>=0.710275238752\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:46 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:46 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_e34b67df-8aa4-4a40-9fd7-b5502b28701d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 85.88790893554688, \"sum\": 85.88790893554688, \"min\": 85.88790893554688}}, \"EndTime\": 1587306406.245645, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306406.159274}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:47 INFO 140144812640064] Epoch[63] Batch[0] avg_epoch_loss=0.738666\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:47 INFO 140144812640064] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=0.738666296005\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:49 INFO 140144812640064] Epoch[63] Batch[5] avg_epoch_loss=0.784210\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:49 INFO 140144812640064] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=0.784209777912\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:49 INFO 140144812640064] Epoch[63] Batch [5]#011Speed: 175.69 samples/sec#011loss=0.784210\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:50 INFO 140144812640064] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4223.43897819519, \"sum\": 4223.43897819519, \"min\": 4223.43897819519}}, \"EndTime\": 1587306410.46922, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306406.245716}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:50 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=151.294421719 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:50 INFO 140144812640064] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:50 INFO 140144812640064] #quality_metric: host=algo-1, epoch=63, train loss <loss>=0.737615352869\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:50 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:51 INFO 140144812640064] Epoch[64] Batch[0] avg_epoch_loss=0.542001\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:51 INFO 140144812640064] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=0.542001366615\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:53 INFO 140144812640064] Epoch[64] Batch[5] avg_epoch_loss=0.605293\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=0.605293293794\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:53 INFO 140144812640064] Epoch[64] Batch [5]#011Speed: 176.81 samples/sec#011loss=0.605293\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:55 INFO 140144812640064] Epoch[64] Batch[10] avg_epoch_loss=0.597453\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=0.588045531511\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:55 INFO 140144812640064] Epoch[64] Batch [10]#011Speed: 173.58 samples/sec#011loss=0.588046\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:55 INFO 140144812640064] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4619.501113891602, \"sum\": 4619.501113891602, \"min\": 4619.501113891602}}, \"EndTime\": 1587306415.08937, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306410.469295}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:55 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.219920363 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:55 INFO 140144812640064] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=64, train loss <loss>=0.597453401847\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:55 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:55 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_774648b6-bb3c-4817-bcd0-f08e5ab72293-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 62.31093406677246, \"sum\": 62.31093406677246, \"min\": 62.31093406677246}}, \"EndTime\": 1587306415.152326, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306415.089436}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:56 INFO 140144812640064] Epoch[65] Batch[0] avg_epoch_loss=0.795686\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:56 INFO 140144812640064] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=0.795685887337\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:57 INFO 140144812640064] Epoch[65] Batch[5] avg_epoch_loss=1.013421\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:57 INFO 140144812640064] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=1.01342139641\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:57 INFO 140144812640064] Epoch[65] Batch [5]#011Speed: 176.98 samples/sec#011loss=1.013421\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:59 INFO 140144812640064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4206.592082977295, \"sum\": 4206.592082977295, \"min\": 4206.592082977295}}, \"EndTime\": 1587306419.359046, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306415.152394}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:59 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=152.138002454 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:59 INFO 140144812640064] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:59 INFO 140144812640064] #quality_metric: host=algo-1, epoch=65, train loss <loss>=0.971629172564\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:26:59 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:00 INFO 140144812640064] Epoch[66] Batch[0] avg_epoch_loss=1.007602\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:00 INFO 140144812640064] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=1.0076020956\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:02 INFO 140144812640064] Epoch[66] Batch[5] avg_epoch_loss=0.852165\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=0.852165311575\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:02 INFO 140144812640064] Epoch[66] Batch [5]#011Speed: 172.45 samples/sec#011loss=0.852165\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:03 INFO 140144812640064] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4317.934989929199, \"sum\": 4317.934989929199, \"min\": 4317.934989929199}}, \"EndTime\": 1587306423.677728, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306419.359123}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:03 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.131183175 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:03 INFO 140144812640064] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:03 INFO 140144812640064] #quality_metric: host=algo-1, epoch=66, train loss <loss>=0.758123683929\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:03 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:04 INFO 140144812640064] Epoch[67] Batch[0] avg_epoch_loss=0.515189\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=0.515189290047\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:06 INFO 140144812640064] Epoch[67] Batch[5] avg_epoch_loss=0.642250\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:06 INFO 140144812640064] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=0.642249693473\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:06 INFO 140144812640064] Epoch[67] Batch [5]#011Speed: 178.40 samples/sec#011loss=0.642250\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:07 INFO 140144812640064] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4260.849952697754, \"sum\": 4260.849952697754, \"min\": 4260.849952697754}}, \"EndTime\": 1587306427.939386, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306423.677799}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:07 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.965605431 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:07 INFO 140144812640064] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=67, train loss <loss>=0.708964419365\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:07 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:08 INFO 140144812640064] Epoch[68] Batch[0] avg_epoch_loss=0.470244\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:08 INFO 140144812640064] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=0.470244467258\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:10 INFO 140144812640064] Epoch[68] Batch[5] avg_epoch_loss=0.582785\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=0.582784687479\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:10 INFO 140144812640064] Epoch[68] Batch [5]#011Speed: 177.07 samples/sec#011loss=0.582785\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:12 INFO 140144812640064] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4207.836151123047, \"sum\": 4207.836151123047, \"min\": 4207.836151123047}}, \"EndTime\": 1587306432.148013, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306427.939466}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:12 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.815440528 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:12 INFO 140144812640064] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=68, train loss <loss>=0.547776767612\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:12 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:12 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_6c708b30-3a24-43cf-8a04-5b714575bb2b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 66.20097160339355, \"sum\": 66.20097160339355, \"min\": 66.20097160339355}}, \"EndTime\": 1587306432.214805, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306432.148089}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:13 INFO 140144812640064] Epoch[69] Batch[0] avg_epoch_loss=1.003085\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:13 INFO 140144812640064] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=1.0030850172\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:14 INFO 140144812640064] Epoch[69] Batch[5] avg_epoch_loss=0.842421\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:14 INFO 140144812640064] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=0.842420597871\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:14 INFO 140144812640064] Epoch[69] Batch [5]#011Speed: 175.32 samples/sec#011loss=0.842421\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:16 INFO 140144812640064] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4213.871955871582, \"sum\": 4213.871955871582, \"min\": 4213.871955871582}}, \"EndTime\": 1587306436.429338, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306432.215403}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:16 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=148.315912486 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:16 INFO 140144812640064] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:16 INFO 140144812640064] #quality_metric: host=algo-1, epoch=69, train loss <loss>=0.801344239712\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:16 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:17 INFO 140144812640064] Epoch[70] Batch[0] avg_epoch_loss=0.638455\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=0.63845539093\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:19 INFO 140144812640064] Epoch[70] Batch[5] avg_epoch_loss=0.592269\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=0.592269361019\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:19 INFO 140144812640064] Epoch[70] Batch [5]#011Speed: 171.70 samples/sec#011loss=0.592269\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:21 INFO 140144812640064] Epoch[70] Batch[10] avg_epoch_loss=0.576526\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=0.557635051012\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:21 INFO 140144812640064] Epoch[70] Batch [10]#011Speed: 176.82 samples/sec#011loss=0.557635\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:21 INFO 140144812640064] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4618.11900138855, \"sum\": 4618.11900138855, \"min\": 4618.11900138855}}, \"EndTime\": 1587306441.048042, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306436.42941}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:21 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.880369447 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:21 INFO 140144812640064] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=70, train loss <loss>=0.576526492834\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:21 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:22 INFO 140144812640064] Epoch[71] Batch[0] avg_epoch_loss=1.226598\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:22 INFO 140144812640064] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=1.226598382\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:23 INFO 140144812640064] Epoch[71] Batch[5] avg_epoch_loss=0.957844\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:23 INFO 140144812640064] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=0.957843889793\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:23 INFO 140144812640064] Epoch[71] Batch [5]#011Speed: 173.89 samples/sec#011loss=0.957844\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:25 INFO 140144812640064] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4313.957929611206, \"sum\": 4313.957929611206, \"min\": 4313.957929611206}}, \"EndTime\": 1587306445.362503, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306441.048119}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:25 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.656495993 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:25 INFO 140144812640064] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=71, train loss <loss>=0.900705426931\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:25 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:26 INFO 140144812640064] Epoch[72] Batch[0] avg_epoch_loss=0.684635\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=0.68463486433\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:28 INFO 140144812640064] Epoch[72] Batch[5] avg_epoch_loss=0.698027\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=0.698026537895\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:28 INFO 140144812640064] Epoch[72] Batch [5]#011Speed: 173.17 samples/sec#011loss=0.698027\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:29 INFO 140144812640064] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4302.7379512786865, \"sum\": 4302.7379512786865, \"min\": 4302.7379512786865}}, \"EndTime\": 1587306449.6658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306445.362576}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:29 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.928452575 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:29 INFO 140144812640064] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:29 INFO 140144812640064] #quality_metric: host=algo-1, epoch=72, train loss <loss>=0.615377271175\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:29 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:30 INFO 140144812640064] Epoch[73] Batch[0] avg_epoch_loss=0.426978\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=0.426977783442\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:32 INFO 140144812640064] Epoch[73] Batch[5] avg_epoch_loss=0.689036\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:32 INFO 140144812640064] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=0.689036334554\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:32 INFO 140144812640064] Epoch[73] Batch [5]#011Speed: 177.25 samples/sec#011loss=0.689036\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:34 INFO 140144812640064] Epoch[73] Batch[10] avg_epoch_loss=0.785220\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:34 INFO 140144812640064] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=0.900640147924\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:34 INFO 140144812640064] Epoch[73] Batch [10]#011Speed: 171.30 samples/sec#011loss=0.900640\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:34 INFO 140144812640064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4740.05389213562, \"sum\": 4740.05389213562, \"min\": 4740.05389213562}}, \"EndTime\": 1587306454.406349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306449.665877}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:34 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=136.49219169 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:34 INFO 140144812640064] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:34 INFO 140144812640064] #quality_metric: host=algo-1, epoch=73, train loss <loss>=0.785219886086\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:34 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:35 INFO 140144812640064] Epoch[74] Batch[0] avg_epoch_loss=1.090880\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:35 INFO 140144812640064] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=1.09088027477\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:37 INFO 140144812640064] Epoch[74] Batch[5] avg_epoch_loss=1.181235\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:37 INFO 140144812640064] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=1.18123459816\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:37 INFO 140144812640064] Epoch[74] Batch [5]#011Speed: 178.37 samples/sec#011loss=1.181235\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:39 INFO 140144812640064] Epoch[74] Batch[10] avg_epoch_loss=1.119499\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=1.04541733265\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:39 INFO 140144812640064] Epoch[74] Batch [10]#011Speed: 171.85 samples/sec#011loss=1.045417\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:39 INFO 140144812640064] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4609.016895294189, \"sum\": 4609.016895294189, \"min\": 4609.016895294189}}, \"EndTime\": 1587306459.01627, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306454.406453}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:39 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.288394877 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:39 INFO 140144812640064] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=74, train loss <loss>=1.11949947747\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:39 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:39 INFO 140144812640064] Epoch[75] Batch[0] avg_epoch_loss=0.958549\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=0.958549439907\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:41 INFO 140144812640064] Epoch[75] Batch[5] avg_epoch_loss=0.876824\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:41 INFO 140144812640064] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=0.876824031274\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:41 INFO 140144812640064] Epoch[75] Batch [5]#011Speed: 176.99 samples/sec#011loss=0.876824\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:43 INFO 140144812640064] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4212.476968765259, \"sum\": 4212.476968765259, \"min\": 4212.476968765259}}, \"EndTime\": 1587306463.229389, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306459.016354}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:43 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.329710607 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:43 INFO 140144812640064] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=75, train loss <loss>=0.76775380373\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:43 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:44 INFO 140144812640064] Epoch[76] Batch[0] avg_epoch_loss=0.698187\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:44 INFO 140144812640064] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=0.69818675518\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:46 INFO 140144812640064] Epoch[76] Batch[5] avg_epoch_loss=0.577547\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=0.577547152837\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:46 INFO 140144812640064] Epoch[76] Batch [5]#011Speed: 176.46 samples/sec#011loss=0.577547\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:47 INFO 140144812640064] Epoch[76] Batch[10] avg_epoch_loss=0.515452\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:47 INFO 140144812640064] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=0.440938597918\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:47 INFO 140144812640064] Epoch[76] Batch [10]#011Speed: 176.77 samples/sec#011loss=0.440939\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:47 INFO 140144812640064] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4605.686187744141, \"sum\": 4605.686187744141, \"min\": 4605.686187744141}}, \"EndTime\": 1587306467.835664, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306463.22945}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:47 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.553710026 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:47 INFO 140144812640064] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:47 INFO 140144812640064] #quality_metric: host=algo-1, epoch=76, train loss <loss>=0.515452355146\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:47 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:47 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_7d2d26cf-bae5-49a5-869b-caaf0d1fa1c7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 69.51284408569336, \"sum\": 69.51284408569336, \"min\": 69.51284408569336}}, \"EndTime\": 1587306467.90581, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306467.835758}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:48 INFO 140144812640064] Epoch[77] Batch[0] avg_epoch_loss=0.706264\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=0.706264257431\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:50 INFO 140144812640064] Epoch[77] Batch[5] avg_epoch_loss=0.641840\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:50 INFO 140144812640064] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=0.641839747628\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:50 INFO 140144812640064] Epoch[77] Batch [5]#011Speed: 176.68 samples/sec#011loss=0.641840\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:52 INFO 140144812640064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4240.333080291748, \"sum\": 4240.333080291748, \"min\": 4240.333080291748}}, \"EndTime\": 1587306472.146444, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306467.905971}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:52 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=150.925353263 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:52 INFO 140144812640064] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:52 INFO 140144812640064] #quality_metric: host=algo-1, epoch=77, train loss <loss>=0.564369976521\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:52 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:53 INFO 140144812640064] Epoch[78] Batch[0] avg_epoch_loss=0.427298\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=0.427297532558\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:54 INFO 140144812640064] Epoch[78] Batch[5] avg_epoch_loss=0.370519\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:54 INFO 140144812640064] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=0.370518888036\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:54 INFO 140144812640064] Epoch[78] Batch [5]#011Speed: 176.19 samples/sec#011loss=0.370519\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:56 INFO 140144812640064] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4233.189105987549, \"sum\": 4233.189105987549, \"min\": 4233.189105987549}}, \"EndTime\": 1587306476.380474, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306472.146509}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:56 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=148.82028002 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:56 INFO 140144812640064] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:56 INFO 140144812640064] #quality_metric: host=algo-1, epoch=78, train loss <loss>=0.549904304743\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:56 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:57 INFO 140144812640064] Epoch[79] Batch[0] avg_epoch_loss=0.694404\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:57 INFO 140144812640064] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=0.694403588772\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:59 INFO 140144812640064] Epoch[79] Batch[5] avg_epoch_loss=0.684305\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:59 INFO 140144812640064] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=0.684304674466\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:27:59 INFO 140144812640064] Epoch[79] Batch [5]#011Speed: 169.82 samples/sec#011loss=0.684305\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:01 INFO 140144812640064] Epoch[79] Batch[10] avg_epoch_loss=0.616197\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:01 INFO 140144812640064] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=0.534468781948\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:01 INFO 140144812640064] Epoch[79] Batch [10]#011Speed: 170.71 samples/sec#011loss=0.534469\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:01 INFO 140144812640064] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4743.551015853882, \"sum\": 4743.551015853882, \"min\": 4743.551015853882}}, \"EndTime\": 1587306481.124549, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306476.380545}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:01 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=145.456845366 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:01 INFO 140144812640064] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:01 INFO 140144812640064] #quality_metric: host=algo-1, epoch=79, train loss <loss>=0.616197450594\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:01 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:02 INFO 140144812640064] Epoch[80] Batch[0] avg_epoch_loss=0.418092\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=0.418091714382\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:03 INFO 140144812640064] Epoch[80] Batch[5] avg_epoch_loss=0.430718\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:03 INFO 140144812640064] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=0.43071782589\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:03 INFO 140144812640064] Epoch[80] Batch [5]#011Speed: 173.13 samples/sec#011loss=0.430718\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:05 INFO 140144812640064] Epoch[80] Batch[10] avg_epoch_loss=0.415796\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=0.397889369726\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:05 INFO 140144812640064] Epoch[80] Batch [10]#011Speed: 176.42 samples/sec#011loss=0.397889\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:05 INFO 140144812640064] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4619.797945022583, \"sum\": 4619.797945022583, \"min\": 4619.797945022583}}, \"EndTime\": 1587306485.745005, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306481.124631}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:05 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=138.747234279 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:05 INFO 140144812640064] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=80, train loss <loss>=0.415795800361\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:05 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:05 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_bdf4de2a-d838-4b77-89b4-395ba712a32f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 72.7989673614502, \"sum\": 72.7989673614502, \"min\": 72.7989673614502}}, \"EndTime\": 1587306485.818349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306485.745082}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:06 INFO 140144812640064] Epoch[81] Batch[0] avg_epoch_loss=0.656857\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:06 INFO 140144812640064] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=0.656856656075\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:08 INFO 140144812640064] Epoch[81] Batch[5] avg_epoch_loss=0.738946\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:08 INFO 140144812640064] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=0.738946219285\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:08 INFO 140144812640064] Epoch[81] Batch [5]#011Speed: 172.79 samples/sec#011loss=0.738946\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:10 INFO 140144812640064] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4285.13503074646, \"sum\": 4285.13503074646, \"min\": 4285.13503074646}}, \"EndTime\": 1587306490.103852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306485.818655}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:10 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.116745087 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:10 INFO 140144812640064] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=81, train loss <loss>=0.684116312861\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:10 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:11 INFO 140144812640064] Epoch[82] Batch[0] avg_epoch_loss=0.408910\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:11 INFO 140144812640064] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=0.408909887075\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:12 INFO 140144812640064] Epoch[82] Batch[5] avg_epoch_loss=0.473276\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=0.473275860151\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:12 INFO 140144812640064] Epoch[82] Batch [5]#011Speed: 175.71 samples/sec#011loss=0.473276\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:14 INFO 140144812640064] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4226.303815841675, \"sum\": 4226.303815841675, \"min\": 4226.303815841675}}, \"EndTime\": 1587306494.330691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306490.103916}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:14 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.147763431 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:14 INFO 140144812640064] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:14 INFO 140144812640064] #quality_metric: host=algo-1, epoch=82, train loss <loss>=0.434961414337\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:14 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:15 INFO 140144812640064] Epoch[83] Batch[0] avg_epoch_loss=0.257314\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:15 INFO 140144812640064] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=0.25731408596\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:17 INFO 140144812640064] Epoch[83] Batch[5] avg_epoch_loss=0.579732\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=0.579731504122\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:17 INFO 140144812640064] Epoch[83] Batch [5]#011Speed: 175.12 samples/sec#011loss=0.579732\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:18 INFO 140144812640064] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4262.401103973389, \"sum\": 4262.401103973389, \"min\": 4262.401103973389}}, \"EndTime\": 1587306498.593726, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306494.33075}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:18 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.329201104 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:18 INFO 140144812640064] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:18 INFO 140144812640064] #quality_metric: host=algo-1, epoch=83, train loss <loss>=0.563794878125\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:18 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:19 INFO 140144812640064] Epoch[84] Batch[0] avg_epoch_loss=0.458917\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=0.458916753531\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:21 INFO 140144812640064] Epoch[84] Batch[5] avg_epoch_loss=0.489399\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=0.489398832122\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:21 INFO 140144812640064] Epoch[84] Batch [5]#011Speed: 176.68 samples/sec#011loss=0.489399\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:23 INFO 140144812640064] Epoch[84] Batch[10] avg_epoch_loss=0.548280\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:23 INFO 140144812640064] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=0.618938186765\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:23 INFO 140144812640064] Epoch[84] Batch [10]#011Speed: 175.40 samples/sec#011loss=0.618938\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:23 INFO 140144812640064] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4596.765995025635, \"sum\": 4596.765995025635, \"min\": 4596.765995025635}}, \"EndTime\": 1587306503.191211, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306498.593791}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:23 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.48426201 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:23 INFO 140144812640064] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:23 INFO 140144812640064] #quality_metric: host=algo-1, epoch=84, train loss <loss>=0.54828035696\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:23 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:24 INFO 140144812640064] Epoch[85] Batch[0] avg_epoch_loss=0.832455\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:24 INFO 140144812640064] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=0.83245486021\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:26 INFO 140144812640064] Epoch[85] Batch[5] avg_epoch_loss=0.709162\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=0.709162498514\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:26 INFO 140144812640064] Epoch[85] Batch [5]#011Speed: 177.10 samples/sec#011loss=0.709162\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:27 INFO 140144812640064] Epoch[85] Batch[10] avg_epoch_loss=0.722516\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:27 INFO 140144812640064] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=0.738539922237\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:27 INFO 140144812640064] Epoch[85] Batch [10]#011Speed: 176.83 samples/sec#011loss=0.738540\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:27 INFO 140144812640064] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4629.987955093384, \"sum\": 4629.987955093384, \"min\": 4629.987955093384}}, \"EndTime\": 1587306507.822007, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306503.191403}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:27 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.193384818 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:27 INFO 140144812640064] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:27 INFO 140144812640064] #quality_metric: host=algo-1, epoch=85, train loss <loss>=0.722515872934\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:27 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:28 INFO 140144812640064] Epoch[86] Batch[0] avg_epoch_loss=0.693895\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=0.69389539957\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:30 INFO 140144812640064] Epoch[86] Batch[5] avg_epoch_loss=0.608623\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=0.608622997999\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:30 INFO 140144812640064] Epoch[86] Batch [5]#011Speed: 173.31 samples/sec#011loss=0.608623\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:32 INFO 140144812640064] Epoch[86] Batch[10] avg_epoch_loss=0.533248\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:32 INFO 140144812640064] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=0.4427985847\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:32 INFO 140144812640064] Epoch[86] Batch [10]#011Speed: 170.43 samples/sec#011loss=0.442799\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:32 INFO 140144812640064] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4698.116064071655, \"sum\": 4698.116064071655, \"min\": 4698.116064071655}}, \"EndTime\": 1587306512.520671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306507.822079}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:32 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.201357975 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:32 INFO 140144812640064] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:32 INFO 140144812640064] #quality_metric: host=algo-1, epoch=86, train loss <loss>=0.533248264681\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:32 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:33 INFO 140144812640064] Epoch[87] Batch[0] avg_epoch_loss=0.426440\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:33 INFO 140144812640064] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=0.426439702511\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:35 INFO 140144812640064] Epoch[87] Batch[5] avg_epoch_loss=0.498059\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:35 INFO 140144812640064] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=0.498058597247\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:35 INFO 140144812640064] Epoch[87] Batch [5]#011Speed: 171.37 samples/sec#011loss=0.498059\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:37 INFO 140144812640064] Epoch[87] Batch[10] avg_epoch_loss=0.458656\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:37 INFO 140144812640064] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=0.411373564601\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:37 INFO 140144812640064] Epoch[87] Batch [10]#011Speed: 178.34 samples/sec#011loss=0.411374\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:37 INFO 140144812640064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4654.667139053345, \"sum\": 4654.667139053345, \"min\": 4654.667139053345}}, \"EndTime\": 1587306517.175914, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306512.520743}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:37 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=138.997018677 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:37 INFO 140144812640064] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:37 INFO 140144812640064] #quality_metric: host=algo-1, epoch=87, train loss <loss>=0.458656309681\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:37 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:38 INFO 140144812640064] Epoch[88] Batch[0] avg_epoch_loss=0.662251\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:38 INFO 140144812640064] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=0.662250638008\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:40 INFO 140144812640064] Epoch[88] Batch[5] avg_epoch_loss=0.793262\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=0.793261746566\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:40 INFO 140144812640064] Epoch[88] Batch [5]#011Speed: 168.05 samples/sec#011loss=0.793262\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:41 INFO 140144812640064] Epoch[88] Batch[10] avg_epoch_loss=0.740338\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:41 INFO 140144812640064] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=0.676828825474\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:41 INFO 140144812640064] Epoch[88] Batch [10]#011Speed: 176.19 samples/sec#011loss=0.676829\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:41 INFO 140144812640064] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4678.132057189941, \"sum\": 4678.132057189941, \"min\": 4678.132057189941}}, \"EndTime\": 1587306521.85463, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306517.175988}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:41 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.00231261 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:41 INFO 140144812640064] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:41 INFO 140144812640064] #quality_metric: host=algo-1, epoch=88, train loss <loss>=0.740337691524\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:41 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:42 INFO 140144812640064] Epoch[89] Batch[0] avg_epoch_loss=0.756702\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=0.756702125072\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:44 INFO 140144812640064] Epoch[89] Batch[5] avg_epoch_loss=0.589367\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:44 INFO 140144812640064] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=0.589366982381\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:44 INFO 140144812640064] Epoch[89] Batch [5]#011Speed: 173.88 samples/sec#011loss=0.589367\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:46 INFO 140144812640064] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4252.699851989746, \"sum\": 4252.699851989746, \"min\": 4252.699851989746}}, \"EndTime\": 1587306526.107986, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306521.854705}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:46 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.788406884 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:46 INFO 140144812640064] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=89, train loss <loss>=0.588459566236\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:46 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:47 INFO 140144812640064] Epoch[90] Batch[0] avg_epoch_loss=0.466818\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:47 INFO 140144812640064] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=0.466818034649\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:48 INFO 140144812640064] Epoch[90] Batch[5] avg_epoch_loss=0.410135\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=0.410134851933\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:48 INFO 140144812640064] Epoch[90] Batch [5]#011Speed: 173.52 samples/sec#011loss=0.410135\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:50 INFO 140144812640064] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4320.851802825928, \"sum\": 4320.851802825928, \"min\": 4320.851802825928}}, \"EndTime\": 1587306530.429372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306526.108063}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:50 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=145.337494121 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:50 INFO 140144812640064] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:50 INFO 140144812640064] #quality_metric: host=algo-1, epoch=90, train loss <loss>=0.483053159714\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:50 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:51 INFO 140144812640064] Epoch[91] Batch[0] avg_epoch_loss=0.338619\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:51 INFO 140144812640064] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=0.338618725538\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:53 INFO 140144812640064] Epoch[91] Batch[5] avg_epoch_loss=0.477860\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=0.477860018611\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:53 INFO 140144812640064] Epoch[91] Batch [5]#011Speed: 177.74 samples/sec#011loss=0.477860\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:55 INFO 140144812640064] Epoch[91] Batch[10] avg_epoch_loss=0.451442\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=0.419740617275\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:55 INFO 140144812640064] Epoch[91] Batch [10]#011Speed: 172.25 samples/sec#011loss=0.419741\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:55 INFO 140144812640064] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4634.469985961914, \"sum\": 4634.469985961914, \"min\": 4634.469985961914}}, \"EndTime\": 1587306535.064564, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306530.429457}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:55 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.112990303 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:55 INFO 140144812640064] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=91, train loss <loss>=0.451442108913\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:55 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:56 INFO 140144812640064] Epoch[92] Batch[0] avg_epoch_loss=0.631175\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:56 INFO 140144812640064] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=0.631174683571\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:57 INFO 140144812640064] Epoch[92] Batch[5] avg_epoch_loss=0.555321\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:57 INFO 140144812640064] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=0.555320988099\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:57 INFO 140144812640064] Epoch[92] Batch [5]#011Speed: 176.04 samples/sec#011loss=0.555321\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:59 INFO 140144812640064] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4314.816951751709, \"sum\": 4314.816951751709, \"min\": 4314.816951751709}}, \"EndTime\": 1587306539.379855, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306535.06464}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:59 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.759807428 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:59 INFO 140144812640064] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:59 INFO 140144812640064] #quality_metric: host=algo-1, epoch=92, train loss <loss>=0.499920807779\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:28:59 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:00 INFO 140144812640064] Epoch[93] Batch[0] avg_epoch_loss=0.303028\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:00 INFO 140144812640064] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=0.303027838469\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:02 INFO 140144812640064] Epoch[93] Batch[5] avg_epoch_loss=0.419190\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=0.419189775983\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:02 INFO 140144812640064] Epoch[93] Batch [5]#011Speed: 169.89 samples/sec#011loss=0.419190\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:04 INFO 140144812640064] Epoch[93] Batch[10] avg_epoch_loss=0.414033\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=0.407844990492\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:04 INFO 140144812640064] Epoch[93] Batch [10]#011Speed: 174.19 samples/sec#011loss=0.407845\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:04 INFO 140144812640064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4675.346851348877, \"sum\": 4675.346851348877, \"min\": 4675.346851348877}}, \"EndTime\": 1587306544.055845, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306539.379939}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:04 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=138.382102753 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:04 INFO 140144812640064] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=93, train loss <loss>=0.414033055305\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:04 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:04 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_314feefb-da6f-47a2-9d50-a2004284c479-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 89.48493003845215, \"sum\": 89.48493003845215, \"min\": 89.48493003845215}}, \"EndTime\": 1587306544.145862, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306544.05592}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:05 INFO 140144812640064] Epoch[94] Batch[0] avg_epoch_loss=0.593591\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=0.593591034412\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:06 INFO 140144812640064] Epoch[94] Batch[5] avg_epoch_loss=0.633840\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:06 INFO 140144812640064] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=0.633840163549\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:06 INFO 140144812640064] Epoch[94] Batch [5]#011Speed: 176.16 samples/sec#011loss=0.633840\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:08 INFO 140144812640064] Epoch[94] Batch[10] avg_epoch_loss=0.588052\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:08 INFO 140144812640064] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=0.53310534358\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:08 INFO 140144812640064] Epoch[94] Batch [10]#011Speed: 176.15 samples/sec#011loss=0.533105\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:08 INFO 140144812640064] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4603.191137313843, \"sum\": 4603.191137313843, \"min\": 4603.191137313843}}, \"EndTime\": 1587306548.749177, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306544.145932}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:08 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.416129304 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:08 INFO 140144812640064] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:08 INFO 140144812640064] #quality_metric: host=algo-1, epoch=94, train loss <loss>=0.588051609018\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:08 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:09 INFO 140144812640064] Epoch[95] Batch[0] avg_epoch_loss=0.592600\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:09 INFO 140144812640064] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=0.592599570751\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:11 INFO 140144812640064] Epoch[95] Batch[5] avg_epoch_loss=0.387736\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:11 INFO 140144812640064] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=0.387736126781\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:11 INFO 140144812640064] Epoch[95] Batch [5]#011Speed: 174.23 samples/sec#011loss=0.387736\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140144812640064] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4280.021190643311, \"sum\": 4280.021190643311, \"min\": 4280.021190643311}}, \"EndTime\": 1587306553.029687, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306548.749271}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.893152182 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140144812640064] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140144812640064] #quality_metric: host=algo-1, epoch=95, train loss <loss>=0.360983130336\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:13 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_54f997aa-da18-435d-a78c-943c773fecbd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 60.99700927734375, \"sum\": 60.99700927734375, \"min\": 60.99700927734375}}, \"EndTime\": 1587306553.091531, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306553.029746}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:14 INFO 140144812640064] Epoch[96] Batch[0] avg_epoch_loss=0.851813\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:14 INFO 140144812640064] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=0.851812899113\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:15 INFO 140144812640064] Epoch[96] Batch[5] avg_epoch_loss=0.555823\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:15 INFO 140144812640064] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=0.55582283934\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:15 INFO 140144812640064] Epoch[96] Batch [5]#011Speed: 173.25 samples/sec#011loss=0.555823\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:17 INFO 140144812640064] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4272.058963775635, \"sum\": 4272.058963775635, \"min\": 4272.058963775635}}, \"EndTime\": 1587306557.363716, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306553.0916}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:17 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.700112619 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:17 INFO 140144812640064] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=96, train loss <loss>=0.560625040531\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:17 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:18 INFO 140144812640064] Epoch[97] Batch[0] avg_epoch_loss=0.495696\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:18 INFO 140144812640064] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=0.495696276426\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:20 INFO 140144812640064] Epoch[97] Batch[5] avg_epoch_loss=0.397111\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:20 INFO 140144812640064] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=0.397110573947\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:20 INFO 140144812640064] Epoch[97] Batch [5]#011Speed: 174.42 samples/sec#011loss=0.397111\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:21 INFO 140144812640064] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4260.648012161255, \"sum\": 4260.648012161255, \"min\": 4260.648012161255}}, \"EndTime\": 1587306561.624897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306557.36379}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:21 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.391922176 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:21 INFO 140144812640064] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=97, train loss <loss>=0.349942745268\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:21 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:21 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_2823ed8c-1c1a-4559-ac20-c1004876cd4c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 64.18395042419434, \"sum\": 64.18395042419434, \"min\": 64.18395042419434}}, \"EndTime\": 1587306561.689939, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306561.624957}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:22 INFO 140144812640064] Epoch[98] Batch[0] avg_epoch_loss=0.199282\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:22 INFO 140144812640064] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=0.199281841516\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:24 INFO 140144812640064] Epoch[98] Batch[5] avg_epoch_loss=0.296912\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:24 INFO 140144812640064] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=0.296912324925\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:24 INFO 140144812640064] Epoch[98] Batch [5]#011Speed: 172.58 samples/sec#011loss=0.296912\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140144812640064] Epoch[98] Batch[10] avg_epoch_loss=0.295354\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=0.293484326638\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140144812640064] Epoch[98] Batch [10]#011Speed: 176.63 samples/sec#011loss=0.293484\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140144812640064] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4617.790937423706, \"sum\": 4617.790937423706, \"min\": 4617.790937423706}}, \"EndTime\": 1587306566.307869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306561.690008}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.488513158 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140144812640064] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=98, train loss <loss>=0.295354143886\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:26 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_71d7bab5-700e-48e8-b6cc-3dea6e25a9c5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.231136322021484, \"sum\": 61.231136322021484, \"min\": 61.231136322021484}}, \"EndTime\": 1587306566.369788, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306566.307952}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:27 INFO 140144812640064] Epoch[99] Batch[0] avg_epoch_loss=0.654621\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:27 INFO 140144812640064] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=0.654621243477\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:29 INFO 140144812640064] Epoch[99] Batch[5] avg_epoch_loss=0.551036\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:29 INFO 140144812640064] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=0.551036010186\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:29 INFO 140144812640064] Epoch[99] Batch [5]#011Speed: 173.48 samples/sec#011loss=0.551036\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:30 INFO 140144812640064] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4266.4549350738525, \"sum\": 4266.4549350738525, \"min\": 4266.4549350738525}}, \"EndTime\": 1587306570.636392, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306566.369866}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:30 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.953043431 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:30 INFO 140144812640064] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=99, train loss <loss>=0.50669490993\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:30 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:31 INFO 140144812640064] Epoch[100] Batch[0] avg_epoch_loss=0.410893\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:31 INFO 140144812640064] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=0.410892874002\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:33 INFO 140144812640064] Epoch[100] Batch[5] avg_epoch_loss=0.340482\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:33 INFO 140144812640064] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=0.34048199902\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:33 INFO 140144812640064] Epoch[100] Batch [5]#011Speed: 175.95 samples/sec#011loss=0.340482\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:35 INFO 140144812640064] Epoch[100] Batch[10] avg_epoch_loss=0.315579\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:35 INFO 140144812640064] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=0.285695675015\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:35 INFO 140144812640064] Epoch[100] Batch [10]#011Speed: 175.60 samples/sec#011loss=0.285696\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:35 INFO 140144812640064] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4630.224943161011, \"sum\": 4630.224943161011, \"min\": 4630.224943161011}}, \"EndTime\": 1587306575.267676, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306570.636563}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:35 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.298773654 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:35 INFO 140144812640064] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:35 INFO 140144812640064] #quality_metric: host=algo-1, epoch=100, train loss <loss>=0.315579124472\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:35 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:36 INFO 140144812640064] Epoch[101] Batch[0] avg_epoch_loss=2.233835\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:36 INFO 140144812640064] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=2.23383522034\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:38 INFO 140144812640064] Epoch[101] Batch[5] avg_epoch_loss=1.514622\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:38 INFO 140144812640064] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=1.51462246974\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:38 INFO 140144812640064] Epoch[101] Batch [5]#011Speed: 175.81 samples/sec#011loss=1.514622\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:39 INFO 140144812640064] Epoch[101] Batch[10] avg_epoch_loss=1.421925\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=1.31068701744\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:39 INFO 140144812640064] Epoch[101] Batch [10]#011Speed: 171.32 samples/sec#011loss=1.310687\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:39 INFO 140144812640064] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4643.706798553467, \"sum\": 4643.706798553467, \"min\": 4643.706798553467}}, \"EndTime\": 1587306579.911967, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306575.26775}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:39 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.909460202 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:39 INFO 140144812640064] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=101, train loss <loss>=1.42192453688\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:39 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:40 INFO 140144812640064] Epoch[102] Batch[0] avg_epoch_loss=1.305904\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=1.3059040308\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:42 INFO 140144812640064] Epoch[102] Batch[5] avg_epoch_loss=1.208142\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=1.20814218124\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:42 INFO 140144812640064] Epoch[102] Batch [5]#011Speed: 174.90 samples/sec#011loss=1.208142\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:44 INFO 140144812640064] Epoch[102] Batch[10] avg_epoch_loss=1.063719\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:44 INFO 140144812640064] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=0.890410256386\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:44 INFO 140144812640064] Epoch[102] Batch [10]#011Speed: 171.87 samples/sec#011loss=0.890410\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:44 INFO 140144812640064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4655.702114105225, \"sum\": 4655.702114105225, \"min\": 4655.702114105225}}, \"EndTime\": 1587306584.568218, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306579.912027}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:44 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=138.965614736 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:44 INFO 140144812640064] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:44 INFO 140144812640064] #quality_metric: host=algo-1, epoch=102, train loss <loss>=1.06371857903\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:44 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:45 INFO 140144812640064] Epoch[103] Batch[0] avg_epoch_loss=0.786526\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:45 INFO 140144812640064] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=0.786525964737\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:47 INFO 140144812640064] Epoch[103] Batch[5] avg_epoch_loss=0.684606\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:47 INFO 140144812640064] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=0.684605558713\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:47 INFO 140144812640064] Epoch[103] Batch [5]#011Speed: 177.71 samples/sec#011loss=0.684606\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:48 INFO 140144812640064] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4207.450866699219, \"sum\": 4207.450866699219, \"min\": 4207.450866699219}}, \"EndTime\": 1587306588.776274, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306584.568304}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:48 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.26430361 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:48 INFO 140144812640064] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=103, train loss <loss>=0.609470567107\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:48 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:49 INFO 140144812640064] Epoch[104] Batch[0] avg_epoch_loss=0.468446\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:49 INFO 140144812640064] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=0.468446165323\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:51 INFO 140144812640064] Epoch[104] Batch[5] avg_epoch_loss=0.394460\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:51 INFO 140144812640064] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=0.394460111856\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:51 INFO 140144812640064] Epoch[104] Batch [5]#011Speed: 175.24 samples/sec#011loss=0.394460\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:53 INFO 140144812640064] Epoch[104] Batch[10] avg_epoch_loss=0.404021\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=0.415493887663\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:53 INFO 140144812640064] Epoch[104] Batch [10]#011Speed: 177.48 samples/sec#011loss=0.415494\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:53 INFO 140144812640064] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4603.911876678467, \"sum\": 4603.911876678467, \"min\": 4603.911876678467}}, \"EndTime\": 1587306593.380914, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306588.77634}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:53 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.832509989 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:53 INFO 140144812640064] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=104, train loss <loss>=0.404020919041\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:53 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:54 INFO 140144812640064] Epoch[105] Batch[0] avg_epoch_loss=0.462296\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:54 INFO 140144812640064] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=0.462296098471\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:56 INFO 140144812640064] Epoch[105] Batch[5] avg_epoch_loss=0.573387\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:56 INFO 140144812640064] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=0.573387414217\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:56 INFO 140144812640064] Epoch[105] Batch [5]#011Speed: 173.70 samples/sec#011loss=0.573387\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:57 INFO 140144812640064] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4241.096019744873, \"sum\": 4241.096019744873, \"min\": 4241.096019744873}}, \"EndTime\": 1587306597.622549, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306593.380985}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:57 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.298102993 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:57 INFO 140144812640064] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:57 INFO 140144812640064] #quality_metric: host=algo-1, epoch=105, train loss <loss>=0.546332815289\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:57 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:58 INFO 140144812640064] Epoch[106] Batch[0] avg_epoch_loss=0.681905\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:29:58 INFO 140144812640064] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=0.681905210018\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:00 INFO 140144812640064] Epoch[106] Batch[5] avg_epoch_loss=0.489222\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:00 INFO 140144812640064] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=0.489222268263\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:00 INFO 140144812640064] Epoch[106] Batch [5]#011Speed: 171.55 samples/sec#011loss=0.489222\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:02 INFO 140144812640064] Epoch[106] Batch[10] avg_epoch_loss=0.442710\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=0.386894184351\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:02 INFO 140144812640064] Epoch[106] Batch [10]#011Speed: 169.10 samples/sec#011loss=0.386894\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:02 INFO 140144812640064] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4771.862983703613, \"sum\": 4771.862983703613, \"min\": 4771.862983703613}}, \"EndTime\": 1587306602.394997, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306597.622634}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:02 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=138.517042168 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:02 INFO 140144812640064] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=106, train loss <loss>=0.442709502849\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:02 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:03 INFO 140144812640064] Epoch[107] Batch[0] avg_epoch_loss=0.381743\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:03 INFO 140144812640064] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=0.381743133068\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:05 INFO 140144812640064] Epoch[107] Batch[5] avg_epoch_loss=0.323210\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=0.323209586243\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:05 INFO 140144812640064] Epoch[107] Batch [5]#011Speed: 172.91 samples/sec#011loss=0.323210\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:07 INFO 140144812640064] Epoch[107] Batch[10] avg_epoch_loss=0.286539\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=0.242535093427\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:07 INFO 140144812640064] Epoch[107] Batch [10]#011Speed: 176.58 samples/sec#011loss=0.242535\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:07 INFO 140144812640064] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4647.831916809082, \"sum\": 4647.831916809082, \"min\": 4647.831916809082}}, \"EndTime\": 1587306607.04333, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306602.395074}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:07 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=138.340404588 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:07 INFO 140144812640064] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=107, train loss <loss>=0.286539362236\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:07 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:07 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_6ccee4ff-058b-41f6-92fe-9f62441fdc82-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 59.96394157409668, \"sum\": 59.96394157409668, \"min\": 59.96394157409668}}, \"EndTime\": 1587306607.103932, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306607.043412}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:08 INFO 140144812640064] Epoch[108] Batch[0] avg_epoch_loss=0.769509\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:08 INFO 140144812640064] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=0.769508719444\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:10 INFO 140144812640064] Epoch[108] Batch[5] avg_epoch_loss=0.535439\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=0.53543873628\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:10 INFO 140144812640064] Epoch[108] Batch [5]#011Speed: 161.58 samples/sec#011loss=0.535439\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:11 INFO 140144812640064] Epoch[108] Batch[10] avg_epoch_loss=0.489309\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:11 INFO 140144812640064] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=0.433953046799\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:11 INFO 140144812640064] Epoch[108] Batch [10]#011Speed: 170.70 samples/sec#011loss=0.433953\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:11 INFO 140144812640064] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4830.250978469849, \"sum\": 4830.250978469849, \"min\": 4830.250978469849}}, \"EndTime\": 1587306611.934324, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306607.10401}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:11 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=140.983310459 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:11 INFO 140144812640064] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:11 INFO 140144812640064] #quality_metric: host=algo-1, epoch=108, train loss <loss>=0.489308877425\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:11 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:12 INFO 140144812640064] Epoch[109] Batch[0] avg_epoch_loss=0.306658\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=0.306657880545\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:14 INFO 140144812640064] Epoch[109] Batch[5] avg_epoch_loss=0.285453\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:14 INFO 140144812640064] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=0.285452969372\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:14 INFO 140144812640064] Epoch[109] Batch [5]#011Speed: 171.12 samples/sec#011loss=0.285453\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:16 INFO 140144812640064] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4283.6668491363525, \"sum\": 4283.6668491363525, \"min\": 4283.6668491363525}}, \"EndTime\": 1587306616.218444, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306611.934396}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:16 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.031437197 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:16 INFO 140144812640064] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:16 INFO 140144812640064] #quality_metric: host=algo-1, epoch=109, train loss <loss>=0.233130189031\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:16 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:16 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_76d89bb3-90a0-4dfe-a777-8393c65cf798-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 65.17481803894043, \"sum\": 65.17481803894043, \"min\": 65.17481803894043}}, \"EndTime\": 1587306616.284296, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306616.218524}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:17 INFO 140144812640064] Epoch[110] Batch[0] avg_epoch_loss=0.462689\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=0.46268850565\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:19 INFO 140144812640064] Epoch[110] Batch[5] avg_epoch_loss=0.277148\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=0.277148067951\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:19 INFO 140144812640064] Epoch[110] Batch [5]#011Speed: 175.95 samples/sec#011loss=0.277148\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:20 INFO 140144812640064] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4258.542060852051, \"sum\": 4258.542060852051, \"min\": 4258.542060852051}}, \"EndTime\": 1587306620.542966, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306616.284363}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:20 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=145.116407933 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:20 INFO 140144812640064] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:20 INFO 140144812640064] #quality_metric: host=algo-1, epoch=110, train loss <loss>=0.239472786849\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:20 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:21 INFO 140144812640064] Epoch[111] Batch[0] avg_epoch_loss=0.188877\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=0.188876792789\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:23 INFO 140144812640064] Epoch[111] Batch[5] avg_epoch_loss=0.145635\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:23 INFO 140144812640064] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=0.145634807646\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:23 INFO 140144812640064] Epoch[111] Batch [5]#011Speed: 176.17 samples/sec#011loss=0.145635\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:24 INFO 140144812640064] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4226.758003234863, \"sum\": 4226.758003234863, \"min\": 4226.758003234863}}, \"EndTime\": 1587306624.770275, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306620.543034}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:24 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.390142608 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:24 INFO 140144812640064] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:24 INFO 140144812640064] #quality_metric: host=algo-1, epoch=111, train loss <loss>=0.369909356534\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:24 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:25 INFO 140144812640064] Epoch[112] Batch[0] avg_epoch_loss=0.725999\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=0.725999414921\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:27 INFO 140144812640064] Epoch[112] Batch[5] avg_epoch_loss=0.642883\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:27 INFO 140144812640064] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=0.642882724603\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:27 INFO 140144812640064] Epoch[112] Batch [5]#011Speed: 176.00 samples/sec#011loss=0.642883\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:29 INFO 140144812640064] Epoch[112] Batch[10] avg_epoch_loss=0.571096\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:29 INFO 140144812640064] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=0.48495233655\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:29 INFO 140144812640064] Epoch[112] Batch [10]#011Speed: 177.40 samples/sec#011loss=0.484952\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:29 INFO 140144812640064] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4659.5518589019775, \"sum\": 4659.5518589019775, \"min\": 4659.5518589019775}}, \"EndTime\": 1587306629.430397, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306624.770354}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:29 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.426443723 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:29 INFO 140144812640064] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:29 INFO 140144812640064] #quality_metric: host=algo-1, epoch=112, train loss <loss>=0.571096184579\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:29 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:30 INFO 140144812640064] Epoch[113] Batch[0] avg_epoch_loss=0.451001\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=0.451001107693\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:32 INFO 140144812640064] Epoch[113] Batch[5] avg_epoch_loss=0.460435\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:32 INFO 140144812640064] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=0.46043510735\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:32 INFO 140144812640064] Epoch[113] Batch [5]#011Speed: 169.95 samples/sec#011loss=0.460435\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:34 INFO 140144812640064] Epoch[113] Batch[10] avg_epoch_loss=0.343900\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:34 INFO 140144812640064] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=0.204057796299\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:34 INFO 140144812640064] Epoch[113] Batch [10]#011Speed: 176.72 samples/sec#011loss=0.204058\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:34 INFO 140144812640064] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4734.48920249939, \"sum\": 4734.48920249939, \"min\": 4734.48920249939}}, \"EndTime\": 1587306634.165439, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306629.430475}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:34 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=136.230948535 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:34 INFO 140144812640064] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:34 INFO 140144812640064] #quality_metric: host=algo-1, epoch=113, train loss <loss>=0.343899965964\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:34 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:35 INFO 140144812640064] Epoch[114] Batch[0] avg_epoch_loss=0.495295\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:35 INFO 140144812640064] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=0.495295226574\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:36 INFO 140144812640064] Epoch[114] Batch[5] avg_epoch_loss=0.380488\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:36 INFO 140144812640064] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=0.380487591028\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:36 INFO 140144812640064] Epoch[114] Batch [5]#011Speed: 176.13 samples/sec#011loss=0.380488\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:38 INFO 140144812640064] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4245.759010314941, \"sum\": 4245.759010314941, \"min\": 4245.759010314941}}, \"EndTime\": 1587306638.41175, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306634.165519}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:38 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.557346966 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:38 INFO 140144812640064] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:38 INFO 140144812640064] #quality_metric: host=algo-1, epoch=114, train loss <loss>=0.327805183828\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:38 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:39 INFO 140144812640064] Epoch[115] Batch[0] avg_epoch_loss=0.285074\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=0.285074234009\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:41 INFO 140144812640064] Epoch[115] Batch[5] avg_epoch_loss=0.194113\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:41 INFO 140144812640064] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=0.194113241509\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:41 INFO 140144812640064] Epoch[115] Batch [5]#011Speed: 172.50 samples/sec#011loss=0.194113\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:42 INFO 140144812640064] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4276.408910751343, \"sum\": 4276.408910751343, \"min\": 4276.408910751343}}, \"EndTime\": 1587306642.688766, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306638.411819}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:42 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=145.679026078 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:42 INFO 140144812640064] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=115, train loss <loss>=0.2055366043\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:42 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:42 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_49f33074-d3a8-42bd-8fc7-056cef45a6a8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.64884567260742, \"sum\": 61.64884567260742, \"min\": 61.64884567260742}}, \"EndTime\": 1587306642.751183, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306642.688842}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:43 INFO 140144812640064] Epoch[116] Batch[0] avg_epoch_loss=0.258599\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=0.258599251509\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:45 INFO 140144812640064] Epoch[116] Batch[5] avg_epoch_loss=0.252757\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:45 INFO 140144812640064] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=0.252756997943\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:45 INFO 140144812640064] Epoch[116] Batch [5]#011Speed: 174.70 samples/sec#011loss=0.252757\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:46 INFO 140144812640064] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4213.613033294678, \"sum\": 4213.613033294678, \"min\": 4213.613033294678}}, \"EndTime\": 1587306646.964937, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306642.75126}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:46 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.578121615 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:46 INFO 140144812640064] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=116, train loss <loss>=0.22012906149\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:46 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:48 INFO 140144812640064] Epoch[117] Batch[0] avg_epoch_loss=0.139607\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=0.139607429504\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:49 INFO 140144812640064] Epoch[117] Batch[5] avg_epoch_loss=0.247658\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:49 INFO 140144812640064] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=0.247657924891\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:49 INFO 140144812640064] Epoch[117] Batch [5]#011Speed: 173.87 samples/sec#011loss=0.247658\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:51 INFO 140144812640064] Epoch[117] Batch[10] avg_epoch_loss=0.246403\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:51 INFO 140144812640064] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=0.24489607811\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:51 INFO 140144812640064] Epoch[117] Batch [10]#011Speed: 176.62 samples/sec#011loss=0.244896\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:51 INFO 140144812640064] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4688.536882400513, \"sum\": 4688.536882400513, \"min\": 4688.536882400513}}, \"EndTime\": 1587306651.654048, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306646.965018}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:51 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.912309131 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:51 INFO 140144812640064] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:51 INFO 140144812640064] #quality_metric: host=algo-1, epoch=117, train loss <loss>=0.24640253999\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:51 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:52 INFO 140144812640064] Epoch[118] Batch[0] avg_epoch_loss=0.632300\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:52 INFO 140144812640064] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=0.632300078869\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:54 INFO 140144812640064] Epoch[118] Batch[5] avg_epoch_loss=0.581231\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:54 INFO 140144812640064] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=0.581231370568\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:54 INFO 140144812640064] Epoch[118] Batch [5]#011Speed: 174.54 samples/sec#011loss=0.581231\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:55 INFO 140144812640064] processed a total of 592 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4242.807865142822, \"sum\": 4242.807865142822, \"min\": 4242.807865142822}}, \"EndTime\": 1587306655.897431, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306651.654124}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:55 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.526782406 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:55 INFO 140144812640064] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=118, train loss <loss>=0.583176773787\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:55 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:56 INFO 140144812640064] Epoch[119] Batch[0] avg_epoch_loss=0.382863\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:56 INFO 140144812640064] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=0.382863134146\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:58 INFO 140144812640064] Epoch[119] Batch[5] avg_epoch_loss=0.331938\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:58 INFO 140144812640064] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=0.331937583784\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:30:58 INFO 140144812640064] Epoch[119] Batch [5]#011Speed: 176.16 samples/sec#011loss=0.331938\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:00 INFO 140144812640064] Epoch[119] Batch[10] avg_epoch_loss=0.272064\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:00 INFO 140144812640064] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=0.200214806199\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:00 INFO 140144812640064] Epoch[119] Batch [10]#011Speed: 173.60 samples/sec#011loss=0.200215\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:00 INFO 140144812640064] processed a total of 692 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4662.638902664185, \"sum\": 4662.638902664185, \"min\": 4662.638902664185}}, \"EndTime\": 1587306660.560846, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306655.897503}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:00 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=148.410462441 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:00 INFO 140144812640064] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:00 INFO 140144812640064] #quality_metric: host=algo-1, epoch=119, train loss <loss>=0.272063593973\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:00 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:01 INFO 140144812640064] Epoch[120] Batch[0] avg_epoch_loss=0.440575\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:01 INFO 140144812640064] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=0.440575301647\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:03 INFO 140144812640064] Epoch[120] Batch[5] avg_epoch_loss=0.339410\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:03 INFO 140144812640064] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=0.339410228034\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:03 INFO 140144812640064] Epoch[120] Batch [5]#011Speed: 175.74 samples/sec#011loss=0.339410\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:05 INFO 140144812640064] Epoch[120] Batch[10] avg_epoch_loss=0.349972\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=0.362646201253\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:05 INFO 140144812640064] Epoch[120] Batch [10]#011Speed: 177.30 samples/sec#011loss=0.362646\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:05 INFO 140144812640064] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4716.118812561035, \"sum\": 4716.118812561035, \"min\": 4716.118812561035}}, \"EndTime\": 1587306665.277424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306660.560914}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:05 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=136.549304836 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:05 INFO 140144812640064] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=120, train loss <loss>=0.349972034043\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:05 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:06 INFO 140144812640064] Epoch[121] Batch[0] avg_epoch_loss=0.675665\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:06 INFO 140144812640064] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=0.675665080547\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:08 INFO 140144812640064] Epoch[121] Batch[5] avg_epoch_loss=0.540088\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:08 INFO 140144812640064] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=0.540087992946\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:08 INFO 140144812640064] Epoch[121] Batch [5]#011Speed: 173.41 samples/sec#011loss=0.540088\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:09 INFO 140144812640064] Epoch[121] Batch[10] avg_epoch_loss=0.448717\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:09 INFO 140144812640064] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=0.339071330428\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:09 INFO 140144812640064] Epoch[121] Batch [10]#011Speed: 172.36 samples/sec#011loss=0.339071\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:09 INFO 140144812640064] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4656.682968139648, \"sum\": 4656.682968139648, \"min\": 4656.682968139648}}, \"EndTime\": 1587306669.934717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306665.27751}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:09 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=140.868414455 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:09 INFO 140144812640064] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:09 INFO 140144812640064] #quality_metric: host=algo-1, epoch=121, train loss <loss>=0.448716782711\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:09 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:10 INFO 140144812640064] Epoch[122] Batch[0] avg_epoch_loss=0.457772\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=0.4577716887\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:12 INFO 140144812640064] Epoch[122] Batch[5] avg_epoch_loss=0.276848\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=0.276848451545\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:12 INFO 140144812640064] Epoch[122] Batch [5]#011Speed: 176.96 samples/sec#011loss=0.276848\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:14 INFO 140144812640064] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4216.28212928772, \"sum\": 4216.28212928772, \"min\": 4216.28212928772}}, \"EndTime\": 1587306674.151691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306669.934801}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:14 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=148.230545363 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:14 INFO 140144812640064] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:14 INFO 140144812640064] #quality_metric: host=algo-1, epoch=122, train loss <loss>=0.242031023651\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:14 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:15 INFO 140144812640064] Epoch[123] Batch[0] avg_epoch_loss=0.206973\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:15 INFO 140144812640064] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=0.206972748041\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:17 INFO 140144812640064] Epoch[123] Batch[5] avg_epoch_loss=0.293722\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=0.293721718093\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:17 INFO 140144812640064] Epoch[123] Batch [5]#011Speed: 177.20 samples/sec#011loss=0.293722\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:18 INFO 140144812640064] Epoch[123] Batch[10] avg_epoch_loss=0.308137\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:18 INFO 140144812640064] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=0.325434674323\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:18 INFO 140144812640064] Epoch[123] Batch [10]#011Speed: 177.65 samples/sec#011loss=0.325435\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:18 INFO 140144812640064] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4669.618844985962, \"sum\": 4669.618844985962, \"min\": 4669.618844985962}}, \"EndTime\": 1587306678.821986, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306674.151774}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:18 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=145.404360897 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:18 INFO 140144812640064] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:18 INFO 140144812640064] #quality_metric: host=algo-1, epoch=123, train loss <loss>=0.308136698197\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:18 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:19 INFO 140144812640064] Epoch[124] Batch[0] avg_epoch_loss=0.273219\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=0.273218780756\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:21 INFO 140144812640064] Epoch[124] Batch[5] avg_epoch_loss=0.181677\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=0.181677183757\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:21 INFO 140144812640064] Epoch[124] Batch [5]#011Speed: 175.62 samples/sec#011loss=0.181677\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:23 INFO 140144812640064] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4289.502143859863, \"sum\": 4289.502143859863, \"min\": 4289.502143859863}}, \"EndTime\": 1587306683.112019, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306678.822066}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:23 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.332564175 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:23 INFO 140144812640064] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:23 INFO 140144812640064] #quality_metric: host=algo-1, epoch=124, train loss <loss>=0.143359714001\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:23 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:23 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_e0af22fa-de30-4d4f-a077-2fbe44ea0501-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 90.56210517883301, \"sum\": 90.56210517883301, \"min\": 90.56210517883301}}, \"EndTime\": 1587306683.20313, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306683.112095}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:24 INFO 140144812640064] Epoch[125] Batch[0] avg_epoch_loss=0.354859\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:24 INFO 140144812640064] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=0.354859083891\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:25 INFO 140144812640064] Epoch[125] Batch[5] avg_epoch_loss=0.345842\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=0.345842433472\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:25 INFO 140144812640064] Epoch[125] Batch [5]#011Speed: 175.41 samples/sec#011loss=0.345842\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:27 INFO 140144812640064] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4212.637901306152, \"sum\": 4212.637901306152, \"min\": 4212.637901306152}}, \"EndTime\": 1587306687.415908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306683.20321}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:27 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=148.121883641 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:27 INFO 140144812640064] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:27 INFO 140144812640064] #quality_metric: host=algo-1, epoch=125, train loss <loss>=0.268039208651\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:27 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:28 INFO 140144812640064] Epoch[126] Batch[0] avg_epoch_loss=0.402893\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=0.402892619371\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:30 INFO 140144812640064] Epoch[126] Batch[5] avg_epoch_loss=0.125502\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=0.12550225202\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:30 INFO 140144812640064] Epoch[126] Batch [5]#011Speed: 177.14 samples/sec#011loss=0.125502\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:31 INFO 140144812640064] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4288.02490234375, \"sum\": 4288.02490234375, \"min\": 4288.02490234375}}, \"EndTime\": 1587306691.704427, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306687.415982}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:31 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=148.782594394 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:31 INFO 140144812640064] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:31 INFO 140144812640064] #quality_metric: host=algo-1, epoch=126, train loss <loss>=0.13491257634\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:31 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:31 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_be3c31c0-49cd-4515-a404-047e455316be-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.688899993896484, \"sum\": 61.688899993896484, \"min\": 61.688899993896484}}, \"EndTime\": 1587306691.766782, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306691.7045}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:32 INFO 140144812640064] Epoch[127] Batch[0] avg_epoch_loss=0.463653\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:32 INFO 140144812640064] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=0.463653385639\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:34 INFO 140144812640064] Epoch[127] Batch[5] avg_epoch_loss=0.228068\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:34 INFO 140144812640064] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=0.228068246817\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:34 INFO 140144812640064] Epoch[127] Batch [5]#011Speed: 176.63 samples/sec#011loss=0.228068\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:36 INFO 140144812640064] Epoch[127] Batch[10] avg_epoch_loss=0.126875\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:36 INFO 140144812640064] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=0.00544208027422\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:36 INFO 140144812640064] Epoch[127] Batch [10]#011Speed: 176.63 samples/sec#011loss=0.005442\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:36 INFO 140144812640064] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4593.749046325684, \"sum\": 4593.749046325684, \"min\": 4593.749046325684}}, \"EndTime\": 1587306696.360692, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306691.766878}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:36 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.934741352 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:36 INFO 140144812640064] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:36 INFO 140144812640064] #quality_metric: host=algo-1, epoch=127, train loss <loss>=0.126874534752\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:36 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:36 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_9a7bb1e4-f8c3-461e-bdd2-8e86fb776d9d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.35892868041992, \"sum\": 61.35892868041992, \"min\": 61.35892868041992}}, \"EndTime\": 1587306696.422715, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306696.360778}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:37 INFO 140144812640064] Epoch[128] Batch[0] avg_epoch_loss=0.049399\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:37 INFO 140144812640064] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=0.0493993870914\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:39 INFO 140144812640064] Epoch[128] Batch[5] avg_epoch_loss=0.337960\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=0.337959947375\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:39 INFO 140144812640064] Epoch[128] Batch [5]#011Speed: 174.68 samples/sec#011loss=0.337960\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:41 INFO 140144812640064] Epoch[128] Batch[10] avg_epoch_loss=0.323944\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:41 INFO 140144812640064] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=0.307124608755\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:41 INFO 140144812640064] Epoch[128] Batch [10]#011Speed: 176.64 samples/sec#011loss=0.307125\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:41 INFO 140144812640064] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4610.440969467163, \"sum\": 4610.440969467163, \"min\": 4610.440969467163}}, \"EndTime\": 1587306701.033301, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306696.422792}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:41 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=148.1386027 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:41 INFO 140144812640064] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:41 INFO 140144812640064] #quality_metric: host=algo-1, epoch=128, train loss <loss>=0.323943884366\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:41 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:42 INFO 140144812640064] Epoch[129] Batch[0] avg_epoch_loss=0.353698\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=0.353697836399\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:43 INFO 140144812640064] Epoch[129] Batch[5] avg_epoch_loss=0.293664\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=0.293663601081\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:43 INFO 140144812640064] Epoch[129] Batch [5]#011Speed: 175.11 samples/sec#011loss=0.293664\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:45 INFO 140144812640064] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4272.511005401611, \"sum\": 4272.511005401611, \"min\": 4272.511005401611}}, \"EndTime\": 1587306705.3063, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306701.03337}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:45 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.450758586 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:45 INFO 140144812640064] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:45 INFO 140144812640064] #quality_metric: host=algo-1, epoch=129, train loss <loss>=0.286460521072\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:45 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:46 INFO 140144812640064] Epoch[130] Batch[0] avg_epoch_loss=0.320047\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=0.320046693087\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:48 INFO 140144812640064] Epoch[130] Batch[5] avg_epoch_loss=0.165522\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=0.165521963189\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:48 INFO 140144812640064] Epoch[130] Batch [5]#011Speed: 176.41 samples/sec#011loss=0.165522\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:49 INFO 140144812640064] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4221.812963485718, \"sum\": 4221.812963485718, \"min\": 4221.812963485718}}, \"EndTime\": 1587306709.528691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306705.306366}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:49 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.45749207 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:49 INFO 140144812640064] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:49 INFO 140144812640064] #quality_metric: host=algo-1, epoch=130, train loss <loss>=0.16638205871\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:49 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:50 INFO 140144812640064] Epoch[131] Batch[0] avg_epoch_loss=-0.016070\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:50 INFO 140144812640064] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=-0.0160700120032\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:52 INFO 140144812640064] Epoch[131] Batch[5] avg_epoch_loss=0.171414\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:52 INFO 140144812640064] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=0.171414130794\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:52 INFO 140144812640064] Epoch[131] Batch [5]#011Speed: 175.28 samples/sec#011loss=0.171414\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:54 INFO 140144812640064] Epoch[131] Batch[10] avg_epoch_loss=0.080909\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:54 INFO 140144812640064] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=-0.0276961501688\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:54 INFO 140144812640064] Epoch[131] Batch [10]#011Speed: 176.28 samples/sec#011loss=-0.027696\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:54 INFO 140144812640064] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4608.649015426636, \"sum\": 4608.649015426636, \"min\": 4608.649015426636}}, \"EndTime\": 1587306714.137946, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306709.528762}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:54 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.724076247 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:54 INFO 140144812640064] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:54 INFO 140144812640064] #quality_metric: host=algo-1, epoch=131, train loss <loss>=0.0809094576292\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:54 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:54 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_58a57ed4-d85d-4ea7-91d0-0794be4aec7e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 64.07403945922852, \"sum\": 64.07403945922852, \"min\": 64.07403945922852}}, \"EndTime\": 1587306714.202701, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306714.138028}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:55 INFO 140144812640064] Epoch[132] Batch[0] avg_epoch_loss=-0.086114\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=-0.0861135572195\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:56 INFO 140144812640064] Epoch[132] Batch[5] avg_epoch_loss=0.159281\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:56 INFO 140144812640064] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=0.159281235809\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:56 INFO 140144812640064] Epoch[132] Batch [5]#011Speed: 176.62 samples/sec#011loss=0.159281\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:58 INFO 140144812640064] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4192.478895187378, \"sum\": 4192.478895187378, \"min\": 4192.478895187378}}, \"EndTime\": 1587306718.39532, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306714.202776}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:58 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.870698789 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:58 INFO 140144812640064] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:58 INFO 140144812640064] #quality_metric: host=algo-1, epoch=132, train loss <loss>=0.160724366829\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:58 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:59 INFO 140144812640064] Epoch[133] Batch[0] avg_epoch_loss=0.541100\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:31:59 INFO 140144812640064] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=0.541100263596\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:01 INFO 140144812640064] Epoch[133] Batch[5] avg_epoch_loss=0.312733\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:01 INFO 140144812640064] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=0.312733434141\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:01 INFO 140144812640064] Epoch[133] Batch [5]#011Speed: 176.32 samples/sec#011loss=0.312733\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:02 INFO 140144812640064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4306.759834289551, \"sum\": 4306.759834289551, \"min\": 4306.759834289551}}, \"EndTime\": 1587306722.702604, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306718.395404}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:02 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=145.348732702 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:02 INFO 140144812640064] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=133, train loss <loss>=0.256611008942\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:02 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:03 INFO 140144812640064] Epoch[134] Batch[0] avg_epoch_loss=0.246820\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:03 INFO 140144812640064] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=0.24681982398\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:05 INFO 140144812640064] Epoch[134] Batch[5] avg_epoch_loss=0.117158\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=0.117157657941\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:05 INFO 140144812640064] Epoch[134] Batch [5]#011Speed: 173.62 samples/sec#011loss=0.117158\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:07 INFO 140144812640064] Epoch[134] Batch[10] avg_epoch_loss=0.086263\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=0.0491889923811\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:07 INFO 140144812640064] Epoch[134] Batch [10]#011Speed: 173.21 samples/sec#011loss=0.049189\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:07 INFO 140144812640064] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4673.6741065979, \"sum\": 4673.6741065979, \"min\": 4673.6741065979}}, \"EndTime\": 1587306727.376842, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306722.702687}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:07 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.713988143 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:07 INFO 140144812640064] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=134, train loss <loss>=0.0862628099593\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:07 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:08 INFO 140144812640064] Epoch[135] Batch[0] avg_epoch_loss=0.461230\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:08 INFO 140144812640064] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=0.461229711771\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:10 INFO 140144812640064] Epoch[135] Batch[5] avg_epoch_loss=0.429471\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=0.429471155008\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:10 INFO 140144812640064] Epoch[135] Batch [5]#011Speed: 174.80 samples/sec#011loss=0.429471\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:12 INFO 140144812640064] Epoch[135] Batch[10] avg_epoch_loss=0.342520\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=0.238179487921\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:12 INFO 140144812640064] Epoch[135] Batch [10]#011Speed: 173.13 samples/sec#011loss=0.238179\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:12 INFO 140144812640064] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4709.182024002075, \"sum\": 4709.182024002075, \"min\": 4709.182024002075}}, \"EndTime\": 1587306732.08665, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306727.376965}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:12 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=137.812356712 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:12 INFO 140144812640064] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=135, train loss <loss>=0.342520397241\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:12 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:13 INFO 140144812640064] Epoch[136] Batch[0] avg_epoch_loss=0.536576\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:13 INFO 140144812640064] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=0.536576271057\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:14 INFO 140144812640064] Epoch[136] Batch[5] avg_epoch_loss=0.379293\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:14 INFO 140144812640064] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=0.379293392102\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:14 INFO 140144812640064] Epoch[136] Batch [5]#011Speed: 175.68 samples/sec#011loss=0.379293\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:15 INFO 140144812640064] processed a total of 575 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3867.2170639038086, \"sum\": 3867.2170639038086, \"min\": 3867.2170639038086}}, \"EndTime\": 1587306735.954537, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306732.086731}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:15 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=148.678811511 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:15 INFO 140144812640064] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:15 INFO 140144812640064] #quality_metric: host=algo-1, epoch=136, train loss <loss>=0.386471582784\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:15 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:16 INFO 140144812640064] Epoch[137] Batch[0] avg_epoch_loss=0.240195\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:16 INFO 140144812640064] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=0.240194901824\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:18 INFO 140144812640064] Epoch[137] Batch[5] avg_epoch_loss=0.212572\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:18 INFO 140144812640064] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=0.212572121372\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:18 INFO 140144812640064] Epoch[137] Batch [5]#011Speed: 176.88 samples/sec#011loss=0.212572\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:20 INFO 140144812640064] Epoch[137] Batch[10] avg_epoch_loss=0.161339\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:20 INFO 140144812640064] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=0.0998593114316\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:20 INFO 140144812640064] Epoch[137] Batch [10]#011Speed: 174.69 samples/sec#011loss=0.099859\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:20 INFO 140144812640064] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4618.92294883728, \"sum\": 4618.92294883728, \"min\": 4618.92294883728}}, \"EndTime\": 1587306740.57415, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306735.954599}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:20 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.318395914 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:20 INFO 140144812640064] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:20 INFO 140144812640064] #quality_metric: host=algo-1, epoch=137, train loss <loss>=0.161339025944\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:20 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:21 INFO 140144812640064] Epoch[138] Batch[0] avg_epoch_loss=0.156119\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=0.156119138002\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:23 INFO 140144812640064] Epoch[138] Batch[5] avg_epoch_loss=0.195266\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:23 INFO 140144812640064] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=0.195266307642\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:23 INFO 140144812640064] Epoch[138] Batch [5]#011Speed: 173.83 samples/sec#011loss=0.195266\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140144812640064] Epoch[138] Batch[10] avg_epoch_loss=0.134111\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=0.0607235774398\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140144812640064] Epoch[138] Batch [10]#011Speed: 174.18 samples/sec#011loss=0.060724\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140144812640064] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4641.1919593811035, \"sum\": 4641.1919593811035, \"min\": 4641.1919593811035}}, \"EndTime\": 1587306745.21617, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306740.574275}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.924669599 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140144812640064] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=138, train loss <loss>=0.134110521186\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:25 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:26 INFO 140144812640064] Epoch[139] Batch[0] avg_epoch_loss=0.101175\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=0.101175010204\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:28 INFO 140144812640064] Epoch[139] Batch[5] avg_epoch_loss=0.071111\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=0.0711107534977\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:28 INFO 140144812640064] Epoch[139] Batch [5]#011Speed: 175.55 samples/sec#011loss=0.071111\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:29 INFO 140144812640064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4248.013973236084, \"sum\": 4248.013973236084, \"min\": 4248.013973236084}}, \"EndTime\": 1587306749.464724, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306745.216253}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:29 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=150.654207496 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:29 INFO 140144812640064] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:29 INFO 140144812640064] #quality_metric: host=algo-1, epoch=139, train loss <loss>=0.154659496713\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:29 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:30 INFO 140144812640064] Epoch[140] Batch[0] avg_epoch_loss=0.002075\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=0.00207457970828\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:32 INFO 140144812640064] Epoch[140] Batch[5] avg_epoch_loss=0.153110\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:32 INFO 140144812640064] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=0.153109822888\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:32 INFO 140144812640064] Epoch[140] Batch [5]#011Speed: 165.48 samples/sec#011loss=0.153110\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:33 INFO 140144812640064] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4365.04602432251, \"sum\": 4365.04602432251, \"min\": 4365.04602432251}}, \"EndTime\": 1587306753.830371, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306749.464809}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:33 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.095756473 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:33 INFO 140144812640064] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:33 INFO 140144812640064] #quality_metric: host=algo-1, epoch=140, train loss <loss>=0.105353492033\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:33 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:34 INFO 140144812640064] Epoch[141] Batch[0] avg_epoch_loss=0.101462\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:34 INFO 140144812640064] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=0.101462125778\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:36 INFO 140144812640064] Epoch[141] Batch[5] avg_epoch_loss=0.089501\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:36 INFO 140144812640064] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=0.0895012114197\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:36 INFO 140144812640064] Epoch[141] Batch [5]#011Speed: 175.53 samples/sec#011loss=0.089501\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:38 INFO 140144812640064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4265.11812210083, \"sum\": 4265.11812210083, \"min\": 4265.11812210083}}, \"EndTime\": 1587306758.096123, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306753.830443}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:38 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.768237278 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:38 INFO 140144812640064] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:38 INFO 140144812640064] #quality_metric: host=algo-1, epoch=141, train loss <loss>=0.102251380309\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:38 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:39 INFO 140144812640064] Epoch[142] Batch[0] avg_epoch_loss=0.006584\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=0.00658359564841\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:40 INFO 140144812640064] Epoch[142] Batch[5] avg_epoch_loss=0.112700\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=0.112700464204\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:40 INFO 140144812640064] Epoch[142] Batch [5]#011Speed: 173.98 samples/sec#011loss=0.112700\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:42 INFO 140144812640064] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4299.236059188843, \"sum\": 4299.236059188843, \"min\": 4299.236059188843}}, \"EndTime\": 1587306762.395862, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306758.0962}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:42 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.208212454 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:42 INFO 140144812640064] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=142, train loss <loss>=0.0983829816803\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:42 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:43 INFO 140144812640064] Epoch[143] Batch[0] avg_epoch_loss=-0.079123\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=-0.0791226774454\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:45 INFO 140144812640064] Epoch[143] Batch[5] avg_epoch_loss=0.046621\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:45 INFO 140144812640064] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=0.0466212516185\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:45 INFO 140144812640064] Epoch[143] Batch [5]#011Speed: 175.14 samples/sec#011loss=0.046621\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:46 INFO 140144812640064] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4311.47313117981, \"sum\": 4311.47313117981, \"min\": 4311.47313117981}}, \"EndTime\": 1587306766.707956, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306762.395923}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:46 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.349893923 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:46 INFO 140144812640064] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=143, train loss <loss>=0.0185196361039\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:46 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:46 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_fb3c8bb6-539c-4e14-a2c1-77577e0a943a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 86.3039493560791, \"sum\": 86.3039493560791, \"min\": 86.3039493560791}}, \"EndTime\": 1587306766.795004, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306766.70803}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:47 INFO 140144812640064] Epoch[144] Batch[0] avg_epoch_loss=0.154873\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:47 INFO 140144812640064] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=0.154873073101\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:49 INFO 140144812640064] Epoch[144] Batch[5] avg_epoch_loss=-0.025228\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:49 INFO 140144812640064] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=-0.0252280409137\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:49 INFO 140144812640064] Epoch[144] Batch [5]#011Speed: 176.12 samples/sec#011loss=-0.025228\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:51 INFO 140144812640064] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4269.659996032715, \"sum\": 4269.659996032715, \"min\": 4269.659996032715}}, \"EndTime\": 1587306771.064803, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306766.795079}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:51 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=145.675191412 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:51 INFO 140144812640064] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:51 INFO 140144812640064] #quality_metric: host=algo-1, epoch=144, train loss <loss>=0.0920133505017\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:51 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:52 INFO 140144812640064] Epoch[145] Batch[0] avg_epoch_loss=0.890903\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:52 INFO 140144812640064] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=0.890902519226\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:53 INFO 140144812640064] Epoch[145] Batch[5] avg_epoch_loss=0.501691\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=0.501690519353\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:53 INFO 140144812640064] Epoch[145] Batch [5]#011Speed: 178.33 samples/sec#011loss=0.501691\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:55 INFO 140144812640064] Epoch[145] Batch[10] avg_epoch_loss=0.428531\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=0.340739551187\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:55 INFO 140144812640064] Epoch[145] Batch [10]#011Speed: 173.34 samples/sec#011loss=0.340740\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:55 INFO 140144812640064] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4627.470016479492, \"sum\": 4627.470016479492, \"min\": 4627.470016479492}}, \"EndTime\": 1587306775.692827, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306771.064878}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:55 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.271150876 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:55 INFO 140144812640064] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=145, train loss <loss>=0.428530988368\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:55 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:56 INFO 140144812640064] Epoch[146] Batch[0] avg_epoch_loss=0.275131\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:56 INFO 140144812640064] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=0.275131165981\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:58 INFO 140144812640064] Epoch[146] Batch[5] avg_epoch_loss=0.270003\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:58 INFO 140144812640064] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=0.270003202061\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:32:58 INFO 140144812640064] Epoch[146] Batch [5]#011Speed: 174.90 samples/sec#011loss=0.270003\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:00 INFO 140144812640064] Epoch[146] Batch[10] avg_epoch_loss=0.188947\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:00 INFO 140144812640064] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=0.0916799411178\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:00 INFO 140144812640064] Epoch[146] Batch [10]#011Speed: 176.19 samples/sec#011loss=0.091680\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:00 INFO 140144812640064] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4627.401113510132, \"sum\": 4627.401113510132, \"min\": 4627.401113510132}}, \"EndTime\": 1587306780.320833, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306775.692907}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:00 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=140.247876706 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:00 INFO 140144812640064] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:00 INFO 140144812640064] #quality_metric: host=algo-1, epoch=146, train loss <loss>=0.188947174359\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:00 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:01 INFO 140144812640064] Epoch[147] Batch[0] avg_epoch_loss=0.120111\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:01 INFO 140144812640064] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=0.120111219585\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:03 INFO 140144812640064] Epoch[147] Batch[5] avg_epoch_loss=0.096052\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:03 INFO 140144812640064] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=0.0960518183808\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:03 INFO 140144812640064] Epoch[147] Batch [5]#011Speed: 169.71 samples/sec#011loss=0.096052\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:04 INFO 140144812640064] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4304.339170455933, \"sum\": 4304.339170455933, \"min\": 4304.339170455933}}, \"EndTime\": 1587306784.625757, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306780.320913}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:04 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.036545015 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:04 INFO 140144812640064] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=147, train loss <loss>=0.0515875883866\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:04 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:05 INFO 140144812640064] Epoch[148] Batch[0] avg_epoch_loss=0.135143\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=0.135143056512\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:07 INFO 140144812640064] Epoch[148] Batch[5] avg_epoch_loss=0.076411\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=0.0764110482608\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:07 INFO 140144812640064] Epoch[148] Batch [5]#011Speed: 173.60 samples/sec#011loss=0.076411\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:09 INFO 140144812640064] Epoch[148] Batch[10] avg_epoch_loss=0.040159\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:09 INFO 140144812640064] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=-0.00334294643253\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:09 INFO 140144812640064] Epoch[148] Batch [10]#011Speed: 176.08 samples/sec#011loss=-0.003343\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:09 INFO 140144812640064] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4684.956073760986, \"sum\": 4684.956073760986, \"min\": 4684.956073760986}}, \"EndTime\": 1587306789.311231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306784.62584}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:09 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.007532747 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:09 INFO 140144812640064] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:09 INFO 140144812640064] #quality_metric: host=algo-1, epoch=148, train loss <loss>=0.0401592324911\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:09 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:10 INFO 140144812640064] Epoch[149] Batch[0] avg_epoch_loss=0.817325\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=0.817325115204\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:12 INFO 140144812640064] Epoch[149] Batch[5] avg_epoch_loss=0.612676\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=0.612676178416\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:12 INFO 140144812640064] Epoch[149] Batch [5]#011Speed: 173.91 samples/sec#011loss=0.612676\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:14 INFO 140144812640064] Epoch[149] Batch[10] avg_epoch_loss=0.533158\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:14 INFO 140144812640064] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=0.437735486031\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:14 INFO 140144812640064] Epoch[149] Batch [10]#011Speed: 175.29 samples/sec#011loss=0.437735\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:14 INFO 140144812640064] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4726.973056793213, \"sum\": 4726.973056793213, \"min\": 4726.973056793213}}, \"EndTime\": 1587306794.038676, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306789.311308}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:14 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.448129797 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:14 INFO 140144812640064] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:14 INFO 140144812640064] #quality_metric: host=algo-1, epoch=149, train loss <loss>=0.533157681877\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:14 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:15 INFO 140144812640064] Epoch[150] Batch[0] avg_epoch_loss=0.343912\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:15 INFO 140144812640064] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=0.343911886215\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:16 INFO 140144812640064] Epoch[150] Batch[5] avg_epoch_loss=0.242748\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:16 INFO 140144812640064] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=0.242747806013\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:16 INFO 140144812640064] Epoch[150] Batch [5]#011Speed: 172.97 samples/sec#011loss=0.242748\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:18 INFO 140144812640064] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4310.756206512451, \"sum\": 4310.756206512451, \"min\": 4310.756206512451}}, \"EndTime\": 1587306798.349948, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306794.038753}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:18 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.998133961 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:18 INFO 140144812640064] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:18 INFO 140144812640064] #quality_metric: host=algo-1, epoch=150, train loss <loss>=0.17565685045\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:18 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:19 INFO 140144812640064] Epoch[151] Batch[0] avg_epoch_loss=0.127193\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=0.127193361521\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:21 INFO 140144812640064] Epoch[151] Batch[5] avg_epoch_loss=0.073042\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=0.0730418525636\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:21 INFO 140144812640064] Epoch[151] Batch [5]#011Speed: 172.20 samples/sec#011loss=0.073042\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:22 INFO 140144812640064] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4278.15318107605, \"sum\": 4278.15318107605, \"min\": 4278.15318107605}}, \"EndTime\": 1587306802.628639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306798.350022}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:22 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.35922904 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:22 INFO 140144812640064] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:22 INFO 140144812640064] #quality_metric: host=algo-1, epoch=151, train loss <loss>=0.0825489491224\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:22 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:23 INFO 140144812640064] Epoch[152] Batch[0] avg_epoch_loss=-0.002269\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:23 INFO 140144812640064] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=-0.00226869131438\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:25 INFO 140144812640064] Epoch[152] Batch[5] avg_epoch_loss=0.045525\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=0.0455250676799\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:25 INFO 140144812640064] Epoch[152] Batch [5]#011Speed: 175.53 samples/sec#011loss=0.045525\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:27 INFO 140144812640064] Epoch[152] Batch[10] avg_epoch_loss=0.042641\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:27 INFO 140144812640064] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=0.0391801945865\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:27 INFO 140144812640064] Epoch[152] Batch [10]#011Speed: 174.93 samples/sec#011loss=0.039180\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:27 INFO 140144812640064] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4653.64408493042, \"sum\": 4653.64408493042, \"min\": 4653.64408493042}}, \"EndTime\": 1587306807.282807, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306802.628722}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:27 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=138.164634792 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:27 INFO 140144812640064] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:27 INFO 140144812640064] #quality_metric: host=algo-1, epoch=152, train loss <loss>=0.0426410344556\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:27 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:28 INFO 140144812640064] Epoch[153] Batch[0] avg_epoch_loss=2.130946\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=2.13094639778\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:30 INFO 140144812640064] Epoch[153] Batch[5] avg_epoch_loss=1.192201\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=1.19220133622\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:30 INFO 140144812640064] Epoch[153] Batch [5]#011Speed: 175.07 samples/sec#011loss=1.192201\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140144812640064] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4309.474945068359, \"sum\": 4309.474945068359, \"min\": 4309.474945068359}}, \"EndTime\": 1587306811.593871, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306807.282991}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.63278414 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140144812640064] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140144812640064] #quality_metric: host=algo-1, epoch=153, train loss <loss>=1.10604210496\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:31 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:32 INFO 140144812640064] Epoch[154] Batch[0] avg_epoch_loss=0.884181\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:32 INFO 140144812640064] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=0.884180963039\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:34 INFO 140144812640064] Epoch[154] Batch[5] avg_epoch_loss=0.885256\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:34 INFO 140144812640064] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=0.885255992413\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:34 INFO 140144812640064] Epoch[154] Batch [5]#011Speed: 175.97 samples/sec#011loss=0.885256\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:36 INFO 140144812640064] Epoch[154] Batch[10] avg_epoch_loss=0.787569\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:36 INFO 140144812640064] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=0.670344561338\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:36 INFO 140144812640064] Epoch[154] Batch [10]#011Speed: 169.51 samples/sec#011loss=0.670345\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:36 INFO 140144812640064] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4750.6561279296875, \"sum\": 4750.6561279296875, \"min\": 4750.6561279296875}}, \"EndTime\": 1587306816.345101, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306811.593953}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:36 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=136.397563129 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:36 INFO 140144812640064] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:36 INFO 140144812640064] #quality_metric: host=algo-1, epoch=154, train loss <loss>=0.787568978288\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:36 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:37 INFO 140144812640064] Epoch[155] Batch[0] avg_epoch_loss=0.556682\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:37 INFO 140144812640064] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=0.556682467461\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:39 INFO 140144812640064] Epoch[155] Batch[5] avg_epoch_loss=0.440524\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=0.440523892641\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:39 INFO 140144812640064] Epoch[155] Batch [5]#011Speed: 175.76 samples/sec#011loss=0.440524\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:40 INFO 140144812640064] Epoch[155] Batch[10] avg_epoch_loss=0.331025\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=0.199625885487\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:40 INFO 140144812640064] Epoch[155] Batch [10]#011Speed: 177.73 samples/sec#011loss=0.199626\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:40 INFO 140144812640064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4619.668960571289, \"sum\": 4619.668960571289, \"min\": 4619.668960571289}}, \"EndTime\": 1587306820.965426, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306816.345184}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:40 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=140.050051121 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:40 INFO 140144812640064] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=155, train loss <loss>=0.33102479848\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:40 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:42 INFO 140144812640064] Epoch[156] Batch[0] avg_epoch_loss=0.235057\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=0.235056936741\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:43 INFO 140144812640064] Epoch[156] Batch[5] avg_epoch_loss=0.261251\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=0.261250680933\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:43 INFO 140144812640064] Epoch[156] Batch [5]#011Speed: 174.07 samples/sec#011loss=0.261251\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:45 INFO 140144812640064] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4338.42396736145, \"sum\": 4338.42396736145, \"min\": 4338.42396736145}}, \"EndTime\": 1587306825.304328, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306820.9655}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:45 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.366135954 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:45 INFO 140144812640064] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:45 INFO 140144812640064] #quality_metric: host=algo-1, epoch=156, train loss <loss>=0.205257054418\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:45 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:46 INFO 140144812640064] Epoch[157] Batch[0] avg_epoch_loss=0.221506\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=0.221506431699\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:48 INFO 140144812640064] Epoch[157] Batch[5] avg_epoch_loss=0.152636\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=0.152635959287\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:48 INFO 140144812640064] Epoch[157] Batch [5]#011Speed: 173.81 samples/sec#011loss=0.152636\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:49 INFO 140144812640064] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4272.07612991333, \"sum\": 4272.07612991333, \"min\": 4272.07612991333}}, \"EndTime\": 1587306829.576897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306825.304407}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:49 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.762755547 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:49 INFO 140144812640064] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:49 INFO 140144812640064] #quality_metric: host=algo-1, epoch=157, train loss <loss>=0.151709281281\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:49 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:50 INFO 140144812640064] Epoch[158] Batch[0] avg_epoch_loss=0.387962\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:50 INFO 140144812640064] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=0.387962162495\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:52 INFO 140144812640064] Epoch[158] Batch[5] avg_epoch_loss=0.071246\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:52 INFO 140144812640064] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=0.0712459683418\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:52 INFO 140144812640064] Epoch[158] Batch [5]#011Speed: 172.63 samples/sec#011loss=0.071246\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:53 INFO 140144812640064] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4316.909074783325, \"sum\": 4316.909074783325, \"min\": 4316.909074783325}}, \"EndTime\": 1587306833.894344, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306829.576981}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:53 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.922168976 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:53 INFO 140144812640064] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=158, train loss <loss>=0.0813981510699\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:53 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:54 INFO 140144812640064] Epoch[159] Batch[0] avg_epoch_loss=-0.009994\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:54 INFO 140144812640064] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=-0.00999383814633\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:56 INFO 140144812640064] Epoch[159] Batch[5] avg_epoch_loss=0.074470\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:56 INFO 140144812640064] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=0.0744702809801\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:56 INFO 140144812640064] Epoch[159] Batch [5]#011Speed: 173.82 samples/sec#011loss=0.074470\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:58 INFO 140144812640064] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4334.484100341797, \"sum\": 4334.484100341797, \"min\": 4334.484100341797}}, \"EndTime\": 1587306838.229391, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306833.89443}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:58 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.880489047 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:58 INFO 140144812640064] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:58 INFO 140144812640064] #quality_metric: host=algo-1, epoch=159, train loss <loss>=0.0522833725903\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:58 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:59 INFO 140144812640064] Epoch[160] Batch[0] avg_epoch_loss=0.160941\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:33:59 INFO 140144812640064] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=0.160940855742\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:01 INFO 140144812640064] Epoch[160] Batch[5] avg_epoch_loss=0.006553\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:01 INFO 140144812640064] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=0.00655281419555\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:01 INFO 140144812640064] Epoch[160] Batch [5]#011Speed: 174.55 samples/sec#011loss=0.006553\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:02 INFO 140144812640064] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4352.034091949463, \"sum\": 4352.034091949463, \"min\": 4352.034091949463}}, \"EndTime\": 1587306842.581968, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306838.229473}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:02 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.296395585 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:02 INFO 140144812640064] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=160, train loss <loss>=0.102020341903\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:02 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:03 INFO 140144812640064] Epoch[161] Batch[0] avg_epoch_loss=0.142317\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:03 INFO 140144812640064] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=0.142317175865\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:05 INFO 140144812640064] Epoch[161] Batch[5] avg_epoch_loss=0.217455\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=0.217454771977\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:05 INFO 140144812640064] Epoch[161] Batch [5]#011Speed: 172.69 samples/sec#011loss=0.217455\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:07 INFO 140144812640064] Epoch[161] Batch[10] avg_epoch_loss=0.274469\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=0.342885407805\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:07 INFO 140144812640064] Epoch[161] Batch [10]#011Speed: 169.49 samples/sec#011loss=0.342885\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:07 INFO 140144812640064] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4749.119997024536, \"sum\": 4749.119997024536, \"min\": 4749.119997024536}}, \"EndTime\": 1587306847.331771, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306842.58205}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:07 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.917118252 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:07 INFO 140144812640064] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=161, train loss <loss>=0.274468697354\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:07 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:08 INFO 140144812640064] Epoch[162] Batch[0] avg_epoch_loss=0.127961\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:08 INFO 140144812640064] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=0.127961322665\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:10 INFO 140144812640064] Epoch[162] Batch[5] avg_epoch_loss=0.049218\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=0.0492180700724\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:10 INFO 140144812640064] Epoch[162] Batch [5]#011Speed: 176.23 samples/sec#011loss=0.049218\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:12 INFO 140144812640064] Epoch[162] Batch[10] avg_epoch_loss=0.071869\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=0.0990495383739\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:12 INFO 140144812640064] Epoch[162] Batch [10]#011Speed: 168.64 samples/sec#011loss=0.099050\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:12 INFO 140144812640064] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4692.447900772095, \"sum\": 4692.447900772095, \"min\": 4692.447900772095}}, \"EndTime\": 1587306852.024703, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306847.331866}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:12 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.156396614 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:12 INFO 140144812640064] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=162, train loss <loss>=0.0718687374822\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:12 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:13 INFO 140144812640064] Epoch[163] Batch[0] avg_epoch_loss=0.732522\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:13 INFO 140144812640064] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=0.732521951199\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:14 INFO 140144812640064] Epoch[163] Batch[5] avg_epoch_loss=0.625177\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:14 INFO 140144812640064] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=0.625176855673\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:14 INFO 140144812640064] Epoch[163] Batch [5]#011Speed: 173.68 samples/sec#011loss=0.625177\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:16 INFO 140144812640064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4332.157850265503, \"sum\": 4332.157850265503, \"min\": 4332.157850265503}}, \"EndTime\": 1587306856.357332, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306852.024782}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:16 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.49713409 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:16 INFO 140144812640064] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:16 INFO 140144812640064] #quality_metric: host=algo-1, epoch=163, train loss <loss>=0.584035065025\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:16 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:17 INFO 140144812640064] Epoch[164] Batch[0] avg_epoch_loss=0.397080\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=0.397079735994\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:19 INFO 140144812640064] Epoch[164] Batch[5] avg_epoch_loss=0.388870\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=0.388870139917\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:19 INFO 140144812640064] Epoch[164] Batch [5]#011Speed: 175.53 samples/sec#011loss=0.388870\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:21 INFO 140144812640064] Epoch[164] Batch[10] avg_epoch_loss=0.364416\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=0.335071977973\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:21 INFO 140144812640064] Epoch[164] Batch [10]#011Speed: 170.34 samples/sec#011loss=0.335072\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:21 INFO 140144812640064] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4730.88002204895, \"sum\": 4730.88002204895, \"min\": 4730.88002204895}}, \"EndTime\": 1587306861.088716, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306856.357405}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:21 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.928875596 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:21 INFO 140144812640064] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=164, train loss <loss>=0.364416429942\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:21 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:22 INFO 140144812640064] Epoch[165] Batch[0] avg_epoch_loss=0.165417\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:22 INFO 140144812640064] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=0.16541673243\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:23 INFO 140144812640064] Epoch[165] Batch[5] avg_epoch_loss=0.054047\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:23 INFO 140144812640064] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=0.0540469554253\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:23 INFO 140144812640064] Epoch[165] Batch [5]#011Speed: 175.62 samples/sec#011loss=0.054047\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:25 INFO 140144812640064] Epoch[165] Batch[10] avg_epoch_loss=0.012904\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=-0.0364683248103\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:25 INFO 140144812640064] Epoch[165] Batch [10]#011Speed: 177.20 samples/sec#011loss=-0.036468\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:25 INFO 140144812640064] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4612.480163574219, \"sum\": 4612.480163574219, \"min\": 4612.480163574219}}, \"EndTime\": 1587306865.70178, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306861.088775}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:25 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.869713173 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:25 INFO 140144812640064] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=165, train loss <loss>=0.0129036462273\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:25 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:25 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_7e4b780a-a3d6-4813-987f-4ba94a48f125-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 64.77904319763184, \"sum\": 64.77904319763184, \"min\": 64.77904319763184}}, \"EndTime\": 1587306865.767248, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306865.701857}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:26 INFO 140144812640064] Epoch[166] Batch[0] avg_epoch_loss=0.685368\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=0.685368418694\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:28 INFO 140144812640064] Epoch[166] Batch[5] avg_epoch_loss=0.373999\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=0.373998715232\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:28 INFO 140144812640064] Epoch[166] Batch [5]#011Speed: 174.77 samples/sec#011loss=0.373999\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:30 INFO 140144812640064] Epoch[166] Batch[10] avg_epoch_loss=0.291499\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=0.192500074208\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:30 INFO 140144812640064] Epoch[166] Batch [10]#011Speed: 176.28 samples/sec#011loss=0.192500\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:30 INFO 140144812640064] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4633.355140686035, \"sum\": 4633.355140686035, \"min\": 4633.355140686035}}, \"EndTime\": 1587306870.400749, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306865.767323}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:30 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.361789396 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:30 INFO 140144812640064] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=166, train loss <loss>=0.291499332948\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:30 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:31 INFO 140144812640064] Epoch[167] Batch[0] avg_epoch_loss=0.175067\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:31 INFO 140144812640064] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=0.175067394972\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:33 INFO 140144812640064] Epoch[167] Batch[5] avg_epoch_loss=0.218221\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:33 INFO 140144812640064] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=0.218221381307\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:33 INFO 140144812640064] Epoch[167] Batch [5]#011Speed: 165.69 samples/sec#011loss=0.218221\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:34 INFO 140144812640064] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4339.0021324157715, \"sum\": 4339.0021324157715, \"min\": 4339.0021324157715}}, \"EndTime\": 1587306874.740389, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306870.400835}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:34 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=145.42119437 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:34 INFO 140144812640064] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:34 INFO 140144812640064] #quality_metric: host=algo-1, epoch=167, train loss <loss>=0.172852805257\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:34 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:35 INFO 140144812640064] Epoch[168] Batch[0] avg_epoch_loss=0.118763\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:35 INFO 140144812640064] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=0.118762917817\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:37 INFO 140144812640064] Epoch[168] Batch[5] avg_epoch_loss=-0.038237\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:37 INFO 140144812640064] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=-0.0382373078416\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:37 INFO 140144812640064] Epoch[168] Batch [5]#011Speed: 174.43 samples/sec#011loss=-0.038237\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:39 INFO 140144812640064] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4287.405967712402, \"sum\": 4287.405967712402, \"min\": 4287.405967712402}}, \"EndTime\": 1587306879.028307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306874.740468}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:39 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.404726493 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:39 INFO 140144812640064] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=168, train loss <loss>=-0.0459439849481\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:39 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:39 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_a1de034c-8ecf-4848-8823-356663415bad-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 82.66401290893555, \"sum\": 82.66401290893555, \"min\": 82.66401290893555}}, \"EndTime\": 1587306879.111678, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306879.02838}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:40 INFO 140144812640064] Epoch[169] Batch[0] avg_epoch_loss=0.175294\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=0.175294220448\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:41 INFO 140144812640064] Epoch[169] Batch[5] avg_epoch_loss=0.240859\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:41 INFO 140144812640064] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=0.240859492371\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:41 INFO 140144812640064] Epoch[169] Batch [5]#011Speed: 172.76 samples/sec#011loss=0.240859\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:43 INFO 140144812640064] Epoch[169] Batch[10] avg_epoch_loss=0.160185\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=0.0633755464107\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:43 INFO 140144812640064] Epoch[169] Batch [10]#011Speed: 171.39 samples/sec#011loss=0.063376\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:43 INFO 140144812640064] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4728.631973266602, \"sum\": 4728.631973266602, \"min\": 4728.631973266602}}, \"EndTime\": 1587306883.84045, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306879.111751}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:43 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=138.51454651 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:43 INFO 140144812640064] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=169, train loss <loss>=0.16018497148\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:43 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:44 INFO 140144812640064] Epoch[170] Batch[0] avg_epoch_loss=-0.001259\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:44 INFO 140144812640064] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=-0.00125933845993\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:46 INFO 140144812640064] Epoch[170] Batch[5] avg_epoch_loss=-0.050605\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=-0.0506049134419\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:46 INFO 140144812640064] Epoch[170] Batch [5]#011Speed: 176.09 samples/sec#011loss=-0.050605\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:48 INFO 140144812640064] Epoch[170] Batch[10] avg_epoch_loss=-0.015091\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=0.027526254952\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:48 INFO 140144812640064] Epoch[170] Batch [10]#011Speed: 172.69 samples/sec#011loss=0.027526\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:48 INFO 140144812640064] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4645.348787307739, \"sum\": 4645.348787307739, \"min\": 4645.348787307739}}, \"EndTime\": 1587306888.48628, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306883.840525}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:48 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.289398742 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:48 INFO 140144812640064] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=170, train loss <loss>=-0.0150907459902\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:48 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:49 INFO 140144812640064] Epoch[171] Batch[0] avg_epoch_loss=1.152639\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:49 INFO 140144812640064] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=1.15263867378\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:51 INFO 140144812640064] Epoch[171] Batch[5] avg_epoch_loss=0.431711\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:51 INFO 140144812640064] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=0.431711435318\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:51 INFO 140144812640064] Epoch[171] Batch [5]#011Speed: 174.43 samples/sec#011loss=0.431711\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:53 INFO 140144812640064] Epoch[171] Batch[10] avg_epoch_loss=0.391873\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=0.344067078829\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:53 INFO 140144812640064] Epoch[171] Batch [10]#011Speed: 169.11 samples/sec#011loss=0.344067\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:53 INFO 140144812640064] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4753.217935562134, \"sum\": 4753.217935562134, \"min\": 4753.217935562134}}, \"EndTime\": 1587306893.240001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306888.486357}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:53 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.319182112 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:53 INFO 140144812640064] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=171, train loss <loss>=0.391873091459\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:53 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:54 INFO 140144812640064] Epoch[172] Batch[0] avg_epoch_loss=0.193831\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:54 INFO 140144812640064] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=0.193830832839\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:55 INFO 140144812640064] Epoch[172] Batch[5] avg_epoch_loss=0.048351\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=0.0483506657183\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:55 INFO 140144812640064] Epoch[172] Batch [5]#011Speed: 178.35 samples/sec#011loss=0.048351\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:57 INFO 140144812640064] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4225.427865982056, \"sum\": 4225.427865982056, \"min\": 4225.427865982056}}, \"EndTime\": 1587306897.466003, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306893.240077}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:57 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.200431165 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:57 INFO 140144812640064] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:57 INFO 140144812640064] #quality_metric: host=algo-1, epoch=172, train loss <loss>=0.00315074641258\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:57 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:58 INFO 140144812640064] Epoch[173] Batch[0] avg_epoch_loss=-0.074984\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:34:58 INFO 140144812640064] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=-0.074983522296\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:00 INFO 140144812640064] Epoch[173] Batch[5] avg_epoch_loss=0.276617\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:00 INFO 140144812640064] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=0.276616536702\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:00 INFO 140144812640064] Epoch[173] Batch [5]#011Speed: 173.99 samples/sec#011loss=0.276617\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:02 INFO 140144812640064] Epoch[173] Batch[10] avg_epoch_loss=0.192894\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=0.0924267031252\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:02 INFO 140144812640064] Epoch[173] Batch [10]#011Speed: 173.77 samples/sec#011loss=0.092427\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:02 INFO 140144812640064] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4639.861822128296, \"sum\": 4639.861822128296, \"min\": 4639.861822128296}}, \"EndTime\": 1587306902.106449, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306897.466074}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:02 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.595348231 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:02 INFO 140144812640064] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=173, train loss <loss>=0.192893885076\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:02 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:03 INFO 140144812640064] Epoch[174] Batch[0] avg_epoch_loss=0.293981\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:03 INFO 140144812640064] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=0.293980628252\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:04 INFO 140144812640064] Epoch[174] Batch[5] avg_epoch_loss=0.304770\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=0.304769555728\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:04 INFO 140144812640064] Epoch[174] Batch [5]#011Speed: 173.67 samples/sec#011loss=0.304770\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:06 INFO 140144812640064] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4284.748077392578, \"sum\": 4284.748077392578, \"min\": 4284.748077392578}}, \"EndTime\": 1587306906.391863, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306902.106531}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:06 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.993522453 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:06 INFO 140144812640064] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:06 INFO 140144812640064] #quality_metric: host=algo-1, epoch=174, train loss <loss>=0.246090979874\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:06 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:07 INFO 140144812640064] Epoch[175] Batch[0] avg_epoch_loss=0.093179\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=0.0931788235903\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:09 INFO 140144812640064] Epoch[175] Batch[5] avg_epoch_loss=0.018051\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:09 INFO 140144812640064] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=0.0180507556846\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:09 INFO 140144812640064] Epoch[175] Batch [5]#011Speed: 174.63 samples/sec#011loss=0.018051\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:11 INFO 140144812640064] Epoch[175] Batch[10] avg_epoch_loss=-0.037047\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:11 INFO 140144812640064] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=-0.103163477592\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:11 INFO 140144812640064] Epoch[175] Batch [10]#011Speed: 176.07 samples/sec#011loss=-0.103163\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:11 INFO 140144812640064] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4672.638893127441, \"sum\": 4672.638893127441, \"min\": 4672.638893127441}}, \"EndTime\": 1587306911.065339, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306906.391936}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:11 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.38054389 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:11 INFO 140144812640064] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:11 INFO 140144812640064] #quality_metric: host=algo-1, epoch=175, train loss <loss>=-0.0370466230776\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:11 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:12 INFO 140144812640064] Epoch[176] Batch[0] avg_epoch_loss=-0.137554\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=-0.137553945184\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:13 INFO 140144812640064] Epoch[176] Batch[5] avg_epoch_loss=0.062874\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:13 INFO 140144812640064] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=0.0628742265205\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:13 INFO 140144812640064] Epoch[176] Batch [5]#011Speed: 174.17 samples/sec#011loss=0.062874\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:15 INFO 140144812640064] Epoch[176] Batch[10] avg_epoch_loss=-0.014993\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:15 INFO 140144812640064] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=-0.108433561772\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:15 INFO 140144812640064] Epoch[176] Batch [10]#011Speed: 176.63 samples/sec#011loss=-0.108434\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:15 INFO 140144812640064] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4692.009925842285, \"sum\": 4692.009925842285, \"min\": 4692.009925842285}}, \"EndTime\": 1587306915.757817, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306911.065416}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:15 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.365863433 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:15 INFO 140144812640064] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:15 INFO 140144812640064] #quality_metric: host=algo-1, epoch=176, train loss <loss>=-0.0149929499762\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:15 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:16 INFO 140144812640064] Epoch[177] Batch[0] avg_epoch_loss=-0.047332\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:16 INFO 140144812640064] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=-0.0473317205906\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:18 INFO 140144812640064] Epoch[177] Batch[5] avg_epoch_loss=-0.066679\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:18 INFO 140144812640064] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=-0.0666786404327\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:18 INFO 140144812640064] Epoch[177] Batch [5]#011Speed: 174.26 samples/sec#011loss=-0.066679\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:20 INFO 140144812640064] Epoch[177] Batch[10] avg_epoch_loss=-0.113135\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:20 INFO 140144812640064] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=-0.168882651627\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:20 INFO 140144812640064] Epoch[177] Batch [10]#011Speed: 177.11 samples/sec#011loss=-0.168883\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:20 INFO 140144812640064] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4644.1969871521, \"sum\": 4644.1969871521, \"min\": 4644.1969871521}}, \"EndTime\": 1587306920.402511, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306915.757905}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:20 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.525634536 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:20 INFO 140144812640064] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:20 INFO 140144812640064] #quality_metric: host=algo-1, epoch=177, train loss <loss>=-0.113135009157\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:20 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:20 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_f97dd643-4247-46dc-ae98-48c8c31565bf-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 91.78590774536133, \"sum\": 91.78590774536133, \"min\": 91.78590774536133}}, \"EndTime\": 1587306920.494904, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306920.402586}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:21 INFO 140144812640064] Epoch[178] Batch[0] avg_epoch_loss=0.164922\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=0.164921984076\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:23 INFO 140144812640064] Epoch[178] Batch[5] avg_epoch_loss=0.365519\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:23 INFO 140144812640064] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=0.365518982212\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:23 INFO 140144812640064] Epoch[178] Batch [5]#011Speed: 171.63 samples/sec#011loss=0.365519\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:25 INFO 140144812640064] Epoch[178] Batch[10] avg_epoch_loss=0.294527\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=0.209335593879\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:25 INFO 140144812640064] Epoch[178] Batch [10]#011Speed: 174.16 samples/sec#011loss=0.209336\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:25 INFO 140144812640064] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4657.644033432007, \"sum\": 4657.644033432007, \"min\": 4657.644033432007}}, \"EndTime\": 1587306925.152684, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306920.494975}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:25 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=140.196292176 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:25 INFO 140144812640064] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=178, train loss <loss>=0.29452653297\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:25 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:26 INFO 140144812640064] Epoch[179] Batch[0] avg_epoch_loss=0.213556\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=0.213555678725\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:27 INFO 140144812640064] Epoch[179] Batch[5] avg_epoch_loss=0.165120\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:27 INFO 140144812640064] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=0.165120491137\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:27 INFO 140144812640064] Epoch[179] Batch [5]#011Speed: 173.50 samples/sec#011loss=0.165120\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:29 INFO 140144812640064] Epoch[179] Batch[10] avg_epoch_loss=0.186996\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:29 INFO 140144812640064] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=0.213246976212\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:29 INFO 140144812640064] Epoch[179] Batch [10]#011Speed: 173.38 samples/sec#011loss=0.213247\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:29 INFO 140144812640064] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4670.109987258911, \"sum\": 4670.109987258911, \"min\": 4670.109987258911}}, \"EndTime\": 1587306929.823252, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306925.152759}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:29 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.033884408 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:29 INFO 140144812640064] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:29 INFO 140144812640064] #quality_metric: host=algo-1, epoch=179, train loss <loss>=0.186996166171\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:29 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:30 INFO 140144812640064] Epoch[180] Batch[0] avg_epoch_loss=-0.099949\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=-0.0999486669898\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:32 INFO 140144812640064] Epoch[180] Batch[5] avg_epoch_loss=-0.095701\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:32 INFO 140144812640064] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=-0.0957007731001\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:32 INFO 140144812640064] Epoch[180] Batch [5]#011Speed: 174.41 samples/sec#011loss=-0.095701\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:34 INFO 140144812640064] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4296.370983123779, \"sum\": 4296.370983123779, \"min\": 4296.370983123779}}, \"EndTime\": 1587306934.120174, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306929.823324}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:34 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.562453276 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:34 INFO 140144812640064] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:34 INFO 140144812640064] #quality_metric: host=algo-1, epoch=180, train loss <loss>=0.03943068441\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:34 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:35 INFO 140144812640064] Epoch[181] Batch[0] avg_epoch_loss=0.038460\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:35 INFO 140144812640064] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=0.0384595692158\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:36 INFO 140144812640064] Epoch[181] Batch[5] avg_epoch_loss=0.068661\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:36 INFO 140144812640064] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=0.0686609999587\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:36 INFO 140144812640064] Epoch[181] Batch [5]#011Speed: 176.51 samples/sec#011loss=0.068661\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:38 INFO 140144812640064] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4290.113925933838, \"sum\": 4290.113925933838, \"min\": 4290.113925933838}}, \"EndTime\": 1587306938.41083, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306934.120251}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:38 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.945500216 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:38 INFO 140144812640064] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:38 INFO 140144812640064] #quality_metric: host=algo-1, epoch=181, train loss <loss>=0.0424141108058\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:38 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:39 INFO 140144812640064] Epoch[182] Batch[0] avg_epoch_loss=0.271643\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=0.271642744541\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:41 INFO 140144812640064] Epoch[182] Batch[5] avg_epoch_loss=0.062666\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:41 INFO 140144812640064] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=0.0626661883046\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:41 INFO 140144812640064] Epoch[182] Batch [5]#011Speed: 174.86 samples/sec#011loss=0.062666\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:42 INFO 140144812640064] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4274.2321491241455, \"sum\": 4274.2321491241455, \"min\": 4274.2321491241455}}, \"EndTime\": 1587306942.685785, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306938.411024}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:42 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.02352235 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:42 INFO 140144812640064] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=182, train loss <loss>=0.0216973241419\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:42 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:43 INFO 140144812640064] Epoch[183] Batch[0] avg_epoch_loss=0.042447\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=0.0424469932914\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:45 INFO 140144812640064] Epoch[183] Batch[5] avg_epoch_loss=-0.076063\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:45 INFO 140144812640064] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=-0.0760629978031\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:45 INFO 140144812640064] Epoch[183] Batch [5]#011Speed: 176.07 samples/sec#011loss=-0.076063\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:46 INFO 140144812640064] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4239.923000335693, \"sum\": 4239.923000335693, \"min\": 4239.923000335693}}, \"EndTime\": 1587306946.926492, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306942.686006}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:46 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.102144562 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:46 INFO 140144812640064] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=183, train loss <loss>=-0.02948333323\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:46 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:47 INFO 140144812640064] Epoch[184] Batch[0] avg_epoch_loss=-0.158630\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:47 INFO 140144812640064] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=-0.158629834652\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:49 INFO 140144812640064] Epoch[184] Batch[5] avg_epoch_loss=0.039275\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:49 INFO 140144812640064] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=0.0392747645577\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:49 INFO 140144812640064] Epoch[184] Batch [5]#011Speed: 175.92 samples/sec#011loss=0.039275\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:51 INFO 140144812640064] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4223.033905029297, \"sum\": 4223.033905029297, \"min\": 4223.033905029297}}, \"EndTime\": 1587306951.150183, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306946.926577}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:51 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.519524189 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:51 INFO 140144812640064] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:51 INFO 140144812640064] #quality_metric: host=algo-1, epoch=184, train loss <loss>=0.0498014874756\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:51 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:52 INFO 140144812640064] Epoch[185] Batch[0] avg_epoch_loss=0.004231\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:52 INFO 140144812640064] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=0.00423066085204\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:53 INFO 140144812640064] Epoch[185] Batch[5] avg_epoch_loss=0.065613\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=0.0656127224211\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:53 INFO 140144812640064] Epoch[185] Batch [5]#011Speed: 172.62 samples/sec#011loss=0.065613\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:55 INFO 140144812640064] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4269.539833068848, \"sum\": 4269.539833068848, \"min\": 4269.539833068848}}, \"EndTime\": 1587306955.420367, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306951.150249}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:55 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.661046709 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:55 INFO 140144812640064] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=185, train loss <loss>=-0.0121094441507\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:55 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:56 INFO 140144812640064] Epoch[186] Batch[0] avg_epoch_loss=0.045671\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:56 INFO 140144812640064] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=0.0456711836159\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:58 INFO 140144812640064] Epoch[186] Batch[5] avg_epoch_loss=-0.133349\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:58 INFO 140144812640064] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=-0.133348856742\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:58 INFO 140144812640064] Epoch[186] Batch [5]#011Speed: 173.66 samples/sec#011loss=-0.133349\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:59 INFO 140144812640064] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4277.817010879517, \"sum\": 4277.817010879517, \"min\": 4277.817010879517}}, \"EndTime\": 1587306959.698771, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306955.420438}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:59 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.56508513 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:59 INFO 140144812640064] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:59 INFO 140144812640064] #quality_metric: host=algo-1, epoch=186, train loss <loss>=-0.00431605540216\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:35:59 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:00 INFO 140144812640064] Epoch[187] Batch[0] avg_epoch_loss=-0.020546\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:00 INFO 140144812640064] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=-0.0205460097641\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:02 INFO 140144812640064] Epoch[187] Batch[5] avg_epoch_loss=-0.066500\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=-0.0665001270051\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:02 INFO 140144812640064] Epoch[187] Batch [5]#011Speed: 173.73 samples/sec#011loss=-0.066500\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:04 INFO 140144812640064] Epoch[187] Batch[10] avg_epoch_loss=-0.116799\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=-0.17715819031\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:04 INFO 140144812640064] Epoch[187] Batch [10]#011Speed: 166.95 samples/sec#011loss=-0.177158\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:04 INFO 140144812640064] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4765.40994644165, \"sum\": 4765.40994644165, \"min\": 4765.40994644165}}, \"EndTime\": 1587306964.46471, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306959.698877}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:04 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.901420509 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:04 INFO 140144812640064] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=187, train loss <loss>=-0.116799246689\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:04 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:04 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_71fa5917-6844-46d5-8b9e-dc078e58a7ae-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 67.69013404846191, \"sum\": 67.69013404846191, \"min\": 67.69013404846191}}, \"EndTime\": 1587306964.533087, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306964.464787}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:05 INFO 140144812640064] Epoch[188] Batch[0] avg_epoch_loss=0.532519\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=0.532519340515\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:07 INFO 140144812640064] Epoch[188] Batch[5] avg_epoch_loss=0.080009\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=0.0800091731362\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:07 INFO 140144812640064] Epoch[188] Batch [5]#011Speed: 176.53 samples/sec#011loss=0.080009\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:09 INFO 140144812640064] Epoch[188] Batch[10] avg_epoch_loss=0.021054\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:09 INFO 140144812640064] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=-0.0496926508844\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:09 INFO 140144812640064] Epoch[188] Batch [10]#011Speed: 174.22 samples/sec#011loss=-0.049693\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:09 INFO 140144812640064] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4653.480052947998, \"sum\": 4653.480052947998, \"min\": 4653.480052947998}}, \"EndTime\": 1587306969.186717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306964.53317}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:09 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=145.69381398 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:09 INFO 140144812640064] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:09 INFO 140144812640064] #quality_metric: host=algo-1, epoch=188, train loss <loss>=0.0210537985814\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:09 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:10 INFO 140144812640064] Epoch[189] Batch[0] avg_epoch_loss=0.138287\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=0.138286709785\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:11 INFO 140144812640064] Epoch[189] Batch[5] avg_epoch_loss=-0.005395\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:11 INFO 140144812640064] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=-0.00539548446735\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:11 INFO 140144812640064] Epoch[189] Batch [5]#011Speed: 176.16 samples/sec#011loss=-0.005395\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:13 INFO 140144812640064] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4215.826034545898, \"sum\": 4215.826034545898, \"min\": 4215.826034545898}}, \"EndTime\": 1587306973.403113, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306969.186795}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:13 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=140.893479267 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:13 INFO 140144812640064] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:13 INFO 140144812640064] #quality_metric: host=algo-1, epoch=189, train loss <loss>=-0.0494099795818\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:13 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:14 INFO 140144812640064] Epoch[190] Batch[0] avg_epoch_loss=0.028660\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:14 INFO 140144812640064] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=0.0286599285901\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:16 INFO 140144812640064] Epoch[190] Batch[5] avg_epoch_loss=-0.019389\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:16 INFO 140144812640064] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=-0.0193894846986\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:16 INFO 140144812640064] Epoch[190] Batch [5]#011Speed: 176.44 samples/sec#011loss=-0.019389\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:17 INFO 140144812640064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4215.512990951538, \"sum\": 4215.512990951538, \"min\": 4215.512990951538}}, \"EndTime\": 1587306977.619225, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306973.403197}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:17 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=151.815583135 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:17 INFO 140144812640064] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=190, train loss <loss>=0.00504126381129\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:17 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:18 INFO 140144812640064] Epoch[191] Batch[0] avg_epoch_loss=0.132309\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:18 INFO 140144812640064] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=0.132309302688\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:20 INFO 140144812640064] Epoch[191] Batch[5] avg_epoch_loss=0.037400\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:20 INFO 140144812640064] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=0.0374001227319\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:20 INFO 140144812640064] Epoch[191] Batch [5]#011Speed: 177.39 samples/sec#011loss=0.037400\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:21 INFO 140144812640064] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4300.992965698242, \"sum\": 4300.992965698242, \"min\": 4300.992965698242}}, \"EndTime\": 1587306981.920775, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306977.61931}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:21 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.403645296 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:21 INFO 140144812640064] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=191, train loss <loss>=-0.0232348486781\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:21 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:22 INFO 140144812640064] Epoch[192] Batch[0] avg_epoch_loss=-0.173579\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:22 INFO 140144812640064] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=-0.17357930541\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:24 INFO 140144812640064] Epoch[192] Batch[5] avg_epoch_loss=-0.132231\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:24 INFO 140144812640064] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=-0.132231451571\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:24 INFO 140144812640064] Epoch[192] Batch [5]#011Speed: 174.79 samples/sec#011loss=-0.132231\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:26 INFO 140144812640064] Epoch[192] Batch[10] avg_epoch_loss=-0.062233\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=0.0217656448483\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:26 INFO 140144812640064] Epoch[192] Batch [10]#011Speed: 172.35 samples/sec#011loss=0.021766\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:26 INFO 140144812640064] processed a total of 700 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4675.468921661377, \"sum\": 4675.468921661377, \"min\": 4675.468921661377}}, \"EndTime\": 1587306986.596759, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306981.920857}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:26 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.713953769 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:26 INFO 140144812640064] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=192, train loss <loss>=-0.0622327713804\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:26 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:27 INFO 140144812640064] Epoch[193] Batch[0] avg_epoch_loss=-0.221196\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:27 INFO 140144812640064] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=-0.221196100116\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:29 INFO 140144812640064] Epoch[193] Batch[5] avg_epoch_loss=-0.132646\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:29 INFO 140144812640064] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=-0.132645810954\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:29 INFO 140144812640064] Epoch[193] Batch [5]#011Speed: 175.61 samples/sec#011loss=-0.132646\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:30 INFO 140144812640064] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4243.614912033081, \"sum\": 4243.614912033081, \"min\": 4243.614912033081}}, \"EndTime\": 1587306990.841016, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306986.596839}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:30 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.396981631 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:30 INFO 140144812640064] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:30 INFO 140144812640064] #quality_metric: host=algo-1, epoch=193, train loss <loss>=-0.0844442596659\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:30 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:31 INFO 140144812640064] Epoch[194] Batch[0] avg_epoch_loss=-0.079391\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:31 INFO 140144812640064] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=-0.0793906897306\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:33 INFO 140144812640064] Epoch[194] Batch[5] avg_epoch_loss=-0.191860\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:33 INFO 140144812640064] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=-0.191859897226\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:33 INFO 140144812640064] Epoch[194] Batch [5]#011Speed: 171.53 samples/sec#011loss=-0.191860\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:35 INFO 140144812640064] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4261.702060699463, \"sum\": 4261.702060699463, \"min\": 4261.702060699463}}, \"EndTime\": 1587306995.103271, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306990.84109}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:35 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.181610156 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:35 INFO 140144812640064] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:35 INFO 140144812640064] #quality_metric: host=algo-1, epoch=194, train loss <loss>=-0.186219979078\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:35 INFO 140144812640064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:35 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/state_07857d96-ba63-49c1-94ef-7c3c98ee68cf-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 62.68000602722168, \"sum\": 62.68000602722168, \"min\": 62.68000602722168}}, \"EndTime\": 1587306995.166729, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306995.103349}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:36 INFO 140144812640064] Epoch[195] Batch[0] avg_epoch_loss=0.268013\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:36 INFO 140144812640064] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=0.268013060093\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:37 INFO 140144812640064] Epoch[195] Batch[5] avg_epoch_loss=0.042852\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:37 INFO 140144812640064] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=0.0428523868322\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:37 INFO 140144812640064] Epoch[195] Batch [5]#011Speed: 176.67 samples/sec#011loss=0.042852\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:39 INFO 140144812640064] Epoch[195] Batch[10] avg_epoch_loss=-0.043617\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=-0.14738008678\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:39 INFO 140144812640064] Epoch[195] Batch [10]#011Speed: 175.70 samples/sec#011loss=-0.147380\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:39 INFO 140144812640064] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4594.996213912964, \"sum\": 4594.996213912964, \"min\": 4594.996213912964}}, \"EndTime\": 1587306999.761834, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306995.166787}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:39 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.019015946 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:39 INFO 140144812640064] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=195, train loss <loss>=-0.043616919355\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:39 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:40 INFO 140144812640064] Epoch[196] Batch[0] avg_epoch_loss=-0.120902\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=-0.120901852846\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:42 INFO 140144812640064] Epoch[196] Batch[5] avg_epoch_loss=-0.160498\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=-0.160497790979\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:42 INFO 140144812640064] Epoch[196] Batch [5]#011Speed: 173.73 samples/sec#011loss=-0.160498\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:43 INFO 140144812640064] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4219.966173171997, \"sum\": 4219.966173171997, \"min\": 4219.966173171997}}, \"EndTime\": 1587307003.982407, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587306999.76193}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:43 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.836610577 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:43 INFO 140144812640064] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=196, train loss <loss>=-0.101725082193\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:43 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:44 INFO 140144812640064] Epoch[197] Batch[0] avg_epoch_loss=0.368865\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:44 INFO 140144812640064] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=0.36886459589\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:46 INFO 140144812640064] Epoch[197] Batch[5] avg_epoch_loss=0.320258\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:46 INFO 140144812640064] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=0.320257549485\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:46 INFO 140144812640064] Epoch[197] Batch [5]#011Speed: 173.49 samples/sec#011loss=0.320258\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:48 INFO 140144812640064] Epoch[197] Batch[10] avg_epoch_loss=0.284509\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=0.241609752178\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:48 INFO 140144812640064] Epoch[197] Batch [10]#011Speed: 177.89 samples/sec#011loss=0.241610\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:48 INFO 140144812640064] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4586.6758823394775, \"sum\": 4586.6758823394775, \"min\": 4586.6758823394775}}, \"EndTime\": 1587307008.569706, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307003.982472}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:48 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.967200369 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:48 INFO 140144812640064] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=197, train loss <loss>=0.284508550709\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:48 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:49 INFO 140144812640064] Epoch[198] Batch[0] avg_epoch_loss=0.172610\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:49 INFO 140144812640064] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=0.172609627247\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:51 INFO 140144812640064] Epoch[198] Batch[5] avg_epoch_loss=0.128363\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:51 INFO 140144812640064] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=0.12836312782\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:51 INFO 140144812640064] Epoch[198] Batch [5]#011Speed: 175.81 samples/sec#011loss=0.128363\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:53 INFO 140144812640064] Epoch[198] Batch[10] avg_epoch_loss=0.058734\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=-0.0248219716363\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:53 INFO 140144812640064] Epoch[198] Batch [10]#011Speed: 176.47 samples/sec#011loss=-0.024822\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:53 INFO 140144812640064] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4591.050148010254, \"sum\": 4591.050148010254, \"min\": 4591.050148010254}}, \"EndTime\": 1587307013.161324, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307008.569786}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:53 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.447318182 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:53 INFO 140144812640064] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=198, train loss <loss>=0.0587335371582\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:53 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:54 INFO 140144812640064] Epoch[199] Batch[0] avg_epoch_loss=0.151037\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:54 INFO 140144812640064] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=0.151036843657\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:55 INFO 140144812640064] Epoch[199] Batch[5] avg_epoch_loss=0.096309\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:55 INFO 140144812640064] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=0.0963092880944\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:55 INFO 140144812640064] Epoch[199] Batch [5]#011Speed: 176.09 samples/sec#011loss=0.096309\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:57 INFO 140144812640064] Epoch[199] Batch[10] avg_epoch_loss=0.035875\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:57 INFO 140144812640064] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=-0.0366455748677\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:57 INFO 140144812640064] Epoch[199] Batch [10]#011Speed: 177.94 samples/sec#011loss=-0.036646\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:57 INFO 140144812640064] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4583.3728313446045, \"sum\": 4583.3728313446045, \"min\": 4583.3728313446045}}, \"EndTime\": 1587307017.745311, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307013.161407}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:57 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.122480609 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:57 INFO 140144812640064] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:57 INFO 140144812640064] #quality_metric: host=algo-1, epoch=199, train loss <loss>=0.0358752594753\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:57 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:58 INFO 140144812640064] Epoch[200] Batch[0] avg_epoch_loss=-0.001704\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:36:58 INFO 140144812640064] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=-0.00170427421108\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:00 INFO 140144812640064] Epoch[200] Batch[5] avg_epoch_loss=0.005127\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:00 INFO 140144812640064] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=0.00512708770111\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:00 INFO 140144812640064] Epoch[200] Batch [5]#011Speed: 176.12 samples/sec#011loss=0.005127\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:01 INFO 140144812640064] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4229.480981826782, \"sum\": 4229.480981826782, \"min\": 4229.480981826782}}, \"EndTime\": 1587307021.975349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307017.74539}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:01 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.113381054 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:01 INFO 140144812640064] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:01 INFO 140144812640064] #quality_metric: host=algo-1, epoch=200, train loss <loss>=-0.0415786498226\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:01 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:02 INFO 140144812640064] Epoch[201] Batch[0] avg_epoch_loss=-0.234401\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=-0.234401375055\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:04 INFO 140144812640064] Epoch[201] Batch[5] avg_epoch_loss=-0.182586\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=-0.18258604221\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:04 INFO 140144812640064] Epoch[201] Batch [5]#011Speed: 170.07 samples/sec#011loss=-0.182586\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:06 INFO 140144812640064] Epoch[201] Batch[10] avg_epoch_loss=-0.098932\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:06 INFO 140144812640064] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=0.00145368762314\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:06 INFO 140144812640064] Epoch[201] Batch [10]#011Speed: 177.08 samples/sec#011loss=0.001454\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:06 INFO 140144812640064] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4673.555135726929, \"sum\": 4673.555135726929, \"min\": 4673.555135726929}}, \"EndTime\": 1587307026.649402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307021.975423}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:06 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=141.430637447 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:06 INFO 140144812640064] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:06 INFO 140144812640064] #quality_metric: host=algo-1, epoch=201, train loss <loss>=-0.0989316195588\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:06 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:07 INFO 140144812640064] Epoch[202] Batch[0] avg_epoch_loss=0.708287\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:07 INFO 140144812640064] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=0.708286941051\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:09 INFO 140144812640064] Epoch[202] Batch[5] avg_epoch_loss=0.459599\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:09 INFO 140144812640064] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=0.459599216779\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:09 INFO 140144812640064] Epoch[202] Batch [5]#011Speed: 172.38 samples/sec#011loss=0.459599\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:10 INFO 140144812640064] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4314.01801109314, \"sum\": 4314.01801109314, \"min\": 4314.01801109314}}, \"EndTime\": 1587307030.963938, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307026.64948}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:10 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=146.495594218 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:10 INFO 140144812640064] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=202, train loss <loss>=0.408570191264\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:10 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:11 INFO 140144812640064] Epoch[203] Batch[0] avg_epoch_loss=0.445992\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:11 INFO 140144812640064] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=0.445992052555\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:13 INFO 140144812640064] Epoch[203] Batch[5] avg_epoch_loss=0.279195\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:13 INFO 140144812640064] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=0.279195060333\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:13 INFO 140144812640064] Epoch[203] Batch [5]#011Speed: 172.54 samples/sec#011loss=0.279195\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:15 INFO 140144812640064] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4277.005195617676, \"sum\": 4277.005195617676, \"min\": 4277.005195617676}}, \"EndTime\": 1587307035.241458, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307030.96401}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:15 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.995813744 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:15 INFO 140144812640064] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:15 INFO 140144812640064] #quality_metric: host=algo-1, epoch=203, train loss <loss>=0.202885955572\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:15 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:16 INFO 140144812640064] Epoch[204] Batch[0] avg_epoch_loss=-0.046240\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:16 INFO 140144812640064] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=-0.0462400354445\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:17 INFO 140144812640064] Epoch[204] Batch[5] avg_epoch_loss=-0.017211\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=-0.0172108226301\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:17 INFO 140144812640064] Epoch[204] Batch [5]#011Speed: 177.77 samples/sec#011loss=-0.017211\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:19 INFO 140144812640064] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4235.832929611206, \"sum\": 4235.832929611206, \"min\": 4235.832929611206}}, \"EndTime\": 1587307039.4779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307035.241559}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:19 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=150.143593 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:19 INFO 140144812640064] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=204, train loss <loss>=-0.0513921089936\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:19 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:20 INFO 140144812640064] Epoch[205] Batch[0] avg_epoch_loss=-0.210078\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:20 INFO 140144812640064] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=-0.210078135133\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:22 INFO 140144812640064] Epoch[205] Batch[5] avg_epoch_loss=-0.071568\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:22 INFO 140144812640064] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=-0.0715675218186\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:22 INFO 140144812640064] Epoch[205] Batch [5]#011Speed: 174.37 samples/sec#011loss=-0.071568\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:24 INFO 140144812640064] Epoch[205] Batch[10] avg_epoch_loss=-0.093157\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:24 INFO 140144812640064] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=-0.119064034149\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:24 INFO 140144812640064] Epoch[205] Batch [10]#011Speed: 175.04 samples/sec#011loss=-0.119064\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:24 INFO 140144812640064] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4659.019947052002, \"sum\": 4659.019947052002, \"min\": 4659.019947052002}}, \"EndTime\": 1587307044.137422, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307039.477974}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:24 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.725511042 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:24 INFO 140144812640064] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:24 INFO 140144812640064] #quality_metric: host=algo-1, epoch=205, train loss <loss>=-0.0931568456052\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:24 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:25 INFO 140144812640064] Epoch[206] Batch[0] avg_epoch_loss=-0.095538\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:25 INFO 140144812640064] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=-0.0955384224653\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:26 INFO 140144812640064] Epoch[206] Batch[5] avg_epoch_loss=-0.022537\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=-0.0225366652012\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:26 INFO 140144812640064] Epoch[206] Batch [5]#011Speed: 176.95 samples/sec#011loss=-0.022537\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:28 INFO 140144812640064] Epoch[206] Batch[10] avg_epoch_loss=-0.087167\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=206, batch=10 train loss <loss>=-0.164722711593\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:28 INFO 140144812640064] Epoch[206] Batch [10]#011Speed: 172.44 samples/sec#011loss=-0.164723\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:28 INFO 140144812640064] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4617.532014846802, \"sum\": 4617.532014846802, \"min\": 4617.532014846802}}, \"EndTime\": 1587307048.755509, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307044.137503}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:28 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=139.031793506 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:28 INFO 140144812640064] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:28 INFO 140144812640064] #quality_metric: host=algo-1, epoch=206, train loss <loss>=-0.0871666862883\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:28 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:29 INFO 140144812640064] Epoch[207] Batch[0] avg_epoch_loss=0.158726\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:29 INFO 140144812640064] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=0.158726036549\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:31 INFO 140144812640064] Epoch[207] Batch[5] avg_epoch_loss=0.027742\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:31 INFO 140144812640064] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=0.027742212483\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:31 INFO 140144812640064] Epoch[207] Batch [5]#011Speed: 174.82 samples/sec#011loss=0.027742\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:33 INFO 140144812640064] Epoch[207] Batch[10] avg_epoch_loss=-0.005967\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:33 INFO 140144812640064] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=-0.046418133378\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:33 INFO 140144812640064] Epoch[207] Batch [10]#011Speed: 170.31 samples/sec#011loss=-0.046418\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:33 INFO 140144812640064] processed a total of 702 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4696.0289478302, \"sum\": 4696.0289478302, \"min\": 4696.0289478302}}, \"EndTime\": 1587307053.452156, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307048.755573}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:33 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=149.483679334 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:33 INFO 140144812640064] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:33 INFO 140144812640064] #quality_metric: host=algo-1, epoch=207, train loss <loss>=-0.00596703563563\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:33 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:34 INFO 140144812640064] Epoch[208] Batch[0] avg_epoch_loss=-0.105904\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:34 INFO 140144812640064] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=-0.105903789401\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:36 INFO 140144812640064] Epoch[208] Batch[5] avg_epoch_loss=-0.162877\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:36 INFO 140144812640064] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=-0.162877246737\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:36 INFO 140144812640064] Epoch[208] Batch [5]#011Speed: 174.25 samples/sec#011loss=-0.162877\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:38 INFO 140144812640064] Epoch[208] Batch[10] avg_epoch_loss=-0.139241\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:38 INFO 140144812640064] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=-0.110877487063\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:38 INFO 140144812640064] Epoch[208] Batch [10]#011Speed: 170.67 samples/sec#011loss=-0.110877\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:38 INFO 140144812640064] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4719.883918762207, \"sum\": 4719.883918762207, \"min\": 4719.883918762207}}, \"EndTime\": 1587307058.172708, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307053.452249}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:38 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=137.711717493 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:38 INFO 140144812640064] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:38 INFO 140144812640064] #quality_metric: host=algo-1, epoch=208, train loss <loss>=-0.13924099234\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:38 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:39 INFO 140144812640064] Epoch[209] Batch[0] avg_epoch_loss=0.424115\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:39 INFO 140144812640064] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=0.424114763737\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:40 INFO 140144812640064] Epoch[209] Batch[5] avg_epoch_loss=0.557937\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:40 INFO 140144812640064] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=0.557936873287\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:40 INFO 140144812640064] Epoch[209] Batch [5]#011Speed: 175.18 samples/sec#011loss=0.557937\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:42 INFO 140144812640064] Epoch[209] Batch[10] avg_epoch_loss=0.452139\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=0.325181558728\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:42 INFO 140144812640064] Epoch[209] Batch [10]#011Speed: 177.77 samples/sec#011loss=0.325182\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:42 INFO 140144812640064] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4607.893943786621, \"sum\": 4607.893943786621, \"min\": 4607.893943786621}}, \"EndTime\": 1587307062.78118, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307058.172787}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:42 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.66313373 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:42 INFO 140144812640064] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:42 INFO 140144812640064] #quality_metric: host=algo-1, epoch=209, train loss <loss>=0.452139003033\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:42 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:43 INFO 140144812640064] Epoch[210] Batch[0] avg_epoch_loss=0.639949\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:43 INFO 140144812640064] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=0.639948606491\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:45 INFO 140144812640064] Epoch[210] Batch[5] avg_epoch_loss=0.441597\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:45 INFO 140144812640064] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=0.441596657038\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:45 INFO 140144812640064] Epoch[210] Batch [5]#011Speed: 175.74 samples/sec#011loss=0.441597\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:47 INFO 140144812640064] Epoch[210] Batch[10] avg_epoch_loss=0.325408\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:47 INFO 140144812640064] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=0.185982298851\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:47 INFO 140144812640064] Epoch[210] Batch [10]#011Speed: 176.38 samples/sec#011loss=0.185982\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:47 INFO 140144812640064] processed a total of 704 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4639.832019805908, \"sum\": 4639.832019805908, \"min\": 4639.832019805908}}, \"EndTime\": 1587307067.421685, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307062.781249}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:47 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=151.725904234 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:47 INFO 140144812640064] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:47 INFO 140144812640064] #quality_metric: host=algo-1, epoch=210, train loss <loss>=0.325408312407\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:47 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:48 INFO 140144812640064] Epoch[211] Batch[0] avg_epoch_loss=0.201848\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:48 INFO 140144812640064] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=0.201848477125\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:50 INFO 140144812640064] Epoch[211] Batch[5] avg_epoch_loss=0.008629\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:50 INFO 140144812640064] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=0.00862937606871\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:50 INFO 140144812640064] Epoch[211] Batch [5]#011Speed: 172.73 samples/sec#011loss=0.008629\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:52 INFO 140144812640064] Epoch[211] Batch[10] avg_epoch_loss=-0.093130\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:52 INFO 140144812640064] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=-0.215242001414\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:52 INFO 140144812640064] Epoch[211] Batch [10]#011Speed: 176.74 samples/sec#011loss=-0.215242\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:52 INFO 140144812640064] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4696.7761516571045, \"sum\": 4696.7761516571045, \"min\": 4696.7761516571045}}, \"EndTime\": 1587307072.118995, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307067.421763}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:52 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=140.73138811 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:52 INFO 140144812640064] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:52 INFO 140144812640064] #quality_metric: host=algo-1, epoch=211, train loss <loss>=-0.093130340969\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:52 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:53 INFO 140144812640064] Epoch[212] Batch[0] avg_epoch_loss=0.392985\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:53 INFO 140144812640064] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=0.392985254526\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:54 INFO 140144812640064] Epoch[212] Batch[5] avg_epoch_loss=0.239340\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:54 INFO 140144812640064] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=0.239339709282\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:54 INFO 140144812640064] Epoch[212] Batch [5]#011Speed: 173.58 samples/sec#011loss=0.239340\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:56 INFO 140144812640064] Epoch[212] Batch[10] avg_epoch_loss=0.132135\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:56 INFO 140144812640064] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=0.00349021963775\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:56 INFO 140144812640064] Epoch[212] Batch [10]#011Speed: 178.12 samples/sec#011loss=0.003490\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:56 INFO 140144812640064] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4675.992965698242, \"sum\": 4675.992965698242, \"min\": 4675.992965698242}}, \"EndTime\": 1587307076.795481, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307072.119074}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:56 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=137.935395279 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:56 INFO 140144812640064] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:56 INFO 140144812640064] #quality_metric: host=algo-1, epoch=212, train loss <loss>=0.132135395807\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:56 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:57 INFO 140144812640064] Epoch[213] Batch[0] avg_epoch_loss=-0.021631\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:57 INFO 140144812640064] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=-0.0216313879937\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:59 INFO 140144812640064] Epoch[213] Batch[5] avg_epoch_loss=-0.026676\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:59 INFO 140144812640064] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=-0.0266755390912\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:37:59 INFO 140144812640064] Epoch[213] Batch [5]#011Speed: 173.51 samples/sec#011loss=-0.026676\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:01 INFO 140144812640064] Epoch[213] Batch[10] avg_epoch_loss=-0.109216\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:01 INFO 140144812640064] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=-0.208263725042\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:01 INFO 140144812640064] Epoch[213] Batch [10]#011Speed: 169.79 samples/sec#011loss=-0.208264\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:01 INFO 140144812640064] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4710.960865020752, \"sum\": 4710.960865020752, \"min\": 4710.960865020752}}, \"EndTime\": 1587307081.50689, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307076.795555}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:01 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.430161989 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:01 INFO 140144812640064] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:01 INFO 140144812640064] #quality_metric: host=algo-1, epoch=213, train loss <loss>=-0.109215623614\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:01 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:02 INFO 140144812640064] Epoch[214] Batch[0] avg_epoch_loss=0.117836\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:02 INFO 140144812640064] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=0.117835924029\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:04 INFO 140144812640064] Epoch[214] Batch[5] avg_epoch_loss=0.212608\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:04 INFO 140144812640064] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=0.212607741045\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:04 INFO 140144812640064] Epoch[214] Batch [5]#011Speed: 165.80 samples/sec#011loss=0.212608\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:05 INFO 140144812640064] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4337.920904159546, \"sum\": 4337.920904159546, \"min\": 4337.920904159546}}, \"EndTime\": 1587307085.845425, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307081.506971}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:05 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=145.687982611 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:05 INFO 140144812640064] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:05 INFO 140144812640064] #quality_metric: host=algo-1, epoch=214, train loss <loss>=0.120073253475\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:05 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:06 INFO 140144812640064] Epoch[215] Batch[0] avg_epoch_loss=-0.048855\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:06 INFO 140144812640064] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=-0.0488549396396\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:08 INFO 140144812640064] Epoch[215] Batch[5] avg_epoch_loss=-0.135542\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:08 INFO 140144812640064] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=-0.135541514804\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:08 INFO 140144812640064] Epoch[215] Batch [5]#011Speed: 176.53 samples/sec#011loss=-0.135542\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:10 INFO 140144812640064] processed a total of 589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4289.318084716797, \"sum\": 4289.318084716797, \"min\": 4289.318084716797}}, \"EndTime\": 1587307090.135281, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307085.845503}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:10 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=137.314185735 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:10 INFO 140144812640064] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:10 INFO 140144812640064] #quality_metric: host=algo-1, epoch=215, train loss <loss>=-0.152303845529\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:10 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:11 INFO 140144812640064] Epoch[216] Batch[0] avg_epoch_loss=0.260624\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:11 INFO 140144812640064] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=0.260624170303\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:12 INFO 140144812640064] Epoch[216] Batch[5] avg_epoch_loss=0.147784\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:12 INFO 140144812640064] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=0.147784088428\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:12 INFO 140144812640064] Epoch[216] Batch [5]#011Speed: 176.10 samples/sec#011loss=0.147784\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:14 INFO 140144812640064] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4351.3970375061035, \"sum\": 4351.3970375061035, \"min\": 4351.3970375061035}}, \"EndTime\": 1587307094.487196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307090.135358}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:14 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=142.708916824 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:14 INFO 140144812640064] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:14 INFO 140144812640064] #quality_metric: host=algo-1, epoch=216, train loss <loss>=0.100619972753\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:14 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:15 INFO 140144812640064] Epoch[217] Batch[0] avg_epoch_loss=-0.092904\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:15 INFO 140144812640064] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=-0.092903777957\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:17 INFO 140144812640064] Epoch[217] Batch[5] avg_epoch_loss=-0.129725\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:17 INFO 140144812640064] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=-0.129724630465\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:17 INFO 140144812640064] Epoch[217] Batch [5]#011Speed: 174.75 samples/sec#011loss=-0.129725\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:19 INFO 140144812640064] Epoch[217] Batch[10] avg_epoch_loss=-0.114813\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=-0.0969188421965\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:19 INFO 140144812640064] Epoch[217] Batch [10]#011Speed: 176.86 samples/sec#011loss=-0.096919\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:19 INFO 140144812640064] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4598.2489585876465, \"sum\": 4598.2489585876465, \"min\": 4598.2489585876465}}, \"EndTime\": 1587307099.086277, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307094.487275}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:19 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=143.094121679 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:19 INFO 140144812640064] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:19 INFO 140144812640064] #quality_metric: host=algo-1, epoch=217, train loss <loss>=-0.114812908525\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:19 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:20 INFO 140144812640064] Epoch[218] Batch[0] avg_epoch_loss=1.897799\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:20 INFO 140144812640064] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=1.89779889584\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:21 INFO 140144812640064] Epoch[218] Batch[5] avg_epoch_loss=1.321838\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:21 INFO 140144812640064] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=1.32183809082\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:21 INFO 140144812640064] Epoch[218] Batch [5]#011Speed: 174.08 samples/sec#011loss=1.321838\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:23 INFO 140144812640064] Epoch[218] Batch[10] avg_epoch_loss=1.050790\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:23 INFO 140144812640064] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=0.725531792641\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:23 INFO 140144812640064] Epoch[218] Batch [10]#011Speed: 175.80 samples/sec#011loss=0.725532\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:23 INFO 140144812640064] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4623.673915863037, \"sum\": 4623.673915863037, \"min\": 4623.673915863037}}, \"EndTime\": 1587307103.710518, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307099.086361}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:23 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=144.470257962 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:23 INFO 140144812640064] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:23 INFO 140144812640064] #quality_metric: host=algo-1, epoch=218, train loss <loss>=1.05078977346\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:23 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:24 INFO 140144812640064] Epoch[219] Batch[0] avg_epoch_loss=0.798839\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:24 INFO 140144812640064] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=0.798838555813\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:26 INFO 140144812640064] Epoch[219] Batch[5] avg_epoch_loss=0.738025\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:26 INFO 140144812640064] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=0.738025248051\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:26 INFO 140144812640064] Epoch[219] Batch [5]#011Speed: 174.71 samples/sec#011loss=0.738025\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:27 INFO 140144812640064] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4280.12490272522, \"sum\": 4280.12490272522, \"min\": 4280.12490272522}}, \"EndTime\": 1587307107.991193, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307103.710596}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:27 INFO 140144812640064] #throughput_metric: host=algo-1, train throughput=147.188563637 records/second\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:27 INFO 140144812640064] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:27 INFO 140144812640064] #quality_metric: host=algo-1, epoch=219, train loss <loss>=0.675369793177\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:27 INFO 140144812640064] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:27 INFO 140144812640064] Loading parameters from best epoch (194)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 25.273799896240234, \"sum\": 25.273799896240234, \"min\": 25.273799896240234}}, \"EndTime\": 1587307108.017175, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307107.991253}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 INFO 140144812640064] stopping training now\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 INFO 140144812640064] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 INFO 140144812640064] Final loss: -0.186219979078 (occurred at epoch 194)\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 INFO 140144812640064] #quality_metric: host=algo-1, train final_loss <loss>=-0.186219979078\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 INFO 140144812640064] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 WARNING 140144812640064] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 INFO 140144812640064] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 660.999059677124, \"sum\": 660.999059677124, \"min\": 660.999059677124}}, \"EndTime\": 1587307108.67899, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307108.017245}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 INFO 140144812640064] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 927.0291328430176, \"sum\": 927.0291328430176, \"min\": 927.0291328430176}}, \"EndTime\": 1587307108.944995, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307108.679055}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 INFO 140144812640064] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 INFO 140144812640064] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 49.479007720947266, \"sum\": 49.479007720947266, \"min\": 49.479007720947266}}, \"EndTime\": 1587307108.99461, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307108.94508}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 INFO 140144812640064] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[04/19/2020 14:38:28 INFO 140144812640064] No test data passed, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 987569.3080425262, \"sum\": 987569.3080425262, \"min\": 987569.3080425262}, \"setuptime\": {\"count\": 1, \"max\": 8.385896682739258, \"sum\": 8.385896682739258, \"min\": 8.385896682739258}}, \"EndTime\": 1587307109.049666, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587307108.994666}\n",
      "\u001b[0m\n",
      "Training seconds: 1036\n",
      "Billable seconds: 309\n",
      "Managed Spot Training savings: 70.2%\n"
     ]
    }
   ],
   "source": [
    "estimator_sj_training_job = fit_model(submission_train_path_sj,\n",
    "                                      None,\n",
    "                                      f'{prefix}-{tag}-sj',\n",
    "                                      {'prediction_length': str(PREDICTION_LENGTH['sj'])})\n",
    "estimator_iq_training_job = fit_model(submission_train_path_iq,\n",
    "                                      None,\n",
    "                                      f'{prefix}-{tag}-iq',\n",
    "                                      {'prediction_length': str(PREDICTION_LENGTH['iq']),\n",
    "                                      'num_cells': '64',\n",
    "                                      'context_length': '32'})\n",
    "\n",
    "estimator_sj = Estimator.attach(estimator_sj_training_job)\n",
    "estimator_iq = Estimator.attach(estimator_iq_training_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer created from dengai-only-target-optim-sj-2020-04-19-14-19-13-146\n",
      "> Transform job dengai-only-target-optim-sj-2020-04-19--2020-04-19-15-00-54-492 created with data: s3://sagemaker-eu-central-1-964501460451/dengai/2020-04-19--12-42-only-target-optim/pprocess_data/submission_test_pp_sj.json\n",
      "Transformer created from dengai-only-target-optim-iq-2020-04-19-14-19-13-332\n",
      "> Transform job dengai-only-target-optim-iq-2020-04-19--2020-04-19-15-00-55-024 created with data: s3://sagemaker-eu-central-1-964501460451/dengai/2020-04-19--12-42-only-target-optim/pprocess_data/submission_test_pp_iq.json\n",
      "......................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34mNo handlers could be found for logger \"root\"\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 INFO 140344906811200] Estimated memory required per model 102MB.\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 INFO 140344906811200] Estimated available memory 15078MB.\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 INFO 140344906811200] Estimated maximum number of workers for the available memory is 146.\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 INFO 140344906811200] Using 4 workers\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 INFO 140344906811200] loading entry points\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 INFO 140344906811200] Prediction endpoint operating in batch mode\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 INFO 140344906811200] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 INFO 140344906811200] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 INFO 140344906811200] loaded model class model\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 WARNING 140344906811200] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 INFO 140344906811200] nvidia-smi took: 0.025239944458 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 INFO 140344906811200] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 INFO 140344906811200] Loading Config from /opt/ml/model/model_algo-1-config.json\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase1.time\": {\"count\": 1, \"max\": 1.6558170318603516, \"sum\": 1.6558170318603516, \"min\": 1.6558170318603516}}, \"EndTime\": 1587308666.303629, \"Dimensions\": {}, \"StartTime\": 1587308666.196994}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:26 INFO 140344906811200] Deserializing model parameters from /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[15:04:26] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202184.0/RHEL5_64/generic-flavor/src/src/engine/engine.cc:55: MXNet start using engine: NaiveEngine\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 497.79510498046875, \"sum\": 497.79510498046875, \"min\": 497.79510498046875}}, \"EndTime\": 1587308667.297514, \"Dimensions\": {}, \"StartTime\": 1587308666.303777}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase2.time\": {\"count\": 1, \"max\": 993.8549995422363, \"sum\": 993.8549995422363, \"min\": 993.8549995422363}}, \"EndTime\": 1587308667.297664, \"Dimensions\": {}, \"StartTime\": 1587308667.297627}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:27 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:27 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:27 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:27 +0000] [34] [INFO] Booting worker with pid: 34\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:27 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:27 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:27 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.04601478576660156, \"sum\": 0.04601478576660156, \"min\": 0.04601478576660156}}, \"EndTime\": 1587308680.075529, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587308667.342438}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.04601478576660156, \"sum\": 0.04601478576660156, \"min\": 0.04601478576660156}}, \"EndTime\": 1587308680.075529, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587308667.342438}\n",
      "\u001b[0m\n",
      "\u001b[32m2020-04-19T15:04:39.915:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.2532005310058594, \"sum\": 0.2532005310058594, \"min\": 0.2532005310058594}}, \"EndTime\": 1587308681.485661, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587308680.075712}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1587308681.485989, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587308681.485735}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.2532005310058594, \"sum\": 0.2532005310058594, \"min\": 0.2532005310058594}}, \"EndTime\": 1587308681.485661, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587308680.075712}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1587308681.485989, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587308681.485735}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34mNo handlers could be found for logger \"root\"\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 INFO 140713046116160] Estimated memory required per model 55MB.\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 INFO 140713046116160] Estimated available memory 15174MB.\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 INFO 140713046116160] Estimated maximum number of workers for the available memory is 275.\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 INFO 140713046116160] Using 4 workers\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 INFO 140713046116160] loading entry points\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 INFO 140713046116160] Prediction endpoint operating in batch mode\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 INFO 140713046116160] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 INFO 140713046116160] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 INFO 140713046116160] loaded model class model\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 WARNING 140713046116160] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 INFO 140713046116160] nvidia-smi took: 0.025249004364 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 INFO 140713046116160] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 INFO 140713046116160] Loading Config from /opt/ml/model/model_algo-1-config.json\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase1.time\": {\"count\": 1, \"max\": 1.561880111694336, \"sum\": 1.561880111694336, \"min\": 1.561880111694336}}, \"EndTime\": 1587308654.709215, \"Dimensions\": {}, \"StartTime\": 1587308654.615708}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/19/2020 15:04:14 INFO 140713046116160] Deserializing model parameters from /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[15:04:14] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202184.0/RHEL5_64/generic-flavor/src/src/engine/engine.cc:55: MXNet start using engine: NaiveEngine\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 305.1280975341797, \"sum\": 305.1280975341797, \"min\": 305.1280975341797}}, \"EndTime\": 1587308655.30174, \"Dimensions\": {}, \"StartTime\": 1587308654.709361}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase2.time\": {\"count\": 1, \"max\": 592.4949645996094, \"sum\": 592.4949645996094, \"min\": 592.4949645996094}}, \"EndTime\": 1587308655.301887, \"Dimensions\": {}, \"StartTime\": 1587308655.301852}\n",
      "\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35mNo handlers could be found for logger \"root\"\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 INFO 140713046116160] Estimated memory required per model 55MB.\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 INFO 140713046116160] Estimated available memory 15174MB.\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 INFO 140713046116160] Estimated maximum number of workers for the available memory is 275.\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 INFO 140713046116160] Using 4 workers\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 INFO 140713046116160] loading entry points\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 INFO 140713046116160] Prediction endpoint operating in batch mode\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 INFO 140713046116160] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 INFO 140713046116160] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 INFO 140713046116160] loaded model class model\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 WARNING 140713046116160] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 INFO 140713046116160] nvidia-smi took: 0.025249004364 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 INFO 140713046116160] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 INFO 140713046116160] Loading Config from /opt/ml/model/model_algo-1-config.json\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.deserialize_phase1.time\": {\"count\": 1, \"max\": 1.561880111694336, \"sum\": 1.561880111694336, \"min\": 1.561880111694336}}, \"EndTime\": 1587308654.709215, \"Dimensions\": {}, \"StartTime\": 1587308654.615708}\n",
      "\u001b[0m\n",
      "\u001b[35m[04/19/2020 15:04:14 INFO 140713046116160] Deserializing model parameters from /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[35m[15:04:14] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202184.0/RHEL5_64/generic-flavor/src/src/engine/engine.cc:55: MXNet start using engine: NaiveEngine\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 305.1280975341797, \"sum\": 305.1280975341797, \"min\": 305.1280975341797}}, \"EndTime\": 1587308655.30174, \"Dimensions\": {}, \"StartTime\": 1587308654.709361}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.deserialize_phase2.time\": {\"count\": 1, \"max\": 592.4949645996094, \"sum\": 592.4949645996094, \"min\": 592.4949645996094}}, \"EndTime\": 1587308655.301887, \"Dimensions\": {}, \"StartTime\": 1587308655.301852}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:15 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:15 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:15 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:15 +0000] [33] [INFO] Booting worker with pid: 33\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:15 +0000] [34] [INFO] Booting worker with pid: 34\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:15 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2020-04-19 15:04:15 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2020-04-19 15:04:15 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-04-19 15:04:15 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-04-19 15:04:15 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2020-04-19 15:04:15 +0000] [33] [INFO] Booting worker with pid: 33\u001b[0m\n",
      "\u001b[35m[2020-04-19 15:04:15 +0000] [34] [INFO] Booting worker with pid: 34\u001b[0m\n",
      "\u001b[35m[2020-04-19 15:04:15 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[35m[2020-04-19 15:04:15 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0438690185546875, \"sum\": 0.0438690185546875, \"min\": 0.0438690185546875}}, \"EndTime\": 1587308670.421422, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587308655.460307}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0438690185546875, \"sum\": 0.0438690185546875, \"min\": 0.0438690185546875}}, \"EndTime\": 1587308670.421422, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587308655.460307}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.1678466796875, \"sum\": 0.1678466796875, \"min\": 0.1678466796875}}, \"EndTime\": 1587308670.891153, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587308670.421576}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1587308670.891445, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587308670.891228}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.1678466796875, \"sum\": 0.1678466796875, \"min\": 0.1678466796875}}, \"EndTime\": 1587308670.891153, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587308670.421576}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1587308670.891445, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1587308670.891228}\n",
      "\u001b[0m\n",
      "\u001b[32m2020-04-19T15:04:30.281:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer_sj_job = batch_transform(estimator_sj, submission_test_path_sj)\n",
    "transformer_iq_job = batch_transform(estimator_iq, submission_test_path_iq)\n",
    "\n",
    "transformer_sj = Transformer.attach(transformer_sj_job).wait()\n",
    "transformer_iq = Transformer.attach(transformer_iq_job).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_sj = unjson_prediction(sagemaker.s3.S3Downloader.read_file(predictions_path(s3_batch_output_path, validation_path_sj)))\n",
    "predictions_iq = unjson_prediction(sagemaker.s3.S3Downloader.read_file(predictions_path(s3_batch_output_path, validation_path_iq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating output CSV for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(predictions_sj, predictions_iq, template_file='./data/input/submission_format.csv', output_dir='./data/submissions'):\n",
    "    submission = pd.read_csv(template_file)\n",
    "    submission.loc[submission.city=='iq', 'total_cases'] = predictions_iq['0.5'].tolist()\n",
    "    submission.loc[submission.city=='sj', 'total_cases'] = predictions_sj['0.5'].tolist()\n",
    "    submission['total_cases'] = np.maximum(0, submission['total_cases'].round().astype(int))\n",
    "    submission.to_csv(f'{output_dir}/submission_{model_version}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(predictions_sj, predictions_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_score = 30.1755\n",
    "\n",
    "submission_infos = {\n",
    "    'model_version': model_version,\n",
    "    'submission_score': submission_score\n",
    "}\n",
    "\n",
    "with open('./data/submissions.infos.csv', 'a+', newline='') as f:\n",
    "    w = csv.DictWriter(f, fieldnames=submission_infos)\n",
    "    if (f.tell()==0):\n",
    "        w.writeheader()\n",
    "    w.writerow(submission_infos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
